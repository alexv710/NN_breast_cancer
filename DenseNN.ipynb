{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation\n",
    "Currently AI is advancing in the field of healthcare to improve detection of malignant tumors, give treatment recommendations, engage patients and support in administrative activities (Davenport and Kalakota 2019). Our goal is to contribute to this field by applying a neural network with transfer learning on a dataset with the aim to detect malignant cells of breast cancer. \n",
    "\n",
    "According to Krebsliga Schweiz (2021), there are 6’250 new cases and 1’410 deaths associated with breast cancer in Switzerland every year. Early diagnosis and treatment are a key to increasing the 5-year survival rate of patients.  \n",
    "\n",
    "From a technical standpoint we want to investigate the performance differences between neural networks with and without transfer learning in the field of tumor detection.\n",
    "\n",
    "## Data\n",
    "\n",
    "We use the Kaggle dataset: Breast Histopathology Images, which contains 277’524 images that are classified whether the sample is positive or negative for Invasive Ductal Carcinoma (IDC). Therefore, we face a binary classification problem with this dataset. The sample dataset contains images scanned at 40x zoom that are prepared in 50 x 50-pixel patches.\n",
    "\n",
    "[Kaggle Dataset](https://www.kaggle.com/paultimothymooney/breast-histopathology-images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pickle\n",
    "import sklearn\n",
    "\n",
    "# used to access folder structures\n",
    "import os\n",
    "\n",
    "# used to open images\n",
    "import PIL\n",
    "\n",
    "# Graphs, visualizations\n",
    "import matplotlib.pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "import scipy\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.regularizers import l2\n",
    "# For Image Data Augmentation\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.optimizers import Adam, SGD\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for gpu support\n",
    "# Troubleshooting: \n",
    "# Python Version = 3.7.9\n",
    "# tensorflow Version = 2.3.0\n",
    "# tf.keras Version = 2.4.0\n",
    "\n",
    "# from platform import python_version\n",
    "# print(python_version())\n",
    "# print(tf.__version__)\n",
    "# print(tf.keras.__version__)\n",
    "\n",
    "# from tensorflow.python.client import device_lib\n",
    "# print(device_lib.list_local_devices())\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Data From Pickle file\n",
    "\n",
    "with open('y.pickle', 'rb') as f:\n",
    "    y_data = pickle.load(f)\n",
    "f.close()\n",
    "y_data\n",
    "\n",
    "with open('X.pickle', 'rb') as f:\n",
    "    X_data = pickle.load(f)\n",
    "f.close()\n",
    "type(X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_plot(history):\n",
    "    plt.plot(history.history['accuracy'], alpha=.6)\n",
    "    plt.plot(history.history['val_accuracy'], alpha=.6)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train_acc', 'val_acc'], loc='upper left')\n",
    "    return plt\n",
    "\n",
    "def loss_plot(history):\n",
    "    plt.plot(history.history['loss'][1:], alpha=.6)\n",
    "    plt.plot(history.history['val_loss'], alpha=.6)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train_loss', 'val_loss'], loc='upper left')\n",
    "    return plt\n",
    "def plot_prc(name, labels, predictions, **kwargs):\n",
    "    precision, recall, _ = sklearn.metrics.precision_recall_curve(labels, predictions)\n",
    "\n",
    "    plt.plot(precision, recall, label=name, linewidth=2, **kwargs)\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.grid(True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect('equal')\n",
    "def conf_matrix(model, x_test, y_test):\n",
    "    \n",
    "    y_pred = [1 * (x[0]>=0.5) for x in model.predict(x_test)]\n",
    "\n",
    "    matrix = sklearn.metrics.confusion_matrix(y_test, y_pred)\n",
    "    df_cm = pd.DataFrame(matrix, index = [i for i in ['No Cancer (actual)', 'Cancer (actual)']],\n",
    "                      columns = [i for i in ['predict No Cancer', 'predict Cancer']])\n",
    "    plt.figure(figsize = (10,7))\n",
    "    sn.heatmap(df_cm, annot=True, fmt='d')\n",
    "    return plt\n",
    "\n",
    "### Callbacks ###\n",
    "\n",
    "#Early stopping callback\n",
    "es = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=25, verbose=2,\n",
    "                                      mode='max', baseline=None, restore_best_weights=True)\n",
    "\n",
    "mcp_save = keras.callbacks.ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "\n",
    "#Learning Rate Annealer\n",
    "lrr = keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy',\n",
    "                       factor=.1,\n",
    "                       patience=9,\n",
    "                       min_lr=1e-4,\n",
    "                       verbose=2)\n",
    "\n",
    "def acc_df(histories):\n",
    "    columns = ['model size' ,'loss', 'accuracy', 'val_loss', 'val_accuracy']\n",
    "    df = pd.DataFrame(columns = columns)\n",
    "    for history in histories:\n",
    "    \n",
    "    # get the epoch with the highest validation accuracy for each history element\n",
    "        i = 0\n",
    "        index = 0\n",
    "        comp = 0\n",
    "        for val_acc in history.history['val_accuracy']:\n",
    "            if val_acc > comp:\n",
    "                comp = val_acc\n",
    "                i = index\n",
    "            index += 1\n",
    "\n",
    "        df_temp = pd.DataFrame([[history.model.name,\n",
    "                                  history.history['loss'][i],\n",
    "                                  history.history['accuracy'][i],\n",
    "                                  history.history['val_loss'][i],\n",
    "                                  history.history['val_accuracy'][i]]], \n",
    "                        columns = columns)\n",
    "        df = df.append(df_temp)\n",
    "\n",
    "    df = df.set_index('model size')\n",
    "\n",
    "    df = df.style.format({\n",
    "        'loss': '{:,.2f}'.format,\n",
    "        'accuracy': '{:,.2%}'.format,\n",
    "        'val_loss': '{:,.2f}'.format,\n",
    "        'val_accuracy': '{:,.2%}'.format,\n",
    "    })\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learnings\n",
    "* The data of positive and negative samples is unbalanced, where patients have more negative patches than positive ones\n",
    "* This could lead to an imbalanced result where we classify more patches as negative, which would be a severe mistake in cancer detection. A confusion matrix should be sufficient so verify this concern, when the model is trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(155412, 50, 50, 3) (155412,) 0.7156204154119373\n",
      "(83258, 50, 50, 3) (83258,) 0.7168440270004084\n",
      "(38854, 50, 50, 3) (38854,) 0.716502805373964\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(50, 50, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train-validation-test split\n",
    "\n",
    "# train test split for validation after training x_test is never touched or looked at during training\n",
    "x_train,x_test,y_train,y_test=train_test_split(np.asarray(X_data),np.asarray(y_data),test_size=.3, random_state=42)\n",
    "\n",
    "# train test split for validation during training\n",
    "x_train,x_val,y_train,y_val=train_test_split(x_train,y_train,test_size=.2, random_state=42)\n",
    "\n",
    "#Dimension of the kaggle dataset & percentage of negative patches\n",
    "print(x_train.shape,y_train.shape, 1-sum(y_train)/y_train.shape[0])\n",
    "print(x_test.shape,y_test.shape, 1-sum(y_test)/y_test.shape[0])\n",
    "print(x_val.shape,y_val.shape, 1-sum(y_val)/y_val.shape[0])\n",
    "\n",
    "input_shape=x_train.shape[1:]\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Neural Network \n",
    "\n",
    "As a first network we:\n",
    "- Flatten the input from the images\n",
    "- Use one hidden layer with 64 neurons and a sigmoid activation function\n",
    "- Use one sigmoid activation function for the ouput layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test different learning rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.5986 - accuracy: 0.7153 - val_loss: 0.5932 - val_accuracy: 0.7162\n",
      "Epoch 2/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5927 - accuracy: 0.7153 - val_loss: 0.5895 - val_accuracy: 0.7163\n",
      "Epoch 3/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5897 - accuracy: 0.7154 - val_loss: 0.5868 - val_accuracy: 0.7164\n",
      "Epoch 4/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5873 - accuracy: 0.7154 - val_loss: 0.5850 - val_accuracy: 0.7165\n",
      "Epoch 5/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5856 - accuracy: 0.7154 - val_loss: 0.5836 - val_accuracy: 0.7163\n",
      "Epoch 6/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5838 - accuracy: 0.7154 - val_loss: 0.5818 - val_accuracy: 0.7162\n",
      "Epoch 7/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5822 - accuracy: 0.7154 - val_loss: 0.5806 - val_accuracy: 0.7163\n",
      "Epoch 8/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5813 - accuracy: 0.7154 - val_loss: 0.5797 - val_accuracy: 0.7163\n",
      "Epoch 9/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5804 - accuracy: 0.7154 - val_loss: 0.5789 - val_accuracy: 0.7163\n",
      "Epoch 10/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5796 - accuracy: 0.7154 - val_loss: 0.5782 - val_accuracy: 0.7163\n",
      "Epoch 11/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5790 - accuracy: 0.7154 - val_loss: 0.5775 - val_accuracy: 0.7163\n",
      "Epoch 12/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5784 - accuracy: 0.7154 - val_loss: 0.5769 - val_accuracy: 0.7165\n",
      "Epoch 13/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5778 - accuracy: 0.7154 - val_loss: 0.5763 - val_accuracy: 0.7165\n",
      "Epoch 14/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5772 - accuracy: 0.7154 - val_loss: 0.5757 - val_accuracy: 0.7164\n",
      "Epoch 15/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5766 - accuracy: 0.7155 - val_loss: 0.5752 - val_accuracy: 0.7166\n",
      "Epoch 16/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5761 - accuracy: 0.7155 - val_loss: 0.5747 - val_accuracy: 0.7166\n",
      "Epoch 17/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5756 - accuracy: 0.7155 - val_loss: 0.5741 - val_accuracy: 0.7165\n",
      "Epoch 18/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5752 - accuracy: 0.7155 - val_loss: 0.5736 - val_accuracy: 0.7166\n",
      "Epoch 19/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5746 - accuracy: 0.7155 - val_loss: 0.5728 - val_accuracy: 0.7166\n",
      "Epoch 20/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5740 - accuracy: 0.7155 - val_loss: 0.5722 - val_accuracy: 0.7166\n",
      "Epoch 21/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5735 - accuracy: 0.7155 - val_loss: 0.5717 - val_accuracy: 0.7166\n",
      "Epoch 22/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5729 - accuracy: 0.7156 - val_loss: 0.5711 - val_accuracy: 0.7167\n",
      "Epoch 23/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5722 - accuracy: 0.7156 - val_loss: 0.5702 - val_accuracy: 0.7168\n",
      "Epoch 24/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5710 - accuracy: 0.7157 - val_loss: 0.5685 - val_accuracy: 0.7166\n",
      "Epoch 25/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5693 - accuracy: 0.7157 - val_loss: 0.5672 - val_accuracy: 0.7165\n",
      "Epoch 26/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5684 - accuracy: 0.7158 - val_loss: 0.5663 - val_accuracy: 0.7166\n",
      "Epoch 27/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5677 - accuracy: 0.7158 - val_loss: 0.5654 - val_accuracy: 0.7166\n",
      "Epoch 28/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5666 - accuracy: 0.7158 - val_loss: 0.5642 - val_accuracy: 0.7168\n",
      "Epoch 29/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5654 - accuracy: 0.7160 - val_loss: 0.5626 - val_accuracy: 0.7166\n",
      "Epoch 30/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5636 - accuracy: 0.7161 - val_loss: 0.5608 - val_accuracy: 0.7167\n",
      "Epoch 31/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5622 - accuracy: 0.7162 - val_loss: 0.5594 - val_accuracy: 0.7166\n",
      "Epoch 32/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5612 - accuracy: 0.7163 - val_loss: 0.5590 - val_accuracy: 0.7168\n",
      "Epoch 33/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5607 - accuracy: 0.7163 - val_loss: 0.5585 - val_accuracy: 0.7168\n",
      "Epoch 34/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5602 - accuracy: 0.7163 - val_loss: 0.5580 - val_accuracy: 0.7169\n",
      "Epoch 35/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5596 - accuracy: 0.7163 - val_loss: 0.5575 - val_accuracy: 0.7170\n",
      "Epoch 36/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5591 - accuracy: 0.7163 - val_loss: 0.5569 - val_accuracy: 0.7171\n",
      "Epoch 37/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5587 - accuracy: 0.7166 - val_loss: 0.5565 - val_accuracy: 0.7172\n",
      "Epoch 38/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5582 - accuracy: 0.7166 - val_loss: 0.5562 - val_accuracy: 0.7171\n",
      "Epoch 39/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5577 - accuracy: 0.7167 - val_loss: 0.5557 - val_accuracy: 0.7172\n",
      "Epoch 40/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5572 - accuracy: 0.7168 - val_loss: 0.5552 - val_accuracy: 0.7173\n",
      "Epoch 41/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5568 - accuracy: 0.7169 - val_loss: 0.5547 - val_accuracy: 0.7175\n",
      "Epoch 42/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5564 - accuracy: 0.7169 - val_loss: 0.5542 - val_accuracy: 0.7177\n",
      "Epoch 43/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5559 - accuracy: 0.7172 - val_loss: 0.5538 - val_accuracy: 0.7177\n",
      "Epoch 44/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5554 - accuracy: 0.7172 - val_loss: 0.5535 - val_accuracy: 0.7177\n",
      "Epoch 45/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5550 - accuracy: 0.7172 - val_loss: 0.5531 - val_accuracy: 0.7177\n",
      "Epoch 46/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5546 - accuracy: 0.7172 - val_loss: 0.5526 - val_accuracy: 0.7179\n",
      "Epoch 47/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5541 - accuracy: 0.7174 - val_loss: 0.5521 - val_accuracy: 0.7180\n",
      "Epoch 48/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5537 - accuracy: 0.7174 - val_loss: 0.5518 - val_accuracy: 0.7179\n",
      "Epoch 49/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5533 - accuracy: 0.7175 - val_loss: 0.5513 - val_accuracy: 0.7179\n",
      "Epoch 50/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5529 - accuracy: 0.7175 - val_loss: 0.5510 - val_accuracy: 0.7179\n",
      "Epoch 51/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5524 - accuracy: 0.7178 - val_loss: 0.5506 - val_accuracy: 0.7182\n",
      "Epoch 52/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5521 - accuracy: 0.7179 - val_loss: 0.5501 - val_accuracy: 0.7182\n",
      "Epoch 53/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5516 - accuracy: 0.7179 - val_loss: 0.5496 - val_accuracy: 0.7181\n",
      "Epoch 54/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5513 - accuracy: 0.7179 - val_loss: 0.5492 - val_accuracy: 0.7182\n",
      "Epoch 55/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5509 - accuracy: 0.7180 - val_loss: 0.5489 - val_accuracy: 0.7184\n",
      "Epoch 56/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5505 - accuracy: 0.7182 - val_loss: 0.5485 - val_accuracy: 0.7186\n",
      "Epoch 57/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5501 - accuracy: 0.7183 - val_loss: 0.5482 - val_accuracy: 0.7189\n",
      "Epoch 58/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5497 - accuracy: 0.7184 - val_loss: 0.5477 - val_accuracy: 0.7187\n",
      "Epoch 59/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5494 - accuracy: 0.7183 - val_loss: 0.5475 - val_accuracy: 0.7188\n",
      "Epoch 60/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5490 - accuracy: 0.7185 - val_loss: 0.5471 - val_accuracy: 0.7187\n",
      "Epoch 61/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5486 - accuracy: 0.7185 - val_loss: 0.5465 - val_accuracy: 0.7189\n",
      "Epoch 62/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5483 - accuracy: 0.7187 - val_loss: 0.5463 - val_accuracy: 0.7189\n",
      "Epoch 63/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5478 - accuracy: 0.7187 - val_loss: 0.5460 - val_accuracy: 0.7191\n",
      "Epoch 64/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5475 - accuracy: 0.7190 - val_loss: 0.5456 - val_accuracy: 0.7192\n",
      "Epoch 65/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5471 - accuracy: 0.7188 - val_loss: 0.5451 - val_accuracy: 0.7196\n",
      "Epoch 66/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5468 - accuracy: 0.7190 - val_loss: 0.5448 - val_accuracy: 0.7195\n",
      "Epoch 67/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5464 - accuracy: 0.7192 - val_loss: 0.5444 - val_accuracy: 0.7197\n",
      "Epoch 68/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5460 - accuracy: 0.7193 - val_loss: 0.5440 - val_accuracy: 0.7197\n",
      "Epoch 69/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5457 - accuracy: 0.7195 - val_loss: 0.5436 - val_accuracy: 0.7198\n",
      "Epoch 70/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5453 - accuracy: 0.7194 - val_loss: 0.5434 - val_accuracy: 0.7198\n",
      "Epoch 71/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5450 - accuracy: 0.7195 - val_loss: 0.5430 - val_accuracy: 0.7197\n",
      "Epoch 72/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5446 - accuracy: 0.7198 - val_loss: 0.5427 - val_accuracy: 0.7201\n",
      "Epoch 73/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5443 - accuracy: 0.7197 - val_loss: 0.5423 - val_accuracy: 0.7200\n",
      "Epoch 74/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5439 - accuracy: 0.7198 - val_loss: 0.5421 - val_accuracy: 0.7201\n",
      "Epoch 75/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5436 - accuracy: 0.7200 - val_loss: 0.5417 - val_accuracy: 0.7201\n",
      "Epoch 76/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5433 - accuracy: 0.7199 - val_loss: 0.5412 - val_accuracy: 0.7204\n",
      "Epoch 77/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5430 - accuracy: 0.7200 - val_loss: 0.5409 - val_accuracy: 0.7207\n",
      "Epoch 78/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5426 - accuracy: 0.7202 - val_loss: 0.5406 - val_accuracy: 0.7206\n",
      "Epoch 79/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5423 - accuracy: 0.7201 - val_loss: 0.5405 - val_accuracy: 0.7203\n",
      "Epoch 80/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5420 - accuracy: 0.7202 - val_loss: 0.5399 - val_accuracy: 0.7205\n",
      "Epoch 81/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5417 - accuracy: 0.7204 - val_loss: 0.5396 - val_accuracy: 0.7205\n",
      "Epoch 82/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5414 - accuracy: 0.7204 - val_loss: 0.5393 - val_accuracy: 0.7206\n",
      "Epoch 83/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5410 - accuracy: 0.7206 - val_loss: 0.5391 - val_accuracy: 0.7205\n",
      "Epoch 84/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5407 - accuracy: 0.7206 - val_loss: 0.5388 - val_accuracy: 0.7205\n",
      "Epoch 85/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5404 - accuracy: 0.7206 - val_loss: 0.5385 - val_accuracy: 0.7206\n",
      "Epoch 86/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5401 - accuracy: 0.7208 - val_loss: 0.5382 - val_accuracy: 0.7207\n",
      "Epoch 87/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5398 - accuracy: 0.7208 - val_loss: 0.5378 - val_accuracy: 0.7207\n",
      "Epoch 88/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5395 - accuracy: 0.7207 - val_loss: 0.5377 - val_accuracy: 0.7210\n",
      "Epoch 89/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5392 - accuracy: 0.7209 - val_loss: 0.5372 - val_accuracy: 0.7211\n",
      "Epoch 90/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5389 - accuracy: 0.7211 - val_loss: 0.5369 - val_accuracy: 0.7214\n",
      "Epoch 91/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5386 - accuracy: 0.7212 - val_loss: 0.5366 - val_accuracy: 0.7217\n",
      "Epoch 92/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5383 - accuracy: 0.7216 - val_loss: 0.5363 - val_accuracy: 0.7213\n",
      "Epoch 93/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5380 - accuracy: 0.7215 - val_loss: 0.5362 - val_accuracy: 0.7214\n",
      "Epoch 94/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5378 - accuracy: 0.7215 - val_loss: 0.5358 - val_accuracy: 0.7217\n",
      "Epoch 95/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5375 - accuracy: 0.7218 - val_loss: 0.5356 - val_accuracy: 0.7219\n",
      "Epoch 96/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5372 - accuracy: 0.7217 - val_loss: 0.5352 - val_accuracy: 0.7222\n",
      "Epoch 97/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5369 - accuracy: 0.7220 - val_loss: 0.5349 - val_accuracy: 0.7219\n",
      "Epoch 98/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5366 - accuracy: 0.7222 - val_loss: 0.5346 - val_accuracy: 0.7219\n",
      "Epoch 99/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5363 - accuracy: 0.7221 - val_loss: 0.5344 - val_accuracy: 0.7222\n",
      "Epoch 100/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5361 - accuracy: 0.7222 - val_loss: 0.5342 - val_accuracy: 0.7227\n",
      "Epoch 101/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5358 - accuracy: 0.7223 - val_loss: 0.5339 - val_accuracy: 0.7229\n",
      "Epoch 102/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5355 - accuracy: 0.7226 - val_loss: 0.5336 - val_accuracy: 0.7229\n",
      "Epoch 103/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5352 - accuracy: 0.7226 - val_loss: 0.5332 - val_accuracy: 0.7229\n",
      "Epoch 104/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5350 - accuracy: 0.7227 - val_loss: 0.5329 - val_accuracy: 0.7232\n",
      "Epoch 105/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5347 - accuracy: 0.7229 - val_loss: 0.5326 - val_accuracy: 0.7235\n",
      "Epoch 106/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5344 - accuracy: 0.7228 - val_loss: 0.5324 - val_accuracy: 0.7238\n",
      "Epoch 107/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5342 - accuracy: 0.7231 - val_loss: 0.5322 - val_accuracy: 0.7235\n",
      "Epoch 108/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5339 - accuracy: 0.7232 - val_loss: 0.5318 - val_accuracy: 0.7237\n",
      "Epoch 109/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5337 - accuracy: 0.7233 - val_loss: 0.5317 - val_accuracy: 0.7241\n",
      "Epoch 110/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5334 - accuracy: 0.7234 - val_loss: 0.5314 - val_accuracy: 0.7235\n",
      "Epoch 111/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5332 - accuracy: 0.7236 - val_loss: 0.5311 - val_accuracy: 0.7241\n",
      "Epoch 112/1000\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.5329 - accuracy: 0.7238 - val_loss: 0.5308 - val_accuracy: 0.7248\n",
      "Epoch 113/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5327 - accuracy: 0.7242 - val_loss: 0.5306 - val_accuracy: 0.7248\n",
      "Epoch 114/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5324 - accuracy: 0.7243 - val_loss: 0.5304 - val_accuracy: 0.7248\n",
      "Epoch 115/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5322 - accuracy: 0.7241 - val_loss: 0.5301 - val_accuracy: 0.7250\n",
      "Epoch 116/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5319 - accuracy: 0.7245 - val_loss: 0.5299 - val_accuracy: 0.7250\n",
      "Epoch 117/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5316 - accuracy: 0.7246 - val_loss: 0.5297 - val_accuracy: 0.7253\n",
      "Epoch 118/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5314 - accuracy: 0.7248 - val_loss: 0.5294 - val_accuracy: 0.7251\n",
      "Epoch 119/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5312 - accuracy: 0.7247 - val_loss: 0.5292 - val_accuracy: 0.7254\n",
      "Epoch 120/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5309 - accuracy: 0.7247 - val_loss: 0.5289 - val_accuracy: 0.7254\n",
      "Epoch 121/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5307 - accuracy: 0.7251 - val_loss: 0.5287 - val_accuracy: 0.7255\n",
      "Epoch 122/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5304 - accuracy: 0.7250 - val_loss: 0.5284 - val_accuracy: 0.7256\n",
      "Epoch 123/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5302 - accuracy: 0.7254 - val_loss: 0.5282 - val_accuracy: 0.7257\n",
      "Epoch 124/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5300 - accuracy: 0.7255 - val_loss: 0.5279 - val_accuracy: 0.7259\n",
      "Epoch 125/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5297 - accuracy: 0.7256 - val_loss: 0.5277 - val_accuracy: 0.7260\n",
      "Epoch 126/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5295 - accuracy: 0.7255 - val_loss: 0.5275 - val_accuracy: 0.7260\n",
      "Epoch 127/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5293 - accuracy: 0.7259 - val_loss: 0.5272 - val_accuracy: 0.7263\n",
      "Epoch 128/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5290 - accuracy: 0.7260 - val_loss: 0.5270 - val_accuracy: 0.7263\n",
      "Epoch 129/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5288 - accuracy: 0.7258 - val_loss: 0.5268 - val_accuracy: 0.7265\n",
      "Epoch 130/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5285 - accuracy: 0.7261 - val_loss: 0.5265 - val_accuracy: 0.7268\n",
      "Epoch 131/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5283 - accuracy: 0.7263 - val_loss: 0.5263 - val_accuracy: 0.7267\n",
      "Epoch 132/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5280 - accuracy: 0.7264 - val_loss: 0.5261 - val_accuracy: 0.7267\n",
      "Epoch 133/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5278 - accuracy: 0.7266 - val_loss: 0.5258 - val_accuracy: 0.7270\n",
      "Epoch 134/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5276 - accuracy: 0.7267 - val_loss: 0.5256 - val_accuracy: 0.7273\n",
      "Epoch 135/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5273 - accuracy: 0.7269 - val_loss: 0.5254 - val_accuracy: 0.7272\n",
      "Epoch 136/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5271 - accuracy: 0.7271 - val_loss: 0.5252 - val_accuracy: 0.7271\n",
      "Epoch 137/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5269 - accuracy: 0.7269 - val_loss: 0.5249 - val_accuracy: 0.7276\n",
      "Epoch 138/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5267 - accuracy: 0.7274 - val_loss: 0.5247 - val_accuracy: 0.7275\n",
      "Epoch 139/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5264 - accuracy: 0.7275 - val_loss: 0.5245 - val_accuracy: 0.7276\n",
      "Epoch 140/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5262 - accuracy: 0.7277 - val_loss: 0.5242 - val_accuracy: 0.7279\n",
      "Epoch 141/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5260 - accuracy: 0.7281 - val_loss: 0.5240 - val_accuracy: 0.7279\n",
      "Epoch 142/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5257 - accuracy: 0.7281 - val_loss: 0.5238 - val_accuracy: 0.7278\n",
      "Epoch 143/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5255 - accuracy: 0.7284 - val_loss: 0.5236 - val_accuracy: 0.7281\n",
      "Epoch 144/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5253 - accuracy: 0.7283 - val_loss: 0.5234 - val_accuracy: 0.7286\n",
      "Epoch 145/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5251 - accuracy: 0.7288 - val_loss: 0.5232 - val_accuracy: 0.7287\n",
      "Epoch 146/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5249 - accuracy: 0.7288 - val_loss: 0.5230 - val_accuracy: 0.7287\n",
      "Epoch 147/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5247 - accuracy: 0.7288 - val_loss: 0.5227 - val_accuracy: 0.7288\n",
      "Epoch 148/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5244 - accuracy: 0.7289 - val_loss: 0.5225 - val_accuracy: 0.7293\n",
      "Epoch 149/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5242 - accuracy: 0.7291 - val_loss: 0.5222 - val_accuracy: 0.7294\n",
      "Epoch 150/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5240 - accuracy: 0.7295 - val_loss: 0.5220 - val_accuracy: 0.7293\n",
      "Epoch 151/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5238 - accuracy: 0.7296 - val_loss: 0.5220 - val_accuracy: 0.7298\n",
      "Epoch 152/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5235 - accuracy: 0.7297 - val_loss: 0.5217 - val_accuracy: 0.7298\n",
      "Epoch 153/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5233 - accuracy: 0.7295 - val_loss: 0.5215 - val_accuracy: 0.7295\n",
      "Epoch 154/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5231 - accuracy: 0.7296 - val_loss: 0.5213 - val_accuracy: 0.7302\n",
      "Epoch 155/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5229 - accuracy: 0.7301 - val_loss: 0.5211 - val_accuracy: 0.7301\n",
      "Epoch 156/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5227 - accuracy: 0.7300 - val_loss: 0.5209 - val_accuracy: 0.7301\n",
      "Epoch 157/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5224 - accuracy: 0.7303 - val_loss: 0.5206 - val_accuracy: 0.7300\n",
      "Epoch 158/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5222 - accuracy: 0.7305 - val_loss: 0.5205 - val_accuracy: 0.7300\n",
      "Epoch 159/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5220 - accuracy: 0.7303 - val_loss: 0.5203 - val_accuracy: 0.7307\n",
      "Epoch 160/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5218 - accuracy: 0.7308 - val_loss: 0.5201 - val_accuracy: 0.7307\n",
      "Epoch 161/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5216 - accuracy: 0.7308 - val_loss: 0.5199 - val_accuracy: 0.7307\n",
      "Epoch 162/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5214 - accuracy: 0.7308 - val_loss: 0.5197 - val_accuracy: 0.7309\n",
      "Epoch 163/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5212 - accuracy: 0.7310 - val_loss: 0.5195 - val_accuracy: 0.7312\n",
      "Epoch 164/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5210 - accuracy: 0.7312 - val_loss: 0.5194 - val_accuracy: 0.7307\n",
      "Epoch 165/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5208 - accuracy: 0.7313 - val_loss: 0.5191 - val_accuracy: 0.7310\n",
      "Epoch 166/1000\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.5206 - accuracy: 0.7315 - val_loss: 0.5190 - val_accuracy: 0.7313\n",
      "Epoch 167/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5204 - accuracy: 0.7318 - val_loss: 0.5188 - val_accuracy: 0.7313\n",
      "Epoch 168/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5202 - accuracy: 0.7318 - val_loss: 0.5185 - val_accuracy: 0.7312\n",
      "Epoch 169/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5200 - accuracy: 0.7318 - val_loss: 0.5183 - val_accuracy: 0.7313\n",
      "Epoch 170/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5198 - accuracy: 0.7322 - val_loss: 0.5181 - val_accuracy: 0.7317\n",
      "Epoch 171/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5196 - accuracy: 0.7321 - val_loss: 0.5179 - val_accuracy: 0.7317\n",
      "Epoch 172/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5195 - accuracy: 0.7324 - val_loss: 0.5177 - val_accuracy: 0.7318\n",
      "Epoch 173/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5193 - accuracy: 0.7324 - val_loss: 0.5175 - val_accuracy: 0.7321\n",
      "Epoch 174/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5191 - accuracy: 0.7327 - val_loss: 0.5174 - val_accuracy: 0.7323\n",
      "Epoch 175/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5189 - accuracy: 0.7328 - val_loss: 0.5172 - val_accuracy: 0.7324\n",
      "Epoch 176/1000\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 0.5187 - accuracy: 0.7329 - val_loss: 0.5171 - val_accuracy: 0.7331\n",
      "Epoch 177/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5185 - accuracy: 0.7329 - val_loss: 0.5169 - val_accuracy: 0.7327\n",
      "Epoch 178/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5183 - accuracy: 0.7330 - val_loss: 0.5166 - val_accuracy: 0.7328\n",
      "Epoch 179/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5181 - accuracy: 0.7330 - val_loss: 0.5165 - val_accuracy: 0.7333\n",
      "Epoch 180/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5179 - accuracy: 0.7333 - val_loss: 0.5163 - val_accuracy: 0.7330\n",
      "Epoch 181/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5178 - accuracy: 0.7335 - val_loss: 0.5161 - val_accuracy: 0.7335\n",
      "Epoch 182/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5176 - accuracy: 0.7335 - val_loss: 0.5160 - val_accuracy: 0.7341\n",
      "Epoch 183/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5174 - accuracy: 0.7336 - val_loss: 0.5158 - val_accuracy: 0.7336\n",
      "Epoch 184/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5173 - accuracy: 0.7341 - val_loss: 0.5156 - val_accuracy: 0.7340\n",
      "Epoch 185/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5170 - accuracy: 0.7339 - val_loss: 0.5153 - val_accuracy: 0.7336\n",
      "Epoch 186/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5169 - accuracy: 0.7342 - val_loss: 0.5152 - val_accuracy: 0.7340\n",
      "Epoch 187/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5167 - accuracy: 0.7341 - val_loss: 0.5151 - val_accuracy: 0.7343\n",
      "Epoch 188/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5165 - accuracy: 0.7342 - val_loss: 0.5149 - val_accuracy: 0.7342\n",
      "Epoch 189/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5163 - accuracy: 0.7344 - val_loss: 0.5147 - val_accuracy: 0.7339\n",
      "Epoch 190/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5162 - accuracy: 0.7346 - val_loss: 0.5146 - val_accuracy: 0.7343\n",
      "Epoch 191/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5160 - accuracy: 0.7348 - val_loss: 0.5143 - val_accuracy: 0.7345\n",
      "Epoch 192/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5158 - accuracy: 0.7348 - val_loss: 0.5143 - val_accuracy: 0.7344\n",
      "Epoch 193/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5157 - accuracy: 0.7349 - val_loss: 0.5140 - val_accuracy: 0.7350\n",
      "Epoch 194/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5155 - accuracy: 0.7353 - val_loss: 0.5138 - val_accuracy: 0.7350\n",
      "Epoch 195/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5153 - accuracy: 0.7353 - val_loss: 0.5137 - val_accuracy: 0.7351\n",
      "Epoch 196/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5152 - accuracy: 0.7354 - val_loss: 0.5135 - val_accuracy: 0.7355\n",
      "Epoch 197/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5150 - accuracy: 0.7359 - val_loss: 0.5134 - val_accuracy: 0.7352\n",
      "Epoch 198/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5148 - accuracy: 0.7359 - val_loss: 0.5132 - val_accuracy: 0.7353\n",
      "Epoch 199/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5147 - accuracy: 0.7356 - val_loss: 0.5131 - val_accuracy: 0.7358\n",
      "Epoch 200/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5145 - accuracy: 0.7361 - val_loss: 0.5129 - val_accuracy: 0.7357\n",
      "Epoch 201/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5143 - accuracy: 0.7364 - val_loss: 0.5128 - val_accuracy: 0.7353\n",
      "Epoch 202/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5142 - accuracy: 0.7364 - val_loss: 0.5126 - val_accuracy: 0.7358\n",
      "Epoch 203/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5140 - accuracy: 0.7365 - val_loss: 0.5125 - val_accuracy: 0.7361\n",
      "Epoch 204/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5139 - accuracy: 0.7368 - val_loss: 0.5123 - val_accuracy: 0.7362\n",
      "Epoch 205/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5137 - accuracy: 0.7370 - val_loss: 0.5121 - val_accuracy: 0.7362\n",
      "Epoch 206/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5136 - accuracy: 0.7371 - val_loss: 0.5120 - val_accuracy: 0.7360\n",
      "Epoch 207/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5134 - accuracy: 0.7371 - val_loss: 0.5118 - val_accuracy: 0.7360\n",
      "Epoch 208/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5133 - accuracy: 0.7372 - val_loss: 0.5117 - val_accuracy: 0.7360\n",
      "Epoch 209/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5131 - accuracy: 0.7371 - val_loss: 0.5116 - val_accuracy: 0.7367\n",
      "Epoch 210/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5129 - accuracy: 0.7376 - val_loss: 0.5114 - val_accuracy: 0.7370\n",
      "Epoch 211/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5128 - accuracy: 0.7378 - val_loss: 0.5113 - val_accuracy: 0.7373\n",
      "Epoch 212/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5126 - accuracy: 0.7380 - val_loss: 0.5110 - val_accuracy: 0.7374\n",
      "Epoch 213/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5125 - accuracy: 0.7381 - val_loss: 0.5108 - val_accuracy: 0.7372\n",
      "Epoch 214/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5123 - accuracy: 0.7384 - val_loss: 0.5108 - val_accuracy: 0.7373\n",
      "Epoch 215/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5122 - accuracy: 0.7384 - val_loss: 0.5106 - val_accuracy: 0.7376\n",
      "Epoch 216/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5120 - accuracy: 0.7388 - val_loss: 0.5104 - val_accuracy: 0.7378\n",
      "Epoch 217/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5118 - accuracy: 0.7387 - val_loss: 0.5103 - val_accuracy: 0.7378\n",
      "Epoch 218/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5117 - accuracy: 0.7388 - val_loss: 0.5102 - val_accuracy: 0.7383\n",
      "Epoch 219/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5116 - accuracy: 0.7392 - val_loss: 0.5101 - val_accuracy: 0.7385\n",
      "Epoch 220/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5114 - accuracy: 0.7392 - val_loss: 0.5098 - val_accuracy: 0.7381\n",
      "Epoch 221/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5112 - accuracy: 0.7394 - val_loss: 0.5097 - val_accuracy: 0.7380\n",
      "Epoch 222/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5111 - accuracy: 0.7395 - val_loss: 0.5096 - val_accuracy: 0.7385\n",
      "Epoch 223/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5110 - accuracy: 0.7396 - val_loss: 0.5093 - val_accuracy: 0.7390\n",
      "Epoch 224/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5108 - accuracy: 0.7399 - val_loss: 0.5092 - val_accuracy: 0.7389\n",
      "Epoch 225/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5106 - accuracy: 0.7399 - val_loss: 0.5090 - val_accuracy: 0.7390\n",
      "Epoch 226/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5105 - accuracy: 0.7400 - val_loss: 0.5090 - val_accuracy: 0.7396\n",
      "Epoch 227/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5104 - accuracy: 0.7402 - val_loss: 0.5087 - val_accuracy: 0.7395\n",
      "Epoch 228/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5102 - accuracy: 0.7403 - val_loss: 0.5087 - val_accuracy: 0.7394\n",
      "Epoch 229/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5101 - accuracy: 0.7404 - val_loss: 0.5084 - val_accuracy: 0.7394\n",
      "Epoch 230/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5099 - accuracy: 0.7406 - val_loss: 0.5083 - val_accuracy: 0.7395\n",
      "Epoch 231/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5098 - accuracy: 0.7406 - val_loss: 0.5082 - val_accuracy: 0.7403\n",
      "Epoch 232/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5096 - accuracy: 0.7410 - val_loss: 0.5081 - val_accuracy: 0.7402\n",
      "Epoch 233/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5095 - accuracy: 0.7409 - val_loss: 0.5081 - val_accuracy: 0.7408\n",
      "Epoch 234/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5093 - accuracy: 0.7410 - val_loss: 0.5078 - val_accuracy: 0.7401\n",
      "Epoch 235/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5092 - accuracy: 0.7413 - val_loss: 0.5076 - val_accuracy: 0.7402\n",
      "Epoch 236/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5091 - accuracy: 0.7414 - val_loss: 0.5075 - val_accuracy: 0.7408\n",
      "Epoch 237/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5089 - accuracy: 0.7415 - val_loss: 0.5074 - val_accuracy: 0.7406\n",
      "Epoch 238/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5088 - accuracy: 0.7419 - val_loss: 0.5071 - val_accuracy: 0.7407\n",
      "Epoch 239/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5086 - accuracy: 0.7420 - val_loss: 0.5072 - val_accuracy: 0.7412\n",
      "Epoch 240/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5085 - accuracy: 0.7421 - val_loss: 0.5069 - val_accuracy: 0.7414\n",
      "Epoch 241/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5084 - accuracy: 0.7425 - val_loss: 0.5068 - val_accuracy: 0.7412\n",
      "Epoch 242/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5082 - accuracy: 0.7425 - val_loss: 0.5067 - val_accuracy: 0.7407\n",
      "Epoch 243/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5081 - accuracy: 0.7427 - val_loss: 0.5065 - val_accuracy: 0.7415\n",
      "Epoch 244/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5080 - accuracy: 0.7427 - val_loss: 0.5064 - val_accuracy: 0.7412\n",
      "Epoch 245/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5078 - accuracy: 0.7428 - val_loss: 0.5063 - val_accuracy: 0.7418\n",
      "Epoch 246/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5077 - accuracy: 0.7431 - val_loss: 0.5060 - val_accuracy: 0.7420\n",
      "Epoch 247/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5075 - accuracy: 0.7431 - val_loss: 0.5060 - val_accuracy: 0.7419\n",
      "Epoch 248/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5074 - accuracy: 0.7431 - val_loss: 0.5059 - val_accuracy: 0.7423\n",
      "Epoch 249/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5073 - accuracy: 0.7435 - val_loss: 0.5058 - val_accuracy: 0.7426\n",
      "Epoch 250/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5071 - accuracy: 0.7439 - val_loss: 0.5057 - val_accuracy: 0.7425\n",
      "Epoch 251/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5070 - accuracy: 0.7441 - val_loss: 0.5056 - val_accuracy: 0.7423\n",
      "Epoch 252/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5069 - accuracy: 0.7439 - val_loss: 0.5054 - val_accuracy: 0.7429\n",
      "Epoch 253/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5067 - accuracy: 0.7442 - val_loss: 0.5051 - val_accuracy: 0.7426\n",
      "Epoch 254/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5066 - accuracy: 0.7443 - val_loss: 0.5051 - val_accuracy: 0.7432\n",
      "Epoch 255/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5065 - accuracy: 0.7445 - val_loss: 0.5049 - val_accuracy: 0.7433\n",
      "Epoch 256/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5063 - accuracy: 0.7445 - val_loss: 0.5048 - val_accuracy: 0.7433\n",
      "Epoch 257/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5062 - accuracy: 0.7450 - val_loss: 0.5048 - val_accuracy: 0.7433\n",
      "Epoch 258/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5061 - accuracy: 0.7448 - val_loss: 0.5046 - val_accuracy: 0.7439\n",
      "Epoch 259/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5059 - accuracy: 0.7450 - val_loss: 0.5045 - val_accuracy: 0.7440\n",
      "Epoch 260/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5058 - accuracy: 0.7453 - val_loss: 0.5044 - val_accuracy: 0.7447\n",
      "Epoch 261/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5057 - accuracy: 0.7452 - val_loss: 0.5042 - val_accuracy: 0.7444\n",
      "Epoch 262/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5056 - accuracy: 0.7452 - val_loss: 0.5040 - val_accuracy: 0.7440\n",
      "Epoch 263/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5054 - accuracy: 0.7455 - val_loss: 0.5042 - val_accuracy: 0.7441\n",
      "Epoch 264/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5053 - accuracy: 0.7456 - val_loss: 0.5037 - val_accuracy: 0.7442\n",
      "Epoch 265/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5052 - accuracy: 0.7458 - val_loss: 0.5036 - val_accuracy: 0.7445\n",
      "Epoch 266/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5050 - accuracy: 0.7458 - val_loss: 0.5036 - val_accuracy: 0.7452\n",
      "Epoch 267/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5049 - accuracy: 0.7461 - val_loss: 0.5035 - val_accuracy: 0.7447\n",
      "Epoch 268/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5048 - accuracy: 0.7461 - val_loss: 0.5033 - val_accuracy: 0.7451\n",
      "Epoch 269/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5047 - accuracy: 0.7462 - val_loss: 0.5032 - val_accuracy: 0.7448\n",
      "Epoch 270/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5045 - accuracy: 0.7464 - val_loss: 0.5030 - val_accuracy: 0.7448\n",
      "Epoch 271/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5044 - accuracy: 0.7465 - val_loss: 0.5031 - val_accuracy: 0.7454\n",
      "Epoch 272/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5043 - accuracy: 0.7466 - val_loss: 0.5028 - val_accuracy: 0.7449\n",
      "Epoch 273/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5042 - accuracy: 0.7466 - val_loss: 0.5027 - val_accuracy: 0.7456\n",
      "Epoch 274/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5041 - accuracy: 0.7469 - val_loss: 0.5026 - val_accuracy: 0.7454\n",
      "Epoch 275/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5039 - accuracy: 0.7470 - val_loss: 0.5025 - val_accuracy: 0.7459\n",
      "Epoch 276/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5038 - accuracy: 0.7471 - val_loss: 0.5024 - val_accuracy: 0.7461\n",
      "Epoch 277/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5037 - accuracy: 0.7470 - val_loss: 0.5022 - val_accuracy: 0.7463\n",
      "Epoch 278/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5036 - accuracy: 0.7472 - val_loss: 0.5021 - val_accuracy: 0.7458\n",
      "Epoch 279/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5035 - accuracy: 0.7473 - val_loss: 0.5020 - val_accuracy: 0.7463\n",
      "Epoch 280/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5034 - accuracy: 0.7476 - val_loss: 0.5018 - val_accuracy: 0.7462\n",
      "Epoch 281/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5032 - accuracy: 0.7477 - val_loss: 0.5018 - val_accuracy: 0.7466\n",
      "Epoch 282/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5031 - accuracy: 0.7477 - val_loss: 0.5016 - val_accuracy: 0.7470\n",
      "Epoch 283/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5030 - accuracy: 0.7477 - val_loss: 0.5015 - val_accuracy: 0.7467\n",
      "Epoch 284/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5029 - accuracy: 0.7479 - val_loss: 0.5016 - val_accuracy: 0.7463\n",
      "Epoch 285/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5028 - accuracy: 0.7481 - val_loss: 0.5012 - val_accuracy: 0.7470\n",
      "Epoch 286/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5027 - accuracy: 0.7484 - val_loss: 0.5012 - val_accuracy: 0.7471\n",
      "Epoch 287/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5026 - accuracy: 0.7484 - val_loss: 0.5011 - val_accuracy: 0.7476\n",
      "Epoch 288/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5025 - accuracy: 0.7484 - val_loss: 0.5009 - val_accuracy: 0.7477\n",
      "Epoch 289/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5023 - accuracy: 0.7487 - val_loss: 0.5008 - val_accuracy: 0.7474\n",
      "Epoch 290/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5022 - accuracy: 0.7487 - val_loss: 0.5007 - val_accuracy: 0.7480\n",
      "Epoch 291/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5021 - accuracy: 0.7491 - val_loss: 0.5006 - val_accuracy: 0.7475\n",
      "Epoch 292/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5020 - accuracy: 0.7490 - val_loss: 0.5006 - val_accuracy: 0.7474\n",
      "Epoch 293/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5019 - accuracy: 0.7490 - val_loss: 0.5004 - val_accuracy: 0.7485\n",
      "Epoch 294/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5018 - accuracy: 0.7493 - val_loss: 0.5003 - val_accuracy: 0.7480\n",
      "Epoch 295/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5017 - accuracy: 0.7492 - val_loss: 0.5002 - val_accuracy: 0.7480\n",
      "Epoch 296/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5016 - accuracy: 0.7493 - val_loss: 0.5002 - val_accuracy: 0.7486\n",
      "Epoch 297/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5015 - accuracy: 0.7498 - val_loss: 0.4999 - val_accuracy: 0.7487\n",
      "Epoch 298/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5014 - accuracy: 0.7495 - val_loss: 0.4998 - val_accuracy: 0.7489\n",
      "Epoch 299/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5013 - accuracy: 0.7497 - val_loss: 0.4997 - val_accuracy: 0.7484\n",
      "Epoch 300/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5012 - accuracy: 0.7499 - val_loss: 0.4996 - val_accuracy: 0.7483\n",
      "Epoch 301/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5010 - accuracy: 0.7499 - val_loss: 0.4995 - val_accuracy: 0.7488\n",
      "Epoch 302/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5009 - accuracy: 0.7499 - val_loss: 0.4994 - val_accuracy: 0.7499\n",
      "Epoch 303/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5008 - accuracy: 0.7504 - val_loss: 0.4993 - val_accuracy: 0.7498\n",
      "Epoch 304/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5007 - accuracy: 0.7501 - val_loss: 0.4992 - val_accuracy: 0.7499\n",
      "Epoch 305/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5006 - accuracy: 0.7504 - val_loss: 0.4991 - val_accuracy: 0.7494\n",
      "Epoch 306/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5005 - accuracy: 0.7504 - val_loss: 0.4989 - val_accuracy: 0.7498\n",
      "Epoch 307/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5004 - accuracy: 0.7507 - val_loss: 0.4988 - val_accuracy: 0.7500\n",
      "Epoch 308/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5003 - accuracy: 0.7506 - val_loss: 0.4987 - val_accuracy: 0.7503\n",
      "Epoch 309/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5002 - accuracy: 0.7510 - val_loss: 0.4986 - val_accuracy: 0.7503\n",
      "Epoch 310/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5001 - accuracy: 0.7509 - val_loss: 0.4985 - val_accuracy: 0.7502\n",
      "Epoch 311/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5000 - accuracy: 0.7510 - val_loss: 0.4985 - val_accuracy: 0.7502\n",
      "Epoch 312/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4999 - accuracy: 0.7511 - val_loss: 0.4984 - val_accuracy: 0.7509\n",
      "Epoch 313/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4998 - accuracy: 0.7513 - val_loss: 0.4983 - val_accuracy: 0.7504\n",
      "Epoch 314/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4997 - accuracy: 0.7516 - val_loss: 0.4981 - val_accuracy: 0.7514\n",
      "Epoch 315/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4996 - accuracy: 0.7516 - val_loss: 0.4980 - val_accuracy: 0.7513\n",
      "Epoch 316/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4995 - accuracy: 0.7521 - val_loss: 0.4979 - val_accuracy: 0.7510\n",
      "Epoch 317/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4994 - accuracy: 0.7519 - val_loss: 0.4979 - val_accuracy: 0.7510\n",
      "Epoch 318/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4993 - accuracy: 0.7521 - val_loss: 0.4977 - val_accuracy: 0.7516\n",
      "Epoch 319/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4992 - accuracy: 0.7520 - val_loss: 0.4976 - val_accuracy: 0.7522\n",
      "Epoch 320/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4990 - accuracy: 0.7522 - val_loss: 0.4974 - val_accuracy: 0.7522\n",
      "Epoch 321/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4989 - accuracy: 0.7525 - val_loss: 0.4974 - val_accuracy: 0.7519\n",
      "Epoch 322/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4988 - accuracy: 0.7524 - val_loss: 0.4973 - val_accuracy: 0.7517\n",
      "Epoch 323/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4987 - accuracy: 0.7528 - val_loss: 0.4971 - val_accuracy: 0.7524\n",
      "Epoch 324/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4986 - accuracy: 0.7527 - val_loss: 0.4971 - val_accuracy: 0.7526\n",
      "Epoch 325/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4985 - accuracy: 0.7530 - val_loss: 0.4970 - val_accuracy: 0.7526\n",
      "Epoch 326/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4984 - accuracy: 0.7529 - val_loss: 0.4969 - val_accuracy: 0.7523\n",
      "Epoch 327/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4983 - accuracy: 0.7532 - val_loss: 0.4967 - val_accuracy: 0.7527\n",
      "Epoch 328/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4982 - accuracy: 0.7534 - val_loss: 0.4966 - val_accuracy: 0.7531\n",
      "Epoch 329/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4981 - accuracy: 0.7535 - val_loss: 0.4966 - val_accuracy: 0.7523\n",
      "Epoch 330/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4980 - accuracy: 0.7533 - val_loss: 0.4965 - val_accuracy: 0.7535\n",
      "Epoch 331/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4979 - accuracy: 0.7538 - val_loss: 0.4963 - val_accuracy: 0.7538\n",
      "Epoch 332/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4978 - accuracy: 0.7540 - val_loss: 0.4962 - val_accuracy: 0.7539\n",
      "Epoch 333/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4977 - accuracy: 0.7542 - val_loss: 0.4962 - val_accuracy: 0.7536\n",
      "Epoch 334/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4976 - accuracy: 0.7542 - val_loss: 0.4960 - val_accuracy: 0.7541\n",
      "Epoch 335/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4975 - accuracy: 0.7542 - val_loss: 0.4959 - val_accuracy: 0.7541\n",
      "Epoch 336/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4974 - accuracy: 0.7543 - val_loss: 0.4959 - val_accuracy: 0.7540\n",
      "Epoch 337/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4973 - accuracy: 0.7545 - val_loss: 0.4959 - val_accuracy: 0.7541\n",
      "Epoch 338/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4972 - accuracy: 0.7545 - val_loss: 0.4957 - val_accuracy: 0.7547\n",
      "Epoch 339/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4971 - accuracy: 0.7546 - val_loss: 0.4956 - val_accuracy: 0.7549\n",
      "Epoch 340/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4970 - accuracy: 0.7547 - val_loss: 0.4955 - val_accuracy: 0.7546\n",
      "Epoch 341/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4969 - accuracy: 0.7548 - val_loss: 0.4954 - val_accuracy: 0.7553\n",
      "Epoch 342/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4968 - accuracy: 0.7553 - val_loss: 0.4952 - val_accuracy: 0.7551\n",
      "Epoch 343/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4967 - accuracy: 0.7553 - val_loss: 0.4952 - val_accuracy: 0.7549\n",
      "Epoch 344/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4966 - accuracy: 0.7555 - val_loss: 0.4951 - val_accuracy: 0.7552\n",
      "Epoch 345/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4965 - accuracy: 0.7557 - val_loss: 0.4950 - val_accuracy: 0.7553\n",
      "Epoch 346/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4964 - accuracy: 0.7554 - val_loss: 0.4948 - val_accuracy: 0.7557\n",
      "Epoch 347/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4963 - accuracy: 0.7556 - val_loss: 0.4947 - val_accuracy: 0.7558\n",
      "Epoch 348/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4962 - accuracy: 0.7559 - val_loss: 0.4947 - val_accuracy: 0.7558\n",
      "Epoch 349/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4961 - accuracy: 0.7558 - val_loss: 0.4946 - val_accuracy: 0.7560\n",
      "Epoch 350/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4960 - accuracy: 0.7561 - val_loss: 0.4945 - val_accuracy: 0.7559\n",
      "Epoch 351/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4959 - accuracy: 0.7561 - val_loss: 0.4945 - val_accuracy: 0.7552\n",
      "Epoch 352/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4958 - accuracy: 0.7560 - val_loss: 0.4943 - val_accuracy: 0.7567\n",
      "Epoch 353/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4958 - accuracy: 0.7563 - val_loss: 0.4942 - val_accuracy: 0.7564\n",
      "Epoch 354/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4957 - accuracy: 0.7565 - val_loss: 0.4941 - val_accuracy: 0.7565\n",
      "Epoch 355/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4956 - accuracy: 0.7567 - val_loss: 0.4941 - val_accuracy: 0.7561\n",
      "Epoch 356/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4955 - accuracy: 0.7566 - val_loss: 0.4939 - val_accuracy: 0.7570\n",
      "Epoch 357/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4954 - accuracy: 0.7569 - val_loss: 0.4939 - val_accuracy: 0.7570\n",
      "Epoch 358/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4953 - accuracy: 0.7570 - val_loss: 0.4938 - val_accuracy: 0.7569\n",
      "Epoch 359/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4952 - accuracy: 0.7569 - val_loss: 0.4937 - val_accuracy: 0.7573\n",
      "Epoch 360/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4951 - accuracy: 0.7571 - val_loss: 0.4936 - val_accuracy: 0.7570\n",
      "Epoch 361/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4950 - accuracy: 0.7573 - val_loss: 0.4935 - val_accuracy: 0.7572\n",
      "Epoch 362/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4949 - accuracy: 0.7575 - val_loss: 0.4934 - val_accuracy: 0.7571\n",
      "Epoch 363/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4948 - accuracy: 0.7574 - val_loss: 0.4933 - val_accuracy: 0.7578\n",
      "Epoch 364/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4947 - accuracy: 0.7577 - val_loss: 0.4933 - val_accuracy: 0.7572\n",
      "Epoch 365/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4946 - accuracy: 0.7579 - val_loss: 0.4931 - val_accuracy: 0.7576\n",
      "Epoch 366/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4945 - accuracy: 0.7580 - val_loss: 0.4930 - val_accuracy: 0.7578\n",
      "Epoch 367/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4944 - accuracy: 0.7582 - val_loss: 0.4929 - val_accuracy: 0.7576\n",
      "Epoch 368/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4944 - accuracy: 0.7581 - val_loss: 0.4928 - val_accuracy: 0.7581\n",
      "Epoch 369/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4942 - accuracy: 0.7583 - val_loss: 0.4928 - val_accuracy: 0.7579\n",
      "Epoch 370/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4942 - accuracy: 0.7583 - val_loss: 0.4927 - val_accuracy: 0.7577\n",
      "Epoch 371/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4941 - accuracy: 0.7583 - val_loss: 0.4926 - val_accuracy: 0.7585\n",
      "Epoch 372/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4940 - accuracy: 0.7587 - val_loss: 0.4925 - val_accuracy: 0.7581\n",
      "Epoch 373/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4939 - accuracy: 0.7588 - val_loss: 0.4924 - val_accuracy: 0.7585\n",
      "Epoch 374/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4938 - accuracy: 0.7590 - val_loss: 0.4923 - val_accuracy: 0.7582\n",
      "Epoch 375/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4937 - accuracy: 0.7588 - val_loss: 0.4922 - val_accuracy: 0.7582\n",
      "Epoch 376/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4936 - accuracy: 0.7591 - val_loss: 0.4921 - val_accuracy: 0.7584\n",
      "Epoch 377/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4935 - accuracy: 0.7592 - val_loss: 0.4921 - val_accuracy: 0.7584\n",
      "Epoch 378/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4934 - accuracy: 0.7592 - val_loss: 0.4919 - val_accuracy: 0.7584\n",
      "Epoch 379/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4934 - accuracy: 0.7595 - val_loss: 0.4918 - val_accuracy: 0.7585\n",
      "Epoch 380/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4933 - accuracy: 0.7594 - val_loss: 0.4918 - val_accuracy: 0.7584\n",
      "Epoch 381/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4932 - accuracy: 0.7597 - val_loss: 0.4917 - val_accuracy: 0.7589\n",
      "Epoch 382/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4931 - accuracy: 0.7596 - val_loss: 0.4916 - val_accuracy: 0.7586\n",
      "Epoch 383/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4930 - accuracy: 0.7597 - val_loss: 0.4915 - val_accuracy: 0.7589\n",
      "Epoch 384/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4929 - accuracy: 0.7599 - val_loss: 0.4914 - val_accuracy: 0.7591\n",
      "Epoch 385/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4928 - accuracy: 0.7600 - val_loss: 0.4913 - val_accuracy: 0.7588\n",
      "Epoch 386/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4927 - accuracy: 0.7603 - val_loss: 0.4913 - val_accuracy: 0.7584\n",
      "Epoch 387/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4926 - accuracy: 0.7600 - val_loss: 0.4913 - val_accuracy: 0.7590\n",
      "Epoch 388/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4926 - accuracy: 0.7604 - val_loss: 0.4911 - val_accuracy: 0.7589\n",
      "Epoch 389/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4925 - accuracy: 0.7601 - val_loss: 0.4910 - val_accuracy: 0.7588\n",
      "Epoch 390/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4924 - accuracy: 0.7603 - val_loss: 0.4909 - val_accuracy: 0.7593\n",
      "Epoch 391/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4923 - accuracy: 0.7604 - val_loss: 0.4909 - val_accuracy: 0.7593\n",
      "Epoch 392/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4922 - accuracy: 0.7608 - val_loss: 0.4907 - val_accuracy: 0.7592\n",
      "Epoch 393/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4921 - accuracy: 0.7605 - val_loss: 0.4907 - val_accuracy: 0.7599\n",
      "Epoch 394/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4920 - accuracy: 0.7610 - val_loss: 0.4906 - val_accuracy: 0.7594\n",
      "Epoch 395/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4919 - accuracy: 0.7609 - val_loss: 0.4904 - val_accuracy: 0.7602\n",
      "Epoch 396/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4919 - accuracy: 0.7613 - val_loss: 0.4904 - val_accuracy: 0.7597\n",
      "Epoch 397/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4918 - accuracy: 0.7609 - val_loss: 0.4904 - val_accuracy: 0.7599\n",
      "Epoch 398/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4917 - accuracy: 0.7613 - val_loss: 0.4902 - val_accuracy: 0.7601\n",
      "Epoch 399/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4916 - accuracy: 0.7613 - val_loss: 0.4902 - val_accuracy: 0.7602\n",
      "Epoch 400/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4915 - accuracy: 0.7615 - val_loss: 0.4900 - val_accuracy: 0.7616\n",
      "Epoch 401/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4914 - accuracy: 0.7617 - val_loss: 0.4899 - val_accuracy: 0.7605\n",
      "Epoch 402/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4913 - accuracy: 0.7614 - val_loss: 0.4899 - val_accuracy: 0.7603\n",
      "Epoch 403/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4913 - accuracy: 0.7617 - val_loss: 0.4899 - val_accuracy: 0.7606\n",
      "Epoch 404/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4912 - accuracy: 0.7617 - val_loss: 0.4897 - val_accuracy: 0.7614\n",
      "Epoch 405/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4911 - accuracy: 0.7618 - val_loss: 0.4897 - val_accuracy: 0.7606\n",
      "Epoch 406/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4910 - accuracy: 0.7615 - val_loss: 0.4896 - val_accuracy: 0.7613\n",
      "Epoch 407/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4909 - accuracy: 0.7619 - val_loss: 0.4896 - val_accuracy: 0.7611\n",
      "Epoch 408/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4908 - accuracy: 0.7621 - val_loss: 0.4894 - val_accuracy: 0.7618\n",
      "Epoch 409/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4907 - accuracy: 0.7620 - val_loss: 0.4893 - val_accuracy: 0.7619\n",
      "Epoch 410/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4907 - accuracy: 0.7625 - val_loss: 0.4893 - val_accuracy: 0.7614\n",
      "Epoch 411/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4906 - accuracy: 0.7623 - val_loss: 0.4892 - val_accuracy: 0.7616\n",
      "Epoch 412/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4905 - accuracy: 0.7626 - val_loss: 0.4890 - val_accuracy: 0.7626\n",
      "Epoch 413/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4904 - accuracy: 0.7628 - val_loss: 0.4889 - val_accuracy: 0.7623\n",
      "Epoch 414/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4903 - accuracy: 0.7625 - val_loss: 0.4889 - val_accuracy: 0.7624\n",
      "Epoch 415/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4902 - accuracy: 0.7628 - val_loss: 0.4888 - val_accuracy: 0.7623\n",
      "Epoch 416/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4902 - accuracy: 0.7631 - val_loss: 0.4888 - val_accuracy: 0.7618\n",
      "Epoch 417/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4901 - accuracy: 0.7629 - val_loss: 0.4886 - val_accuracy: 0.7624\n",
      "Epoch 418/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4900 - accuracy: 0.7631 - val_loss: 0.4888 - val_accuracy: 0.7619\n",
      "Epoch 419/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4899 - accuracy: 0.7634 - val_loss: 0.4885 - val_accuracy: 0.7627\n",
      "Epoch 420/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4898 - accuracy: 0.7634 - val_loss: 0.4884 - val_accuracy: 0.7623\n",
      "Epoch 421/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4897 - accuracy: 0.7636 - val_loss: 0.4884 - val_accuracy: 0.7624\n",
      "Epoch 422/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4896 - accuracy: 0.7633 - val_loss: 0.4882 - val_accuracy: 0.7626\n",
      "Epoch 423/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4896 - accuracy: 0.7634 - val_loss: 0.4882 - val_accuracy: 0.7623\n",
      "Epoch 424/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4895 - accuracy: 0.7634 - val_loss: 0.4880 - val_accuracy: 0.7633\n",
      "Epoch 425/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4894 - accuracy: 0.7638 - val_loss: 0.4880 - val_accuracy: 0.7634\n",
      "Epoch 426/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4893 - accuracy: 0.7638 - val_loss: 0.4880 - val_accuracy: 0.7634\n",
      "Epoch 427/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4893 - accuracy: 0.7642 - val_loss: 0.4878 - val_accuracy: 0.7633\n",
      "Epoch 428/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4892 - accuracy: 0.7642 - val_loss: 0.4878 - val_accuracy: 0.7631\n",
      "Epoch 429/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4891 - accuracy: 0.7641 - val_loss: 0.4877 - val_accuracy: 0.7634\n",
      "Epoch 430/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4890 - accuracy: 0.7645 - val_loss: 0.4876 - val_accuracy: 0.7632\n",
      "Epoch 431/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4889 - accuracy: 0.7643 - val_loss: 0.4875 - val_accuracy: 0.7636\n",
      "Epoch 432/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4888 - accuracy: 0.7642 - val_loss: 0.4875 - val_accuracy: 0.7636\n",
      "Epoch 433/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4888 - accuracy: 0.7645 - val_loss: 0.4874 - val_accuracy: 0.7636\n",
      "Epoch 434/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4887 - accuracy: 0.7647 - val_loss: 0.4872 - val_accuracy: 0.7642\n",
      "Epoch 435/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4886 - accuracy: 0.7647 - val_loss: 0.4873 - val_accuracy: 0.7639\n",
      "Epoch 436/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4885 - accuracy: 0.7650 - val_loss: 0.4872 - val_accuracy: 0.7640\n",
      "Epoch 437/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4885 - accuracy: 0.7648 - val_loss: 0.4871 - val_accuracy: 0.7645\n",
      "Epoch 438/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4884 - accuracy: 0.7651 - val_loss: 0.4869 - val_accuracy: 0.7640\n",
      "Epoch 439/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4883 - accuracy: 0.7652 - val_loss: 0.4869 - val_accuracy: 0.7639\n",
      "Epoch 440/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4882 - accuracy: 0.7651 - val_loss: 0.4868 - val_accuracy: 0.7647\n",
      "Epoch 441/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4881 - accuracy: 0.7655 - val_loss: 0.4867 - val_accuracy: 0.7647\n",
      "Epoch 442/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4880 - accuracy: 0.7655 - val_loss: 0.4867 - val_accuracy: 0.7648\n",
      "Epoch 443/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4880 - accuracy: 0.7656 - val_loss: 0.4866 - val_accuracy: 0.7649\n",
      "Epoch 444/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4879 - accuracy: 0.7659 - val_loss: 0.4867 - val_accuracy: 0.7640\n",
      "Epoch 445/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4878 - accuracy: 0.7657 - val_loss: 0.4864 - val_accuracy: 0.7647\n",
      "Epoch 446/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4877 - accuracy: 0.7659 - val_loss: 0.4864 - val_accuracy: 0.7646\n",
      "Epoch 447/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4877 - accuracy: 0.7662 - val_loss: 0.4863 - val_accuracy: 0.7650\n",
      "Epoch 448/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4876 - accuracy: 0.7664 - val_loss: 0.4862 - val_accuracy: 0.7650\n",
      "Epoch 449/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4875 - accuracy: 0.7658 - val_loss: 0.4861 - val_accuracy: 0.7657\n",
      "Epoch 450/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4874 - accuracy: 0.7663 - val_loss: 0.4860 - val_accuracy: 0.7655\n",
      "Epoch 451/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4874 - accuracy: 0.7665 - val_loss: 0.4859 - val_accuracy: 0.7655\n",
      "Epoch 452/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4872 - accuracy: 0.7665 - val_loss: 0.4860 - val_accuracy: 0.7647\n",
      "Epoch 453/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4872 - accuracy: 0.7664 - val_loss: 0.4859 - val_accuracy: 0.7655\n",
      "Epoch 454/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4871 - accuracy: 0.7667 - val_loss: 0.4858 - val_accuracy: 0.7655\n",
      "Epoch 455/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4870 - accuracy: 0.7667 - val_loss: 0.4857 - val_accuracy: 0.7658\n",
      "Epoch 456/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4869 - accuracy: 0.7669 - val_loss: 0.4857 - val_accuracy: 0.7650\n",
      "Epoch 457/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4869 - accuracy: 0.7669 - val_loss: 0.4855 - val_accuracy: 0.7657\n",
      "Epoch 458/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4868 - accuracy: 0.7669 - val_loss: 0.4854 - val_accuracy: 0.7658\n",
      "Epoch 459/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4867 - accuracy: 0.7670 - val_loss: 0.4854 - val_accuracy: 0.7660\n",
      "Epoch 460/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4866 - accuracy: 0.7670 - val_loss: 0.4853 - val_accuracy: 0.7663\n",
      "Epoch 461/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4866 - accuracy: 0.7673 - val_loss: 0.4852 - val_accuracy: 0.7660\n",
      "Epoch 462/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4865 - accuracy: 0.7673 - val_loss: 0.4853 - val_accuracy: 0.7662\n",
      "Epoch 463/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4864 - accuracy: 0.7675 - val_loss: 0.4851 - val_accuracy: 0.7662\n",
      "Epoch 464/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4863 - accuracy: 0.7674 - val_loss: 0.4850 - val_accuracy: 0.7666\n",
      "Epoch 465/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4863 - accuracy: 0.7679 - val_loss: 0.4849 - val_accuracy: 0.7668\n",
      "Epoch 466/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4862 - accuracy: 0.7678 - val_loss: 0.4848 - val_accuracy: 0.7664\n",
      "Epoch 467/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4861 - accuracy: 0.7680 - val_loss: 0.4848 - val_accuracy: 0.7666\n",
      "Epoch 468/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4860 - accuracy: 0.7682 - val_loss: 0.4848 - val_accuracy: 0.7663\n",
      "Epoch 469/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4860 - accuracy: 0.7679 - val_loss: 0.4847 - val_accuracy: 0.7669\n",
      "Epoch 470/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4859 - accuracy: 0.7685 - val_loss: 0.4846 - val_accuracy: 0.7666\n",
      "Epoch 471/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4858 - accuracy: 0.7682 - val_loss: 0.4844 - val_accuracy: 0.7672\n",
      "Epoch 472/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4857 - accuracy: 0.7684 - val_loss: 0.4844 - val_accuracy: 0.7668\n",
      "Epoch 473/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4857 - accuracy: 0.7685 - val_loss: 0.4844 - val_accuracy: 0.7671\n",
      "Epoch 474/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4855 - accuracy: 0.7686 - val_loss: 0.4843 - val_accuracy: 0.7670\n",
      "Epoch 475/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4855 - accuracy: 0.7685 - val_loss: 0.4842 - val_accuracy: 0.7674\n",
      "Epoch 476/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4854 - accuracy: 0.7688 - val_loss: 0.4841 - val_accuracy: 0.7673\n",
      "Epoch 477/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4854 - accuracy: 0.7688 - val_loss: 0.4841 - val_accuracy: 0.7673\n",
      "Epoch 478/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4853 - accuracy: 0.7687 - val_loss: 0.4840 - val_accuracy: 0.7676\n",
      "Epoch 479/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4852 - accuracy: 0.7693 - val_loss: 0.4839 - val_accuracy: 0.7674\n",
      "Epoch 480/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4851 - accuracy: 0.7691 - val_loss: 0.4838 - val_accuracy: 0.7677\n",
      "Epoch 481/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4851 - accuracy: 0.7694 - val_loss: 0.4838 - val_accuracy: 0.7675\n",
      "Epoch 482/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4850 - accuracy: 0.7693 - val_loss: 0.4837 - val_accuracy: 0.7675\n",
      "Epoch 483/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4849 - accuracy: 0.7694 - val_loss: 0.4837 - val_accuracy: 0.7677\n",
      "Epoch 484/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4849 - accuracy: 0.7696 - val_loss: 0.4836 - val_accuracy: 0.7681\n",
      "Epoch 485/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4848 - accuracy: 0.7698 - val_loss: 0.4835 - val_accuracy: 0.7678\n",
      "Epoch 486/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4847 - accuracy: 0.7699 - val_loss: 0.4835 - val_accuracy: 0.7682\n",
      "Epoch 487/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4846 - accuracy: 0.7699 - val_loss: 0.4834 - val_accuracy: 0.7682\n",
      "Epoch 488/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4845 - accuracy: 0.7700 - val_loss: 0.4833 - val_accuracy: 0.7680\n",
      "Epoch 489/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4845 - accuracy: 0.7699 - val_loss: 0.4832 - val_accuracy: 0.7680\n",
      "Epoch 490/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4844 - accuracy: 0.7701 - val_loss: 0.4832 - val_accuracy: 0.7679\n",
      "Epoch 491/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4843 - accuracy: 0.7702 - val_loss: 0.4831 - val_accuracy: 0.7685\n",
      "Epoch 492/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4843 - accuracy: 0.7703 - val_loss: 0.4830 - val_accuracy: 0.7682\n",
      "Epoch 493/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4842 - accuracy: 0.7703 - val_loss: 0.4830 - val_accuracy: 0.7690\n",
      "Epoch 494/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4841 - accuracy: 0.7706 - val_loss: 0.4829 - val_accuracy: 0.7686\n",
      "Epoch 495/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4840 - accuracy: 0.7705 - val_loss: 0.4828 - val_accuracy: 0.7690\n",
      "Epoch 496/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4840 - accuracy: 0.7708 - val_loss: 0.4828 - val_accuracy: 0.7688\n",
      "Epoch 497/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4839 - accuracy: 0.7706 - val_loss: 0.4827 - val_accuracy: 0.7689\n",
      "Epoch 498/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4839 - accuracy: 0.7709 - val_loss: 0.4826 - val_accuracy: 0.7688\n",
      "Epoch 499/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4838 - accuracy: 0.7707 - val_loss: 0.4826 - val_accuracy: 0.7688\n",
      "Epoch 500/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4837 - accuracy: 0.7710 - val_loss: 0.4826 - val_accuracy: 0.7682\n",
      "Epoch 501/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4836 - accuracy: 0.7708 - val_loss: 0.4824 - val_accuracy: 0.7688\n",
      "Epoch 502/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4836 - accuracy: 0.7711 - val_loss: 0.4823 - val_accuracy: 0.7696\n",
      "Epoch 503/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4835 - accuracy: 0.7712 - val_loss: 0.4823 - val_accuracy: 0.7693\n",
      "Epoch 504/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4834 - accuracy: 0.7712 - val_loss: 0.4821 - val_accuracy: 0.7700\n",
      "Epoch 505/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4834 - accuracy: 0.7715 - val_loss: 0.4822 - val_accuracy: 0.7695\n",
      "Epoch 506/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4833 - accuracy: 0.7716 - val_loss: 0.4821 - val_accuracy: 0.7696\n",
      "Epoch 507/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4832 - accuracy: 0.7718 - val_loss: 0.4820 - val_accuracy: 0.7697\n",
      "Epoch 508/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4831 - accuracy: 0.7716 - val_loss: 0.4820 - val_accuracy: 0.7698\n",
      "Epoch 509/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4831 - accuracy: 0.7719 - val_loss: 0.4819 - val_accuracy: 0.7698\n",
      "Epoch 510/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4830 - accuracy: 0.7719 - val_loss: 0.4818 - val_accuracy: 0.7703\n",
      "Epoch 511/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4830 - accuracy: 0.7719 - val_loss: 0.4818 - val_accuracy: 0.7698\n",
      "Epoch 512/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4829 - accuracy: 0.7721 - val_loss: 0.4817 - val_accuracy: 0.7701\n",
      "Epoch 513/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4828 - accuracy: 0.7722 - val_loss: 0.4817 - val_accuracy: 0.7706\n",
      "Epoch 514/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4827 - accuracy: 0.7721 - val_loss: 0.4816 - val_accuracy: 0.7700\n",
      "Epoch 515/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4827 - accuracy: 0.7721 - val_loss: 0.4815 - val_accuracy: 0.7707\n",
      "Epoch 516/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4826 - accuracy: 0.7723 - val_loss: 0.4813 - val_accuracy: 0.7705\n",
      "Epoch 517/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4826 - accuracy: 0.7723 - val_loss: 0.4813 - val_accuracy: 0.7707\n",
      "Epoch 518/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4825 - accuracy: 0.7726 - val_loss: 0.4812 - val_accuracy: 0.7709\n",
      "Epoch 519/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4824 - accuracy: 0.7724 - val_loss: 0.4813 - val_accuracy: 0.7704\n",
      "Epoch 520/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4824 - accuracy: 0.7727 - val_loss: 0.4811 - val_accuracy: 0.7709\n",
      "Epoch 521/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4823 - accuracy: 0.7726 - val_loss: 0.4811 - val_accuracy: 0.7704\n",
      "Epoch 522/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4822 - accuracy: 0.7727 - val_loss: 0.4811 - val_accuracy: 0.7707\n",
      "Epoch 523/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4822 - accuracy: 0.7729 - val_loss: 0.4810 - val_accuracy: 0.7711\n",
      "Epoch 524/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4821 - accuracy: 0.7730 - val_loss: 0.4809 - val_accuracy: 0.7708\n",
      "Epoch 525/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4820 - accuracy: 0.7728 - val_loss: 0.4808 - val_accuracy: 0.7711\n",
      "Epoch 526/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4819 - accuracy: 0.7728 - val_loss: 0.4808 - val_accuracy: 0.7715\n",
      "Epoch 527/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4819 - accuracy: 0.7732 - val_loss: 0.4807 - val_accuracy: 0.7711\n",
      "Epoch 528/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4818 - accuracy: 0.7731 - val_loss: 0.4807 - val_accuracy: 0.7714\n",
      "Epoch 529/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4818 - accuracy: 0.7733 - val_loss: 0.4805 - val_accuracy: 0.7718\n",
      "Epoch 530/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4817 - accuracy: 0.7733 - val_loss: 0.4804 - val_accuracy: 0.7717\n",
      "Epoch 531/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4816 - accuracy: 0.7734 - val_loss: 0.4804 - val_accuracy: 0.7717\n",
      "Epoch 532/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4816 - accuracy: 0.7735 - val_loss: 0.4803 - val_accuracy: 0.7718\n",
      "Epoch 533/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4815 - accuracy: 0.7736 - val_loss: 0.4803 - val_accuracy: 0.7715\n",
      "Epoch 534/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4814 - accuracy: 0.7737 - val_loss: 0.4802 - val_accuracy: 0.7718\n",
      "Epoch 535/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4813 - accuracy: 0.7739 - val_loss: 0.4803 - val_accuracy: 0.7715\n",
      "Epoch 536/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4813 - accuracy: 0.7738 - val_loss: 0.4802 - val_accuracy: 0.7714\n",
      "Epoch 537/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4812 - accuracy: 0.7737 - val_loss: 0.4800 - val_accuracy: 0.7716\n",
      "Epoch 538/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4812 - accuracy: 0.7739 - val_loss: 0.4800 - val_accuracy: 0.7717\n",
      "Epoch 539/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4811 - accuracy: 0.7739 - val_loss: 0.4799 - val_accuracy: 0.7719\n",
      "Epoch 540/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4810 - accuracy: 0.7738 - val_loss: 0.4799 - val_accuracy: 0.7722\n",
      "Epoch 541/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4810 - accuracy: 0.7742 - val_loss: 0.4798 - val_accuracy: 0.7717\n",
      "Epoch 542/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4809 - accuracy: 0.7741 - val_loss: 0.4797 - val_accuracy: 0.7724\n",
      "Epoch 543/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4808 - accuracy: 0.7741 - val_loss: 0.4797 - val_accuracy: 0.7721\n",
      "Epoch 544/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4808 - accuracy: 0.7742 - val_loss: 0.4796 - val_accuracy: 0.7724\n",
      "Epoch 545/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4807 - accuracy: 0.7741 - val_loss: 0.4795 - val_accuracy: 0.7724\n",
      "Epoch 546/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4807 - accuracy: 0.7744 - val_loss: 0.4795 - val_accuracy: 0.7724\n",
      "Epoch 547/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4806 - accuracy: 0.7743 - val_loss: 0.4794 - val_accuracy: 0.7726\n",
      "Epoch 548/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4805 - accuracy: 0.7746 - val_loss: 0.4793 - val_accuracy: 0.7723\n",
      "Epoch 549/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4805 - accuracy: 0.7744 - val_loss: 0.4793 - val_accuracy: 0.7728\n",
      "Epoch 550/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4804 - accuracy: 0.7747 - val_loss: 0.4793 - val_accuracy: 0.7725\n",
      "Epoch 551/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4803 - accuracy: 0.7744 - val_loss: 0.4792 - val_accuracy: 0.7728\n",
      "Epoch 552/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4803 - accuracy: 0.7747 - val_loss: 0.4791 - val_accuracy: 0.7732\n",
      "Epoch 553/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4802 - accuracy: 0.7746 - val_loss: 0.4791 - val_accuracy: 0.7728\n",
      "Epoch 554/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4802 - accuracy: 0.7750 - val_loss: 0.4790 - val_accuracy: 0.7734\n",
      "Epoch 555/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4801 - accuracy: 0.7749 - val_loss: 0.4789 - val_accuracy: 0.7731\n",
      "Epoch 556/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4800 - accuracy: 0.7751 - val_loss: 0.4789 - val_accuracy: 0.7731\n",
      "Epoch 557/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4800 - accuracy: 0.7749 - val_loss: 0.4788 - val_accuracy: 0.7736\n",
      "Epoch 558/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4799 - accuracy: 0.7751 - val_loss: 0.4788 - val_accuracy: 0.7732\n",
      "Epoch 559/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4798 - accuracy: 0.7752 - val_loss: 0.4786 - val_accuracy: 0.7734\n",
      "Epoch 560/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4798 - accuracy: 0.7752 - val_loss: 0.4787 - val_accuracy: 0.7737\n",
      "Epoch 561/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4797 - accuracy: 0.7754 - val_loss: 0.4786 - val_accuracy: 0.7736\n",
      "Epoch 562/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4796 - accuracy: 0.7756 - val_loss: 0.4786 - val_accuracy: 0.7732\n",
      "Epoch 563/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4796 - accuracy: 0.7754 - val_loss: 0.4785 - val_accuracy: 0.7731\n",
      "Epoch 564/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4795 - accuracy: 0.7754 - val_loss: 0.4783 - val_accuracy: 0.7736\n",
      "Epoch 565/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4795 - accuracy: 0.7758 - val_loss: 0.4783 - val_accuracy: 0.7737\n",
      "Epoch 566/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4794 - accuracy: 0.7756 - val_loss: 0.4783 - val_accuracy: 0.7735\n",
      "Epoch 567/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4794 - accuracy: 0.7756 - val_loss: 0.4782 - val_accuracy: 0.7740\n",
      "Epoch 568/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4793 - accuracy: 0.7759 - val_loss: 0.4782 - val_accuracy: 0.7740\n",
      "Epoch 569/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4792 - accuracy: 0.7759 - val_loss: 0.4781 - val_accuracy: 0.7740\n",
      "Epoch 570/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4792 - accuracy: 0.7758 - val_loss: 0.4780 - val_accuracy: 0.7737\n",
      "Epoch 571/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4791 - accuracy: 0.7759 - val_loss: 0.4780 - val_accuracy: 0.7738\n",
      "Epoch 572/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4790 - accuracy: 0.7760 - val_loss: 0.4780 - val_accuracy: 0.7741\n",
      "Epoch 573/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4790 - accuracy: 0.7761 - val_loss: 0.4779 - val_accuracy: 0.7742\n",
      "Epoch 574/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4789 - accuracy: 0.7762 - val_loss: 0.4778 - val_accuracy: 0.7741\n",
      "Epoch 575/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4789 - accuracy: 0.7765 - val_loss: 0.4777 - val_accuracy: 0.7743\n",
      "Epoch 576/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4788 - accuracy: 0.7764 - val_loss: 0.4777 - val_accuracy: 0.7741\n",
      "Epoch 577/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4788 - accuracy: 0.7764 - val_loss: 0.4776 - val_accuracy: 0.7744\n",
      "Epoch 578/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4787 - accuracy: 0.7766 - val_loss: 0.4776 - val_accuracy: 0.7745\n",
      "Epoch 579/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4786 - accuracy: 0.7768 - val_loss: 0.4774 - val_accuracy: 0.7743\n",
      "Epoch 580/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4786 - accuracy: 0.7768 - val_loss: 0.4775 - val_accuracy: 0.7743\n",
      "Epoch 581/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4785 - accuracy: 0.7766 - val_loss: 0.4773 - val_accuracy: 0.7745\n",
      "Epoch 582/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4785 - accuracy: 0.7769 - val_loss: 0.4772 - val_accuracy: 0.7747\n",
      "Epoch 583/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4784 - accuracy: 0.7770 - val_loss: 0.4772 - val_accuracy: 0.7745\n",
      "Epoch 584/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4783 - accuracy: 0.7772 - val_loss: 0.4771 - val_accuracy: 0.7748\n",
      "Epoch 585/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4783 - accuracy: 0.7771 - val_loss: 0.4772 - val_accuracy: 0.7749\n",
      "Epoch 586/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4782 - accuracy: 0.7770 - val_loss: 0.4770 - val_accuracy: 0.7751\n",
      "Epoch 587/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4782 - accuracy: 0.7771 - val_loss: 0.4770 - val_accuracy: 0.7747\n",
      "Epoch 588/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4781 - accuracy: 0.7772 - val_loss: 0.4770 - val_accuracy: 0.7747\n",
      "Epoch 589/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4781 - accuracy: 0.7772 - val_loss: 0.4769 - val_accuracy: 0.7750\n",
      "Epoch 590/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4780 - accuracy: 0.7775 - val_loss: 0.4768 - val_accuracy: 0.7751\n",
      "Epoch 591/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4779 - accuracy: 0.7775 - val_loss: 0.4768 - val_accuracy: 0.7754\n",
      "Epoch 592/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4779 - accuracy: 0.7775 - val_loss: 0.4767 - val_accuracy: 0.7754\n",
      "Epoch 593/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4778 - accuracy: 0.7777 - val_loss: 0.4767 - val_accuracy: 0.7753\n",
      "Epoch 594/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4778 - accuracy: 0.7779 - val_loss: 0.4766 - val_accuracy: 0.7755\n",
      "Epoch 595/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4777 - accuracy: 0.7780 - val_loss: 0.4766 - val_accuracy: 0.7750\n",
      "Epoch 596/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4776 - accuracy: 0.7778 - val_loss: 0.4765 - val_accuracy: 0.7756\n",
      "Epoch 597/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4776 - accuracy: 0.7779 - val_loss: 0.4765 - val_accuracy: 0.7754\n",
      "Epoch 598/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4775 - accuracy: 0.7780 - val_loss: 0.4764 - val_accuracy: 0.7756\n",
      "Epoch 599/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4775 - accuracy: 0.7781 - val_loss: 0.4763 - val_accuracy: 0.7759\n",
      "Epoch 600/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4774 - accuracy: 0.7782 - val_loss: 0.4763 - val_accuracy: 0.7758\n",
      "Epoch 601/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4773 - accuracy: 0.7782 - val_loss: 0.4763 - val_accuracy: 0.7761\n",
      "Epoch 602/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4773 - accuracy: 0.7783 - val_loss: 0.4762 - val_accuracy: 0.7755\n",
      "Epoch 603/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4772 - accuracy: 0.7784 - val_loss: 0.4760 - val_accuracy: 0.7761\n",
      "Epoch 604/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4772 - accuracy: 0.7785 - val_loss: 0.4761 - val_accuracy: 0.7761\n",
      "Epoch 605/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4771 - accuracy: 0.7783 - val_loss: 0.4759 - val_accuracy: 0.7767\n",
      "Epoch 606/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4771 - accuracy: 0.7788 - val_loss: 0.4759 - val_accuracy: 0.7762\n",
      "Epoch 607/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4770 - accuracy: 0.7788 - val_loss: 0.4758 - val_accuracy: 0.7764\n",
      "Epoch 608/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4770 - accuracy: 0.7789 - val_loss: 0.4758 - val_accuracy: 0.7763\n",
      "Epoch 609/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4769 - accuracy: 0.7787 - val_loss: 0.4758 - val_accuracy: 0.7763\n",
      "Epoch 610/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4768 - accuracy: 0.7788 - val_loss: 0.4756 - val_accuracy: 0.7763\n",
      "Epoch 611/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4768 - accuracy: 0.7788 - val_loss: 0.4757 - val_accuracy: 0.7764\n",
      "Epoch 612/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4767 - accuracy: 0.7790 - val_loss: 0.4756 - val_accuracy: 0.7764\n",
      "Epoch 613/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4767 - accuracy: 0.7793 - val_loss: 0.4756 - val_accuracy: 0.7760\n",
      "Epoch 614/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4766 - accuracy: 0.7792 - val_loss: 0.4755 - val_accuracy: 0.7760\n",
      "Epoch 615/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4766 - accuracy: 0.7792 - val_loss: 0.4755 - val_accuracy: 0.7762\n",
      "Epoch 616/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4765 - accuracy: 0.7792 - val_loss: 0.4754 - val_accuracy: 0.7767\n",
      "Epoch 617/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4765 - accuracy: 0.7795 - val_loss: 0.4754 - val_accuracy: 0.7766\n",
      "Epoch 618/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4764 - accuracy: 0.7793 - val_loss: 0.4753 - val_accuracy: 0.7768\n",
      "Epoch 619/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4764 - accuracy: 0.7795 - val_loss: 0.4752 - val_accuracy: 0.7771\n",
      "Epoch 620/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4763 - accuracy: 0.7797 - val_loss: 0.4752 - val_accuracy: 0.7769\n",
      "Epoch 621/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4763 - accuracy: 0.7794 - val_loss: 0.4751 - val_accuracy: 0.7770\n",
      "Epoch 622/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4762 - accuracy: 0.7797 - val_loss: 0.4751 - val_accuracy: 0.7766\n",
      "Epoch 623/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4761 - accuracy: 0.7796 - val_loss: 0.4750 - val_accuracy: 0.7772\n",
      "Epoch 624/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4761 - accuracy: 0.7799 - val_loss: 0.4750 - val_accuracy: 0.7771\n",
      "Epoch 625/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4760 - accuracy: 0.7798 - val_loss: 0.4749 - val_accuracy: 0.7768\n",
      "Epoch 626/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4760 - accuracy: 0.7798 - val_loss: 0.4748 - val_accuracy: 0.7772\n",
      "Epoch 627/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4759 - accuracy: 0.7799 - val_loss: 0.4747 - val_accuracy: 0.7777\n",
      "Epoch 628/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4759 - accuracy: 0.7800 - val_loss: 0.4747 - val_accuracy: 0.7770\n",
      "Epoch 629/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4758 - accuracy: 0.7800 - val_loss: 0.4746 - val_accuracy: 0.7777\n",
      "Epoch 630/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4758 - accuracy: 0.7800 - val_loss: 0.4746 - val_accuracy: 0.7774\n",
      "Epoch 631/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4757 - accuracy: 0.7800 - val_loss: 0.4745 - val_accuracy: 0.7777\n",
      "Epoch 632/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4756 - accuracy: 0.7803 - val_loss: 0.4746 - val_accuracy: 0.7772\n",
      "Epoch 633/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4756 - accuracy: 0.7802 - val_loss: 0.4745 - val_accuracy: 0.7772\n",
      "Epoch 634/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4755 - accuracy: 0.7802 - val_loss: 0.4744 - val_accuracy: 0.7778\n",
      "Epoch 635/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4755 - accuracy: 0.7803 - val_loss: 0.4743 - val_accuracy: 0.7783\n",
      "Epoch 636/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4754 - accuracy: 0.7804 - val_loss: 0.4743 - val_accuracy: 0.7777\n",
      "Epoch 637/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4754 - accuracy: 0.7802 - val_loss: 0.4742 - val_accuracy: 0.7779\n",
      "Epoch 638/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4753 - accuracy: 0.7807 - val_loss: 0.4742 - val_accuracy: 0.7781\n",
      "Epoch 639/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4753 - accuracy: 0.7804 - val_loss: 0.4741 - val_accuracy: 0.7780\n",
      "Epoch 640/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4752 - accuracy: 0.7804 - val_loss: 0.4741 - val_accuracy: 0.7782\n",
      "Epoch 641/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4751 - accuracy: 0.7807 - val_loss: 0.4741 - val_accuracy: 0.7782\n",
      "Epoch 642/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4751 - accuracy: 0.7806 - val_loss: 0.4740 - val_accuracy: 0.7783\n",
      "Epoch 643/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4750 - accuracy: 0.7806 - val_loss: 0.4740 - val_accuracy: 0.7782\n",
      "Epoch 644/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4750 - accuracy: 0.7806 - val_loss: 0.4738 - val_accuracy: 0.7791\n",
      "Epoch 645/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4749 - accuracy: 0.7809 - val_loss: 0.4739 - val_accuracy: 0.7776\n",
      "Epoch 646/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4749 - accuracy: 0.7807 - val_loss: 0.4738 - val_accuracy: 0.7787\n",
      "Epoch 647/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4748 - accuracy: 0.7809 - val_loss: 0.4737 - val_accuracy: 0.7791\n",
      "Epoch 648/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4748 - accuracy: 0.7809 - val_loss: 0.4737 - val_accuracy: 0.7782\n",
      "Epoch 649/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4747 - accuracy: 0.7812 - val_loss: 0.4737 - val_accuracy: 0.7786\n",
      "Epoch 650/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4747 - accuracy: 0.7810 - val_loss: 0.4736 - val_accuracy: 0.7784\n",
      "Epoch 651/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4746 - accuracy: 0.7811 - val_loss: 0.4735 - val_accuracy: 0.7793\n",
      "Epoch 652/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4746 - accuracy: 0.7811 - val_loss: 0.4735 - val_accuracy: 0.7788\n",
      "Epoch 653/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4745 - accuracy: 0.7810 - val_loss: 0.4733 - val_accuracy: 0.7792\n",
      "Epoch 654/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4745 - accuracy: 0.7812 - val_loss: 0.4734 - val_accuracy: 0.7792\n",
      "Epoch 655/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4744 - accuracy: 0.7813 - val_loss: 0.4733 - val_accuracy: 0.7789\n",
      "Epoch 656/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4744 - accuracy: 0.7813 - val_loss: 0.4732 - val_accuracy: 0.7791\n",
      "Epoch 657/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4743 - accuracy: 0.7813 - val_loss: 0.4733 - val_accuracy: 0.7784\n",
      "Epoch 658/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4743 - accuracy: 0.7813 - val_loss: 0.4732 - val_accuracy: 0.7790\n",
      "Epoch 659/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4742 - accuracy: 0.7813 - val_loss: 0.4732 - val_accuracy: 0.7788\n",
      "Epoch 660/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4741 - accuracy: 0.7816 - val_loss: 0.4730 - val_accuracy: 0.7789\n",
      "Epoch 661/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4741 - accuracy: 0.7816 - val_loss: 0.4730 - val_accuracy: 0.7793\n",
      "Epoch 662/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4740 - accuracy: 0.7817 - val_loss: 0.4730 - val_accuracy: 0.7795\n",
      "Epoch 663/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4740 - accuracy: 0.7814 - val_loss: 0.4729 - val_accuracy: 0.7795\n",
      "Epoch 664/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4739 - accuracy: 0.7818 - val_loss: 0.4728 - val_accuracy: 0.7797\n",
      "Epoch 665/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4739 - accuracy: 0.7816 - val_loss: 0.4728 - val_accuracy: 0.7795\n",
      "Epoch 666/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4738 - accuracy: 0.7818 - val_loss: 0.4728 - val_accuracy: 0.7798\n",
      "Epoch 667/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4738 - accuracy: 0.7818 - val_loss: 0.4727 - val_accuracy: 0.7799\n",
      "Epoch 668/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4737 - accuracy: 0.7821 - val_loss: 0.4726 - val_accuracy: 0.7803\n",
      "Epoch 669/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4737 - accuracy: 0.7823 - val_loss: 0.4726 - val_accuracy: 0.7798\n",
      "Epoch 670/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4736 - accuracy: 0.7821 - val_loss: 0.4725 - val_accuracy: 0.7800\n",
      "Epoch 671/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4736 - accuracy: 0.7822 - val_loss: 0.4725 - val_accuracy: 0.7802\n",
      "Epoch 672/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4735 - accuracy: 0.7822 - val_loss: 0.4725 - val_accuracy: 0.7798\n",
      "Epoch 673/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4735 - accuracy: 0.7822 - val_loss: 0.4724 - val_accuracy: 0.7802\n",
      "Epoch 674/1000\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.4734 - accuracy: 0.78 - 1s 5ms/step - loss: 0.4734 - accuracy: 0.7824 - val_loss: 0.4723 - val_accuracy: 0.7811\n",
      "Epoch 675/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4734 - accuracy: 0.7825 - val_loss: 0.4723 - val_accuracy: 0.7806\n",
      "Epoch 676/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4733 - accuracy: 0.7825 - val_loss: 0.4724 - val_accuracy: 0.7799\n",
      "Epoch 677/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4733 - accuracy: 0.7827 - val_loss: 0.4723 - val_accuracy: 0.7805\n",
      "Epoch 678/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4732 - accuracy: 0.7827 - val_loss: 0.4721 - val_accuracy: 0.7809\n",
      "Epoch 679/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4732 - accuracy: 0.7829 - val_loss: 0.4721 - val_accuracy: 0.7811\n",
      "Epoch 680/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4731 - accuracy: 0.7830 - val_loss: 0.4721 - val_accuracy: 0.7802\n",
      "Epoch 681/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4731 - accuracy: 0.7828 - val_loss: 0.4720 - val_accuracy: 0.7810\n",
      "Epoch 682/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4730 - accuracy: 0.7832 - val_loss: 0.4720 - val_accuracy: 0.7803\n",
      "Epoch 683/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4730 - accuracy: 0.7830 - val_loss: 0.4719 - val_accuracy: 0.7813\n",
      "Epoch 684/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4729 - accuracy: 0.7830 - val_loss: 0.4718 - val_accuracy: 0.7813\n",
      "Epoch 685/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4729 - accuracy: 0.7831 - val_loss: 0.4718 - val_accuracy: 0.7809\n",
      "Epoch 686/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4728 - accuracy: 0.7834 - val_loss: 0.4717 - val_accuracy: 0.7813\n",
      "Epoch 687/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4728 - accuracy: 0.7834 - val_loss: 0.4718 - val_accuracy: 0.7806\n",
      "Epoch 688/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4727 - accuracy: 0.7835 - val_loss: 0.4717 - val_accuracy: 0.7801\n",
      "Epoch 689/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4727 - accuracy: 0.7831 - val_loss: 0.4716 - val_accuracy: 0.7811\n",
      "Epoch 690/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4726 - accuracy: 0.7834 - val_loss: 0.4716 - val_accuracy: 0.7811\n",
      "Epoch 691/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4726 - accuracy: 0.7835 - val_loss: 0.4715 - val_accuracy: 0.7811\n",
      "Epoch 692/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4725 - accuracy: 0.7836 - val_loss: 0.4715 - val_accuracy: 0.7812\n",
      "Epoch 693/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4725 - accuracy: 0.7835 - val_loss: 0.4714 - val_accuracy: 0.7815\n",
      "Epoch 694/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4724 - accuracy: 0.7839 - val_loss: 0.4713 - val_accuracy: 0.7816\n",
      "Epoch 695/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4724 - accuracy: 0.7838 - val_loss: 0.4713 - val_accuracy: 0.7811\n",
      "Epoch 696/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4723 - accuracy: 0.7838 - val_loss: 0.4713 - val_accuracy: 0.7815\n",
      "Epoch 697/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4723 - accuracy: 0.7840 - val_loss: 0.4712 - val_accuracy: 0.7814\n",
      "Epoch 698/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4722 - accuracy: 0.7839 - val_loss: 0.4712 - val_accuracy: 0.7815\n",
      "Epoch 699/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4722 - accuracy: 0.7842 - val_loss: 0.4711 - val_accuracy: 0.7813\n",
      "Epoch 700/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4721 - accuracy: 0.7841 - val_loss: 0.4711 - val_accuracy: 0.7818\n",
      "Epoch 701/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4721 - accuracy: 0.7840 - val_loss: 0.4711 - val_accuracy: 0.7813\n",
      "Epoch 702/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4720 - accuracy: 0.7843 - val_loss: 0.4710 - val_accuracy: 0.7819\n",
      "Epoch 703/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4720 - accuracy: 0.7842 - val_loss: 0.4710 - val_accuracy: 0.7811\n",
      "Epoch 704/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4719 - accuracy: 0.7841 - val_loss: 0.4709 - val_accuracy: 0.7820\n",
      "Epoch 705/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4719 - accuracy: 0.7842 - val_loss: 0.4709 - val_accuracy: 0.7816\n",
      "Epoch 706/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4718 - accuracy: 0.7841 - val_loss: 0.4708 - val_accuracy: 0.7824\n",
      "Epoch 707/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4718 - accuracy: 0.7845 - val_loss: 0.4707 - val_accuracy: 0.7822\n",
      "Epoch 708/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4717 - accuracy: 0.7847 - val_loss: 0.4707 - val_accuracy: 0.7825\n",
      "Epoch 709/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4717 - accuracy: 0.7845 - val_loss: 0.4707 - val_accuracy: 0.7814\n",
      "Epoch 710/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4716 - accuracy: 0.7844 - val_loss: 0.4707 - val_accuracy: 0.7822\n",
      "Epoch 711/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4716 - accuracy: 0.7845 - val_loss: 0.4706 - val_accuracy: 0.7821\n",
      "Epoch 712/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4715 - accuracy: 0.7846 - val_loss: 0.4706 - val_accuracy: 0.7818\n",
      "Epoch 713/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4715 - accuracy: 0.7844 - val_loss: 0.4705 - val_accuracy: 0.7824\n",
      "Epoch 714/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4714 - accuracy: 0.7848 - val_loss: 0.4705 - val_accuracy: 0.7822\n",
      "Epoch 715/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4714 - accuracy: 0.7847 - val_loss: 0.4703 - val_accuracy: 0.7834\n",
      "Epoch 716/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4713 - accuracy: 0.7849 - val_loss: 0.4703 - val_accuracy: 0.7825\n",
      "Epoch 717/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4713 - accuracy: 0.7850 - val_loss: 0.4703 - val_accuracy: 0.7820\n",
      "Epoch 718/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4712 - accuracy: 0.7848 - val_loss: 0.4702 - val_accuracy: 0.7834\n",
      "Epoch 719/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4712 - accuracy: 0.7850 - val_loss: 0.4702 - val_accuracy: 0.7826\n",
      "Epoch 720/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4711 - accuracy: 0.7851 - val_loss: 0.4702 - val_accuracy: 0.7823\n",
      "Epoch 721/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4711 - accuracy: 0.7851 - val_loss: 0.4700 - val_accuracy: 0.7834\n",
      "Epoch 722/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4710 - accuracy: 0.7854 - val_loss: 0.4701 - val_accuracy: 0.7829\n",
      "Epoch 723/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4710 - accuracy: 0.7852 - val_loss: 0.4700 - val_accuracy: 0.7835\n",
      "Epoch 724/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4709 - accuracy: 0.7856 - val_loss: 0.4700 - val_accuracy: 0.7831\n",
      "Epoch 725/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4709 - accuracy: 0.7854 - val_loss: 0.4699 - val_accuracy: 0.7827\n",
      "Epoch 726/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4708 - accuracy: 0.7855 - val_loss: 0.4699 - val_accuracy: 0.7828\n",
      "Epoch 727/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4708 - accuracy: 0.7855 - val_loss: 0.4699 - val_accuracy: 0.7829\n",
      "Epoch 728/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4707 - accuracy: 0.7855 - val_loss: 0.4698 - val_accuracy: 0.7833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 729/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4707 - accuracy: 0.7857 - val_loss: 0.4698 - val_accuracy: 0.7828\n",
      "Epoch 730/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4706 - accuracy: 0.7858 - val_loss: 0.4697 - val_accuracy: 0.7834\n",
      "Epoch 731/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4706 - accuracy: 0.7858 - val_loss: 0.4697 - val_accuracy: 0.7832\n",
      "Epoch 732/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4705 - accuracy: 0.7859 - val_loss: 0.4695 - val_accuracy: 0.7836\n",
      "Epoch 733/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4705 - accuracy: 0.7859 - val_loss: 0.4695 - val_accuracy: 0.7831\n",
      "Epoch 734/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4705 - accuracy: 0.7861 - val_loss: 0.4695 - val_accuracy: 0.7830\n",
      "Epoch 735/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4704 - accuracy: 0.7859 - val_loss: 0.4695 - val_accuracy: 0.7830\n",
      "Epoch 736/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4704 - accuracy: 0.7857 - val_loss: 0.4694 - val_accuracy: 0.7837\n",
      "Epoch 737/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4703 - accuracy: 0.7860 - val_loss: 0.4694 - val_accuracy: 0.7839\n",
      "Epoch 738/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4703 - accuracy: 0.7861 - val_loss: 0.4693 - val_accuracy: 0.7835\n",
      "Epoch 739/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4702 - accuracy: 0.7863 - val_loss: 0.4693 - val_accuracy: 0.7838\n",
      "Epoch 740/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4702 - accuracy: 0.7861 - val_loss: 0.4693 - val_accuracy: 0.7835\n",
      "Epoch 741/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4701 - accuracy: 0.7864 - val_loss: 0.4692 - val_accuracy: 0.7836\n",
      "Epoch 742/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4701 - accuracy: 0.7863 - val_loss: 0.4691 - val_accuracy: 0.7836\n",
      "Epoch 743/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4700 - accuracy: 0.7864 - val_loss: 0.4692 - val_accuracy: 0.7837\n",
      "Epoch 744/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4700 - accuracy: 0.7864 - val_loss: 0.4690 - val_accuracy: 0.7841\n",
      "Epoch 745/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4699 - accuracy: 0.7864 - val_loss: 0.4690 - val_accuracy: 0.7837\n",
      "Epoch 746/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4699 - accuracy: 0.7866 - val_loss: 0.4689 - val_accuracy: 0.7838\n",
      "Epoch 747/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4698 - accuracy: 0.7866 - val_loss: 0.4689 - val_accuracy: 0.7840\n",
      "Epoch 748/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4698 - accuracy: 0.7864 - val_loss: 0.4688 - val_accuracy: 0.7843\n",
      "Epoch 749/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4697 - accuracy: 0.7865 - val_loss: 0.4688 - val_accuracy: 0.7838\n",
      "Epoch 750/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4697 - accuracy: 0.7865 - val_loss: 0.4688 - val_accuracy: 0.7841\n",
      "Epoch 751/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4697 - accuracy: 0.7865 - val_loss: 0.4687 - val_accuracy: 0.7844\n",
      "Epoch 752/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4696 - accuracy: 0.7866 - val_loss: 0.4687 - val_accuracy: 0.7844\n",
      "Epoch 753/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4696 - accuracy: 0.7865 - val_loss: 0.4687 - val_accuracy: 0.7847\n",
      "Epoch 754/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4695 - accuracy: 0.7867 - val_loss: 0.4685 - val_accuracy: 0.7844\n",
      "Epoch 755/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4695 - accuracy: 0.7869 - val_loss: 0.4686 - val_accuracy: 0.7845\n",
      "Epoch 756/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4694 - accuracy: 0.7867 - val_loss: 0.4685 - val_accuracy: 0.7847\n",
      "Epoch 757/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4694 - accuracy: 0.7869 - val_loss: 0.4685 - val_accuracy: 0.7849\n",
      "Epoch 758/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4693 - accuracy: 0.7871 - val_loss: 0.4685 - val_accuracy: 0.7843\n",
      "Epoch 759/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4693 - accuracy: 0.7870 - val_loss: 0.4683 - val_accuracy: 0.7850\n",
      "Epoch 760/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4692 - accuracy: 0.7867 - val_loss: 0.4684 - val_accuracy: 0.7845\n",
      "Epoch 761/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4692 - accuracy: 0.7869 - val_loss: 0.4683 - val_accuracy: 0.7846\n",
      "Epoch 762/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4691 - accuracy: 0.7870 - val_loss: 0.4681 - val_accuracy: 0.7854\n",
      "Epoch 763/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4691 - accuracy: 0.7872 - val_loss: 0.4682 - val_accuracy: 0.7849\n",
      "Epoch 764/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4690 - accuracy: 0.7872 - val_loss: 0.4681 - val_accuracy: 0.7848\n",
      "Epoch 765/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4690 - accuracy: 0.7873 - val_loss: 0.4681 - val_accuracy: 0.7853\n",
      "Epoch 766/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4690 - accuracy: 0.7872 - val_loss: 0.4680 - val_accuracy: 0.7853\n",
      "Epoch 767/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4689 - accuracy: 0.7873 - val_loss: 0.4681 - val_accuracy: 0.7851\n",
      "Epoch 768/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4689 - accuracy: 0.7873 - val_loss: 0.4680 - val_accuracy: 0.7854\n",
      "Epoch 769/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4688 - accuracy: 0.7875 - val_loss: 0.4680 - val_accuracy: 0.7848\n",
      "Epoch 770/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4688 - accuracy: 0.7874 - val_loss: 0.4678 - val_accuracy: 0.7852\n",
      "Epoch 771/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4687 - accuracy: 0.7874 - val_loss: 0.4678 - val_accuracy: 0.7855\n",
      "Epoch 772/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4687 - accuracy: 0.7873 - val_loss: 0.4678 - val_accuracy: 0.7857\n",
      "Epoch 773/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4686 - accuracy: 0.7875 - val_loss: 0.4677 - val_accuracy: 0.7854\n",
      "Epoch 774/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4686 - accuracy: 0.7872 - val_loss: 0.4677 - val_accuracy: 0.7854\n",
      "Epoch 775/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4685 - accuracy: 0.7875 - val_loss: 0.4677 - val_accuracy: 0.7855\n",
      "Epoch 776/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4685 - accuracy: 0.7875 - val_loss: 0.4676 - val_accuracy: 0.7859\n",
      "Epoch 777/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4685 - accuracy: 0.7876 - val_loss: 0.4676 - val_accuracy: 0.7854\n",
      "Epoch 778/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4684 - accuracy: 0.7876 - val_loss: 0.4675 - val_accuracy: 0.7855\n",
      "Epoch 779/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4684 - accuracy: 0.7878 - val_loss: 0.4675 - val_accuracy: 0.7857\n",
      "Epoch 780/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4683 - accuracy: 0.7877 - val_loss: 0.4674 - val_accuracy: 0.7854\n",
      "Epoch 781/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4683 - accuracy: 0.7880 - val_loss: 0.4674 - val_accuracy: 0.7862\n",
      "Epoch 782/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4682 - accuracy: 0.7879 - val_loss: 0.4673 - val_accuracy: 0.7858\n",
      "Epoch 783/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4682 - accuracy: 0.7879 - val_loss: 0.4673 - val_accuracy: 0.7855\n",
      "Epoch 784/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4681 - accuracy: 0.7880 - val_loss: 0.4673 - val_accuracy: 0.7858\n",
      "Epoch 785/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4681 - accuracy: 0.7880 - val_loss: 0.4672 - val_accuracy: 0.7859\n",
      "Epoch 786/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4681 - accuracy: 0.7880 - val_loss: 0.4672 - val_accuracy: 0.7862\n",
      "Epoch 787/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4680 - accuracy: 0.7880 - val_loss: 0.4670 - val_accuracy: 0.7861\n",
      "Epoch 788/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4680 - accuracy: 0.7884 - val_loss: 0.4671 - val_accuracy: 0.7857\n",
      "Epoch 789/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4679 - accuracy: 0.7882 - val_loss: 0.4671 - val_accuracy: 0.7860\n",
      "Epoch 790/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4679 - accuracy: 0.7881 - val_loss: 0.4670 - val_accuracy: 0.7864\n",
      "Epoch 791/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4678 - accuracy: 0.7882 - val_loss: 0.4669 - val_accuracy: 0.7858\n",
      "Epoch 792/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4678 - accuracy: 0.7881 - val_loss: 0.4669 - val_accuracy: 0.7869\n",
      "Epoch 793/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4677 - accuracy: 0.7882 - val_loss: 0.4669 - val_accuracy: 0.7865\n",
      "Epoch 794/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4677 - accuracy: 0.7884 - val_loss: 0.4668 - val_accuracy: 0.7869\n",
      "Epoch 795/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4676 - accuracy: 0.7884 - val_loss: 0.4668 - val_accuracy: 0.7865\n",
      "Epoch 796/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4676 - accuracy: 0.7884 - val_loss: 0.4667 - val_accuracy: 0.7866\n",
      "Epoch 797/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4676 - accuracy: 0.7883 - val_loss: 0.4667 - val_accuracy: 0.7868\n",
      "Epoch 798/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4675 - accuracy: 0.7883 - val_loss: 0.4666 - val_accuracy: 0.7868\n",
      "Epoch 799/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4675 - accuracy: 0.7883 - val_loss: 0.4666 - val_accuracy: 0.7873\n",
      "Epoch 800/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4674 - accuracy: 0.7886 - val_loss: 0.4666 - val_accuracy: 0.7872\n",
      "Epoch 801/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4674 - accuracy: 0.7887 - val_loss: 0.4666 - val_accuracy: 0.7872\n",
      "Epoch 802/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4674 - accuracy: 0.7885 - val_loss: 0.4665 - val_accuracy: 0.7865\n",
      "Epoch 803/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4673 - accuracy: 0.7887 - val_loss: 0.4665 - val_accuracy: 0.7866\n",
      "Epoch 804/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4673 - accuracy: 0.7887 - val_loss: 0.4665 - val_accuracy: 0.7868\n",
      "Epoch 805/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4672 - accuracy: 0.7886 - val_loss: 0.4663 - val_accuracy: 0.7879\n",
      "Epoch 806/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4672 - accuracy: 0.7887 - val_loss: 0.4663 - val_accuracy: 0.7872\n",
      "Epoch 807/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4671 - accuracy: 0.7887 - val_loss: 0.4663 - val_accuracy: 0.7871\n",
      "Epoch 808/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4671 - accuracy: 0.7889 - val_loss: 0.4663 - val_accuracy: 0.7873\n",
      "Epoch 809/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4671 - accuracy: 0.7887 - val_loss: 0.4663 - val_accuracy: 0.7872\n",
      "Epoch 810/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4670 - accuracy: 0.7888 - val_loss: 0.4662 - val_accuracy: 0.7874\n",
      "Epoch 811/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4670 - accuracy: 0.7889 - val_loss: 0.4662 - val_accuracy: 0.7871\n",
      "Epoch 812/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4669 - accuracy: 0.7889 - val_loss: 0.4661 - val_accuracy: 0.7871\n",
      "Epoch 813/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4669 - accuracy: 0.7885 - val_loss: 0.4661 - val_accuracy: 0.7873\n",
      "Epoch 814/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4668 - accuracy: 0.7890 - val_loss: 0.4660 - val_accuracy: 0.7872\n",
      "Epoch 815/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4668 - accuracy: 0.7886 - val_loss: 0.4659 - val_accuracy: 0.7882\n",
      "Epoch 816/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4667 - accuracy: 0.7892 - val_loss: 0.4659 - val_accuracy: 0.7876\n",
      "Epoch 817/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4667 - accuracy: 0.7889 - val_loss: 0.4658 - val_accuracy: 0.7882\n",
      "Epoch 818/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4667 - accuracy: 0.7889 - val_loss: 0.4659 - val_accuracy: 0.7878\n",
      "Epoch 819/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4666 - accuracy: 0.7891 - val_loss: 0.4658 - val_accuracy: 0.7879\n",
      "Epoch 820/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4666 - accuracy: 0.7890 - val_loss: 0.4658 - val_accuracy: 0.7873\n",
      "Epoch 821/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4666 - accuracy: 0.7890 - val_loss: 0.4657 - val_accuracy: 0.7877\n",
      "Epoch 822/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4665 - accuracy: 0.7891 - val_loss: 0.4657 - val_accuracy: 0.7880\n",
      "Epoch 823/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4665 - accuracy: 0.7893 - val_loss: 0.4656 - val_accuracy: 0.7877\n",
      "Epoch 824/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4664 - accuracy: 0.7893 - val_loss: 0.4656 - val_accuracy: 0.7876\n",
      "Epoch 825/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4664 - accuracy: 0.7892 - val_loss: 0.4656 - val_accuracy: 0.7878\n",
      "Epoch 826/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4663 - accuracy: 0.7893 - val_loss: 0.4655 - val_accuracy: 0.7878\n",
      "Epoch 827/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4663 - accuracy: 0.7894 - val_loss: 0.4654 - val_accuracy: 0.7883\n",
      "Epoch 828/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4662 - accuracy: 0.7894 - val_loss: 0.4654 - val_accuracy: 0.7878\n",
      "Epoch 829/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4662 - accuracy: 0.7893 - val_loss: 0.4654 - val_accuracy: 0.7883\n",
      "Epoch 830/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4662 - accuracy: 0.7893 - val_loss: 0.4654 - val_accuracy: 0.7888\n",
      "Epoch 831/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4661 - accuracy: 0.7896 - val_loss: 0.4654 - val_accuracy: 0.7883\n",
      "Epoch 832/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4661 - accuracy: 0.7895 - val_loss: 0.4653 - val_accuracy: 0.7884\n",
      "Epoch 833/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4660 - accuracy: 0.7893 - val_loss: 0.4653 - val_accuracy: 0.7882\n",
      "Epoch 834/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4660 - accuracy: 0.7896 - val_loss: 0.4652 - val_accuracy: 0.7886\n",
      "Epoch 835/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4660 - accuracy: 0.7896 - val_loss: 0.4652 - val_accuracy: 0.7888\n",
      "Epoch 836/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4659 - accuracy: 0.7895 - val_loss: 0.4651 - val_accuracy: 0.7887\n",
      "Epoch 837/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4659 - accuracy: 0.7896 - val_loss: 0.4651 - val_accuracy: 0.7889\n",
      "Epoch 838/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4658 - accuracy: 0.7896 - val_loss: 0.4650 - val_accuracy: 0.7886\n",
      "Epoch 839/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4658 - accuracy: 0.7897 - val_loss: 0.4649 - val_accuracy: 0.7887\n",
      "Epoch 840/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4658 - accuracy: 0.7896 - val_loss: 0.4649 - val_accuracy: 0.7890\n",
      "Epoch 841/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4657 - accuracy: 0.7896 - val_loss: 0.4649 - val_accuracy: 0.7885\n",
      "Epoch 842/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4657 - accuracy: 0.7898 - val_loss: 0.4648 - val_accuracy: 0.7890\n",
      "Epoch 843/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4656 - accuracy: 0.7898 - val_loss: 0.4648 - val_accuracy: 0.7891\n",
      "Epoch 844/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4656 - accuracy: 0.7898 - val_loss: 0.4648 - val_accuracy: 0.7889\n",
      "Epoch 845/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4656 - accuracy: 0.7898 - val_loss: 0.4648 - val_accuracy: 0.7886\n",
      "Epoch 846/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4655 - accuracy: 0.7899 - val_loss: 0.4648 - val_accuracy: 0.7882\n",
      "Epoch 847/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4655 - accuracy: 0.7898 - val_loss: 0.4647 - val_accuracy: 0.7890\n",
      "Epoch 848/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4654 - accuracy: 0.7901 - val_loss: 0.4646 - val_accuracy: 0.7891\n",
      "Epoch 849/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4654 - accuracy: 0.7901 - val_loss: 0.4646 - val_accuracy: 0.7885\n",
      "Epoch 850/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4653 - accuracy: 0.7899 - val_loss: 0.4646 - val_accuracy: 0.7887\n",
      "Epoch 851/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4653 - accuracy: 0.7899 - val_loss: 0.4646 - val_accuracy: 0.7888\n",
      "Epoch 852/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4653 - accuracy: 0.7900 - val_loss: 0.4645 - val_accuracy: 0.7889\n",
      "Epoch 853/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4652 - accuracy: 0.7900 - val_loss: 0.4644 - val_accuracy: 0.7890\n",
      "Epoch 854/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4652 - accuracy: 0.7902 - val_loss: 0.4644 - val_accuracy: 0.7893\n",
      "Epoch 855/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4652 - accuracy: 0.7901 - val_loss: 0.4644 - val_accuracy: 0.7891\n",
      "Epoch 856/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4651 - accuracy: 0.7902 - val_loss: 0.4643 - val_accuracy: 0.7891\n",
      "Epoch 857/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4651 - accuracy: 0.7903 - val_loss: 0.4643 - val_accuracy: 0.7894\n",
      "Epoch 858/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4650 - accuracy: 0.7902 - val_loss: 0.4643 - val_accuracy: 0.7894\n",
      "Epoch 859/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4650 - accuracy: 0.7903 - val_loss: 0.4642 - val_accuracy: 0.7894\n",
      "Epoch 860/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4650 - accuracy: 0.7902 - val_loss: 0.4641 - val_accuracy: 0.7894\n",
      "Epoch 861/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4649 - accuracy: 0.7902 - val_loss: 0.4642 - val_accuracy: 0.7891\n",
      "Epoch 862/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4649 - accuracy: 0.7904 - val_loss: 0.4641 - val_accuracy: 0.7891\n",
      "Epoch 863/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4648 - accuracy: 0.7904 - val_loss: 0.4640 - val_accuracy: 0.7894\n",
      "Epoch 864/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4648 - accuracy: 0.7903 - val_loss: 0.4640 - val_accuracy: 0.7897\n",
      "Epoch 865/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4648 - accuracy: 0.7903 - val_loss: 0.4640 - val_accuracy: 0.7896\n",
      "Epoch 866/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4647 - accuracy: 0.7903 - val_loss: 0.4640 - val_accuracy: 0.7897\n",
      "Epoch 867/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4647 - accuracy: 0.7906 - val_loss: 0.4639 - val_accuracy: 0.7898\n",
      "Epoch 868/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4646 - accuracy: 0.7905 - val_loss: 0.4639 - val_accuracy: 0.7897\n",
      "Epoch 869/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4646 - accuracy: 0.7906 - val_loss: 0.4639 - val_accuracy: 0.7893\n",
      "Epoch 870/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4646 - accuracy: 0.7905 - val_loss: 0.4638 - val_accuracy: 0.7895\n",
      "Epoch 871/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4645 - accuracy: 0.7907 - val_loss: 0.4637 - val_accuracy: 0.7896\n",
      "Epoch 872/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4645 - accuracy: 0.7904 - val_loss: 0.4636 - val_accuracy: 0.7899\n",
      "Epoch 873/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4644 - accuracy: 0.7907 - val_loss: 0.4637 - val_accuracy: 0.7898\n",
      "Epoch 874/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4644 - accuracy: 0.7907 - val_loss: 0.4636 - val_accuracy: 0.7896\n",
      "Epoch 875/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4644 - accuracy: 0.7906 - val_loss: 0.4636 - val_accuracy: 0.7894\n",
      "Epoch 876/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4643 - accuracy: 0.7907 - val_loss: 0.4635 - val_accuracy: 0.7898\n",
      "Epoch 877/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4643 - accuracy: 0.7907 - val_loss: 0.4635 - val_accuracy: 0.7895\n",
      "Epoch 878/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4642 - accuracy: 0.7906 - val_loss: 0.4635 - val_accuracy: 0.7898\n",
      "Epoch 879/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4642 - accuracy: 0.7906 - val_loss: 0.4635 - val_accuracy: 0.7902\n",
      "Epoch 880/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4642 - accuracy: 0.7908 - val_loss: 0.4633 - val_accuracy: 0.7901\n",
      "Epoch 881/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4641 - accuracy: 0.7909 - val_loss: 0.4634 - val_accuracy: 0.7894\n",
      "Epoch 882/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4641 - accuracy: 0.7908 - val_loss: 0.4633 - val_accuracy: 0.7899\n",
      "Epoch 883/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4640 - accuracy: 0.7907 - val_loss: 0.4632 - val_accuracy: 0.7902\n",
      "Epoch 884/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4640 - accuracy: 0.7909 - val_loss: 0.4633 - val_accuracy: 0.7897\n",
      "Epoch 885/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4640 - accuracy: 0.7910 - val_loss: 0.4632 - val_accuracy: 0.7903\n",
      "Epoch 886/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4639 - accuracy: 0.7911 - val_loss: 0.4632 - val_accuracy: 0.7902\n",
      "Epoch 887/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4639 - accuracy: 0.7910 - val_loss: 0.4630 - val_accuracy: 0.7911\n",
      "Epoch 888/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4638 - accuracy: 0.7910 - val_loss: 0.4631 - val_accuracy: 0.7899\n",
      "Epoch 889/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4637 - accuracy: 0.7911 - val_loss: 0.4630 - val_accuracy: 0.7909\n",
      "Epoch 890/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4637 - accuracy: 0.7912 - val_loss: 0.4628 - val_accuracy: 0.7902\n",
      "Epoch 891/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4636 - accuracy: 0.7912 - val_loss: 0.4626 - val_accuracy: 0.7908\n",
      "Epoch 892/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4634 - accuracy: 0.7918 - val_loss: 0.4625 - val_accuracy: 0.7911\n",
      "Epoch 893/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4633 - accuracy: 0.7920 - val_loss: 0.4623 - val_accuracy: 0.7916\n",
      "Epoch 894/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4632 - accuracy: 0.7921 - val_loss: 0.4622 - val_accuracy: 0.7922\n",
      "Epoch 895/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4630 - accuracy: 0.7925 - val_loss: 0.4620 - val_accuracy: 0.7925\n",
      "Epoch 896/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4630 - accuracy: 0.7927 - val_loss: 0.4619 - val_accuracy: 0.7926\n",
      "Epoch 897/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4628 - accuracy: 0.7930 - val_loss: 0.4618 - val_accuracy: 0.7935\n",
      "Epoch 898/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4626 - accuracy: 0.7939 - val_loss: 0.4617 - val_accuracy: 0.7944\n",
      "Epoch 899/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4625 - accuracy: 0.7947 - val_loss: 0.4616 - val_accuracy: 0.7943\n",
      "Epoch 900/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4624 - accuracy: 0.7944 - val_loss: 0.4615 - val_accuracy: 0.7941\n",
      "Epoch 901/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4624 - accuracy: 0.7946 - val_loss: 0.4615 - val_accuracy: 0.7941\n",
      "Epoch 902/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4623 - accuracy: 0.7944 - val_loss: 0.4614 - val_accuracy: 0.7944\n",
      "Epoch 903/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4623 - accuracy: 0.7941 - val_loss: 0.4614 - val_accuracy: 0.7945\n",
      "Epoch 904/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4622 - accuracy: 0.7945 - val_loss: 0.4613 - val_accuracy: 0.7946\n",
      "Epoch 905/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4621 - accuracy: 0.7949 - val_loss: 0.4613 - val_accuracy: 0.7948\n",
      "Epoch 906/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4621 - accuracy: 0.7951 - val_loss: 0.4613 - val_accuracy: 0.7948\n",
      "Epoch 907/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4620 - accuracy: 0.7949 - val_loss: 0.4613 - val_accuracy: 0.7951\n",
      "Epoch 908/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4619 - accuracy: 0.7952 - val_loss: 0.4612 - val_accuracy: 0.7942\n",
      "Epoch 909/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4619 - accuracy: 0.7954 - val_loss: 0.4611 - val_accuracy: 0.7949\n",
      "Epoch 910/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4618 - accuracy: 0.7951 - val_loss: 0.4611 - val_accuracy: 0.7948\n",
      "Epoch 911/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4618 - accuracy: 0.7955 - val_loss: 0.4609 - val_accuracy: 0.7947\n",
      "Epoch 912/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4617 - accuracy: 0.7950 - val_loss: 0.4610 - val_accuracy: 0.7951\n",
      "Epoch 913/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4617 - accuracy: 0.7952 - val_loss: 0.4609 - val_accuracy: 0.7950\n",
      "Epoch 914/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4616 - accuracy: 0.7952 - val_loss: 0.4609 - val_accuracy: 0.7946\n",
      "Epoch 915/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4615 - accuracy: 0.7953 - val_loss: 0.4607 - val_accuracy: 0.7945\n",
      "Epoch 916/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4615 - accuracy: 0.7950 - val_loss: 0.4607 - val_accuracy: 0.7950\n",
      "Epoch 917/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4615 - accuracy: 0.7952 - val_loss: 0.4607 - val_accuracy: 0.7953\n",
      "Epoch 918/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4614 - accuracy: 0.7955 - val_loss: 0.4606 - val_accuracy: 0.7949\n",
      "Epoch 919/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4614 - accuracy: 0.7955 - val_loss: 0.4606 - val_accuracy: 0.7949\n",
      "Epoch 920/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4613 - accuracy: 0.7955 - val_loss: 0.4605 - val_accuracy: 0.7952\n",
      "Epoch 921/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4612 - accuracy: 0.7955 - val_loss: 0.4604 - val_accuracy: 0.7948\n",
      "Epoch 922/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4612 - accuracy: 0.7954 - val_loss: 0.4604 - val_accuracy: 0.7947\n",
      "Epoch 923/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4611 - accuracy: 0.7954 - val_loss: 0.4604 - val_accuracy: 0.7956\n",
      "Epoch 924/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4611 - accuracy: 0.7959 - val_loss: 0.4605 - val_accuracy: 0.7958\n",
      "Epoch 925/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4610 - accuracy: 0.7960 - val_loss: 0.4603 - val_accuracy: 0.7955\n",
      "Epoch 926/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4610 - accuracy: 0.7959 - val_loss: 0.4602 - val_accuracy: 0.7955\n",
      "Epoch 927/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4609 - accuracy: 0.7963 - val_loss: 0.4603 - val_accuracy: 0.7952\n",
      "Epoch 928/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4608 - accuracy: 0.7961 - val_loss: 0.4601 - val_accuracy: 0.7951\n",
      "Epoch 929/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4608 - accuracy: 0.7957 - val_loss: 0.4601 - val_accuracy: 0.7957\n",
      "Epoch 930/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4607 - accuracy: 0.7958 - val_loss: 0.4600 - val_accuracy: 0.7959\n",
      "Epoch 931/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4607 - accuracy: 0.7962 - val_loss: 0.4600 - val_accuracy: 0.7955\n",
      "Epoch 932/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4606 - accuracy: 0.7963 - val_loss: 0.4601 - val_accuracy: 0.7956\n",
      "Epoch 933/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4606 - accuracy: 0.7962 - val_loss: 0.4599 - val_accuracy: 0.7957\n",
      "Epoch 934/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4605 - accuracy: 0.7962 - val_loss: 0.4599 - val_accuracy: 0.7952\n",
      "Epoch 935/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4605 - accuracy: 0.7963 - val_loss: 0.4599 - val_accuracy: 0.7956\n",
      "Epoch 936/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4604 - accuracy: 0.7964 - val_loss: 0.4597 - val_accuracy: 0.7956\n",
      "Epoch 937/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4603 - accuracy: 0.7963 - val_loss: 0.4597 - val_accuracy: 0.7951\n",
      "Epoch 938/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4603 - accuracy: 0.7961 - val_loss: 0.4597 - val_accuracy: 0.7960\n",
      "Epoch 939/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4602 - accuracy: 0.7965 - val_loss: 0.4596 - val_accuracy: 0.7953\n",
      "Epoch 940/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4602 - accuracy: 0.7963 - val_loss: 0.4596 - val_accuracy: 0.7958\n",
      "Epoch 941/1000\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.4602 - accuracy: 0.79 - 1s 5ms/step - loss: 0.4601 - accuracy: 0.7966 - val_loss: 0.4596 - val_accuracy: 0.7957\n",
      "Epoch 942/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4601 - accuracy: 0.7963 - val_loss: 0.4596 - val_accuracy: 0.7959\n",
      "Epoch 943/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4600 - accuracy: 0.7966 - val_loss: 0.4596 - val_accuracy: 0.7957\n",
      "Epoch 944/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4599 - accuracy: 0.7967 - val_loss: 0.4594 - val_accuracy: 0.7955\n",
      "Epoch 945/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4599 - accuracy: 0.7964 - val_loss: 0.4593 - val_accuracy: 0.7957\n",
      "Epoch 946/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4598 - accuracy: 0.7963 - val_loss: 0.4593 - val_accuracy: 0.7959\n",
      "Epoch 947/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4598 - accuracy: 0.7968 - val_loss: 0.4592 - val_accuracy: 0.7960\n",
      "Epoch 948/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4597 - accuracy: 0.7967 - val_loss: 0.4592 - val_accuracy: 0.7959\n",
      "Epoch 949/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4597 - accuracy: 0.7968 - val_loss: 0.4591 - val_accuracy: 0.7961\n",
      "Epoch 950/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4596 - accuracy: 0.7968 - val_loss: 0.4590 - val_accuracy: 0.7957\n",
      "Epoch 951/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4596 - accuracy: 0.7964 - val_loss: 0.4590 - val_accuracy: 0.7960\n",
      "Epoch 952/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4595 - accuracy: 0.7966 - val_loss: 0.4590 - val_accuracy: 0.7957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 953/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4595 - accuracy: 0.7968 - val_loss: 0.4590 - val_accuracy: 0.7959\n",
      "Epoch 954/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4594 - accuracy: 0.7970 - val_loss: 0.4590 - val_accuracy: 0.7960\n",
      "Epoch 955/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4594 - accuracy: 0.7969 - val_loss: 0.4588 - val_accuracy: 0.7959\n",
      "Epoch 956/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4593 - accuracy: 0.7967 - val_loss: 0.4589 - val_accuracy: 0.7961\n",
      "Epoch 957/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4593 - accuracy: 0.7969 - val_loss: 0.4587 - val_accuracy: 0.7960\n",
      "Epoch 958/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4592 - accuracy: 0.7968 - val_loss: 0.4587 - val_accuracy: 0.7961\n",
      "Epoch 959/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4592 - accuracy: 0.7970 - val_loss: 0.4587 - val_accuracy: 0.7960\n",
      "Epoch 960/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4591 - accuracy: 0.7970 - val_loss: 0.4586 - val_accuracy: 0.7959\n",
      "Epoch 961/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4591 - accuracy: 0.7969 - val_loss: 0.4585 - val_accuracy: 0.7959\n",
      "Epoch 962/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4590 - accuracy: 0.7970 - val_loss: 0.4584 - val_accuracy: 0.7961\n",
      "Epoch 963/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4590 - accuracy: 0.7970 - val_loss: 0.4585 - val_accuracy: 0.7962\n",
      "Epoch 964/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4589 - accuracy: 0.7971 - val_loss: 0.4585 - val_accuracy: 0.7968\n",
      "Epoch 965/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4589 - accuracy: 0.7971 - val_loss: 0.4583 - val_accuracy: 0.7953\n",
      "Epoch 966/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4588 - accuracy: 0.7971 - val_loss: 0.4583 - val_accuracy: 0.7959\n",
      "Epoch 967/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4588 - accuracy: 0.7971 - val_loss: 0.4584 - val_accuracy: 0.7966\n",
      "Epoch 968/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4587 - accuracy: 0.7972 - val_loss: 0.4583 - val_accuracy: 0.7961\n",
      "Epoch 969/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4587 - accuracy: 0.7973 - val_loss: 0.4582 - val_accuracy: 0.7962\n",
      "Epoch 970/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4586 - accuracy: 0.7973 - val_loss: 0.4582 - val_accuracy: 0.7963\n",
      "Epoch 971/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4586 - accuracy: 0.7972 - val_loss: 0.4581 - val_accuracy: 0.7964\n",
      "Epoch 972/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4585 - accuracy: 0.7974 - val_loss: 0.4581 - val_accuracy: 0.7962\n",
      "Epoch 973/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4585 - accuracy: 0.7974 - val_loss: 0.4579 - val_accuracy: 0.7961\n",
      "Epoch 974/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4584 - accuracy: 0.7974 - val_loss: 0.4580 - val_accuracy: 0.7964\n",
      "Epoch 975/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4584 - accuracy: 0.7975 - val_loss: 0.4579 - val_accuracy: 0.7964\n",
      "Epoch 976/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4583 - accuracy: 0.7975 - val_loss: 0.4579 - val_accuracy: 0.7966\n",
      "Epoch 977/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4583 - accuracy: 0.7976 - val_loss: 0.4579 - val_accuracy: 0.7968\n",
      "Epoch 978/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4582 - accuracy: 0.7975 - val_loss: 0.4578 - val_accuracy: 0.7960\n",
      "Epoch 979/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4582 - accuracy: 0.7976 - val_loss: 0.4577 - val_accuracy: 0.7966\n",
      "Epoch 980/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4581 - accuracy: 0.7978 - val_loss: 0.4577 - val_accuracy: 0.7963\n",
      "Epoch 981/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4581 - accuracy: 0.7973 - val_loss: 0.4577 - val_accuracy: 0.7966\n",
      "Epoch 982/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4580 - accuracy: 0.7976 - val_loss: 0.4577 - val_accuracy: 0.7967\n",
      "Epoch 983/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4580 - accuracy: 0.7976 - val_loss: 0.4575 - val_accuracy: 0.7965\n",
      "Epoch 984/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4579 - accuracy: 0.7976 - val_loss: 0.4576 - val_accuracy: 0.7964\n",
      "Epoch 985/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4579 - accuracy: 0.7978 - val_loss: 0.4575 - val_accuracy: 0.7964\n",
      "Epoch 986/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4578 - accuracy: 0.7974 - val_loss: 0.4574 - val_accuracy: 0.7965\n",
      "Epoch 987/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4578 - accuracy: 0.7977 - val_loss: 0.4573 - val_accuracy: 0.7963\n",
      "Epoch 988/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4577 - accuracy: 0.7976 - val_loss: 0.4573 - val_accuracy: 0.7959\n",
      "Epoch 989/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4577 - accuracy: 0.7978 - val_loss: 0.4573 - val_accuracy: 0.7966\n",
      "Epoch 990/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4576 - accuracy: 0.7979 - val_loss: 0.4572 - val_accuracy: 0.7965\n",
      "Epoch 991/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4576 - accuracy: 0.7977 - val_loss: 0.4572 - val_accuracy: 0.7969\n",
      "Epoch 992/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4575 - accuracy: 0.7978 - val_loss: 0.4571 - val_accuracy: 0.7966\n",
      "Epoch 993/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4575 - accuracy: 0.7977 - val_loss: 0.4572 - val_accuracy: 0.7966\n",
      "Epoch 994/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4574 - accuracy: 0.7978 - val_loss: 0.4571 - val_accuracy: 0.7966\n",
      "Epoch 995/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4574 - accuracy: 0.7979 - val_loss: 0.4570 - val_accuracy: 0.7964\n",
      "Epoch 996/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4573 - accuracy: 0.7979 - val_loss: 0.4570 - val_accuracy: 0.7968\n",
      "Epoch 997/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4573 - accuracy: 0.7983 - val_loss: 0.4569 - val_accuracy: 0.7963\n",
      "Epoch 998/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4572 - accuracy: 0.7978 - val_loss: 0.4569 - val_accuracy: 0.7967\n",
      "Epoch 999/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4572 - accuracy: 0.7979 - val_loss: 0.4568 - val_accuracy: 0.7966\n",
      "Epoch 1000/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4571 - accuracy: 0.7979 - val_loss: 0.4568 - val_accuracy: 0.7965\n",
      "Epoch 1/1000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.5854 - accuracy: 0.7153 - val_loss: 0.5752 - val_accuracy: 0.7165\n",
      "Epoch 2/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5736 - accuracy: 0.7155 - val_loss: 0.5684 - val_accuracy: 0.7168\n",
      "Epoch 3/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5673 - accuracy: 0.7161 - val_loss: 0.5615 - val_accuracy: 0.7175\n",
      "Epoch 4/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5593 - accuracy: 0.7168 - val_loss: 0.5546 - val_accuracy: 0.7174\n",
      "Epoch 5/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5544 - accuracy: 0.7170 - val_loss: 0.5504 - val_accuracy: 0.7179\n",
      "Epoch 6/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5503 - accuracy: 0.7176 - val_loss: 0.5459 - val_accuracy: 0.7182\n",
      "Epoch 7/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5465 - accuracy: 0.7184 - val_loss: 0.5425 - val_accuracy: 0.7188\n",
      "Epoch 8/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5432 - accuracy: 0.7197 - val_loss: 0.5397 - val_accuracy: 0.7195\n",
      "Epoch 9/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5401 - accuracy: 0.7205 - val_loss: 0.5360 - val_accuracy: 0.7214\n",
      "Epoch 10/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5370 - accuracy: 0.7218 - val_loss: 0.5337 - val_accuracy: 0.7224\n",
      "Epoch 11/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5344 - accuracy: 0.7229 - val_loss: 0.5308 - val_accuracy: 0.7247\n",
      "Epoch 12/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5319 - accuracy: 0.7241 - val_loss: 0.5286 - val_accuracy: 0.7246\n",
      "Epoch 13/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5294 - accuracy: 0.7257 - val_loss: 0.5265 - val_accuracy: 0.7258\n",
      "Epoch 14/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5271 - accuracy: 0.7275 - val_loss: 0.5247 - val_accuracy: 0.7287\n",
      "Epoch 15/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5248 - accuracy: 0.7284 - val_loss: 0.5214 - val_accuracy: 0.7299\n",
      "Epoch 16/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5227 - accuracy: 0.7300 - val_loss: 0.5194 - val_accuracy: 0.7327\n",
      "Epoch 17/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5208 - accuracy: 0.7316 - val_loss: 0.5173 - val_accuracy: 0.7319\n",
      "Epoch 18/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5190 - accuracy: 0.7321 - val_loss: 0.5158 - val_accuracy: 0.7351\n",
      "Epoch 19/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5170 - accuracy: 0.7348 - val_loss: 0.5144 - val_accuracy: 0.7349\n",
      "Epoch 20/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5154 - accuracy: 0.7361 - val_loss: 0.5133 - val_accuracy: 0.7348\n",
      "Epoch 21/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5138 - accuracy: 0.7377 - val_loss: 0.5117 - val_accuracy: 0.7375\n",
      "Epoch 22/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5122 - accuracy: 0.7389 - val_loss: 0.5097 - val_accuracy: 0.7399\n",
      "Epoch 23/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5107 - accuracy: 0.7410 - val_loss: 0.5076 - val_accuracy: 0.7410\n",
      "Epoch 24/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5093 - accuracy: 0.7422 - val_loss: 0.5072 - val_accuracy: 0.7406\n",
      "Epoch 25/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5082 - accuracy: 0.7438 - val_loss: 0.5050 - val_accuracy: 0.7428\n",
      "Epoch 26/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5068 - accuracy: 0.7447 - val_loss: 0.5045 - val_accuracy: 0.7452\n",
      "Epoch 27/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5054 - accuracy: 0.7462 - val_loss: 0.5031 - val_accuracy: 0.7465\n",
      "Epoch 28/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5041 - accuracy: 0.7475 - val_loss: 0.5022 - val_accuracy: 0.7485\n",
      "Epoch 29/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5030 - accuracy: 0.7484 - val_loss: 0.5019 - val_accuracy: 0.7468\n",
      "Epoch 30/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5018 - accuracy: 0.7499 - val_loss: 0.4995 - val_accuracy: 0.7489\n",
      "Epoch 31/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5008 - accuracy: 0.7508 - val_loss: 0.4984 - val_accuracy: 0.7514\n",
      "Epoch 32/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4997 - accuracy: 0.7525 - val_loss: 0.4977 - val_accuracy: 0.7495\n",
      "Epoch 33/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4987 - accuracy: 0.7543 - val_loss: 0.4962 - val_accuracy: 0.7522\n",
      "Epoch 34/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4976 - accuracy: 0.7554 - val_loss: 0.4947 - val_accuracy: 0.7545\n",
      "Epoch 35/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4968 - accuracy: 0.7555 - val_loss: 0.4945 - val_accuracy: 0.7544\n",
      "Epoch 36/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4957 - accuracy: 0.7566 - val_loss: 0.4933 - val_accuracy: 0.7602\n",
      "Epoch 37/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4948 - accuracy: 0.7583 - val_loss: 0.4923 - val_accuracy: 0.7601\n",
      "Epoch 38/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4939 - accuracy: 0.7583 - val_loss: 0.4915 - val_accuracy: 0.7620\n",
      "Epoch 39/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4930 - accuracy: 0.7597 - val_loss: 0.4903 - val_accuracy: 0.7582\n",
      "Epoch 40/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4919 - accuracy: 0.7602 - val_loss: 0.4898 - val_accuracy: 0.7628\n",
      "Epoch 41/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4912 - accuracy: 0.7618 - val_loss: 0.4884 - val_accuracy: 0.7624\n",
      "Epoch 42/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4902 - accuracy: 0.7626 - val_loss: 0.4898 - val_accuracy: 0.7632\n",
      "Epoch 43/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4895 - accuracy: 0.7635 - val_loss: 0.4873 - val_accuracy: 0.7660\n",
      "Epoch 44/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4887 - accuracy: 0.7645 - val_loss: 0.4864 - val_accuracy: 0.7657\n",
      "Epoch 45/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4880 - accuracy: 0.7668 - val_loss: 0.4853 - val_accuracy: 0.7648\n",
      "Epoch 46/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4872 - accuracy: 0.7660 - val_loss: 0.4848 - val_accuracy: 0.7671\n",
      "Epoch 47/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4862 - accuracy: 0.7674 - val_loss: 0.4842 - val_accuracy: 0.7671\n",
      "Epoch 48/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4855 - accuracy: 0.7689 - val_loss: 0.4833 - val_accuracy: 0.7665\n",
      "Epoch 49/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4849 - accuracy: 0.7690 - val_loss: 0.4827 - val_accuracy: 0.7683\n",
      "Epoch 50/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4840 - accuracy: 0.7708 - val_loss: 0.4822 - val_accuracy: 0.7712\n",
      "Epoch 51/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4834 - accuracy: 0.7711 - val_loss: 0.4815 - val_accuracy: 0.7711\n",
      "Epoch 52/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4827 - accuracy: 0.7719 - val_loss: 0.4807 - val_accuracy: 0.7713\n",
      "Epoch 53/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4821 - accuracy: 0.7727 - val_loss: 0.4795 - val_accuracy: 0.7718\n",
      "Epoch 54/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4814 - accuracy: 0.7741 - val_loss: 0.4793 - val_accuracy: 0.7692\n",
      "Epoch 55/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4807 - accuracy: 0.7748 - val_loss: 0.4788 - val_accuracy: 0.7732\n",
      "Epoch 56/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4800 - accuracy: 0.7752 - val_loss: 0.4783 - val_accuracy: 0.7721\n",
      "Epoch 57/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4794 - accuracy: 0.7756 - val_loss: 0.4769 - val_accuracy: 0.7744\n",
      "Epoch 58/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4788 - accuracy: 0.7764 - val_loss: 0.4764 - val_accuracy: 0.7755\n",
      "Epoch 59/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4781 - accuracy: 0.7774 - val_loss: 0.4761 - val_accuracy: 0.7755\n",
      "Epoch 60/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4776 - accuracy: 0.7779 - val_loss: 0.4755 - val_accuracy: 0.7775\n",
      "Epoch 61/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4771 - accuracy: 0.7793 - val_loss: 0.4754 - val_accuracy: 0.7751\n",
      "Epoch 62/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4764 - accuracy: 0.7792 - val_loss: 0.4743 - val_accuracy: 0.7789\n",
      "Epoch 63/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4758 - accuracy: 0.7809 - val_loss: 0.4742 - val_accuracy: 0.7765\n",
      "Epoch 64/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4752 - accuracy: 0.7808 - val_loss: 0.4733 - val_accuracy: 0.7837\n",
      "Epoch 65/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4747 - accuracy: 0.7824 - val_loss: 0.4725 - val_accuracy: 0.7811\n",
      "Epoch 66/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4741 - accuracy: 0.7821 - val_loss: 0.4719 - val_accuracy: 0.7812\n",
      "Epoch 67/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4737 - accuracy: 0.7827 - val_loss: 0.4719 - val_accuracy: 0.7827\n",
      "Epoch 68/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4732 - accuracy: 0.7837 - val_loss: 0.4711 - val_accuracy: 0.7813\n",
      "Epoch 69/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4725 - accuracy: 0.7837 - val_loss: 0.4710 - val_accuracy: 0.7796\n",
      "Epoch 70/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4723 - accuracy: 0.7847 - val_loss: 0.4702 - val_accuracy: 0.7798\n",
      "Epoch 71/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4718 - accuracy: 0.7853 - val_loss: 0.4703 - val_accuracy: 0.7814\n",
      "Epoch 72/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4711 - accuracy: 0.7862 - val_loss: 0.4697 - val_accuracy: 0.7816\n",
      "Epoch 73/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4706 - accuracy: 0.7863 - val_loss: 0.4688 - val_accuracy: 0.7842\n",
      "Epoch 74/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4702 - accuracy: 0.7866 - val_loss: 0.4683 - val_accuracy: 0.7851\n",
      "Epoch 75/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4697 - accuracy: 0.7867 - val_loss: 0.4680 - val_accuracy: 0.7854\n",
      "Epoch 76/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4692 - accuracy: 0.7881 - val_loss: 0.4672 - val_accuracy: 0.7860\n",
      "Epoch 77/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4688 - accuracy: 0.7880 - val_loss: 0.4664 - val_accuracy: 0.7881\n",
      "Epoch 78/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4683 - accuracy: 0.7888 - val_loss: 0.4662 - val_accuracy: 0.7858\n",
      "Epoch 79/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4680 - accuracy: 0.7893 - val_loss: 0.4656 - val_accuracy: 0.7879\n",
      "Epoch 80/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4673 - accuracy: 0.7893 - val_loss: 0.4666 - val_accuracy: 0.7870\n",
      "Epoch 81/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4670 - accuracy: 0.7900 - val_loss: 0.4653 - val_accuracy: 0.7911\n",
      "Epoch 82/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4666 - accuracy: 0.7904 - val_loss: 0.4644 - val_accuracy: 0.7904\n",
      "Epoch 83/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4662 - accuracy: 0.7911 - val_loss: 0.4642 - val_accuracy: 0.7886\n",
      "Epoch 84/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4659 - accuracy: 0.7910 - val_loss: 0.4634 - val_accuracy: 0.7912\n",
      "Epoch 85/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4654 - accuracy: 0.7916 - val_loss: 0.4632 - val_accuracy: 0.7899\n",
      "Epoch 86/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4649 - accuracy: 0.7923 - val_loss: 0.4639 - val_accuracy: 0.7929\n",
      "Epoch 87/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4646 - accuracy: 0.7925 - val_loss: 0.4622 - val_accuracy: 0.7919\n",
      "Epoch 88/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4643 - accuracy: 0.7931 - val_loss: 0.4621 - val_accuracy: 0.7924\n",
      "Epoch 89/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4638 - accuracy: 0.7933 - val_loss: 0.4620 - val_accuracy: 0.7908\n",
      "Epoch 90/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4633 - accuracy: 0.7938 - val_loss: 0.4618 - val_accuracy: 0.7913\n",
      "Epoch 91/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4631 - accuracy: 0.7935 - val_loss: 0.4623 - val_accuracy: 0.7965\n",
      "Epoch 92/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4628 - accuracy: 0.7948 - val_loss: 0.4607 - val_accuracy: 0.7947\n",
      "Epoch 93/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4622 - accuracy: 0.7950 - val_loss: 0.4600 - val_accuracy: 0.7954\n",
      "Epoch 94/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4620 - accuracy: 0.7952 - val_loss: 0.4600 - val_accuracy: 0.7976\n",
      "Epoch 95/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4614 - accuracy: 0.7955 - val_loss: 0.4598 - val_accuracy: 0.7940\n",
      "Epoch 96/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4612 - accuracy: 0.7952 - val_loss: 0.4592 - val_accuracy: 0.7937\n",
      "Epoch 97/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4608 - accuracy: 0.7960 - val_loss: 0.4601 - val_accuracy: 0.7977\n",
      "Epoch 98/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4605 - accuracy: 0.7961 - val_loss: 0.4589 - val_accuracy: 0.7943\n",
      "Epoch 99/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4601 - accuracy: 0.7963 - val_loss: 0.4589 - val_accuracy: 0.7976\n",
      "Epoch 100/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4597 - accuracy: 0.7971 - val_loss: 0.4574 - val_accuracy: 0.7970\n",
      "Epoch 101/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4596 - accuracy: 0.7968 - val_loss: 0.4577 - val_accuracy: 0.7945\n",
      "Epoch 102/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4591 - accuracy: 0.7974 - val_loss: 0.4568 - val_accuracy: 0.7989\n",
      "Epoch 103/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4588 - accuracy: 0.7976 - val_loss: 0.4567 - val_accuracy: 0.7974\n",
      "Epoch 104/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4585 - accuracy: 0.7977 - val_loss: 0.4564 - val_accuracy: 0.7964\n",
      "Epoch 105/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4583 - accuracy: 0.7985 - val_loss: 0.4556 - val_accuracy: 0.7988\n",
      "Epoch 106/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4577 - accuracy: 0.7985 - val_loss: 0.4559 - val_accuracy: 0.7960\n",
      "Epoch 107/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4576 - accuracy: 0.7987 - val_loss: 0.4549 - val_accuracy: 0.7990\n",
      "Epoch 108/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4571 - accuracy: 0.7991 - val_loss: 0.4548 - val_accuracy: 0.7991\n",
      "Epoch 109/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4569 - accuracy: 0.7992 - val_loss: 0.4544 - val_accuracy: 0.7998\n",
      "Epoch 110/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4565 - accuracy: 0.7996 - val_loss: 0.4544 - val_accuracy: 0.7993\n",
      "Epoch 111/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4563 - accuracy: 0.7999 - val_loss: 0.4544 - val_accuracy: 0.7978\n",
      "Epoch 112/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4559 - accuracy: 0.7994 - val_loss: 0.4534 - val_accuracy: 0.7994\n",
      "Epoch 113/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4557 - accuracy: 0.7994 - val_loss: 0.4537 - val_accuracy: 0.7991\n",
      "Epoch 114/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4555 - accuracy: 0.7999 - val_loss: 0.4530 - val_accuracy: 0.7994\n",
      "Epoch 115/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4550 - accuracy: 0.8001 - val_loss: 0.4530 - val_accuracy: 0.8005\n",
      "Epoch 116/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4548 - accuracy: 0.8005 - val_loss: 0.4522 - val_accuracy: 0.8018\n",
      "Epoch 117/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4545 - accuracy: 0.8006 - val_loss: 0.4526 - val_accuracy: 0.8000\n",
      "Epoch 118/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4543 - accuracy: 0.8006 - val_loss: 0.4518 - val_accuracy: 0.8015\n",
      "Epoch 119/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4539 - accuracy: 0.8013 - val_loss: 0.4517 - val_accuracy: 0.8005\n",
      "Epoch 120/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4536 - accuracy: 0.8010 - val_loss: 0.4512 - val_accuracy: 0.8027\n",
      "Epoch 121/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4534 - accuracy: 0.8013 - val_loss: 0.4517 - val_accuracy: 0.8002\n",
      "Epoch 122/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4532 - accuracy: 0.8014 - val_loss: 0.4513 - val_accuracy: 0.8010\n",
      "Epoch 123/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4528 - accuracy: 0.8022 - val_loss: 0.4505 - val_accuracy: 0.8017\n",
      "Epoch 124/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4526 - accuracy: 0.8021 - val_loss: 0.4502 - val_accuracy: 0.8032\n",
      "Epoch 125/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4523 - accuracy: 0.8020 - val_loss: 0.4502 - val_accuracy: 0.8028\n",
      "Epoch 126/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4520 - accuracy: 0.8026 - val_loss: 0.4503 - val_accuracy: 0.8016\n",
      "Epoch 127/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4518 - accuracy: 0.8022 - val_loss: 0.4496 - val_accuracy: 0.8023\n",
      "Epoch 128/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4515 - accuracy: 0.8024 - val_loss: 0.4493 - val_accuracy: 0.8036\n",
      "Epoch 129/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4513 - accuracy: 0.8030 - val_loss: 0.4488 - val_accuracy: 0.8043\n",
      "Epoch 130/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4510 - accuracy: 0.8033 - val_loss: 0.4493 - val_accuracy: 0.8022\n",
      "Epoch 131/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4509 - accuracy: 0.8026 - val_loss: 0.4484 - val_accuracy: 0.8043\n",
      "Epoch 132/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4505 - accuracy: 0.8033 - val_loss: 0.4482 - val_accuracy: 0.8039\n",
      "Epoch 133/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4503 - accuracy: 0.8030 - val_loss: 0.4476 - val_accuracy: 0.8036\n",
      "Epoch 134/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4499 - accuracy: 0.8037 - val_loss: 0.4482 - val_accuracy: 0.8029\n",
      "Epoch 135/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4497 - accuracy: 0.8037 - val_loss: 0.4482 - val_accuracy: 0.8038\n",
      "Epoch 136/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4494 - accuracy: 0.8045 - val_loss: 0.4469 - val_accuracy: 0.8056\n",
      "Epoch 137/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4490 - accuracy: 0.8045 - val_loss: 0.4470 - val_accuracy: 0.8035\n",
      "Epoch 138/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4489 - accuracy: 0.8047 - val_loss: 0.4464 - val_accuracy: 0.8051\n",
      "Epoch 139/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4488 - accuracy: 0.8040 - val_loss: 0.4467 - val_accuracy: 0.8061\n",
      "Epoch 140/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4484 - accuracy: 0.8049 - val_loss: 0.4465 - val_accuracy: 0.8058\n",
      "Epoch 141/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4483 - accuracy: 0.8046 - val_loss: 0.4458 - val_accuracy: 0.8060\n",
      "Epoch 142/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4479 - accuracy: 0.8050 - val_loss: 0.4456 - val_accuracy: 0.8044\n",
      "Epoch 143/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4477 - accuracy: 0.8049 - val_loss: 0.4462 - val_accuracy: 0.8053\n",
      "Epoch 144/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4475 - accuracy: 0.8052 - val_loss: 0.4451 - val_accuracy: 0.8072\n",
      "Epoch 145/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4472 - accuracy: 0.8054 - val_loss: 0.4450 - val_accuracy: 0.8064\n",
      "Epoch 146/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4469 - accuracy: 0.8057 - val_loss: 0.4453 - val_accuracy: 0.8055\n",
      "Epoch 147/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4468 - accuracy: 0.8052 - val_loss: 0.4450 - val_accuracy: 0.8067\n",
      "Epoch 148/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4466 - accuracy: 0.8057 - val_loss: 0.4444 - val_accuracy: 0.8059\n",
      "Epoch 149/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4462 - accuracy: 0.8056 - val_loss: 0.4443 - val_accuracy: 0.8066\n",
      "Epoch 150/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4459 - accuracy: 0.8061 - val_loss: 0.4442 - val_accuracy: 0.8076\n",
      "Epoch 151/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4458 - accuracy: 0.8061 - val_loss: 0.4435 - val_accuracy: 0.8071\n",
      "Epoch 152/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4457 - accuracy: 0.8063 - val_loss: 0.4434 - val_accuracy: 0.8074\n",
      "Epoch 153/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4453 - accuracy: 0.8061 - val_loss: 0.4434 - val_accuracy: 0.8062\n",
      "Epoch 154/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4453 - accuracy: 0.8059 - val_loss: 0.4433 - val_accuracy: 0.8081\n",
      "Epoch 155/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4448 - accuracy: 0.8066 - val_loss: 0.4428 - val_accuracy: 0.8076\n",
      "Epoch 156/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4451 - accuracy: 0.8062 - val_loss: 0.4434 - val_accuracy: 0.8076\n",
      "Epoch 157/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4447 - accuracy: 0.8063 - val_loss: 0.4426 - val_accuracy: 0.8069\n",
      "Epoch 158/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4442 - accuracy: 0.8065 - val_loss: 0.4427 - val_accuracy: 0.8076\n",
      "Epoch 159/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4441 - accuracy: 0.8070 - val_loss: 0.4417 - val_accuracy: 0.8071\n",
      "Epoch 160/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4439 - accuracy: 0.8070 - val_loss: 0.4422 - val_accuracy: 0.8072\n",
      "Epoch 161/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4437 - accuracy: 0.8068 - val_loss: 0.4430 - val_accuracy: 0.8097\n",
      "Epoch 162/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4436 - accuracy: 0.8074 - val_loss: 0.4419 - val_accuracy: 0.8079\n",
      "Epoch 163/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4433 - accuracy: 0.8074 - val_loss: 0.4429 - val_accuracy: 0.8056\n",
      "Epoch 164/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4431 - accuracy: 0.8072 - val_loss: 0.4411 - val_accuracy: 0.8085\n",
      "Epoch 165/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4428 - accuracy: 0.8077 - val_loss: 0.4407 - val_accuracy: 0.8074\n",
      "Epoch 166/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4426 - accuracy: 0.8074 - val_loss: 0.4410 - val_accuracy: 0.8093\n",
      "Epoch 167/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4424 - accuracy: 0.8076 - val_loss: 0.4409 - val_accuracy: 0.8086\n",
      "Epoch 168/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4422 - accuracy: 0.8079 - val_loss: 0.4405 - val_accuracy: 0.8072\n",
      "Epoch 169/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4421 - accuracy: 0.8076 - val_loss: 0.4400 - val_accuracy: 0.8089\n",
      "Epoch 170/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4420 - accuracy: 0.8079 - val_loss: 0.4399 - val_accuracy: 0.8088\n",
      "Epoch 171/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4418 - accuracy: 0.8078 - val_loss: 0.4402 - val_accuracy: 0.8091\n",
      "Epoch 172/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4415 - accuracy: 0.8079 - val_loss: 0.4402 - val_accuracy: 0.8090\n",
      "Epoch 173/1000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.4416 - accuracy: 0.8080 - val_loss: 0.4396 - val_accuracy: 0.8085\n",
      "Epoch 174/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4413 - accuracy: 0.8081 - val_loss: 0.4391 - val_accuracy: 0.8095\n",
      "Epoch 175/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4412 - accuracy: 0.8084 - val_loss: 0.4391 - val_accuracy: 0.8105\n",
      "Epoch 176/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4408 - accuracy: 0.8080 - val_loss: 0.4392 - val_accuracy: 0.8090\n",
      "Epoch 177/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4406 - accuracy: 0.8085 - val_loss: 0.4390 - val_accuracy: 0.8087\n",
      "Epoch 178/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4406 - accuracy: 0.8087 - val_loss: 0.4389 - val_accuracy: 0.8086\n",
      "Epoch 179/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4403 - accuracy: 0.8085 - val_loss: 0.4387 - val_accuracy: 0.8083\n",
      "Epoch 180/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4400 - accuracy: 0.8086 - val_loss: 0.4383 - val_accuracy: 0.8094\n",
      "Epoch 181/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4400 - accuracy: 0.8088 - val_loss: 0.4383 - val_accuracy: 0.8085\n",
      "Epoch 182/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4397 - accuracy: 0.8090 - val_loss: 0.4379 - val_accuracy: 0.8081\n",
      "Epoch 183/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4398 - accuracy: 0.8093 - val_loss: 0.4378 - val_accuracy: 0.8096\n",
      "Epoch 184/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4396 - accuracy: 0.8087 - val_loss: 0.4375 - val_accuracy: 0.8100\n",
      "Epoch 185/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4393 - accuracy: 0.8092 - val_loss: 0.4381 - val_accuracy: 0.8084\n",
      "Epoch 186/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4394 - accuracy: 0.8084 - val_loss: 0.4371 - val_accuracy: 0.8097\n",
      "Epoch 187/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4390 - accuracy: 0.8094 - val_loss: 0.4377 - val_accuracy: 0.8086\n",
      "Epoch 188/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4387 - accuracy: 0.8093 - val_loss: 0.4372 - val_accuracy: 0.8096\n",
      "Epoch 189/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4385 - accuracy: 0.8091 - val_loss: 0.4367 - val_accuracy: 0.8102\n",
      "Epoch 190/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4386 - accuracy: 0.8093 - val_loss: 0.4371 - val_accuracy: 0.8089\n",
      "Epoch 191/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4384 - accuracy: 0.8097 - val_loss: 0.4364 - val_accuracy: 0.8098\n",
      "Epoch 192/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4383 - accuracy: 0.8094 - val_loss: 0.4364 - val_accuracy: 0.8107\n",
      "Epoch 193/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4380 - accuracy: 0.8092 - val_loss: 0.4372 - val_accuracy: 0.8094\n",
      "Epoch 194/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4381 - accuracy: 0.8093 - val_loss: 0.4367 - val_accuracy: 0.8085\n",
      "Epoch 195/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4381 - accuracy: 0.8092 - val_loss: 0.4364 - val_accuracy: 0.8102\n",
      "Epoch 196/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4378 - accuracy: 0.8100 - val_loss: 0.4357 - val_accuracy: 0.8097\n",
      "Epoch 197/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4374 - accuracy: 0.8100 - val_loss: 0.4354 - val_accuracy: 0.8102\n",
      "Epoch 198/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4375 - accuracy: 0.8099 - val_loss: 0.4352 - val_accuracy: 0.8094\n",
      "Epoch 199/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4373 - accuracy: 0.8098 - val_loss: 0.4353 - val_accuracy: 0.8104\n",
      "Epoch 200/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4372 - accuracy: 0.8099 - val_loss: 0.4353 - val_accuracy: 0.8099\n",
      "Epoch 201/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4370 - accuracy: 0.8098 - val_loss: 0.4350 - val_accuracy: 0.8107\n",
      "Epoch 202/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4370 - accuracy: 0.8099 - val_loss: 0.4351 - val_accuracy: 0.8096\n",
      "Epoch 203/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4366 - accuracy: 0.8100 - val_loss: 0.4361 - val_accuracy: 0.8086\n",
      "Epoch 204/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4365 - accuracy: 0.8102 - val_loss: 0.4347 - val_accuracy: 0.8107\n",
      "Epoch 205/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4364 - accuracy: 0.8104 - val_loss: 0.4347 - val_accuracy: 0.8105\n",
      "Epoch 206/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4362 - accuracy: 0.8103 - val_loss: 0.4346 - val_accuracy: 0.8112\n",
      "Epoch 207/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4362 - accuracy: 0.8104 - val_loss: 0.4341 - val_accuracy: 0.8096\n",
      "Epoch 208/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4360 - accuracy: 0.8106 - val_loss: 0.4349 - val_accuracy: 0.8101\n",
      "Epoch 209/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4360 - accuracy: 0.8105 - val_loss: 0.4342 - val_accuracy: 0.8107\n",
      "Epoch 210/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4354 - accuracy: 0.8107 - val_loss: 0.4343 - val_accuracy: 0.8100\n",
      "Epoch 211/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4355 - accuracy: 0.8108 - val_loss: 0.4340 - val_accuracy: 0.8103\n",
      "Epoch 212/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4356 - accuracy: 0.8107 - val_loss: 0.4339 - val_accuracy: 0.8103\n",
      "Epoch 213/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4351 - accuracy: 0.8109 - val_loss: 0.4337 - val_accuracy: 0.8113\n",
      "Epoch 214/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4353 - accuracy: 0.8107 - val_loss: 0.4335 - val_accuracy: 0.8103\n",
      "Epoch 215/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4350 - accuracy: 0.8112 - val_loss: 0.4335 - val_accuracy: 0.8111\n",
      "Epoch 216/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4350 - accuracy: 0.8108 - val_loss: 0.4334 - val_accuracy: 0.8109\n",
      "Epoch 217/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4348 - accuracy: 0.8109 - val_loss: 0.4334 - val_accuracy: 0.8107\n",
      "Epoch 218/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4347 - accuracy: 0.8109 - val_loss: 0.4333 - val_accuracy: 0.8112\n",
      "Epoch 219/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4345 - accuracy: 0.8109 - val_loss: 0.4335 - val_accuracy: 0.8105\n",
      "Epoch 220/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4345 - accuracy: 0.8110 - val_loss: 0.4326 - val_accuracy: 0.8113\n",
      "Epoch 221/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4344 - accuracy: 0.8110 - val_loss: 0.4327 - val_accuracy: 0.8105\n",
      "Epoch 222/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4344 - accuracy: 0.8111 - val_loss: 0.4323 - val_accuracy: 0.8110\n",
      "Epoch 223/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4340 - accuracy: 0.8111 - val_loss: 0.4333 - val_accuracy: 0.8097\n",
      "Epoch 224/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4341 - accuracy: 0.8115 - val_loss: 0.4333 - val_accuracy: 0.8109\n",
      "Epoch 225/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4336 - accuracy: 0.8117 - val_loss: 0.4331 - val_accuracy: 0.8100\n",
      "Epoch 226/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4337 - accuracy: 0.8109 - val_loss: 0.4322 - val_accuracy: 0.8103\n",
      "Epoch 227/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4334 - accuracy: 0.8111 - val_loss: 0.4322 - val_accuracy: 0.8109\n",
      "Epoch 228/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4335 - accuracy: 0.8111 - val_loss: 0.4325 - val_accuracy: 0.8102\n",
      "Epoch 229/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4333 - accuracy: 0.8116 - val_loss: 0.4323 - val_accuracy: 0.8113\n",
      "Epoch 230/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4331 - accuracy: 0.8114 - val_loss: 0.4321 - val_accuracy: 0.8104\n",
      "Epoch 231/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4337 - accuracy: 0.8110 - val_loss: 0.4322 - val_accuracy: 0.8110\n",
      "Epoch 232/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4330 - accuracy: 0.8111 - val_loss: 0.4315 - val_accuracy: 0.8112\n",
      "Epoch 233/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4334 - accuracy: 0.8109 - val_loss: 0.4320 - val_accuracy: 0.8114\n",
      "Epoch 234/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4330 - accuracy: 0.8115 - val_loss: 0.4312 - val_accuracy: 0.8110\n",
      "Epoch 235/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4326 - accuracy: 0.8118 - val_loss: 0.4316 - val_accuracy: 0.8110\n",
      "Epoch 236/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4326 - accuracy: 0.8114 - val_loss: 0.4313 - val_accuracy: 0.8105\n",
      "Epoch 237/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4323 - accuracy: 0.8117 - val_loss: 0.4310 - val_accuracy: 0.8113\n",
      "Epoch 238/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4324 - accuracy: 0.8117 - val_loss: 0.4308 - val_accuracy: 0.8108\n",
      "Epoch 239/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4320 - accuracy: 0.8119 - val_loss: 0.4312 - val_accuracy: 0.8102\n",
      "Epoch 240/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4321 - accuracy: 0.8116 - val_loss: 0.4305 - val_accuracy: 0.8114\n",
      "Epoch 241/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4321 - accuracy: 0.8118 - val_loss: 0.4311 - val_accuracy: 0.8106\n",
      "Epoch 242/1000\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.4317 - accuracy: 0.81 - 1s 5ms/step - loss: 0.4320 - accuracy: 0.8118 - val_loss: 0.4308 - val_accuracy: 0.8108\n",
      "Epoch 243/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4320 - accuracy: 0.8116 - val_loss: 0.4310 - val_accuracy: 0.8104\n",
      "Epoch 244/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4315 - accuracy: 0.8120 - val_loss: 0.4303 - val_accuracy: 0.8109\n",
      "Epoch 245/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4316 - accuracy: 0.8116 - val_loss: 0.4306 - val_accuracy: 0.8107\n",
      "Epoch 246/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4315 - accuracy: 0.8118 - val_loss: 0.4307 - val_accuracy: 0.8110\n",
      "Epoch 247/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4315 - accuracy: 0.8122 - val_loss: 0.4301 - val_accuracy: 0.8114\n",
      "Epoch 248/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4314 - accuracy: 0.8115 - val_loss: 0.4305 - val_accuracy: 0.8110\n",
      "Epoch 249/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4312 - accuracy: 0.8117 - val_loss: 0.4297 - val_accuracy: 0.8118\n",
      "Epoch 250/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4312 - accuracy: 0.8121 - val_loss: 0.4299 - val_accuracy: 0.8120\n",
      "Epoch 251/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4311 - accuracy: 0.8118 - val_loss: 0.4300 - val_accuracy: 0.8119\n",
      "Epoch 252/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4309 - accuracy: 0.8119 - val_loss: 0.4297 - val_accuracy: 0.8114\n",
      "Epoch 253/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4309 - accuracy: 0.8120 - val_loss: 0.4299 - val_accuracy: 0.8110\n",
      "Epoch 254/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4307 - accuracy: 0.8123 - val_loss: 0.4295 - val_accuracy: 0.8119\n",
      "Epoch 255/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4308 - accuracy: 0.8126 - val_loss: 0.4300 - val_accuracy: 0.8121\n",
      "Epoch 256/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4306 - accuracy: 0.8118 - val_loss: 0.4294 - val_accuracy: 0.8124\n",
      "Epoch 257/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4304 - accuracy: 0.8123 - val_loss: 0.4294 - val_accuracy: 0.8124\n",
      "Epoch 258/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4307 - accuracy: 0.8123 - val_loss: 0.4292 - val_accuracy: 0.8119\n",
      "Epoch 259/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4305 - accuracy: 0.8124 - val_loss: 0.4296 - val_accuracy: 0.8122\n",
      "Epoch 260/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4304 - accuracy: 0.8125 - val_loss: 0.4294 - val_accuracy: 0.8128\n",
      "Epoch 261/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4303 - accuracy: 0.8123 - val_loss: 0.4289 - val_accuracy: 0.8119\n",
      "Epoch 262/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4300 - accuracy: 0.8125 - val_loss: 0.4297 - val_accuracy: 0.8120\n",
      "Epoch 263/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4299 - accuracy: 0.8125 - val_loss: 0.4297 - val_accuracy: 0.8111\n",
      "Epoch 264/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4299 - accuracy: 0.8124 - val_loss: 0.4293 - val_accuracy: 0.8119\n",
      "Epoch 265/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4302 - accuracy: 0.8121 - val_loss: 0.4289 - val_accuracy: 0.8121\n",
      "Epoch 266/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4296 - accuracy: 0.8124 - val_loss: 0.4295 - val_accuracy: 0.8118\n",
      "Epoch 267/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4296 - accuracy: 0.8125 - val_loss: 0.4286 - val_accuracy: 0.8125\n",
      "Epoch 268/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4297 - accuracy: 0.8124 - val_loss: 0.4289 - val_accuracy: 0.8122\n",
      "Epoch 269/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4294 - accuracy: 0.8122 - val_loss: 0.4283 - val_accuracy: 0.8123\n",
      "Epoch 270/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4295 - accuracy: 0.8125 - val_loss: 0.4287 - val_accuracy: 0.8120\n",
      "Epoch 271/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4292 - accuracy: 0.8125 - val_loss: 0.4286 - val_accuracy: 0.8119\n",
      "Epoch 272/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4293 - accuracy: 0.8127 - val_loss: 0.4280 - val_accuracy: 0.8120\n",
      "Epoch 273/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4291 - accuracy: 0.8129 - val_loss: 0.4282 - val_accuracy: 0.8120\n",
      "Epoch 274/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4289 - accuracy: 0.8128 - val_loss: 0.4281 - val_accuracy: 0.8122\n",
      "Epoch 275/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4287 - accuracy: 0.8127 - val_loss: 0.4279 - val_accuracy: 0.8124\n",
      "Epoch 276/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4288 - accuracy: 0.8130 - val_loss: 0.4275 - val_accuracy: 0.8127\n",
      "Epoch 277/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4287 - accuracy: 0.8129 - val_loss: 0.4278 - val_accuracy: 0.8130\n",
      "Epoch 278/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4286 - accuracy: 0.8131 - val_loss: 0.4281 - val_accuracy: 0.8122\n",
      "Epoch 279/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4286 - accuracy: 0.8131 - val_loss: 0.4288 - val_accuracy: 0.8133\n",
      "Epoch 280/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4286 - accuracy: 0.8128 - val_loss: 0.4280 - val_accuracy: 0.8124\n",
      "Epoch 281/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4283 - accuracy: 0.8129 - val_loss: 0.4279 - val_accuracy: 0.8123\n",
      "Epoch 282/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4285 - accuracy: 0.8125 - val_loss: 0.4275 - val_accuracy: 0.8129\n",
      "Epoch 283/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4280 - accuracy: 0.8133 - val_loss: 0.4272 - val_accuracy: 0.8123\n",
      "Epoch 284/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4282 - accuracy: 0.8129 - val_loss: 0.4278 - val_accuracy: 0.8129\n",
      "Epoch 285/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4284 - accuracy: 0.8131 - val_loss: 0.4274 - val_accuracy: 0.8126\n",
      "Epoch 286/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4280 - accuracy: 0.8134 - val_loss: 0.4272 - val_accuracy: 0.8119\n",
      "Epoch 287/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4280 - accuracy: 0.8136 - val_loss: 0.4271 - val_accuracy: 0.8128\n",
      "Epoch 288/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4279 - accuracy: 0.8133 - val_loss: 0.4274 - val_accuracy: 0.8122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 289/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4277 - accuracy: 0.8132 - val_loss: 0.4274 - val_accuracy: 0.8139\n",
      "Epoch 290/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4279 - accuracy: 0.8129 - val_loss: 0.4269 - val_accuracy: 0.8132\n",
      "Epoch 291/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4277 - accuracy: 0.8133 - val_loss: 0.4269 - val_accuracy: 0.8127\n",
      "Epoch 292/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4276 - accuracy: 0.8131 - val_loss: 0.4270 - val_accuracy: 0.8127\n",
      "Epoch 293/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4275 - accuracy: 0.8136 - val_loss: 0.4270 - val_accuracy: 0.8131\n",
      "Epoch 294/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4274 - accuracy: 0.8134 - val_loss: 0.4266 - val_accuracy: 0.8124\n",
      "Epoch 295/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4274 - accuracy: 0.8129 - val_loss: 0.4267 - val_accuracy: 0.8128\n",
      "Epoch 296/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4272 - accuracy: 0.8133 - val_loss: 0.4266 - val_accuracy: 0.8129\n",
      "Epoch 297/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4272 - accuracy: 0.8128 - val_loss: 0.4261 - val_accuracy: 0.8130\n",
      "Epoch 298/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4270 - accuracy: 0.8137 - val_loss: 0.4265 - val_accuracy: 0.8127\n",
      "Epoch 299/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4268 - accuracy: 0.8138 - val_loss: 0.4273 - val_accuracy: 0.8137\n",
      "Epoch 300/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4270 - accuracy: 0.8134 - val_loss: 0.4262 - val_accuracy: 0.8136\n",
      "Epoch 301/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4268 - accuracy: 0.8137 - val_loss: 0.4264 - val_accuracy: 0.8130\n",
      "Epoch 302/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4269 - accuracy: 0.8130 - val_loss: 0.4264 - val_accuracy: 0.8128\n",
      "Epoch 303/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4271 - accuracy: 0.8135 - val_loss: 0.4260 - val_accuracy: 0.8130\n",
      "Epoch 304/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4267 - accuracy: 0.8137 - val_loss: 0.4262 - val_accuracy: 0.8134\n",
      "Epoch 305/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4266 - accuracy: 0.8140 - val_loss: 0.4262 - val_accuracy: 0.8132\n",
      "Epoch 306/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4266 - accuracy: 0.8138 - val_loss: 0.4267 - val_accuracy: 0.8128\n",
      "Epoch 307/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4264 - accuracy: 0.8139 - val_loss: 0.4262 - val_accuracy: 0.8123\n",
      "Epoch 308/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4263 - accuracy: 0.8141 - val_loss: 0.4264 - val_accuracy: 0.8130\n",
      "Epoch 309/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4262 - accuracy: 0.8136 - val_loss: 0.4266 - val_accuracy: 0.8134\n",
      "Epoch 310/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4261 - accuracy: 0.8139 - val_loss: 0.4257 - val_accuracy: 0.8125\n",
      "Epoch 311/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4266 - accuracy: 0.8132 - val_loss: 0.4257 - val_accuracy: 0.8136\n",
      "Epoch 312/1000\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.4262 - accuracy: 0.81 - 1s 5ms/step - loss: 0.4261 - accuracy: 0.8139 - val_loss: 0.4256 - val_accuracy: 0.8134\n",
      "Epoch 313/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4262 - accuracy: 0.8137 - val_loss: 0.4259 - val_accuracy: 0.8142\n",
      "Epoch 314/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4261 - accuracy: 0.8139 - val_loss: 0.4258 - val_accuracy: 0.8132\n",
      "Epoch 315/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4259 - accuracy: 0.8142 - val_loss: 0.4262 - val_accuracy: 0.8130\n",
      "Epoch 316/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4262 - accuracy: 0.8138 - val_loss: 0.4253 - val_accuracy: 0.8133\n",
      "Epoch 317/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4261 - accuracy: 0.8134 - val_loss: 0.4252 - val_accuracy: 0.8138\n",
      "Epoch 318/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4258 - accuracy: 0.8142 - val_loss: 0.4254 - val_accuracy: 0.8138\n",
      "Epoch 319/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4259 - accuracy: 0.8138 - val_loss: 0.4253 - val_accuracy: 0.8131\n",
      "Epoch 320/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4257 - accuracy: 0.8143 - val_loss: 0.4252 - val_accuracy: 0.8136\n",
      "Epoch 321/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4257 - accuracy: 0.8146 - val_loss: 0.4247 - val_accuracy: 0.8137\n",
      "Epoch 322/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4256 - accuracy: 0.8140 - val_loss: 0.4249 - val_accuracy: 0.8141\n",
      "Epoch 323/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4258 - accuracy: 0.8139 - val_loss: 0.4252 - val_accuracy: 0.8136\n",
      "Epoch 324/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4255 - accuracy: 0.8140 - val_loss: 0.4249 - val_accuracy: 0.8136\n",
      "Epoch 325/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4252 - accuracy: 0.8142 - val_loss: 0.4247 - val_accuracy: 0.8145\n",
      "Epoch 326/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4253 - accuracy: 0.8140 - val_loss: 0.4249 - val_accuracy: 0.8137\n",
      "Epoch 327/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4252 - accuracy: 0.8143 - val_loss: 0.4251 - val_accuracy: 0.8137\n",
      "Epoch 328/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4251 - accuracy: 0.8143 - val_loss: 0.4251 - val_accuracy: 0.8138\n",
      "Epoch 329/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4252 - accuracy: 0.8139 - val_loss: 0.4251 - val_accuracy: 0.8131\n",
      "Epoch 330/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4250 - accuracy: 0.8143 - val_loss: 0.4257 - val_accuracy: 0.8128\n",
      "Epoch 331/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4250 - accuracy: 0.8146 - val_loss: 0.4247 - val_accuracy: 0.8137\n",
      "Epoch 332/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4252 - accuracy: 0.8145 - val_loss: 0.4249 - val_accuracy: 0.8139\n",
      "Epoch 333/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4246 - accuracy: 0.8144 - val_loss: 0.4243 - val_accuracy: 0.8140\n",
      "Epoch 334/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4250 - accuracy: 0.8141 - val_loss: 0.4243 - val_accuracy: 0.8140\n",
      "Epoch 335/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4247 - accuracy: 0.8146 - val_loss: 0.4249 - val_accuracy: 0.8138\n",
      "Epoch 336/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4248 - accuracy: 0.8144 - val_loss: 0.4243 - val_accuracy: 0.8139\n",
      "Epoch 337/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4246 - accuracy: 0.8141 - val_loss: 0.4249 - val_accuracy: 0.8136\n",
      "Epoch 338/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4247 - accuracy: 0.8142 - val_loss: 0.4246 - val_accuracy: 0.8134\n",
      "Epoch 339/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4245 - accuracy: 0.8140 - val_loss: 0.4242 - val_accuracy: 0.8136\n",
      "Epoch 340/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4244 - accuracy: 0.8144 - val_loss: 0.4241 - val_accuracy: 0.8138\n",
      "Epoch 341/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4243 - accuracy: 0.8146 - val_loss: 0.4243 - val_accuracy: 0.8140\n",
      "Epoch 342/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4243 - accuracy: 0.8150 - val_loss: 0.4239 - val_accuracy: 0.8142\n",
      "Epoch 343/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4240 - accuracy: 0.8146 - val_loss: 0.4244 - val_accuracy: 0.8127\n",
      "Epoch 344/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4241 - accuracy: 0.8146 - val_loss: 0.4242 - val_accuracy: 0.8141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 345/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4241 - accuracy: 0.8144 - val_loss: 0.4241 - val_accuracy: 0.8136\n",
      "Epoch 346/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4239 - accuracy: 0.8144 - val_loss: 0.4240 - val_accuracy: 0.8141\n",
      "Epoch 347/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4243 - accuracy: 0.8143 - val_loss: 0.4241 - val_accuracy: 0.8140\n",
      "Epoch 348/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4240 - accuracy: 0.8148 - val_loss: 0.4242 - val_accuracy: 0.8140\n",
      "Epoch 349/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4239 - accuracy: 0.8145 - val_loss: 0.4235 - val_accuracy: 0.8134\n",
      "Epoch 350/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4240 - accuracy: 0.8147 - val_loss: 0.4241 - val_accuracy: 0.8142\n",
      "Epoch 351/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4242 - accuracy: 0.8143 - val_loss: 0.4243 - val_accuracy: 0.8137\n",
      "Epoch 352/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4238 - accuracy: 0.8148 - val_loss: 0.4242 - val_accuracy: 0.8139\n",
      "Epoch 353/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4239 - accuracy: 0.8146 - val_loss: 0.4237 - val_accuracy: 0.8141\n",
      "Epoch 354/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4238 - accuracy: 0.8147 - val_loss: 0.4241 - val_accuracy: 0.8136\n",
      "Epoch 355/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4236 - accuracy: 0.8150 - val_loss: 0.4238 - val_accuracy: 0.8142\n",
      "Epoch 356/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4236 - accuracy: 0.8146 - val_loss: 0.4234 - val_accuracy: 0.8139\n",
      "Epoch 357/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4235 - accuracy: 0.8142 - val_loss: 0.4239 - val_accuracy: 0.8134\n",
      "Epoch 358/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4233 - accuracy: 0.8148 - val_loss: 0.4240 - val_accuracy: 0.8140\n",
      "Epoch 359/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4234 - accuracy: 0.8151 - val_loss: 0.4239 - val_accuracy: 0.8149\n",
      "Epoch 360/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4236 - accuracy: 0.8146 - val_loss: 0.4238 - val_accuracy: 0.8135\n",
      "Epoch 361/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4232 - accuracy: 0.8151 - val_loss: 0.4233 - val_accuracy: 0.8149\n",
      "Epoch 362/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4232 - accuracy: 0.8148 - val_loss: 0.4237 - val_accuracy: 0.8141\n",
      "Epoch 363/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4233 - accuracy: 0.8147 - val_loss: 0.4233 - val_accuracy: 0.8138\n",
      "Epoch 364/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4230 - accuracy: 0.8150 - val_loss: 0.4232 - val_accuracy: 0.8144\n",
      "Epoch 365/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4232 - accuracy: 0.8148 - val_loss: 0.4232 - val_accuracy: 0.8144\n",
      "Epoch 366/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4229 - accuracy: 0.8146 - val_loss: 0.4239 - val_accuracy: 0.8131\n",
      "Epoch 367/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4229 - accuracy: 0.8150 - val_loss: 0.4239 - val_accuracy: 0.8140\n",
      "Epoch 368/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4227 - accuracy: 0.8150 - val_loss: 0.4232 - val_accuracy: 0.8144\n",
      "Epoch 369/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4226 - accuracy: 0.8151 - val_loss: 0.4232 - val_accuracy: 0.8138\n",
      "Epoch 370/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4227 - accuracy: 0.8151 - val_loss: 0.4231 - val_accuracy: 0.8140\n",
      "Epoch 371/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4228 - accuracy: 0.8151 - val_loss: 0.4231 - val_accuracy: 0.8148\n",
      "Epoch 372/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4226 - accuracy: 0.8152 - val_loss: 0.4229 - val_accuracy: 0.8143\n",
      "Epoch 373/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4226 - accuracy: 0.8151 - val_loss: 0.4225 - val_accuracy: 0.8148\n",
      "Epoch 374/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4223 - accuracy: 0.8154 - val_loss: 0.4229 - val_accuracy: 0.8145\n",
      "Epoch 375/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4224 - accuracy: 0.8155 - val_loss: 0.4229 - val_accuracy: 0.8143\n",
      "Epoch 376/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4223 - accuracy: 0.8152 - val_loss: 0.4230 - val_accuracy: 0.8139\n",
      "Epoch 377/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4225 - accuracy: 0.8151 - val_loss: 0.4228 - val_accuracy: 0.8141\n",
      "Epoch 378/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4228 - accuracy: 0.8146 - val_loss: 0.4226 - val_accuracy: 0.8141\n",
      "Epoch 379/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4220 - accuracy: 0.8152 - val_loss: 0.4227 - val_accuracy: 0.8145\n",
      "Epoch 380/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4220 - accuracy: 0.8153 - val_loss: 0.4228 - val_accuracy: 0.8144\n",
      "Epoch 381/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4224 - accuracy: 0.8149 - val_loss: 0.4226 - val_accuracy: 0.8147\n",
      "Epoch 382/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4220 - accuracy: 0.8153 - val_loss: 0.4229 - val_accuracy: 0.8147\n",
      "Epoch 383/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4220 - accuracy: 0.8157 - val_loss: 0.4223 - val_accuracy: 0.8146\n",
      "Epoch 384/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4220 - accuracy: 0.8156 - val_loss: 0.4230 - val_accuracy: 0.8139\n",
      "Epoch 385/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4221 - accuracy: 0.8155 - val_loss: 0.4221 - val_accuracy: 0.8147\n",
      "Epoch 386/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4221 - accuracy: 0.8152 - val_loss: 0.4223 - val_accuracy: 0.8144\n",
      "Epoch 387/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4216 - accuracy: 0.8156 - val_loss: 0.4223 - val_accuracy: 0.8144\n",
      "Epoch 388/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4219 - accuracy: 0.8152 - val_loss: 0.4224 - val_accuracy: 0.8146\n",
      "Epoch 389/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4217 - accuracy: 0.8151 - val_loss: 0.4231 - val_accuracy: 0.8142\n",
      "Epoch 390/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4220 - accuracy: 0.8150 - val_loss: 0.4220 - val_accuracy: 0.8152\n",
      "Epoch 391/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4217 - accuracy: 0.8153 - val_loss: 0.4222 - val_accuracy: 0.8153\n",
      "Epoch 392/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4215 - accuracy: 0.8154 - val_loss: 0.4228 - val_accuracy: 0.8135\n",
      "Epoch 393/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4218 - accuracy: 0.8154 - val_loss: 0.4223 - val_accuracy: 0.8140\n",
      "Epoch 394/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4213 - accuracy: 0.8153 - val_loss: 0.4219 - val_accuracy: 0.8146\n",
      "Epoch 395/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4214 - accuracy: 0.8152 - val_loss: 0.4226 - val_accuracy: 0.8139\n",
      "Epoch 396/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4213 - accuracy: 0.8154 - val_loss: 0.4220 - val_accuracy: 0.8151\n",
      "Epoch 397/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4214 - accuracy: 0.8159 - val_loss: 0.4224 - val_accuracy: 0.8147\n",
      "Epoch 398/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4213 - accuracy: 0.8156 - val_loss: 0.4221 - val_accuracy: 0.8143\n",
      "Epoch 399/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4212 - accuracy: 0.8156 - val_loss: 0.4219 - val_accuracy: 0.8143\n",
      "Epoch 400/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4211 - accuracy: 0.8158 - val_loss: 0.4218 - val_accuracy: 0.8147\n",
      "Epoch 401/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4210 - accuracy: 0.8156 - val_loss: 0.4220 - val_accuracy: 0.8146\n",
      "Epoch 402/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4212 - accuracy: 0.8154 - val_loss: 0.4223 - val_accuracy: 0.8147\n",
      "Epoch 403/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4209 - accuracy: 0.8159 - val_loss: 0.4217 - val_accuracy: 0.8148\n",
      "Epoch 404/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4209 - accuracy: 0.8156 - val_loss: 0.4217 - val_accuracy: 0.8144\n",
      "Epoch 405/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4209 - accuracy: 0.8156 - val_loss: 0.4216 - val_accuracy: 0.8153\n",
      "Epoch 406/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4208 - accuracy: 0.8153 - val_loss: 0.4222 - val_accuracy: 0.8142\n",
      "Epoch 407/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4208 - accuracy: 0.8155 - val_loss: 0.4220 - val_accuracy: 0.8142\n",
      "Epoch 408/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4208 - accuracy: 0.8156 - val_loss: 0.4221 - val_accuracy: 0.8140\n",
      "Epoch 409/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4209 - accuracy: 0.8155 - val_loss: 0.4218 - val_accuracy: 0.8146\n",
      "Epoch 410/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4206 - accuracy: 0.8156 - val_loss: 0.4218 - val_accuracy: 0.8146\n",
      "Epoch 411/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4207 - accuracy: 0.8157 - val_loss: 0.4221 - val_accuracy: 0.8141\n",
      "Epoch 412/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4207 - accuracy: 0.8157 - val_loss: 0.4218 - val_accuracy: 0.8145\n",
      "Epoch 413/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4210 - accuracy: 0.8154 - val_loss: 0.4217 - val_accuracy: 0.8148\n",
      "Epoch 414/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4204 - accuracy: 0.8158 - val_loss: 0.4217 - val_accuracy: 0.8144\n",
      "Epoch 415/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4204 - accuracy: 0.8158 - val_loss: 0.4217 - val_accuracy: 0.8141\n",
      "Epoch 416/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4205 - accuracy: 0.8157 - val_loss: 0.4216 - val_accuracy: 0.8147\n",
      "Epoch 417/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4204 - accuracy: 0.8157 - val_loss: 0.4215 - val_accuracy: 0.8150\n",
      "Epoch 418/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4205 - accuracy: 0.8158 - val_loss: 0.4214 - val_accuracy: 0.8144\n",
      "Epoch 419/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4201 - accuracy: 0.8161 - val_loss: 0.4215 - val_accuracy: 0.8147\n",
      "Epoch 420/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4203 - accuracy: 0.8160 - val_loss: 0.4213 - val_accuracy: 0.8143\n",
      "Epoch 421/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4202 - accuracy: 0.8160 - val_loss: 0.4220 - val_accuracy: 0.8140\n",
      "Epoch 422/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4202 - accuracy: 0.8159 - val_loss: 0.4211 - val_accuracy: 0.8145\n",
      "Epoch 423/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4199 - accuracy: 0.8158 - val_loss: 0.4213 - val_accuracy: 0.8145\n",
      "Epoch 424/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4205 - accuracy: 0.8152 - val_loss: 0.4219 - val_accuracy: 0.8143\n",
      "Epoch 425/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4200 - accuracy: 0.8161 - val_loss: 0.4209 - val_accuracy: 0.8152\n",
      "Epoch 426/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4201 - accuracy: 0.8161 - val_loss: 0.4209 - val_accuracy: 0.8141\n",
      "Epoch 427/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4201 - accuracy: 0.8158 - val_loss: 0.4210 - val_accuracy: 0.8150\n",
      "Epoch 428/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4197 - accuracy: 0.8160 - val_loss: 0.4212 - val_accuracy: 0.8139\n",
      "Epoch 429/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4198 - accuracy: 0.8161 - val_loss: 0.4214 - val_accuracy: 0.8149\n",
      "Epoch 430/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4197 - accuracy: 0.8163 - val_loss: 0.4209 - val_accuracy: 0.8148\n",
      "Epoch 431/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4202 - accuracy: 0.8160 - val_loss: 0.4211 - val_accuracy: 0.8147\n",
      "Epoch 432/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4198 - accuracy: 0.8163 - val_loss: 0.4206 - val_accuracy: 0.8152\n",
      "Epoch 433/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4195 - accuracy: 0.8162 - val_loss: 0.4214 - val_accuracy: 0.8146\n",
      "Epoch 434/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4194 - accuracy: 0.8165 - val_loss: 0.4215 - val_accuracy: 0.8144\n",
      "Epoch 435/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4198 - accuracy: 0.8162 - val_loss: 0.4211 - val_accuracy: 0.8145\n",
      "Epoch 436/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4193 - accuracy: 0.8161 - val_loss: 0.4212 - val_accuracy: 0.8146\n",
      "Epoch 437/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4193 - accuracy: 0.8163 - val_loss: 0.4209 - val_accuracy: 0.8152\n",
      "Epoch 438/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4192 - accuracy: 0.8162 - val_loss: 0.4211 - val_accuracy: 0.8145\n",
      "Epoch 439/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4195 - accuracy: 0.8162 - val_loss: 0.4206 - val_accuracy: 0.8151\n",
      "Epoch 440/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4194 - accuracy: 0.8166 - val_loss: 0.4218 - val_accuracy: 0.8140\n",
      "Epoch 441/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4191 - accuracy: 0.8165 - val_loss: 0.4210 - val_accuracy: 0.8145\n",
      "Epoch 442/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4193 - accuracy: 0.8164 - val_loss: 0.4206 - val_accuracy: 0.8139\n",
      "Epoch 443/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4191 - accuracy: 0.8165 - val_loss: 0.4204 - val_accuracy: 0.8154\n",
      "Epoch 444/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4194 - accuracy: 0.8160 - val_loss: 0.4208 - val_accuracy: 0.8150\n",
      "Epoch 445/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4192 - accuracy: 0.8167 - val_loss: 0.4208 - val_accuracy: 0.8152\n",
      "Epoch 446/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4190 - accuracy: 0.8165 - val_loss: 0.4203 - val_accuracy: 0.8154\n",
      "Epoch 447/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4191 - accuracy: 0.8165 - val_loss: 0.4207 - val_accuracy: 0.8146\n",
      "Epoch 448/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4188 - accuracy: 0.8165 - val_loss: 0.4211 - val_accuracy: 0.8139\n",
      "Epoch 449/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4191 - accuracy: 0.8162 - val_loss: 0.4209 - val_accuracy: 0.8151\n",
      "Epoch 450/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4189 - accuracy: 0.8171 - val_loss: 0.4205 - val_accuracy: 0.8145\n",
      "Epoch 451/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4185 - accuracy: 0.8165 - val_loss: 0.4202 - val_accuracy: 0.8150\n",
      "Epoch 452/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4188 - accuracy: 0.8163 - val_loss: 0.4206 - val_accuracy: 0.8154\n",
      "Epoch 453/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4189 - accuracy: 0.8163 - val_loss: 0.4203 - val_accuracy: 0.8149\n",
      "Epoch 454/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4190 - accuracy: 0.8160 - val_loss: 0.4203 - val_accuracy: 0.8145\n",
      "Epoch 455/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4190 - accuracy: 0.8161 - val_loss: 0.4205 - val_accuracy: 0.8150\n",
      "Epoch 456/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4188 - accuracy: 0.8163 - val_loss: 0.4210 - val_accuracy: 0.8147\n",
      "Epoch 457/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4187 - accuracy: 0.8166 - val_loss: 0.4202 - val_accuracy: 0.8143\n",
      "Epoch 458/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4186 - accuracy: 0.8167 - val_loss: 0.4202 - val_accuracy: 0.8144\n",
      "Epoch 459/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4183 - accuracy: 0.8168 - val_loss: 0.4202 - val_accuracy: 0.8149\n",
      "Epoch 460/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4184 - accuracy: 0.8166 - val_loss: 0.4202 - val_accuracy: 0.8148\n",
      "Epoch 461/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4184 - accuracy: 0.8170 - val_loss: 0.4203 - val_accuracy: 0.8153\n",
      "Epoch 462/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4182 - accuracy: 0.8167 - val_loss: 0.4200 - val_accuracy: 0.8148\n",
      "Epoch 463/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4182 - accuracy: 0.8168 - val_loss: 0.4215 - val_accuracy: 0.8144\n",
      "Epoch 464/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4182 - accuracy: 0.8166 - val_loss: 0.4201 - val_accuracy: 0.8144\n",
      "Epoch 465/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4183 - accuracy: 0.8167 - val_loss: 0.4200 - val_accuracy: 0.8151\n",
      "Epoch 466/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4182 - accuracy: 0.8168 - val_loss: 0.4195 - val_accuracy: 0.8151\n",
      "Epoch 467/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4185 - accuracy: 0.8166 - val_loss: 0.4197 - val_accuracy: 0.8147\n",
      "Epoch 468/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4180 - accuracy: 0.8169 - val_loss: 0.4200 - val_accuracy: 0.8146\n",
      "Epoch 469/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4181 - accuracy: 0.8168 - val_loss: 0.4201 - val_accuracy: 0.8144\n",
      "Epoch 470/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4178 - accuracy: 0.8170 - val_loss: 0.4206 - val_accuracy: 0.8151\n",
      "Epoch 471/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4179 - accuracy: 0.8170 - val_loss: 0.4203 - val_accuracy: 0.8145\n",
      "Epoch 472/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4178 - accuracy: 0.8168 - val_loss: 0.4198 - val_accuracy: 0.8152\n",
      "Epoch 473/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4178 - accuracy: 0.8166 - val_loss: 0.4198 - val_accuracy: 0.8153\n",
      "Epoch 474/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4176 - accuracy: 0.8170 - val_loss: 0.4204 - val_accuracy: 0.8145\n",
      "Epoch 475/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4180 - accuracy: 0.8168 - val_loss: 0.4198 - val_accuracy: 0.8149\n",
      "Epoch 476/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4178 - accuracy: 0.8173 - val_loss: 0.4207 - val_accuracy: 0.8139\n",
      "Epoch 477/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4177 - accuracy: 0.8171 - val_loss: 0.4204 - val_accuracy: 0.8151\n",
      "Epoch 478/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4177 - accuracy: 0.8172 - val_loss: 0.4195 - val_accuracy: 0.8147\n",
      "Epoch 479/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4177 - accuracy: 0.8168 - val_loss: 0.4197 - val_accuracy: 0.8152\n",
      "Epoch 480/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4174 - accuracy: 0.8171 - val_loss: 0.4198 - val_accuracy: 0.8137\n",
      "Epoch 481/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4177 - accuracy: 0.8169 - val_loss: 0.4198 - val_accuracy: 0.8153\n",
      "Epoch 482/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4176 - accuracy: 0.8167 - val_loss: 0.4201 - val_accuracy: 0.8145\n",
      "Epoch 483/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4174 - accuracy: 0.8167 - val_loss: 0.4193 - val_accuracy: 0.8156\n",
      "Epoch 484/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4176 - accuracy: 0.8171 - val_loss: 0.4204 - val_accuracy: 0.8146\n",
      "Epoch 485/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4177 - accuracy: 0.8168 - val_loss: 0.4199 - val_accuracy: 0.8157\n",
      "Epoch 486/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4175 - accuracy: 0.8169 - val_loss: 0.4194 - val_accuracy: 0.8151\n",
      "Epoch 487/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4171 - accuracy: 0.8169 - val_loss: 0.4198 - val_accuracy: 0.8147\n",
      "Epoch 488/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4172 - accuracy: 0.8171 - val_loss: 0.4201 - val_accuracy: 0.8147\n",
      "Epoch 489/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4175 - accuracy: 0.8169 - val_loss: 0.4196 - val_accuracy: 0.8146\n",
      "Epoch 490/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4171 - accuracy: 0.8172 - val_loss: 0.4195 - val_accuracy: 0.8151\n",
      "Epoch 491/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4171 - accuracy: 0.8172 - val_loss: 0.4192 - val_accuracy: 0.8143\n",
      "Epoch 492/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4171 - accuracy: 0.8175 - val_loss: 0.4202 - val_accuracy: 0.8144\n",
      "Epoch 493/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4172 - accuracy: 0.8168 - val_loss: 0.4197 - val_accuracy: 0.8144\n",
      "Epoch 494/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4172 - accuracy: 0.8168 - val_loss: 0.4197 - val_accuracy: 0.8152\n",
      "Epoch 495/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4168 - accuracy: 0.8173 - val_loss: 0.4195 - val_accuracy: 0.8149\n",
      "Epoch 496/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4170 - accuracy: 0.8172 - val_loss: 0.4193 - val_accuracy: 0.8142\n",
      "Epoch 497/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4169 - accuracy: 0.8174 - val_loss: 0.4198 - val_accuracy: 0.8146\n",
      "Epoch 498/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4171 - accuracy: 0.8172 - val_loss: 0.4194 - val_accuracy: 0.8142\n",
      "Epoch 499/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4167 - accuracy: 0.8172 - val_loss: 0.4196 - val_accuracy: 0.8145\n",
      "Epoch 500/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4168 - accuracy: 0.8172 - val_loss: 0.4191 - val_accuracy: 0.8150\n",
      "Epoch 501/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4164 - accuracy: 0.8174 - val_loss: 0.4190 - val_accuracy: 0.8144\n",
      "Epoch 502/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4167 - accuracy: 0.8170 - val_loss: 0.4191 - val_accuracy: 0.8141\n",
      "Epoch 503/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4168 - accuracy: 0.8174 - val_loss: 0.4199 - val_accuracy: 0.8146\n",
      "Epoch 504/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4166 - accuracy: 0.8176 - val_loss: 0.4196 - val_accuracy: 0.8149\n",
      "Epoch 505/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4163 - accuracy: 0.8176 - val_loss: 0.4196 - val_accuracy: 0.8152\n",
      "Epoch 506/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4163 - accuracy: 0.8178 - val_loss: 0.4193 - val_accuracy: 0.8153\n",
      "Epoch 507/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4163 - accuracy: 0.8177 - val_loss: 0.4194 - val_accuracy: 0.8145\n",
      "Epoch 508/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4165 - accuracy: 0.8177 - val_loss: 0.4194 - val_accuracy: 0.8150\n",
      "Epoch 509/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4166 - accuracy: 0.8173 - val_loss: 0.4188 - val_accuracy: 0.8158\n",
      "Epoch 510/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4165 - accuracy: 0.8175 - val_loss: 0.4196 - val_accuracy: 0.8149\n",
      "Epoch 511/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4165 - accuracy: 0.8177 - val_loss: 0.4191 - val_accuracy: 0.8152\n",
      "Epoch 512/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4165 - accuracy: 0.8171 - val_loss: 0.4195 - val_accuracy: 0.8145\n",
      "Epoch 513/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4163 - accuracy: 0.8177 - val_loss: 0.4189 - val_accuracy: 0.8148\n",
      "Epoch 514/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4163 - accuracy: 0.8172 - val_loss: 0.4190 - val_accuracy: 0.8147\n",
      "Epoch 515/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4162 - accuracy: 0.8175 - val_loss: 0.4187 - val_accuracy: 0.8148\n",
      "Epoch 516/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4161 - accuracy: 0.8176 - val_loss: 0.4191 - val_accuracy: 0.8148\n",
      "Epoch 517/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4163 - accuracy: 0.8174 - val_loss: 0.4189 - val_accuracy: 0.8152\n",
      "Epoch 518/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4164 - accuracy: 0.8173 - val_loss: 0.4192 - val_accuracy: 0.8146\n",
      "Epoch 519/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4163 - accuracy: 0.8177 - val_loss: 0.4195 - val_accuracy: 0.8150\n",
      "Epoch 520/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4161 - accuracy: 0.8175 - val_loss: 0.4197 - val_accuracy: 0.8143\n",
      "Epoch 521/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4163 - accuracy: 0.8175 - val_loss: 0.4198 - val_accuracy: 0.8147\n",
      "Epoch 522/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4160 - accuracy: 0.8175 - val_loss: 0.4193 - val_accuracy: 0.8151\n",
      "Epoch 523/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4158 - accuracy: 0.8174 - val_loss: 0.4193 - val_accuracy: 0.8150\n",
      "Epoch 524/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4161 - accuracy: 0.8175 - val_loss: 0.4187 - val_accuracy: 0.8154\n",
      "Epoch 525/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4159 - accuracy: 0.8176 - val_loss: 0.4190 - val_accuracy: 0.8152\n",
      "Epoch 526/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4157 - accuracy: 0.8180 - val_loss: 0.4189 - val_accuracy: 0.8156\n",
      "Epoch 527/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4159 - accuracy: 0.8179 - val_loss: 0.4190 - val_accuracy: 0.8149\n",
      "Epoch 528/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4155 - accuracy: 0.8180 - val_loss: 0.4190 - val_accuracy: 0.8152\n",
      "Epoch 529/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4158 - accuracy: 0.8177 - val_loss: 0.4188 - val_accuracy: 0.8153\n",
      "Epoch 530/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4158 - accuracy: 0.8176 - val_loss: 0.4186 - val_accuracy: 0.8149\n",
      "Epoch 531/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4157 - accuracy: 0.8179 - val_loss: 0.4186 - val_accuracy: 0.8151\n",
      "Epoch 532/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4157 - accuracy: 0.8175 - val_loss: 0.4188 - val_accuracy: 0.8146\n",
      "Epoch 533/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4157 - accuracy: 0.8177 - val_loss: 0.4189 - val_accuracy: 0.8153\n",
      "Epoch 534/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4155 - accuracy: 0.8180 - val_loss: 0.4192 - val_accuracy: 0.8152\n",
      "Epoch 535/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4154 - accuracy: 0.8179 - val_loss: 0.4191 - val_accuracy: 0.8149\n",
      "Epoch 536/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4156 - accuracy: 0.8179 - val_loss: 0.4188 - val_accuracy: 0.8151\n",
      "Epoch 537/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4155 - accuracy: 0.8182 - val_loss: 0.4184 - val_accuracy: 0.8155\n",
      "Epoch 538/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4154 - accuracy: 0.8179 - val_loss: 0.4188 - val_accuracy: 0.8152\n",
      "Epoch 539/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4155 - accuracy: 0.8175 - val_loss: 0.4187 - val_accuracy: 0.8152\n",
      "Epoch 540/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4153 - accuracy: 0.8183 - val_loss: 0.4191 - val_accuracy: 0.8147\n",
      "Epoch 541/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4152 - accuracy: 0.8181 - val_loss: 0.4187 - val_accuracy: 0.8147\n",
      "Epoch 542/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4155 - accuracy: 0.8177 - val_loss: 0.4192 - val_accuracy: 0.8148\n",
      "Epoch 543/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4152 - accuracy: 0.8178 - val_loss: 0.4188 - val_accuracy: 0.8150\n",
      "Epoch 544/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4151 - accuracy: 0.8180 - val_loss: 0.4185 - val_accuracy: 0.8151\n",
      "Epoch 545/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4151 - accuracy: 0.8181 - val_loss: 0.4186 - val_accuracy: 0.8151\n",
      "Epoch 546/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4155 - accuracy: 0.8177 - val_loss: 0.4185 - val_accuracy: 0.8152\n",
      "Epoch 547/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4150 - accuracy: 0.8180 - val_loss: 0.4180 - val_accuracy: 0.8155\n",
      "Epoch 548/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4152 - accuracy: 0.8179 - val_loss: 0.4183 - val_accuracy: 0.8156\n",
      "Epoch 549/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4150 - accuracy: 0.8180 - val_loss: 0.4187 - val_accuracy: 0.8150\n",
      "Epoch 550/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4153 - accuracy: 0.8180 - val_loss: 0.4188 - val_accuracy: 0.8154\n",
      "Epoch 551/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4151 - accuracy: 0.8181 - val_loss: 0.4188 - val_accuracy: 0.8150\n",
      "Epoch 552/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4148 - accuracy: 0.8181 - val_loss: 0.4186 - val_accuracy: 0.8148\n",
      "Epoch 553/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4153 - accuracy: 0.8182 - val_loss: 0.4182 - val_accuracy: 0.8152\n",
      "Epoch 554/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4147 - accuracy: 0.8183 - val_loss: 0.4190 - val_accuracy: 0.8148\n",
      "Epoch 555/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4147 - accuracy: 0.8181 - val_loss: 0.4186 - val_accuracy: 0.8151\n",
      "Epoch 556/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4148 - accuracy: 0.8182 - val_loss: 0.4189 - val_accuracy: 0.8150\n",
      "Epoch 557/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4146 - accuracy: 0.8179 - val_loss: 0.4182 - val_accuracy: 0.8154\n",
      "Epoch 558/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4144 - accuracy: 0.8182 - val_loss: 0.4184 - val_accuracy: 0.8147\n",
      "Epoch 559/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4146 - accuracy: 0.8181 - val_loss: 0.4186 - val_accuracy: 0.8149\n",
      "Epoch 560/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4147 - accuracy: 0.8182 - val_loss: 0.4185 - val_accuracy: 0.8157\n",
      "Epoch 561/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4146 - accuracy: 0.8180 - val_loss: 0.4181 - val_accuracy: 0.8156\n",
      "Epoch 562/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4148 - accuracy: 0.8184 - val_loss: 0.4187 - val_accuracy: 0.8148\n",
      "Epoch 563/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4148 - accuracy: 0.8183 - val_loss: 0.4182 - val_accuracy: 0.8154\n",
      "Epoch 564/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4143 - accuracy: 0.8182 - val_loss: 0.4179 - val_accuracy: 0.8156\n",
      "Epoch 565/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4146 - accuracy: 0.8180 - val_loss: 0.4189 - val_accuracy: 0.8150\n",
      "Epoch 566/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4147 - accuracy: 0.8184 - val_loss: 0.4183 - val_accuracy: 0.8156\n",
      "Epoch 567/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4144 - accuracy: 0.8183 - val_loss: 0.4186 - val_accuracy: 0.8152\n",
      "Epoch 568/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4145 - accuracy: 0.8184 - val_loss: 0.4185 - val_accuracy: 0.8155\n",
      "Epoch 569/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4145 - accuracy: 0.8183 - val_loss: 0.4184 - val_accuracy: 0.8146\n",
      "Epoch 570/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4144 - accuracy: 0.8186 - val_loss: 0.4186 - val_accuracy: 0.8142\n",
      "Epoch 571/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4142 - accuracy: 0.8185 - val_loss: 0.4189 - val_accuracy: 0.8153\n",
      "Epoch 572/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4141 - accuracy: 0.8189 - val_loss: 0.4185 - val_accuracy: 0.8155\n",
      "Epoch 573/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4147 - accuracy: 0.8182 - val_loss: 0.4183 - val_accuracy: 0.8152\n",
      "Epoch 574/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4141 - accuracy: 0.8186 - val_loss: 0.4181 - val_accuracy: 0.8154\n",
      "Epoch 575/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4139 - accuracy: 0.8186 - val_loss: 0.4176 - val_accuracy: 0.8154\n",
      "Epoch 576/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4145 - accuracy: 0.8184 - val_loss: 0.4184 - val_accuracy: 0.8149\n",
      "Epoch 577/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4140 - accuracy: 0.8186 - val_loss: 0.4183 - val_accuracy: 0.8153\n",
      "Epoch 578/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4140 - accuracy: 0.8188 - val_loss: 0.4182 - val_accuracy: 0.8154\n",
      "Epoch 579/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4140 - accuracy: 0.8185 - val_loss: 0.4178 - val_accuracy: 0.8149\n",
      "Epoch 580/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4141 - accuracy: 0.8188 - val_loss: 0.4181 - val_accuracy: 0.8153\n",
      "Epoch 581/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4138 - accuracy: 0.8186 - val_loss: 0.4182 - val_accuracy: 0.8150\n",
      "Epoch 582/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4141 - accuracy: 0.8188 - val_loss: 0.4183 - val_accuracy: 0.8152\n",
      "Epoch 583/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4138 - accuracy: 0.8188 - val_loss: 0.4183 - val_accuracy: 0.8151\n",
      "Epoch 584/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4138 - accuracy: 0.8188 - val_loss: 0.4184 - val_accuracy: 0.8150\n",
      "Epoch 585/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4142 - accuracy: 0.8186 - val_loss: 0.4185 - val_accuracy: 0.8152\n",
      "Epoch 586/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4136 - accuracy: 0.8190 - val_loss: 0.4180 - val_accuracy: 0.8150\n",
      "Epoch 587/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4136 - accuracy: 0.8186 - val_loss: 0.4183 - val_accuracy: 0.8153\n",
      "Epoch 588/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4135 - accuracy: 0.8188 - val_loss: 0.4184 - val_accuracy: 0.8149\n",
      "Epoch 589/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4137 - accuracy: 0.8187 - val_loss: 0.4181 - val_accuracy: 0.8154\n",
      "Epoch 590/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4135 - accuracy: 0.8190 - val_loss: 0.4179 - val_accuracy: 0.8148\n",
      "Epoch 591/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4134 - accuracy: 0.8190 - val_loss: 0.4180 - val_accuracy: 0.8148\n",
      "Epoch 592/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4137 - accuracy: 0.8189 - val_loss: 0.4182 - val_accuracy: 0.8152\n",
      "Epoch 593/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4136 - accuracy: 0.8185 - val_loss: 0.4180 - val_accuracy: 0.8155\n",
      "Epoch 594/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4134 - accuracy: 0.8190 - val_loss: 0.4180 - val_accuracy: 0.8151\n",
      "Epoch 595/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4134 - accuracy: 0.8189 - val_loss: 0.4178 - val_accuracy: 0.8158\n",
      "Epoch 596/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4133 - accuracy: 0.8190 - val_loss: 0.4185 - val_accuracy: 0.8151\n",
      "Epoch 597/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4132 - accuracy: 0.8190 - val_loss: 0.4181 - val_accuracy: 0.8150\n",
      "Epoch 598/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4135 - accuracy: 0.8189 - val_loss: 0.4181 - val_accuracy: 0.8147\n",
      "Epoch 599/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4134 - accuracy: 0.8188 - val_loss: 0.4182 - val_accuracy: 0.8145\n",
      "Epoch 600/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4132 - accuracy: 0.8190 - val_loss: 0.4184 - val_accuracy: 0.8152\n",
      "Epoch 601/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4133 - accuracy: 0.8190 - val_loss: 0.4182 - val_accuracy: 0.8148\n",
      "Epoch 602/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4132 - accuracy: 0.8192 - val_loss: 0.4177 - val_accuracy: 0.8152\n",
      "Epoch 603/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4130 - accuracy: 0.8191 - val_loss: 0.4173 - val_accuracy: 0.8156\n",
      "Epoch 604/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4132 - accuracy: 0.8190 - val_loss: 0.4174 - val_accuracy: 0.8152\n",
      "Epoch 605/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4132 - accuracy: 0.8186 - val_loss: 0.4180 - val_accuracy: 0.8155\n",
      "Epoch 606/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4132 - accuracy: 0.8189 - val_loss: 0.4180 - val_accuracy: 0.8153\n",
      "Epoch 607/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4133 - accuracy: 0.8189 - val_loss: 0.4179 - val_accuracy: 0.8147\n",
      "Epoch 608/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4129 - accuracy: 0.8192 - val_loss: 0.4180 - val_accuracy: 0.8154\n",
      "Epoch 609/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4132 - accuracy: 0.8188 - val_loss: 0.4183 - val_accuracy: 0.8151\n",
      "Epoch 610/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4128 - accuracy: 0.8193 - val_loss: 0.4177 - val_accuracy: 0.8151\n",
      "Epoch 611/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4132 - accuracy: 0.8192 - val_loss: 0.4177 - val_accuracy: 0.8152\n",
      "Epoch 612/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4127 - accuracy: 0.8191 - val_loss: 0.4182 - val_accuracy: 0.8151\n",
      "Epoch 613/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4130 - accuracy: 0.8189 - val_loss: 0.4177 - val_accuracy: 0.8151\n",
      "Epoch 614/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4126 - accuracy: 0.8192 - val_loss: 0.4178 - val_accuracy: 0.8153\n",
      "Epoch 615/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4128 - accuracy: 0.8192 - val_loss: 0.4176 - val_accuracy: 0.8156\n",
      "Epoch 616/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4129 - accuracy: 0.8194 - val_loss: 0.4183 - val_accuracy: 0.8154\n",
      "Epoch 617/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4126 - accuracy: 0.8193 - val_loss: 0.4175 - val_accuracy: 0.8150\n",
      "Epoch 618/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4128 - accuracy: 0.8189 - val_loss: 0.4178 - val_accuracy: 0.8152\n",
      "Epoch 619/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4127 - accuracy: 0.8191 - val_loss: 0.4178 - val_accuracy: 0.8151\n",
      "Epoch 620/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4127 - accuracy: 0.8193 - val_loss: 0.4182 - val_accuracy: 0.8146\n",
      "Epoch 621/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4127 - accuracy: 0.8191 - val_loss: 0.4181 - val_accuracy: 0.8153\n",
      "Epoch 622/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4126 - accuracy: 0.8194 - val_loss: 0.4180 - val_accuracy: 0.8149\n",
      "Epoch 623/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4125 - accuracy: 0.8194 - val_loss: 0.4181 - val_accuracy: 0.8152\n",
      "Epoch 624/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4127 - accuracy: 0.8193 - val_loss: 0.4177 - val_accuracy: 0.8149\n",
      "Epoch 625/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4126 - accuracy: 0.8194 - val_loss: 0.4181 - val_accuracy: 0.8149\n",
      "Epoch 626/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4123 - accuracy: 0.8191 - val_loss: 0.4174 - val_accuracy: 0.8156\n",
      "Epoch 627/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4123 - accuracy: 0.8195 - val_loss: 0.4176 - val_accuracy: 0.8148\n",
      "Epoch 628/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4126 - accuracy: 0.8193 - val_loss: 0.4178 - val_accuracy: 0.8148\n",
      "Epoch 629/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4124 - accuracy: 0.8193 - val_loss: 0.4177 - val_accuracy: 0.8144\n",
      "Epoch 630/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4121 - accuracy: 0.8193 - val_loss: 0.4178 - val_accuracy: 0.8149\n",
      "Epoch 631/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4121 - accuracy: 0.8193 - val_loss: 0.4173 - val_accuracy: 0.8148\n",
      "Epoch 632/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4123 - accuracy: 0.8193 - val_loss: 0.4176 - val_accuracy: 0.8154\n",
      "Epoch 633/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4123 - accuracy: 0.8194 - val_loss: 0.4178 - val_accuracy: 0.8152\n",
      "Epoch 634/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4122 - accuracy: 0.8196 - val_loss: 0.4176 - val_accuracy: 0.8154\n",
      "Epoch 635/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4121 - accuracy: 0.8196 - val_loss: 0.4175 - val_accuracy: 0.8155\n",
      "Epoch 636/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4123 - accuracy: 0.8193 - val_loss: 0.4176 - val_accuracy: 0.8152\n",
      "Epoch 637/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4120 - accuracy: 0.8196 - val_loss: 0.4175 - val_accuracy: 0.8142\n",
      "Epoch 638/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4118 - accuracy: 0.8197 - val_loss: 0.4181 - val_accuracy: 0.8153\n",
      "Epoch 639/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4120 - accuracy: 0.8194 - val_loss: 0.4177 - val_accuracy: 0.8152\n",
      "Epoch 640/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4121 - accuracy: 0.8193 - val_loss: 0.4178 - val_accuracy: 0.8156\n",
      "Epoch 641/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4120 - accuracy: 0.8195 - val_loss: 0.4176 - val_accuracy: 0.8144\n",
      "Epoch 642/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4120 - accuracy: 0.8195 - val_loss: 0.4181 - val_accuracy: 0.8152\n",
      "Epoch 643/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4119 - accuracy: 0.8198 - val_loss: 0.4177 - val_accuracy: 0.8150\n",
      "Epoch 644/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4117 - accuracy: 0.8197 - val_loss: 0.4174 - val_accuracy: 0.8153\n",
      "Epoch 645/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4122 - accuracy: 0.8191 - val_loss: 0.4178 - val_accuracy: 0.8144\n",
      "Epoch 646/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4120 - accuracy: 0.8196 - val_loss: 0.4174 - val_accuracy: 0.8154\n",
      "Epoch 647/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4123 - accuracy: 0.8194 - val_loss: 0.4173 - val_accuracy: 0.8147\n",
      "Epoch 648/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4118 - accuracy: 0.8194 - val_loss: 0.4180 - val_accuracy: 0.8152\n",
      "Epoch 649/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4118 - accuracy: 0.8196 - val_loss: 0.4171 - val_accuracy: 0.8154\n",
      "Epoch 650/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4116 - accuracy: 0.8199 - val_loss: 0.4176 - val_accuracy: 0.8155\n",
      "Epoch 651/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4118 - accuracy: 0.8196 - val_loss: 0.4174 - val_accuracy: 0.8154\n",
      "Epoch 652/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4118 - accuracy: 0.8197 - val_loss: 0.4171 - val_accuracy: 0.8153\n",
      "Epoch 653/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4115 - accuracy: 0.8201 - val_loss: 0.4174 - val_accuracy: 0.8152\n",
      "Epoch 654/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4117 - accuracy: 0.8195 - val_loss: 0.4175 - val_accuracy: 0.8148\n",
      "Epoch 655/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4119 - accuracy: 0.8194 - val_loss: 0.4177 - val_accuracy: 0.8149\n",
      "Epoch 656/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4114 - accuracy: 0.8199 - val_loss: 0.4174 - val_accuracy: 0.8157\n",
      "Epoch 657/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4116 - accuracy: 0.8196 - val_loss: 0.4171 - val_accuracy: 0.8152\n",
      "Epoch 658/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4116 - accuracy: 0.8197 - val_loss: 0.4175 - val_accuracy: 0.8150\n",
      "Epoch 659/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4114 - accuracy: 0.8199 - val_loss: 0.4171 - val_accuracy: 0.8153\n",
      "Epoch 660/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4114 - accuracy: 0.8199 - val_loss: 0.4172 - val_accuracy: 0.8154\n",
      "Epoch 661/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4115 - accuracy: 0.8196 - val_loss: 0.4175 - val_accuracy: 0.8147\n",
      "Epoch 662/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4112 - accuracy: 0.8199 - val_loss: 0.4172 - val_accuracy: 0.8150\n",
      "Epoch 663/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4118 - accuracy: 0.8193 - val_loss: 0.4170 - val_accuracy: 0.8156\n",
      "Epoch 664/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4115 - accuracy: 0.8196 - val_loss: 0.4173 - val_accuracy: 0.8152\n",
      "Epoch 665/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4112 - accuracy: 0.8200 - val_loss: 0.4173 - val_accuracy: 0.8151\n",
      "Epoch 666/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4112 - accuracy: 0.8199 - val_loss: 0.4175 - val_accuracy: 0.8149\n",
      "Epoch 667/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4112 - accuracy: 0.8198 - val_loss: 0.4173 - val_accuracy: 0.8154\n",
      "Epoch 668/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4112 - accuracy: 0.8198 - val_loss: 0.4175 - val_accuracy: 0.8149\n",
      "Epoch 669/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4110 - accuracy: 0.8202 - val_loss: 0.4170 - val_accuracy: 0.8158\n",
      "Epoch 670/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4110 - accuracy: 0.8202 - val_loss: 0.4173 - val_accuracy: 0.8152\n",
      "Epoch 671/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4112 - accuracy: 0.8200 - val_loss: 0.4170 - val_accuracy: 0.8145\n",
      "Epoch 672/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4115 - accuracy: 0.8196 - val_loss: 0.4174 - val_accuracy: 0.8156\n",
      "Epoch 673/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4110 - accuracy: 0.8201 - val_loss: 0.4171 - val_accuracy: 0.8154\n",
      "Epoch 674/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4110 - accuracy: 0.8202 - val_loss: 0.4174 - val_accuracy: 0.8151\n",
      "Epoch 675/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4110 - accuracy: 0.8198 - val_loss: 0.4179 - val_accuracy: 0.8155\n",
      "Epoch 676/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4108 - accuracy: 0.8200 - val_loss: 0.4171 - val_accuracy: 0.8152\n",
      "Epoch 677/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4112 - accuracy: 0.8198 - val_loss: 0.4181 - val_accuracy: 0.8144\n",
      "Epoch 678/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4113 - accuracy: 0.8192 - val_loss: 0.4173 - val_accuracy: 0.8150\n",
      "Epoch 679/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4109 - accuracy: 0.8200 - val_loss: 0.4171 - val_accuracy: 0.8147\n",
      "Epoch 680/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4113 - accuracy: 0.8201 - val_loss: 0.4172 - val_accuracy: 0.8154\n",
      "Epoch 681/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4110 - accuracy: 0.8198 - val_loss: 0.4168 - val_accuracy: 0.8156\n",
      "Epoch 682/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4109 - accuracy: 0.8200 - val_loss: 0.4168 - val_accuracy: 0.8153\n",
      "Epoch 683/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4108 - accuracy: 0.8200 - val_loss: 0.4174 - val_accuracy: 0.8154\n",
      "Epoch 684/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4108 - accuracy: 0.8198 - val_loss: 0.4168 - val_accuracy: 0.8153\n",
      "Epoch 685/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4107 - accuracy: 0.8200 - val_loss: 0.4172 - val_accuracy: 0.8152\n",
      "Epoch 686/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4107 - accuracy: 0.8204 - val_loss: 0.4167 - val_accuracy: 0.8151\n",
      "Epoch 687/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4111 - accuracy: 0.8198 - val_loss: 0.4171 - val_accuracy: 0.8152\n",
      "Epoch 688/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4108 - accuracy: 0.8198 - val_loss: 0.4168 - val_accuracy: 0.8156\n",
      "Epoch 689/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4108 - accuracy: 0.8201 - val_loss: 0.4173 - val_accuracy: 0.8148\n",
      "Epoch 690/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4103 - accuracy: 0.8204 - val_loss: 0.4176 - val_accuracy: 0.8145\n",
      "Epoch 691/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4108 - accuracy: 0.8202 - val_loss: 0.4166 - val_accuracy: 0.8152\n",
      "Epoch 692/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4104 - accuracy: 0.8203 - val_loss: 0.4168 - val_accuracy: 0.8154\n",
      "Epoch 693/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4106 - accuracy: 0.8199 - val_loss: 0.4172 - val_accuracy: 0.8149\n",
      "Epoch 694/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4104 - accuracy: 0.8205 - val_loss: 0.4169 - val_accuracy: 0.8156\n",
      "Epoch 695/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4104 - accuracy: 0.8203 - val_loss: 0.4169 - val_accuracy: 0.8152\n",
      "Epoch 696/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4103 - accuracy: 0.8205 - val_loss: 0.4170 - val_accuracy: 0.8160\n",
      "Epoch 697/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4105 - accuracy: 0.8201 - val_loss: 0.4169 - val_accuracy: 0.8154\n",
      "Epoch 698/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4103 - accuracy: 0.8203 - val_loss: 0.4172 - val_accuracy: 0.8153\n",
      "Epoch 699/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4104 - accuracy: 0.8202 - val_loss: 0.4172 - val_accuracy: 0.8151\n",
      "Epoch 700/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4104 - accuracy: 0.8204 - val_loss: 0.4173 - val_accuracy: 0.8157\n",
      "Epoch 701/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4103 - accuracy: 0.8205 - val_loss: 0.4173 - val_accuracy: 0.8151\n",
      "Epoch 702/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4102 - accuracy: 0.8203 - val_loss: 0.4168 - val_accuracy: 0.8155\n",
      "Epoch 703/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4102 - accuracy: 0.8204 - val_loss: 0.4171 - val_accuracy: 0.8150\n",
      "Epoch 704/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4100 - accuracy: 0.8202 - val_loss: 0.4170 - val_accuracy: 0.8156\n",
      "Epoch 705/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4103 - accuracy: 0.8205 - val_loss: 0.4176 - val_accuracy: 0.8151\n",
      "Epoch 706/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4099 - accuracy: 0.8205 - val_loss: 0.4171 - val_accuracy: 0.8152\n",
      "Epoch 707/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4100 - accuracy: 0.8203 - val_loss: 0.4171 - val_accuracy: 0.8149\n",
      "Epoch 708/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4099 - accuracy: 0.8205 - val_loss: 0.4174 - val_accuracy: 0.8153\n",
      "Epoch 709/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4101 - accuracy: 0.8204 - val_loss: 0.4171 - val_accuracy: 0.8144\n",
      "Epoch 710/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4101 - accuracy: 0.8203 - val_loss: 0.4169 - val_accuracy: 0.8152\n",
      "Epoch 711/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4101 - accuracy: 0.8207 - val_loss: 0.4166 - val_accuracy: 0.8155\n",
      "Epoch 712/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4098 - accuracy: 0.8207 - val_loss: 0.4170 - val_accuracy: 0.8151\n",
      "Epoch 713/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4099 - accuracy: 0.8203 - val_loss: 0.4170 - val_accuracy: 0.8154\n",
      "Epoch 714/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4098 - accuracy: 0.8207 - val_loss: 0.4170 - val_accuracy: 0.8153\n",
      "Epoch 715/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4099 - accuracy: 0.8206 - val_loss: 0.4167 - val_accuracy: 0.8156\n",
      "Epoch 716/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4100 - accuracy: 0.8205 - val_loss: 0.4171 - val_accuracy: 0.8149\n",
      "Epoch 717/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4098 - accuracy: 0.8207 - val_loss: 0.4166 - val_accuracy: 0.8154\n",
      "Epoch 718/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4099 - accuracy: 0.8207 - val_loss: 0.4171 - val_accuracy: 0.8150\n",
      "Epoch 719/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4100 - accuracy: 0.8203 - val_loss: 0.4164 - val_accuracy: 0.8148\n",
      "Epoch 720/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4096 - accuracy: 0.8206 - val_loss: 0.4168 - val_accuracy: 0.8153\n",
      "Epoch 721/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4099 - accuracy: 0.8203 - val_loss: 0.4169 - val_accuracy: 0.8156\n",
      "Epoch 722/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4099 - accuracy: 0.8204 - val_loss: 0.4168 - val_accuracy: 0.8148\n",
      "Epoch 723/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4096 - accuracy: 0.8207 - val_loss: 0.4170 - val_accuracy: 0.8152\n",
      "Epoch 724/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4096 - accuracy: 0.8205 - val_loss: 0.4166 - val_accuracy: 0.8153\n",
      "Epoch 725/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4098 - accuracy: 0.8203 - val_loss: 0.4170 - val_accuracy: 0.8151\n",
      "Epoch 726/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4095 - accuracy: 0.8210 - val_loss: 0.4172 - val_accuracy: 0.8150\n",
      "Epoch 727/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4094 - accuracy: 0.8210 - val_loss: 0.4169 - val_accuracy: 0.8151\n",
      "Epoch 728/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4093 - accuracy: 0.8211 - val_loss: 0.4173 - val_accuracy: 0.8146\n",
      "Epoch 729/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4101 - accuracy: 0.8202 - val_loss: 0.4170 - val_accuracy: 0.8149\n",
      "Epoch 730/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4108 - accuracy: 0.8196 - val_loss: 0.4173 - val_accuracy: 0.8155\n",
      "Epoch 731/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4097 - accuracy: 0.8207 - val_loss: 0.4166 - val_accuracy: 0.8156\n",
      "Epoch 732/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4094 - accuracy: 0.8209 - val_loss: 0.4166 - val_accuracy: 0.8151\n",
      "Epoch 733/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4095 - accuracy: 0.8207 - val_loss: 0.4169 - val_accuracy: 0.8152\n",
      "Epoch 734/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4092 - accuracy: 0.8207 - val_loss: 0.4170 - val_accuracy: 0.8151\n",
      "Epoch 735/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4093 - accuracy: 0.8208 - val_loss: 0.4165 - val_accuracy: 0.8152\n",
      "Epoch 736/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4094 - accuracy: 0.8207 - val_loss: 0.4173 - val_accuracy: 0.8143\n",
      "Epoch 737/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4092 - accuracy: 0.8208 - val_loss: 0.4170 - val_accuracy: 0.8147\n",
      "Epoch 738/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4092 - accuracy: 0.8209 - val_loss: 0.4167 - val_accuracy: 0.8150\n",
      "Epoch 739/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4092 - accuracy: 0.8209 - val_loss: 0.4169 - val_accuracy: 0.8149\n",
      "Epoch 740/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4092 - accuracy: 0.8209 - val_loss: 0.4164 - val_accuracy: 0.8154\n",
      "Epoch 741/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4090 - accuracy: 0.8208 - val_loss: 0.4166 - val_accuracy: 0.8152\n",
      "Epoch 742/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4089 - accuracy: 0.8210 - val_loss: 0.4166 - val_accuracy: 0.8148\n",
      "Epoch 743/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4093 - accuracy: 0.8208 - val_loss: 0.4164 - val_accuracy: 0.8153\n",
      "Epoch 744/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4091 - accuracy: 0.8209 - val_loss: 0.4164 - val_accuracy: 0.8154\n",
      "Epoch 745/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4091 - accuracy: 0.8209 - val_loss: 0.4172 - val_accuracy: 0.8143\n",
      "Epoch 746/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4090 - accuracy: 0.8210 - val_loss: 0.4168 - val_accuracy: 0.8151\n",
      "Epoch 747/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4088 - accuracy: 0.8207 - val_loss: 0.4164 - val_accuracy: 0.8154\n",
      "Epoch 748/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4089 - accuracy: 0.8209 - val_loss: 0.4165 - val_accuracy: 0.8150\n",
      "Epoch 749/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4091 - accuracy: 0.8206 - val_loss: 0.4173 - val_accuracy: 0.8147\n",
      "Epoch 750/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4089 - accuracy: 0.8209 - val_loss: 0.4165 - val_accuracy: 0.8154\n",
      "Epoch 751/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4091 - accuracy: 0.8206 - val_loss: 0.4169 - val_accuracy: 0.8145\n",
      "Epoch 752/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4088 - accuracy: 0.8209 - val_loss: 0.4167 - val_accuracy: 0.8149\n",
      "Epoch 753/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4091 - accuracy: 0.8206 - val_loss: 0.4169 - val_accuracy: 0.8150\n",
      "Epoch 754/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4090 - accuracy: 0.8208 - val_loss: 0.4169 - val_accuracy: 0.8149\n",
      "Epoch 755/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4096 - accuracy: 0.8204 - val_loss: 0.4165 - val_accuracy: 0.8152\n",
      "Epoch 756/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4088 - accuracy: 0.8211 - val_loss: 0.4167 - val_accuracy: 0.8144\n",
      "Epoch 757/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4089 - accuracy: 0.8209 - val_loss: 0.4168 - val_accuracy: 0.8145\n",
      "Epoch 758/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4088 - accuracy: 0.8210 - val_loss: 0.4166 - val_accuracy: 0.8149\n",
      "Epoch 759/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4085 - accuracy: 0.8210 - val_loss: 0.4167 - val_accuracy: 0.8148\n",
      "Epoch 760/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4089 - accuracy: 0.8209 - val_loss: 0.4169 - val_accuracy: 0.8149\n",
      "Epoch 761/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4088 - accuracy: 0.8207 - val_loss: 0.4169 - val_accuracy: 0.8150\n",
      "Epoch 762/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4087 - accuracy: 0.8209 - val_loss: 0.4162 - val_accuracy: 0.8152\n",
      "Epoch 763/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4087 - accuracy: 0.8211 - val_loss: 0.4165 - val_accuracy: 0.8145\n",
      "Epoch 764/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4086 - accuracy: 0.8212 - val_loss: 0.4168 - val_accuracy: 0.8152\n",
      "Epoch 765/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4088 - accuracy: 0.8210 - val_loss: 0.4166 - val_accuracy: 0.8149\n",
      "Epoch 766/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4088 - accuracy: 0.8211 - val_loss: 0.4165 - val_accuracy: 0.8152\n",
      "Epoch 767/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4086 - accuracy: 0.8212 - val_loss: 0.4166 - val_accuracy: 0.8155\n",
      "Epoch 768/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4084 - accuracy: 0.8213 - val_loss: 0.4169 - val_accuracy: 0.8146\n",
      "Epoch 769/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4085 - accuracy: 0.8211 - val_loss: 0.4166 - val_accuracy: 0.8153\n",
      "Epoch 770/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4086 - accuracy: 0.8210 - val_loss: 0.4166 - val_accuracy: 0.8146\n",
      "Epoch 771/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4084 - accuracy: 0.8214 - val_loss: 0.4162 - val_accuracy: 0.8148\n",
      "Epoch 772/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4083 - accuracy: 0.8211 - val_loss: 0.4166 - val_accuracy: 0.8157\n",
      "Epoch 773/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4084 - accuracy: 0.8212 - val_loss: 0.4166 - val_accuracy: 0.8148\n",
      "Epoch 774/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4086 - accuracy: 0.8211 - val_loss: 0.4169 - val_accuracy: 0.8149\n",
      "Epoch 775/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4086 - accuracy: 0.8213 - val_loss: 0.4167 - val_accuracy: 0.8147\n",
      "Epoch 776/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4084 - accuracy: 0.8214 - val_loss: 0.4165 - val_accuracy: 0.8148\n",
      "Epoch 777/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4085 - accuracy: 0.8212 - val_loss: 0.4167 - val_accuracy: 0.8151\n",
      "Epoch 778/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4083 - accuracy: 0.8211 - val_loss: 0.4168 - val_accuracy: 0.8151\n",
      "Epoch 779/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4083 - accuracy: 0.8211 - val_loss: 0.4165 - val_accuracy: 0.8151\n",
      "Epoch 780/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4084 - accuracy: 0.8212 - val_loss: 0.4167 - val_accuracy: 0.8149\n",
      "Epoch 781/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4082 - accuracy: 0.8212 - val_loss: 0.4163 - val_accuracy: 0.8147\n",
      "Epoch 782/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4085 - accuracy: 0.8213 - val_loss: 0.4162 - val_accuracy: 0.8151\n",
      "Epoch 783/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4084 - accuracy: 0.8211 - val_loss: 0.4170 - val_accuracy: 0.8150\n",
      "Epoch 784/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4083 - accuracy: 0.8211 - val_loss: 0.4163 - val_accuracy: 0.8153\n",
      "Epoch 785/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4080 - accuracy: 0.8214 - val_loss: 0.4165 - val_accuracy: 0.8145\n",
      "Epoch 786/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4080 - accuracy: 0.8215 - val_loss: 0.4162 - val_accuracy: 0.8153\n",
      "Epoch 787/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4079 - accuracy: 0.8216 - val_loss: 0.4163 - val_accuracy: 0.8145\n",
      "Epoch 788/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4080 - accuracy: 0.8211 - val_loss: 0.4169 - val_accuracy: 0.8147\n",
      "Epoch 789/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4080 - accuracy: 0.8213 - val_loss: 0.4168 - val_accuracy: 0.8149\n",
      "Epoch 790/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4082 - accuracy: 0.8212 - val_loss: 0.4168 - val_accuracy: 0.8147\n",
      "Epoch 791/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4081 - accuracy: 0.8213 - val_loss: 0.4164 - val_accuracy: 0.8148\n",
      "Epoch 792/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4080 - accuracy: 0.8213 - val_loss: 0.4166 - val_accuracy: 0.8147\n",
      "Epoch 793/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4079 - accuracy: 0.8212 - val_loss: 0.4165 - val_accuracy: 0.8152\n",
      "Epoch 794/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4080 - accuracy: 0.8214 - val_loss: 0.4161 - val_accuracy: 0.8151\n",
      "Epoch 795/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4080 - accuracy: 0.8212 - val_loss: 0.4170 - val_accuracy: 0.8148\n",
      "Epoch 796/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4079 - accuracy: 0.8212 - val_loss: 0.4163 - val_accuracy: 0.8158\n",
      "Epoch 797/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4080 - accuracy: 0.8213 - val_loss: 0.4165 - val_accuracy: 0.8152\n",
      "Epoch 798/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4077 - accuracy: 0.8214 - val_loss: 0.4163 - val_accuracy: 0.8150\n",
      "Epoch 799/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4076 - accuracy: 0.8217 - val_loss: 0.4166 - val_accuracy: 0.8147\n",
      "Epoch 800/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4084 - accuracy: 0.8213 - val_loss: 0.4166 - val_accuracy: 0.8150\n",
      "Epoch 801/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4078 - accuracy: 0.8213 - val_loss: 0.4168 - val_accuracy: 0.8149\n",
      "Epoch 802/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4076 - accuracy: 0.8218 - val_loss: 0.4161 - val_accuracy: 0.8149\n",
      "Epoch 803/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4079 - accuracy: 0.8214 - val_loss: 0.4166 - val_accuracy: 0.8149\n",
      "Epoch 804/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4086 - accuracy: 0.8209 - val_loss: 0.4160 - val_accuracy: 0.8148\n",
      "Epoch 805/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4080 - accuracy: 0.8213 - val_loss: 0.4161 - val_accuracy: 0.8145\n",
      "Epoch 806/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4078 - accuracy: 0.8212 - val_loss: 0.4163 - val_accuracy: 0.8147\n",
      "Epoch 807/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4077 - accuracy: 0.8211 - val_loss: 0.4171 - val_accuracy: 0.8153\n",
      "Epoch 808/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4076 - accuracy: 0.8213 - val_loss: 0.4164 - val_accuracy: 0.8151\n",
      "Epoch 809/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4078 - accuracy: 0.8213 - val_loss: 0.4163 - val_accuracy: 0.8148\n",
      "Epoch 810/1000\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.4081 - accuracy: 0.82 - 1s 5ms/step - loss: 0.4076 - accuracy: 0.8214 - val_loss: 0.4167 - val_accuracy: 0.8142\n",
      "Epoch 811/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4077 - accuracy: 0.8214 - val_loss: 0.4164 - val_accuracy: 0.8151\n",
      "Epoch 812/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4073 - accuracy: 0.8218 - val_loss: 0.4167 - val_accuracy: 0.8150\n",
      "Epoch 813/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4075 - accuracy: 0.8217 - val_loss: 0.4160 - val_accuracy: 0.8155\n",
      "Epoch 814/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4075 - accuracy: 0.8217 - val_loss: 0.4164 - val_accuracy: 0.8147\n",
      "Epoch 815/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4074 - accuracy: 0.8216 - val_loss: 0.4166 - val_accuracy: 0.8151\n",
      "Epoch 816/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4073 - accuracy: 0.8218 - val_loss: 0.4164 - val_accuracy: 0.8153\n",
      "Epoch 817/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4073 - accuracy: 0.8216 - val_loss: 0.4166 - val_accuracy: 0.8153\n",
      "Epoch 818/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4076 - accuracy: 0.8215 - val_loss: 0.4161 - val_accuracy: 0.8152\n",
      "Epoch 819/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4075 - accuracy: 0.8214 - val_loss: 0.4163 - val_accuracy: 0.8147\n",
      "Epoch 820/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4072 - accuracy: 0.8220 - val_loss: 0.4166 - val_accuracy: 0.8151\n",
      "Epoch 821/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4073 - accuracy: 0.8216 - val_loss: 0.4163 - val_accuracy: 0.8147\n",
      "Epoch 822/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4072 - accuracy: 0.8214 - val_loss: 0.4164 - val_accuracy: 0.8154\n",
      "Epoch 823/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4071 - accuracy: 0.8217 - val_loss: 0.4161 - val_accuracy: 0.8156\n",
      "Epoch 824/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4079 - accuracy: 0.8214 - val_loss: 0.4162 - val_accuracy: 0.8153\n",
      "Epoch 825/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4072 - accuracy: 0.8217 - val_loss: 0.4171 - val_accuracy: 0.8148\n",
      "Epoch 826/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4071 - accuracy: 0.8218 - val_loss: 0.4167 - val_accuracy: 0.8147\n",
      "Epoch 827/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4071 - accuracy: 0.8214 - val_loss: 0.4168 - val_accuracy: 0.8146\n",
      "Epoch 828/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4069 - accuracy: 0.8218 - val_loss: 0.4160 - val_accuracy: 0.8158\n",
      "Epoch 829/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4074 - accuracy: 0.8214 - val_loss: 0.4163 - val_accuracy: 0.8151\n",
      "Epoch 830/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4071 - accuracy: 0.8216 - val_loss: 0.4160 - val_accuracy: 0.8154\n",
      "Epoch 831/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4071 - accuracy: 0.8218 - val_loss: 0.4158 - val_accuracy: 0.8149\n",
      "Epoch 832/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4071 - accuracy: 0.8217 - val_loss: 0.4163 - val_accuracy: 0.8147\n",
      "Epoch 833/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4073 - accuracy: 0.8216 - val_loss: 0.4160 - val_accuracy: 0.8155\n",
      "Epoch 834/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4072 - accuracy: 0.8218 - val_loss: 0.4159 - val_accuracy: 0.8148\n",
      "Epoch 835/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4075 - accuracy: 0.8214 - val_loss: 0.4166 - val_accuracy: 0.8150\n",
      "Epoch 836/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4070 - accuracy: 0.8216 - val_loss: 0.4170 - val_accuracy: 0.8144\n",
      "Epoch 837/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4069 - accuracy: 0.8219 - val_loss: 0.4162 - val_accuracy: 0.8149\n",
      "Epoch 838/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4070 - accuracy: 0.8217 - val_loss: 0.4162 - val_accuracy: 0.8151\n",
      "Epoch 839/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4071 - accuracy: 0.8217 - val_loss: 0.4168 - val_accuracy: 0.8148\n",
      "Epoch 840/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4067 - accuracy: 0.8222 - val_loss: 0.4162 - val_accuracy: 0.8152\n",
      "Epoch 841/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4068 - accuracy: 0.8219 - val_loss: 0.4165 - val_accuracy: 0.8151\n",
      "Epoch 842/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4068 - accuracy: 0.8218 - val_loss: 0.4161 - val_accuracy: 0.8149\n",
      "Epoch 843/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4066 - accuracy: 0.8220 - val_loss: 0.4166 - val_accuracy: 0.8151\n",
      "Epoch 844/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4069 - accuracy: 0.8219 - val_loss: 0.4163 - val_accuracy: 0.8150\n",
      "Epoch 845/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4066 - accuracy: 0.8220 - val_loss: 0.4163 - val_accuracy: 0.8151\n",
      "Epoch 846/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4067 - accuracy: 0.8223 - val_loss: 0.4163 - val_accuracy: 0.8150\n",
      "Epoch 847/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4067 - accuracy: 0.8220 - val_loss: 0.4162 - val_accuracy: 0.8148\n",
      "Epoch 848/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4065 - accuracy: 0.8221 - val_loss: 0.4164 - val_accuracy: 0.8139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 849/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4068 - accuracy: 0.8219 - val_loss: 0.4164 - val_accuracy: 0.8149\n",
      "Epoch 850/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4066 - accuracy: 0.8222 - val_loss: 0.4165 - val_accuracy: 0.8148\n",
      "Epoch 851/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4063 - accuracy: 0.8222 - val_loss: 0.4163 - val_accuracy: 0.8143\n",
      "Epoch 852/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4066 - accuracy: 0.8219 - val_loss: 0.4164 - val_accuracy: 0.8151\n",
      "Epoch 853/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4066 - accuracy: 0.8221 - val_loss: 0.4159 - val_accuracy: 0.8149\n",
      "Epoch 854/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4066 - accuracy: 0.8218 - val_loss: 0.4165 - val_accuracy: 0.8148\n",
      "Epoch 855/1000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.4063 - accuracy: 0.8222 - val_loss: 0.4163 - val_accuracy: 0.8155\n",
      "Epoch 856/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4064 - accuracy: 0.8219 - val_loss: 0.4164 - val_accuracy: 0.8151\n",
      "Epoch 857/1000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.4066 - accuracy: 0.8218 - val_loss: 0.4166 - val_accuracy: 0.8148\n",
      "Epoch 858/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4066 - accuracy: 0.8220 - val_loss: 0.4159 - val_accuracy: 0.8149\n",
      "Epoch 859/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4065 - accuracy: 0.8220 - val_loss: 0.4162 - val_accuracy: 0.8147\n",
      "Epoch 860/1000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.4065 - accuracy: 0.8217 - val_loss: 0.4160 - val_accuracy: 0.8154\n",
      "Epoch 861/1000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.4064 - accuracy: 0.8221 - val_loss: 0.4168 - val_accuracy: 0.8143\n",
      "Epoch 862/1000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.4063 - accuracy: 0.8221 - val_loss: 0.4161 - val_accuracy: 0.8147\n",
      "Epoch 863/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4063 - accuracy: 0.8222 - val_loss: 0.4158 - val_accuracy: 0.8153\n",
      "Epoch 864/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4066 - accuracy: 0.8219 - val_loss: 0.4162 - val_accuracy: 0.8148\n",
      "Epoch 865/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4063 - accuracy: 0.8218 - val_loss: 0.4159 - val_accuracy: 0.8158\n",
      "Epoch 866/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4062 - accuracy: 0.8220 - val_loss: 0.4163 - val_accuracy: 0.8147\n",
      "Epoch 867/1000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.4064 - accuracy: 0.8221 - val_loss: 0.4169 - val_accuracy: 0.8151\n",
      "Epoch 868/1000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.4062 - accuracy: 0.8222 - val_loss: 0.4160 - val_accuracy: 0.8153\n",
      "Epoch 869/1000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.4066 - accuracy: 0.8219 - val_loss: 0.4167 - val_accuracy: 0.8146\n",
      "Epoch 870/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4065 - accuracy: 0.8220 - val_loss: 0.4163 - val_accuracy: 0.8149\n",
      "Epoch 871/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4062 - accuracy: 0.8222 - val_loss: 0.4160 - val_accuracy: 0.8153\n",
      "Epoch 872/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4061 - accuracy: 0.8222 - val_loss: 0.4164 - val_accuracy: 0.8149\n",
      "Epoch 873/1000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 0.4066 - accuracy: 0.8215 - val_loss: 0.4166 - val_accuracy: 0.8149\n",
      "Epoch 874/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4060 - accuracy: 0.8221 - val_loss: 0.4168 - val_accuracy: 0.8146\n",
      "Epoch 875/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4064 - accuracy: 0.8219 - val_loss: 0.4166 - val_accuracy: 0.8144\n",
      "Epoch 876/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4061 - accuracy: 0.8222 - val_loss: 0.4161 - val_accuracy: 0.8144\n",
      "Epoch 877/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4066 - accuracy: 0.8218 - val_loss: 0.4163 - val_accuracy: 0.8146\n",
      "Epoch 878/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4065 - accuracy: 0.8221 - val_loss: 0.4163 - val_accuracy: 0.8144\n",
      "Epoch 879/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4065 - accuracy: 0.8218 - val_loss: 0.4158 - val_accuracy: 0.8154\n",
      "Epoch 880/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4063 - accuracy: 0.8218 - val_loss: 0.4158 - val_accuracy: 0.8150\n",
      "Epoch 881/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4060 - accuracy: 0.8224 - val_loss: 0.4164 - val_accuracy: 0.8155\n",
      "Epoch 882/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4059 - accuracy: 0.8222 - val_loss: 0.4162 - val_accuracy: 0.8145\n",
      "Epoch 883/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4060 - accuracy: 0.8223 - val_loss: 0.4161 - val_accuracy: 0.8152\n",
      "Epoch 884/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4058 - accuracy: 0.8224 - val_loss: 0.4159 - val_accuracy: 0.8146\n",
      "Epoch 885/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4063 - accuracy: 0.8218 - val_loss: 0.4159 - val_accuracy: 0.8154\n",
      "Epoch 886/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4065 - accuracy: 0.8221 - val_loss: 0.4157 - val_accuracy: 0.8147\n",
      "Epoch 887/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4063 - accuracy: 0.8219 - val_loss: 0.4157 - val_accuracy: 0.8146\n",
      "Epoch 888/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4057 - accuracy: 0.8223 - val_loss: 0.4163 - val_accuracy: 0.8148\n",
      "Epoch 889/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4062 - accuracy: 0.8220 - val_loss: 0.4161 - val_accuracy: 0.8153\n",
      "Epoch 890/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4062 - accuracy: 0.8221 - val_loss: 0.4156 - val_accuracy: 0.8153\n",
      "Epoch 891/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4060 - accuracy: 0.8219 - val_loss: 0.4164 - val_accuracy: 0.8153\n",
      "Epoch 892/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4057 - accuracy: 0.8224 - val_loss: 0.4160 - val_accuracy: 0.8148\n",
      "Epoch 893/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4061 - accuracy: 0.8223 - val_loss: 0.4160 - val_accuracy: 0.8151\n",
      "Epoch 894/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4059 - accuracy: 0.8220 - val_loss: 0.4158 - val_accuracy: 0.8149\n",
      "Epoch 895/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4059 - accuracy: 0.8225 - val_loss: 0.4160 - val_accuracy: 0.8152\n",
      "Epoch 896/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4058 - accuracy: 0.8227 - val_loss: 0.4159 - val_accuracy: 0.8154\n",
      "Epoch 897/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4058 - accuracy: 0.8221 - val_loss: 0.4158 - val_accuracy: 0.8158\n",
      "Epoch 898/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4056 - accuracy: 0.8222 - val_loss: 0.4158 - val_accuracy: 0.8152\n",
      "Epoch 899/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4060 - accuracy: 0.8223 - val_loss: 0.4159 - val_accuracy: 0.8146\n",
      "Epoch 900/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4060 - accuracy: 0.8221 - val_loss: 0.4165 - val_accuracy: 0.8142\n",
      "Epoch 901/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4062 - accuracy: 0.8220 - val_loss: 0.4161 - val_accuracy: 0.8148\n",
      "Epoch 902/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4055 - accuracy: 0.8224 - val_loss: 0.4157 - val_accuracy: 0.8145\n",
      "Epoch 903/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4055 - accuracy: 0.8225 - val_loss: 0.4156 - val_accuracy: 0.8152\n",
      "Epoch 904/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4055 - accuracy: 0.8225 - val_loss: 0.4159 - val_accuracy: 0.8152\n",
      "Epoch 905/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4060 - accuracy: 0.8222 - val_loss: 0.4160 - val_accuracy: 0.8144\n",
      "Epoch 906/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4055 - accuracy: 0.8225 - val_loss: 0.4157 - val_accuracy: 0.8142\n",
      "Epoch 907/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4056 - accuracy: 0.8223 - val_loss: 0.4158 - val_accuracy: 0.8153\n",
      "Epoch 908/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4053 - accuracy: 0.8225 - val_loss: 0.4164 - val_accuracy: 0.8152\n",
      "Epoch 909/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4055 - accuracy: 0.8227 - val_loss: 0.4162 - val_accuracy: 0.8149\n",
      "Epoch 910/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4053 - accuracy: 0.8228 - val_loss: 0.4156 - val_accuracy: 0.8152\n",
      "Epoch 911/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4053 - accuracy: 0.8225 - val_loss: 0.4160 - val_accuracy: 0.8149\n",
      "Epoch 912/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4063 - accuracy: 0.8220 - val_loss: 0.4161 - val_accuracy: 0.8144\n",
      "Epoch 913/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4053 - accuracy: 0.8226 - val_loss: 0.4163 - val_accuracy: 0.8152\n",
      "Epoch 914/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4053 - accuracy: 0.8226 - val_loss: 0.4156 - val_accuracy: 0.8153\n",
      "Epoch 915/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4055 - accuracy: 0.8226 - val_loss: 0.4161 - val_accuracy: 0.8151\n",
      "Epoch 916/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4054 - accuracy: 0.8225 - val_loss: 0.4159 - val_accuracy: 0.8149\n",
      "Epoch 917/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4060 - accuracy: 0.8220 - val_loss: 0.4164 - val_accuracy: 0.8148\n",
      "Epoch 918/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4052 - accuracy: 0.8226 - val_loss: 0.4164 - val_accuracy: 0.8145\n",
      "Epoch 919/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4051 - accuracy: 0.8227 - val_loss: 0.4165 - val_accuracy: 0.8155\n",
      "Epoch 920/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4052 - accuracy: 0.8226 - val_loss: 0.4167 - val_accuracy: 0.8137\n",
      "Epoch 921/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4058 - accuracy: 0.8224 - val_loss: 0.4158 - val_accuracy: 0.8143\n",
      "Epoch 922/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4057 - accuracy: 0.8225 - val_loss: 0.4164 - val_accuracy: 0.8143\n",
      "Epoch 923/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4054 - accuracy: 0.8223 - val_loss: 0.4157 - val_accuracy: 0.8149\n",
      "Epoch 924/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4053 - accuracy: 0.8227 - val_loss: 0.4158 - val_accuracy: 0.8148\n",
      "Epoch 925/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4055 - accuracy: 0.8223 - val_loss: 0.4155 - val_accuracy: 0.8152\n",
      "Epoch 926/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4049 - accuracy: 0.8230 - val_loss: 0.4160 - val_accuracy: 0.8152\n",
      "Epoch 927/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4050 - accuracy: 0.8224 - val_loss: 0.4159 - val_accuracy: 0.8150\n",
      "Epoch 928/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4051 - accuracy: 0.8226 - val_loss: 0.4166 - val_accuracy: 0.8149\n",
      "Epoch 929/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4049 - accuracy: 0.8227 - val_loss: 0.4157 - val_accuracy: 0.8151\n",
      "Epoch 930/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4050 - accuracy: 0.8226 - val_loss: 0.4160 - val_accuracy: 0.8145\n",
      "Epoch 931/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4049 - accuracy: 0.8229 - val_loss: 0.4165 - val_accuracy: 0.8145\n",
      "Epoch 932/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4050 - accuracy: 0.8226 - val_loss: 0.4161 - val_accuracy: 0.8152\n",
      "Epoch 933/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4048 - accuracy: 0.8226 - val_loss: 0.4157 - val_accuracy: 0.8152\n",
      "Epoch 934/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4047 - accuracy: 0.8226 - val_loss: 0.4158 - val_accuracy: 0.8155\n",
      "Epoch 935/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4049 - accuracy: 0.8229 - val_loss: 0.4164 - val_accuracy: 0.8149\n",
      "Epoch 936/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4051 - accuracy: 0.8224 - val_loss: 0.4160 - val_accuracy: 0.8152\n",
      "Epoch 937/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4052 - accuracy: 0.8228 - val_loss: 0.4161 - val_accuracy: 0.8152\n",
      "Epoch 938/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4048 - accuracy: 0.8232 - val_loss: 0.4156 - val_accuracy: 0.8149\n",
      "Epoch 939/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4050 - accuracy: 0.8226 - val_loss: 0.4162 - val_accuracy: 0.8152\n",
      "Epoch 940/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4046 - accuracy: 0.8229 - val_loss: 0.4162 - val_accuracy: 0.8149\n",
      "Epoch 941/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4047 - accuracy: 0.8227 - val_loss: 0.4158 - val_accuracy: 0.8146\n",
      "Epoch 942/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4048 - accuracy: 0.8227 - val_loss: 0.4160 - val_accuracy: 0.8152\n",
      "Epoch 943/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4047 - accuracy: 0.8230 - val_loss: 0.4157 - val_accuracy: 0.8148\n",
      "Epoch 944/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4050 - accuracy: 0.8226 - val_loss: 0.4159 - val_accuracy: 0.8149\n",
      "Epoch 945/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4048 - accuracy: 0.8229 - val_loss: 0.4159 - val_accuracy: 0.8149\n",
      "Epoch 946/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4046 - accuracy: 0.8228 - val_loss: 0.4160 - val_accuracy: 0.8149\n",
      "Epoch 947/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4049 - accuracy: 0.8227 - val_loss: 0.4167 - val_accuracy: 0.8148\n",
      "Epoch 948/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4047 - accuracy: 0.8230 - val_loss: 0.4155 - val_accuracy: 0.8152\n",
      "Epoch 949/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4046 - accuracy: 0.8232 - val_loss: 0.4160 - val_accuracy: 0.8146\n",
      "Epoch 950/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4048 - accuracy: 0.8226 - val_loss: 0.4162 - val_accuracy: 0.8151\n",
      "Epoch 951/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4048 - accuracy: 0.8225 - val_loss: 0.4158 - val_accuracy: 0.8153\n",
      "Epoch 952/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4045 - accuracy: 0.8229 - val_loss: 0.4156 - val_accuracy: 0.8151\n",
      "Epoch 953/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4045 - accuracy: 0.8226 - val_loss: 0.4156 - val_accuracy: 0.8144\n",
      "Epoch 954/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4049 - accuracy: 0.8226 - val_loss: 0.4170 - val_accuracy: 0.8142\n",
      "Epoch 955/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4042 - accuracy: 0.8230 - val_loss: 0.4162 - val_accuracy: 0.8151\n",
      "Epoch 956/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4046 - accuracy: 0.8228 - val_loss: 0.4154 - val_accuracy: 0.8152\n",
      "Epoch 957/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4045 - accuracy: 0.8229 - val_loss: 0.4164 - val_accuracy: 0.8152\n",
      "Epoch 958/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4044 - accuracy: 0.8227 - val_loss: 0.4159 - val_accuracy: 0.8154\n",
      "Epoch 959/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4044 - accuracy: 0.8229 - val_loss: 0.4157 - val_accuracy: 0.8156\n",
      "Epoch 960/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4043 - accuracy: 0.8230 - val_loss: 0.4161 - val_accuracy: 0.8147\n",
      "Epoch 961/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4044 - accuracy: 0.8229 - val_loss: 0.4161 - val_accuracy: 0.8143\n",
      "Epoch 962/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4043 - accuracy: 0.8231 - val_loss: 0.4159 - val_accuracy: 0.8151\n",
      "Epoch 963/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4046 - accuracy: 0.8229 - val_loss: 0.4160 - val_accuracy: 0.8150\n",
      "Epoch 964/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4042 - accuracy: 0.8228 - val_loss: 0.4158 - val_accuracy: 0.8151\n",
      "Epoch 965/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4045 - accuracy: 0.8229 - val_loss: 0.4161 - val_accuracy: 0.8144\n",
      "Epoch 966/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4044 - accuracy: 0.8233 - val_loss: 0.4165 - val_accuracy: 0.8149\n",
      "Epoch 967/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4042 - accuracy: 0.8231 - val_loss: 0.4162 - val_accuracy: 0.8145\n",
      "Epoch 968/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4043 - accuracy: 0.8230 - val_loss: 0.4158 - val_accuracy: 0.8148\n",
      "Epoch 969/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4043 - accuracy: 0.8231 - val_loss: 0.4168 - val_accuracy: 0.8151\n",
      "Epoch 970/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4040 - accuracy: 0.8229 - val_loss: 0.4157 - val_accuracy: 0.8153\n",
      "Epoch 971/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4044 - accuracy: 0.8229 - val_loss: 0.4167 - val_accuracy: 0.8146\n",
      "Epoch 972/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4039 - accuracy: 0.8231 - val_loss: 0.4154 - val_accuracy: 0.8157\n",
      "Epoch 973/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4042 - accuracy: 0.8231 - val_loss: 0.4161 - val_accuracy: 0.8155\n",
      "Epoch 974/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4040 - accuracy: 0.8232 - val_loss: 0.4155 - val_accuracy: 0.8150\n",
      "Epoch 975/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4042 - accuracy: 0.8229 - val_loss: 0.4162 - val_accuracy: 0.8149\n",
      "Epoch 976/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4045 - accuracy: 0.8225 - val_loss: 0.4150 - val_accuracy: 0.8153\n",
      "Epoch 977/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4041 - accuracy: 0.8228 - val_loss: 0.4156 - val_accuracy: 0.8152\n",
      "Epoch 978/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4038 - accuracy: 0.8234 - val_loss: 0.4160 - val_accuracy: 0.8156\n",
      "Epoch 979/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4041 - accuracy: 0.8231 - val_loss: 0.4157 - val_accuracy: 0.8148\n",
      "Epoch 980/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4040 - accuracy: 0.8230 - val_loss: 0.4162 - val_accuracy: 0.8152\n",
      "Epoch 981/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4044 - accuracy: 0.8228 - val_loss: 0.4158 - val_accuracy: 0.8151\n",
      "Epoch 982/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4042 - accuracy: 0.8229 - val_loss: 0.4155 - val_accuracy: 0.8148\n",
      "Epoch 983/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4041 - accuracy: 0.8232 - val_loss: 0.4155 - val_accuracy: 0.8153\n",
      "Epoch 984/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4044 - accuracy: 0.8229 - val_loss: 0.4156 - val_accuracy: 0.8147\n",
      "Epoch 985/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4047 - accuracy: 0.8225 - val_loss: 0.4166 - val_accuracy: 0.8147\n",
      "Epoch 986/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4040 - accuracy: 0.8233 - val_loss: 0.4158 - val_accuracy: 0.8149\n",
      "Epoch 987/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4038 - accuracy: 0.8232 - val_loss: 0.4160 - val_accuracy: 0.8147\n",
      "Epoch 988/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4040 - accuracy: 0.8230 - val_loss: 0.4153 - val_accuracy: 0.8151\n",
      "Epoch 989/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4041 - accuracy: 0.8231 - val_loss: 0.4157 - val_accuracy: 0.8158\n",
      "Epoch 990/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4040 - accuracy: 0.8233 - val_loss: 0.4155 - val_accuracy: 0.8153\n",
      "Epoch 991/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4042 - accuracy: 0.8228 - val_loss: 0.4151 - val_accuracy: 0.8154\n",
      "Epoch 992/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4041 - accuracy: 0.8230 - val_loss: 0.4160 - val_accuracy: 0.8148\n",
      "Epoch 993/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4040 - accuracy: 0.8233 - val_loss: 0.4157 - val_accuracy: 0.8153\n",
      "Epoch 994/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4043 - accuracy: 0.8229 - val_loss: 0.4159 - val_accuracy: 0.8153\n",
      "Epoch 995/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4040 - accuracy: 0.8229 - val_loss: 0.4158 - val_accuracy: 0.8152\n",
      "Epoch 996/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4037 - accuracy: 0.8233 - val_loss: 0.4158 - val_accuracy: 0.8150\n",
      "Epoch 997/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4036 - accuracy: 0.8233 - val_loss: 0.4155 - val_accuracy: 0.8146\n",
      "Epoch 998/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4036 - accuracy: 0.8233 - val_loss: 0.4156 - val_accuracy: 0.8152\n",
      "Epoch 999/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4038 - accuracy: 0.8231 - val_loss: 0.4156 - val_accuracy: 0.8154\n",
      "Epoch 1000/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4040 - accuracy: 0.8230 - val_loss: 0.4152 - val_accuracy: 0.8153\n",
      "Epoch 1/1000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.5721 - accuracy: 0.7168 - val_loss: 0.5509 - val_accuracy: 0.7211\n",
      "Epoch 2/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5473 - accuracy: 0.7231 - val_loss: 0.5431 - val_accuracy: 0.7226\n",
      "Epoch 3/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5293 - accuracy: 0.7347 - val_loss: 0.5221 - val_accuracy: 0.7375\n",
      "Epoch 4/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5152 - accuracy: 0.7457 - val_loss: 0.5242 - val_accuracy: 0.7288\n",
      "Epoch 5/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5037 - accuracy: 0.7561 - val_loss: 0.4948 - val_accuracy: 0.7602\n",
      "Epoch 6/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4947 - accuracy: 0.7647 - val_loss: 0.4888 - val_accuracy: 0.7736\n",
      "Epoch 7/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4884 - accuracy: 0.7704 - val_loss: 0.4913 - val_accuracy: 0.7610\n",
      "Epoch 8/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4815 - accuracy: 0.7763 - val_loss: 0.4704 - val_accuracy: 0.7929\n",
      "Epoch 9/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4764 - accuracy: 0.7819 - val_loss: 0.4717 - val_accuracy: 0.7851\n",
      "Epoch 10/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4716 - accuracy: 0.7850 - val_loss: 0.4713 - val_accuracy: 0.7832\n",
      "Epoch 11/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4681 - accuracy: 0.7889 - val_loss: 0.4599 - val_accuracy: 0.7894\n",
      "Epoch 12/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4641 - accuracy: 0.7915 - val_loss: 0.4736 - val_accuracy: 0.7744\n",
      "Epoch 13/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4608 - accuracy: 0.7937 - val_loss: 0.4576 - val_accuracy: 0.7941\n",
      "Epoch 14/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4594 - accuracy: 0.7955 - val_loss: 0.4546 - val_accuracy: 0.7919\n",
      "Epoch 15/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4575 - accuracy: 0.7973 - val_loss: 0.4463 - val_accuracy: 0.8019\n",
      "Epoch 16/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4533 - accuracy: 0.7989 - val_loss: 0.4456 - val_accuracy: 0.8026\n",
      "Epoch 17/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4509 - accuracy: 0.7995 - val_loss: 0.4500 - val_accuracy: 0.7960\n",
      "Epoch 18/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4489 - accuracy: 0.8021 - val_loss: 0.4398 - val_accuracy: 0.8048\n",
      "Epoch 19/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4494 - accuracy: 0.8007 - val_loss: 0.4434 - val_accuracy: 0.8041\n",
      "Epoch 20/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4476 - accuracy: 0.8022 - val_loss: 0.4391 - val_accuracy: 0.8041\n",
      "Epoch 21/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4458 - accuracy: 0.8027 - val_loss: 0.4439 - val_accuracy: 0.8076\n",
      "Epoch 22/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4437 - accuracy: 0.8037 - val_loss: 0.4403 - val_accuracy: 0.8019\n",
      "Epoch 23/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4430 - accuracy: 0.8038 - val_loss: 0.4394 - val_accuracy: 0.8017\n",
      "Epoch 24/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4422 - accuracy: 0.8030 - val_loss: 0.4401 - val_accuracy: 0.7968\n",
      "Epoch 25/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4418 - accuracy: 0.8027 - val_loss: 0.4376 - val_accuracy: 0.8009\n",
      "Epoch 26/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4404 - accuracy: 0.8045 - val_loss: 0.4341 - val_accuracy: 0.8096\n",
      "Epoch 27/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4393 - accuracy: 0.8054 - val_loss: 0.4366 - val_accuracy: 0.8042\n",
      "Epoch 28/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4390 - accuracy: 0.8047 - val_loss: 0.4342 - val_accuracy: 0.8061\n",
      "Epoch 29/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4368 - accuracy: 0.8070 - val_loss: 0.4381 - val_accuracy: 0.8057\n",
      "Epoch 30/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4374 - accuracy: 0.8065 - val_loss: 0.4369 - val_accuracy: 0.8082\n",
      "Epoch 31/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4364 - accuracy: 0.8061 - val_loss: 0.4322 - val_accuracy: 0.8077\n",
      "Epoch 32/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4350 - accuracy: 0.8065 - val_loss: 0.4365 - val_accuracy: 0.8074\n",
      "Epoch 33/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4347 - accuracy: 0.8066 - val_loss: 0.4283 - val_accuracy: 0.8103\n",
      "Epoch 34/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4342 - accuracy: 0.8075 - val_loss: 0.4272 - val_accuracy: 0.8114\n",
      "Epoch 35/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4339 - accuracy: 0.8073 - val_loss: 0.4320 - val_accuracy: 0.8086\n",
      "Epoch 36/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4318 - accuracy: 0.8084 - val_loss: 0.4327 - val_accuracy: 0.8085\n",
      "Epoch 37/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4335 - accuracy: 0.8080 - val_loss: 0.4324 - val_accuracy: 0.8062\n",
      "Epoch 38/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4322 - accuracy: 0.8075 - val_loss: 0.4259 - val_accuracy: 0.8101\n",
      "Epoch 39/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4318 - accuracy: 0.8088 - val_loss: 0.4239 - val_accuracy: 0.8120\n",
      "Epoch 40/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4311 - accuracy: 0.8092 - val_loss: 0.4264 - val_accuracy: 0.8108\n",
      "Epoch 41/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4308 - accuracy: 0.8086 - val_loss: 0.4229 - val_accuracy: 0.8124\n",
      "Epoch 42/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4319 - accuracy: 0.8085 - val_loss: 0.4270 - val_accuracy: 0.8101\n",
      "Epoch 43/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4304 - accuracy: 0.8094 - val_loss: 0.4274 - val_accuracy: 0.8120\n",
      "Epoch 44/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4294 - accuracy: 0.8090 - val_loss: 0.4247 - val_accuracy: 0.8081\n",
      "Epoch 45/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4285 - accuracy: 0.8091 - val_loss: 0.4241 - val_accuracy: 0.8135\n",
      "Epoch 46/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4294 - accuracy: 0.8090 - val_loss: 0.4268 - val_accuracy: 0.8109\n",
      "Epoch 47/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4291 - accuracy: 0.8096 - val_loss: 0.4231 - val_accuracy: 0.8111\n",
      "Epoch 48/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4292 - accuracy: 0.8096 - val_loss: 0.4292 - val_accuracy: 0.8076\n",
      "Epoch 49/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4281 - accuracy: 0.8093 - val_loss: 0.4196 - val_accuracy: 0.8131\n",
      "Epoch 50/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4276 - accuracy: 0.8097 - val_loss: 0.4208 - val_accuracy: 0.8131\n",
      "Epoch 51/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4279 - accuracy: 0.8097 - val_loss: 0.4231 - val_accuracy: 0.8126\n",
      "Epoch 52/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4272 - accuracy: 0.8098 - val_loss: 0.4239 - val_accuracy: 0.8068\n",
      "Epoch 53/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4258 - accuracy: 0.8107 - val_loss: 0.4201 - val_accuracy: 0.8144\n",
      "Epoch 54/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4263 - accuracy: 0.8102 - val_loss: 0.4255 - val_accuracy: 0.8072\n",
      "Epoch 55/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4268 - accuracy: 0.8111 - val_loss: 0.4218 - val_accuracy: 0.8111\n",
      "Epoch 56/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4279 - accuracy: 0.8098 - val_loss: 0.4201 - val_accuracy: 0.8140\n",
      "Epoch 57/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4270 - accuracy: 0.8084 - val_loss: 0.4217 - val_accuracy: 0.8122\n",
      "Epoch 58/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4259 - accuracy: 0.8108 - val_loss: 0.4181 - val_accuracy: 0.8154\n",
      "Epoch 59/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4249 - accuracy: 0.8114 - val_loss: 0.4340 - val_accuracy: 0.8040\n",
      "Epoch 60/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4252 - accuracy: 0.8117 - val_loss: 0.4201 - val_accuracy: 0.8134\n",
      "Epoch 61/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4244 - accuracy: 0.8114 - val_loss: 0.4249 - val_accuracy: 0.8097\n",
      "Epoch 62/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4249 - accuracy: 0.8108 - val_loss: 0.4260 - val_accuracy: 0.8113\n",
      "Epoch 63/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4233 - accuracy: 0.8116 - val_loss: 0.4179 - val_accuracy: 0.8141\n",
      "Epoch 64/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4237 - accuracy: 0.8117 - val_loss: 0.4316 - val_accuracy: 0.8089\n",
      "Epoch 65/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4246 - accuracy: 0.8116 - val_loss: 0.4192 - val_accuracy: 0.8122\n",
      "Epoch 66/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4238 - accuracy: 0.8117 - val_loss: 0.4250 - val_accuracy: 0.8090\n",
      "Epoch 67/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4234 - accuracy: 0.8113 - val_loss: 0.4186 - val_accuracy: 0.8157\n",
      "Epoch 68/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4234 - accuracy: 0.8122 - val_loss: 0.4176 - val_accuracy: 0.8137\n",
      "Epoch 69/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4234 - accuracy: 0.8116 - val_loss: 0.4317 - val_accuracy: 0.8102\n",
      "Epoch 70/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4221 - accuracy: 0.8124 - val_loss: 0.4252 - val_accuracy: 0.8093\n",
      "Epoch 71/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4212 - accuracy: 0.8120 - val_loss: 0.4180 - val_accuracy: 0.8120\n",
      "Epoch 72/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4228 - accuracy: 0.8113 - val_loss: 0.4169 - val_accuracy: 0.8139\n",
      "Epoch 73/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4213 - accuracy: 0.8121 - val_loss: 0.4179 - val_accuracy: 0.8129\n",
      "Epoch 74/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4221 - accuracy: 0.8122 - val_loss: 0.4135 - val_accuracy: 0.8163\n",
      "Epoch 75/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4207 - accuracy: 0.8126 - val_loss: 0.4168 - val_accuracy: 0.8146\n",
      "Epoch 76/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4212 - accuracy: 0.8115 - val_loss: 0.4169 - val_accuracy: 0.8144\n",
      "Epoch 77/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4202 - accuracy: 0.8124 - val_loss: 0.4202 - val_accuracy: 0.8095\n",
      "Epoch 78/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4227 - accuracy: 0.8114 - val_loss: 0.4281 - val_accuracy: 0.8150\n",
      "Epoch 79/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4231 - accuracy: 0.8115 - val_loss: 0.4143 - val_accuracy: 0.8153\n",
      "Epoch 80/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4216 - accuracy: 0.8124 - val_loss: 0.4206 - val_accuracy: 0.8104\n",
      "Epoch 81/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4209 - accuracy: 0.8133 - val_loss: 0.4163 - val_accuracy: 0.8125\n",
      "Epoch 82/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4217 - accuracy: 0.8120 - val_loss: 0.4206 - val_accuracy: 0.8130\n",
      "Epoch 83/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4214 - accuracy: 0.8119 - val_loss: 0.4169 - val_accuracy: 0.8124\n",
      "Epoch 84/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4212 - accuracy: 0.8113 - val_loss: 0.4133 - val_accuracy: 0.8159\n",
      "Epoch 85/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4190 - accuracy: 0.8130 - val_loss: 0.4186 - val_accuracy: 0.8140\n",
      "Epoch 86/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4211 - accuracy: 0.8121 - val_loss: 0.4207 - val_accuracy: 0.8077\n",
      "Epoch 87/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4211 - accuracy: 0.8133 - val_loss: 0.4192 - val_accuracy: 0.8102\n",
      "Epoch 88/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4200 - accuracy: 0.8130 - val_loss: 0.4151 - val_accuracy: 0.8134\n",
      "Epoch 89/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4201 - accuracy: 0.8132 - val_loss: 0.4184 - val_accuracy: 0.8067\n",
      "Epoch 90/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4202 - accuracy: 0.8129 - val_loss: 0.4171 - val_accuracy: 0.8129\n",
      "Epoch 91/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4202 - accuracy: 0.8128 - val_loss: 0.4117 - val_accuracy: 0.8164\n",
      "Epoch 92/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4196 - accuracy: 0.8129 - val_loss: 0.4244 - val_accuracy: 0.8135\n",
      "Epoch 93/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4200 - accuracy: 0.8124 - val_loss: 0.4223 - val_accuracy: 0.8109\n",
      "Epoch 94/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4198 - accuracy: 0.8130 - val_loss: 0.4111 - val_accuracy: 0.8179\n",
      "Epoch 95/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4192 - accuracy: 0.8135 - val_loss: 0.4210 - val_accuracy: 0.8130\n",
      "Epoch 96/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4197 - accuracy: 0.8140 - val_loss: 0.4177 - val_accuracy: 0.8104\n",
      "Epoch 97/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4201 - accuracy: 0.8133 - val_loss: 0.4171 - val_accuracy: 0.8102\n",
      "Epoch 98/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4198 - accuracy: 0.8130 - val_loss: 0.4173 - val_accuracy: 0.8157\n",
      "Epoch 99/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4200 - accuracy: 0.8124 - val_loss: 0.4254 - val_accuracy: 0.8049\n",
      "Epoch 100/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4183 - accuracy: 0.8137 - val_loss: 0.4184 - val_accuracy: 0.8127\n",
      "Epoch 101/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4198 - accuracy: 0.8135 - val_loss: 0.4134 - val_accuracy: 0.8139\n",
      "Epoch 102/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4201 - accuracy: 0.8132 - val_loss: 0.4210 - val_accuracy: 0.8169\n",
      "Epoch 103/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4182 - accuracy: 0.8150 - val_loss: 0.4175 - val_accuracy: 0.8129\n",
      "Epoch 104/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4190 - accuracy: 0.8143 - val_loss: 0.4194 - val_accuracy: 0.8091\n",
      "Epoch 105/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4195 - accuracy: 0.8129 - val_loss: 0.4187 - val_accuracy: 0.8121\n",
      "Epoch 106/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4171 - accuracy: 0.8143 - val_loss: 0.4152 - val_accuracy: 0.8148\n",
      "Epoch 107/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4189 - accuracy: 0.8135 - val_loss: 0.4153 - val_accuracy: 0.8127\n",
      "Epoch 108/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4196 - accuracy: 0.8126 - val_loss: 0.4148 - val_accuracy: 0.8164\n",
      "Epoch 109/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4179 - accuracy: 0.8142 - val_loss: 0.4210 - val_accuracy: 0.8173\n",
      "Epoch 110/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4183 - accuracy: 0.8140 - val_loss: 0.4148 - val_accuracy: 0.8153\n",
      "Epoch 111/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4183 - accuracy: 0.8141 - val_loss: 0.4182 - val_accuracy: 0.8123\n",
      "Epoch 112/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4189 - accuracy: 0.8142 - val_loss: 0.4153 - val_accuracy: 0.8170\n",
      "Epoch 113/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4183 - accuracy: 0.8145 - val_loss: 0.4139 - val_accuracy: 0.8147\n",
      "Epoch 114/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4186 - accuracy: 0.8136 - val_loss: 0.4140 - val_accuracy: 0.8132\n",
      "Epoch 115/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4180 - accuracy: 0.8141 - val_loss: 0.4203 - val_accuracy: 0.8085\n",
      "Epoch 116/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4191 - accuracy: 0.8128 - val_loss: 0.4206 - val_accuracy: 0.8067\n",
      "Epoch 117/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4198 - accuracy: 0.8130 - val_loss: 0.4124 - val_accuracy: 0.8162\n",
      "Epoch 118/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4172 - accuracy: 0.8137 - val_loss: 0.4169 - val_accuracy: 0.8156\n",
      "Epoch 119/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4169 - accuracy: 0.8147 - val_loss: 0.4168 - val_accuracy: 0.8088\n",
      "Epoch 120/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4190 - accuracy: 0.8137 - val_loss: 0.4145 - val_accuracy: 0.8150\n",
      "Epoch 121/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4176 - accuracy: 0.8143 - val_loss: 0.4176 - val_accuracy: 0.8149\n",
      "Epoch 122/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4201 - accuracy: 0.8135 - val_loss: 0.4178 - val_accuracy: 0.8160\n",
      "Epoch 123/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4199 - accuracy: 0.8138 - val_loss: 0.4220 - val_accuracy: 0.8053\n",
      "Epoch 124/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4210 - accuracy: 0.8139 - val_loss: 0.4153 - val_accuracy: 0.8157\n",
      "Epoch 125/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4197 - accuracy: 0.8147 - val_loss: 0.4119 - val_accuracy: 0.8185\n",
      "Epoch 126/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4191 - accuracy: 0.8146 - val_loss: 0.4176 - val_accuracy: 0.8094\n",
      "Epoch 127/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4197 - accuracy: 0.8136 - val_loss: 0.4183 - val_accuracy: 0.8135\n",
      "Epoch 128/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4192 - accuracy: 0.8138 - val_loss: 0.4172 - val_accuracy: 0.8148\n",
      "Epoch 129/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4195 - accuracy: 0.8130 - val_loss: 0.4228 - val_accuracy: 0.8142\n",
      "Epoch 130/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4198 - accuracy: 0.8134 - val_loss: 0.4145 - val_accuracy: 0.8147\n",
      "Epoch 131/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4198 - accuracy: 0.8126 - val_loss: 0.4179 - val_accuracy: 0.8144\n",
      "Epoch 132/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4187 - accuracy: 0.8137 - val_loss: 0.4282 - val_accuracy: 0.8137\n",
      "Epoch 133/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4196 - accuracy: 0.8139 - val_loss: 0.4170 - val_accuracy: 0.8148\n",
      "Epoch 134/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4181 - accuracy: 0.8140 - val_loss: 0.4133 - val_accuracy: 0.8147\n",
      "Epoch 135/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4195 - accuracy: 0.8134 - val_loss: 0.4196 - val_accuracy: 0.8139\n",
      "Epoch 136/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4180 - accuracy: 0.8142 - val_loss: 0.4120 - val_accuracy: 0.8179\n",
      "Epoch 137/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4187 - accuracy: 0.8138 - val_loss: 0.4130 - val_accuracy: 0.8157\n",
      "Epoch 138/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4183 - accuracy: 0.8139 - val_loss: 0.4127 - val_accuracy: 0.8171\n",
      "Epoch 139/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4172 - accuracy: 0.8146 - val_loss: 0.4171 - val_accuracy: 0.8138\n",
      "Epoch 140/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4175 - accuracy: 0.8143 - val_loss: 0.4190 - val_accuracy: 0.8148\n",
      "Epoch 141/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4169 - accuracy: 0.8142 - val_loss: 0.4150 - val_accuracy: 0.8129\n",
      "Epoch 142/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4191 - accuracy: 0.8148 - val_loss: 0.4146 - val_accuracy: 0.8153\n",
      "Epoch 143/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4197 - accuracy: 0.8137 - val_loss: 0.4200 - val_accuracy: 0.8078\n",
      "Epoch 144/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4180 - accuracy: 0.8133 - val_loss: 0.4138 - val_accuracy: 0.8160\n",
      "Epoch 145/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4178 - accuracy: 0.8140 - val_loss: 0.4177 - val_accuracy: 0.8131\n",
      "Epoch 146/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4172 - accuracy: 0.8143 - val_loss: 0.4145 - val_accuracy: 0.8177\n",
      "Epoch 147/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4179 - accuracy: 0.8139 - val_loss: 0.4164 - val_accuracy: 0.8156\n",
      "Epoch 148/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4183 - accuracy: 0.8137 - val_loss: 0.4211 - val_accuracy: 0.8124\n",
      "Epoch 149/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4174 - accuracy: 0.8145 - val_loss: 0.4175 - val_accuracy: 0.8142\n",
      "Epoch 150/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4180 - accuracy: 0.8143 - val_loss: 0.4152 - val_accuracy: 0.8133\n",
      "Epoch 151/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4175 - accuracy: 0.8144 - val_loss: 0.4118 - val_accuracy: 0.8166\n",
      "Epoch 152/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4180 - accuracy: 0.8147 - val_loss: 0.4161 - val_accuracy: 0.8147\n",
      "Epoch 153/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4186 - accuracy: 0.8142 - val_loss: 0.4139 - val_accuracy: 0.8158\n",
      "Epoch 154/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4193 - accuracy: 0.8131 - val_loss: 0.4174 - val_accuracy: 0.8104\n",
      "Epoch 155/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4192 - accuracy: 0.8142 - val_loss: 0.4103 - val_accuracy: 0.8177\n",
      "Epoch 156/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4162 - accuracy: 0.8152 - val_loss: 0.4115 - val_accuracy: 0.8170\n",
      "Epoch 157/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4177 - accuracy: 0.8147 - val_loss: 0.4093 - val_accuracy: 0.8184\n",
      "Epoch 158/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4178 - accuracy: 0.8145 - val_loss: 0.4197 - val_accuracy: 0.8131\n",
      "Epoch 159/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4179 - accuracy: 0.8142 - val_loss: 0.4172 - val_accuracy: 0.8157\n",
      "Epoch 160/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4187 - accuracy: 0.8146 - val_loss: 0.4272 - val_accuracy: 0.8122\n",
      "Epoch 161/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4164 - accuracy: 0.8152 - val_loss: 0.4117 - val_accuracy: 0.8184\n",
      "Epoch 162/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4182 - accuracy: 0.8143 - val_loss: 0.4119 - val_accuracy: 0.8172\n",
      "Epoch 163/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4157 - accuracy: 0.8157 - val_loss: 0.4122 - val_accuracy: 0.8175\n",
      "Epoch 164/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4160 - accuracy: 0.8150 - val_loss: 0.4158 - val_accuracy: 0.8112\n",
      "Epoch 165/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4181 - accuracy: 0.8137 - val_loss: 0.4119 - val_accuracy: 0.8166\n",
      "Epoch 166/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4158 - accuracy: 0.8154 - val_loss: 0.4114 - val_accuracy: 0.8150\n",
      "Epoch 167/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4157 - accuracy: 0.8139 - val_loss: 0.4150 - val_accuracy: 0.8131\n",
      "Epoch 168/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4187 - accuracy: 0.8147 - val_loss: 0.4131 - val_accuracy: 0.8174\n",
      "Epoch 169/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4182 - accuracy: 0.8152 - val_loss: 0.4202 - val_accuracy: 0.8152\n",
      "Epoch 170/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4174 - accuracy: 0.8156 - val_loss: 0.4220 - val_accuracy: 0.8130\n",
      "Epoch 171/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4170 - accuracy: 0.8151 - val_loss: 0.4145 - val_accuracy: 0.8164\n",
      "Epoch 172/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4172 - accuracy: 0.8155 - val_loss: 0.4156 - val_accuracy: 0.8149\n",
      "Epoch 173/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4185 - accuracy: 0.8137 - val_loss: 0.4133 - val_accuracy: 0.8163\n",
      "Epoch 174/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4165 - accuracy: 0.8161 - val_loss: 0.4136 - val_accuracy: 0.8160\n",
      "Epoch 175/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4167 - accuracy: 0.8155 - val_loss: 0.4182 - val_accuracy: 0.8143\n",
      "Epoch 176/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4171 - accuracy: 0.8151 - val_loss: 0.4169 - val_accuracy: 0.8123\n",
      "Epoch 177/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4165 - accuracy: 0.8157 - val_loss: 0.4275 - val_accuracy: 0.8139\n",
      "Epoch 178/1000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.4171 - accuracy: 0.8152 - val_loss: 0.4121 - val_accuracy: 0.8170\n",
      "Epoch 179/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4180 - accuracy: 0.8137 - val_loss: 0.4207 - val_accuracy: 0.8103\n",
      "Epoch 180/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4166 - accuracy: 0.8158 - val_loss: 0.4104 - val_accuracy: 0.8169\n",
      "Epoch 181/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4162 - accuracy: 0.8156 - val_loss: 0.4164 - val_accuracy: 0.8128\n",
      "Epoch 182/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4159 - accuracy: 0.8154 - val_loss: 0.4187 - val_accuracy: 0.8177\n",
      "Epoch 183/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4168 - accuracy: 0.8146 - val_loss: 0.4166 - val_accuracy: 0.8130\n",
      "Epoch 184/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4165 - accuracy: 0.8154 - val_loss: 0.4166 - val_accuracy: 0.8121\n",
      "Epoch 185/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4170 - accuracy: 0.8157 - val_loss: 0.4166 - val_accuracy: 0.8140\n",
      "Epoch 186/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4170 - accuracy: 0.8160 - val_loss: 0.4188 - val_accuracy: 0.8100\n",
      "Epoch 187/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4177 - accuracy: 0.8144 - val_loss: 0.4156 - val_accuracy: 0.8140\n",
      "Epoch 188/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4157 - accuracy: 0.8152 - val_loss: 0.4116 - val_accuracy: 0.8177\n",
      "Epoch 189/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4162 - accuracy: 0.8158 - val_loss: 0.4178 - val_accuracy: 0.8165\n",
      "Epoch 190/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4172 - accuracy: 0.8154 - val_loss: 0.4117 - val_accuracy: 0.8176\n",
      "Epoch 191/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4163 - accuracy: 0.8154 - val_loss: 0.4160 - val_accuracy: 0.8138\n",
      "Epoch 192/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4161 - accuracy: 0.8158 - val_loss: 0.4184 - val_accuracy: 0.8107\n",
      "Epoch 193/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4181 - accuracy: 0.8138 - val_loss: 0.4284 - val_accuracy: 0.8105\n",
      "Epoch 194/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4215 - accuracy: 0.8144 - val_loss: 0.4157 - val_accuracy: 0.8143\n",
      "Epoch 195/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4181 - accuracy: 0.8158 - val_loss: 0.4203 - val_accuracy: 0.8049\n",
      "Epoch 196/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4184 - accuracy: 0.8145 - val_loss: 0.4124 - val_accuracy: 0.8157\n",
      "Epoch 197/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4171 - accuracy: 0.8157 - val_loss: 0.4249 - val_accuracy: 0.8070\n",
      "Epoch 198/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4170 - accuracy: 0.8139 - val_loss: 0.4245 - val_accuracy: 0.8116\n",
      "Epoch 199/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4174 - accuracy: 0.8143 - val_loss: 0.4174 - val_accuracy: 0.8126\n",
      "Epoch 200/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4176 - accuracy: 0.8144 - val_loss: 0.4113 - val_accuracy: 0.8142\n",
      "Epoch 201/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4178 - accuracy: 0.8145 - val_loss: 0.4167 - val_accuracy: 0.8105\n",
      "Epoch 202/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4159 - accuracy: 0.8140 - val_loss: 0.4141 - val_accuracy: 0.8171\n",
      "Epoch 203/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4162 - accuracy: 0.8152 - val_loss: 0.4166 - val_accuracy: 0.8106\n",
      "Epoch 204/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4160 - accuracy: 0.8155 - val_loss: 0.4136 - val_accuracy: 0.8160\n",
      "Epoch 205/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4159 - accuracy: 0.8145 - val_loss: 0.4151 - val_accuracy: 0.8109\n",
      "Epoch 206/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4161 - accuracy: 0.8151 - val_loss: 0.4192 - val_accuracy: 0.8138\n",
      "Epoch 207/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4174 - accuracy: 0.8154 - val_loss: 0.4195 - val_accuracy: 0.8127\n",
      "Epoch 208/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4150 - accuracy: 0.8151 - val_loss: 0.4140 - val_accuracy: 0.8163\n",
      "Epoch 209/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4150 - accuracy: 0.8151 - val_loss: 0.4125 - val_accuracy: 0.8168\n",
      "Epoch 210/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4160 - accuracy: 0.8148 - val_loss: 0.4170 - val_accuracy: 0.8139\n",
      "Epoch 211/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4156 - accuracy: 0.8156 - val_loss: 0.4120 - val_accuracy: 0.8161\n",
      "Epoch 212/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4156 - accuracy: 0.8148 - val_loss: 0.4186 - val_accuracy: 0.8164\n",
      "Epoch 213/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4151 - accuracy: 0.8149 - val_loss: 0.4086 - val_accuracy: 0.8182\n",
      "Epoch 214/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4149 - accuracy: 0.8148 - val_loss: 0.4141 - val_accuracy: 0.8126\n",
      "Epoch 215/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4159 - accuracy: 0.8152 - val_loss: 0.4163 - val_accuracy: 0.8140\n",
      "Epoch 216/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4178 - accuracy: 0.8137 - val_loss: 0.4134 - val_accuracy: 0.8181\n",
      "Epoch 217/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4171 - accuracy: 0.8141 - val_loss: 0.4104 - val_accuracy: 0.8160\n",
      "Epoch 218/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4168 - accuracy: 0.8138 - val_loss: 0.4209 - val_accuracy: 0.8139\n",
      "Epoch 219/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4166 - accuracy: 0.8146 - val_loss: 0.4113 - val_accuracy: 0.8144\n",
      "Epoch 220/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4140 - accuracy: 0.8150 - val_loss: 0.4116 - val_accuracy: 0.8156\n",
      "Epoch 221/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4150 - accuracy: 0.8156 - val_loss: 0.4175 - val_accuracy: 0.8136\n",
      "Epoch 222/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4151 - accuracy: 0.8149 - val_loss: 0.4114 - val_accuracy: 0.8148\n",
      "Epoch 223/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4147 - accuracy: 0.8156 - val_loss: 0.4126 - val_accuracy: 0.8138\n",
      "Epoch 224/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4164 - accuracy: 0.8145 - val_loss: 0.4140 - val_accuracy: 0.8148\n",
      "Epoch 225/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4153 - accuracy: 0.8158 - val_loss: 0.4126 - val_accuracy: 0.8153\n",
      "Epoch 226/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4152 - accuracy: 0.8158 - val_loss: 0.4116 - val_accuracy: 0.8167\n",
      "Epoch 227/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4140 - accuracy: 0.8157 - val_loss: 0.4114 - val_accuracy: 0.8161\n",
      "Epoch 228/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4142 - accuracy: 0.8151 - val_loss: 0.4133 - val_accuracy: 0.8148\n",
      "Epoch 229/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4148 - accuracy: 0.8150 - val_loss: 0.4120 - val_accuracy: 0.8166\n",
      "Epoch 230/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4144 - accuracy: 0.8151 - val_loss: 0.4097 - val_accuracy: 0.8150\n",
      "Epoch 231/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4153 - accuracy: 0.8146 - val_loss: 0.4111 - val_accuracy: 0.8180\n",
      "Epoch 232/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4149 - accuracy: 0.8154 - val_loss: 0.4135 - val_accuracy: 0.8161\n",
      "Epoch 233/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4143 - accuracy: 0.8155 - val_loss: 0.4171 - val_accuracy: 0.8124\n",
      "Epoch 234/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4158 - accuracy: 0.8151 - val_loss: 0.4095 - val_accuracy: 0.8160\n",
      "Epoch 235/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4153 - accuracy: 0.8157 - val_loss: 0.4147 - val_accuracy: 0.8152\n",
      "Epoch 236/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4156 - accuracy: 0.8162 - val_loss: 0.4135 - val_accuracy: 0.8215\n",
      "Epoch 237/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4149 - accuracy: 0.8147 - val_loss: 0.4117 - val_accuracy: 0.8158\n",
      "Epoch 238/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4139 - accuracy: 0.8153 - val_loss: 0.4126 - val_accuracy: 0.8157\n",
      "Epoch 239/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4137 - accuracy: 0.8162 - val_loss: 0.4096 - val_accuracy: 0.8176\n",
      "Epoch 240/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4146 - accuracy: 0.8144 - val_loss: 0.4188 - val_accuracy: 0.8101\n",
      "Epoch 241/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4165 - accuracy: 0.8142 - val_loss: 0.4140 - val_accuracy: 0.8169\n",
      "Epoch 242/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4143 - accuracy: 0.8153 - val_loss: 0.4086 - val_accuracy: 0.8189\n",
      "Epoch 243/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4148 - accuracy: 0.8157 - val_loss: 0.4142 - val_accuracy: 0.8168\n",
      "Epoch 244/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4158 - accuracy: 0.8159 - val_loss: 0.4146 - val_accuracy: 0.8155\n",
      "Epoch 245/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4152 - accuracy: 0.8149 - val_loss: 0.4084 - val_accuracy: 0.8162\n",
      "Epoch 246/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4146 - accuracy: 0.8153 - val_loss: 0.4123 - val_accuracy: 0.8165\n",
      "Epoch 247/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4155 - accuracy: 0.8159 - val_loss: 0.4231 - val_accuracy: 0.8194\n",
      "Epoch 248/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4150 - accuracy: 0.8156 - val_loss: 0.4124 - val_accuracy: 0.8160\n",
      "Epoch 249/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4148 - accuracy: 0.8150 - val_loss: 0.4191 - val_accuracy: 0.8180\n",
      "Epoch 250/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4140 - accuracy: 0.8166 - val_loss: 0.4142 - val_accuracy: 0.8148\n",
      "Epoch 251/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4139 - accuracy: 0.8162 - val_loss: 0.4125 - val_accuracy: 0.8132\n",
      "Epoch 252/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4146 - accuracy: 0.8153 - val_loss: 0.4104 - val_accuracy: 0.8174\n",
      "Epoch 253/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4153 - accuracy: 0.8156 - val_loss: 0.4104 - val_accuracy: 0.8178\n",
      "Epoch 254/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4130 - accuracy: 0.8158 - val_loss: 0.4110 - val_accuracy: 0.8181\n",
      "Epoch 255/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4133 - accuracy: 0.8169 - val_loss: 0.4108 - val_accuracy: 0.8158\n",
      "Epoch 256/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4145 - accuracy: 0.8160 - val_loss: 0.4121 - val_accuracy: 0.8164\n",
      "Epoch 257/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4162 - accuracy: 0.8146 - val_loss: 0.4123 - val_accuracy: 0.8114\n",
      "Epoch 258/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4139 - accuracy: 0.8156 - val_loss: 0.4230 - val_accuracy: 0.8139\n",
      "Epoch 259/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4138 - accuracy: 0.8163 - val_loss: 0.4139 - val_accuracy: 0.8136\n",
      "Epoch 260/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4159 - accuracy: 0.8157 - val_loss: 0.4169 - val_accuracy: 0.8151\n",
      "Epoch 261/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4148 - accuracy: 0.8159 - val_loss: 0.4184 - val_accuracy: 0.8100\n",
      "Epoch 262/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4153 - accuracy: 0.8157 - val_loss: 0.4110 - val_accuracy: 0.8149\n",
      "Epoch 263/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4135 - accuracy: 0.8179 - val_loss: 0.4129 - val_accuracy: 0.8121\n",
      "Epoch 264/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4130 - accuracy: 0.8170 - val_loss: 0.4159 - val_accuracy: 0.8147\n",
      "Epoch 265/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4135 - accuracy: 0.8150 - val_loss: 0.4119 - val_accuracy: 0.8178\n",
      "Epoch 266/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4134 - accuracy: 0.8165 - val_loss: 0.4174 - val_accuracy: 0.8138\n",
      "Epoch 267/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4138 - accuracy: 0.8168 - val_loss: 0.4121 - val_accuracy: 0.8155\n",
      "Epoch 268/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4120 - accuracy: 0.8160 - val_loss: 0.4110 - val_accuracy: 0.8148\n",
      "Epoch 269/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4140 - accuracy: 0.8163 - val_loss: 0.4097 - val_accuracy: 0.8174\n",
      "Epoch 270/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4158 - accuracy: 0.8149 - val_loss: 0.4138 - val_accuracy: 0.8192\n",
      "Epoch 271/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4137 - accuracy: 0.8160 - val_loss: 0.4181 - val_accuracy: 0.8057\n",
      "Epoch 272/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4129 - accuracy: 0.8169 - val_loss: 0.4143 - val_accuracy: 0.8165\n",
      "Epoch 273/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4128 - accuracy: 0.8165 - val_loss: 0.4243 - val_accuracy: 0.8096\n",
      "Epoch 274/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4133 - accuracy: 0.8158 - val_loss: 0.4146 - val_accuracy: 0.8078\n",
      "Epoch 275/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4120 - accuracy: 0.8164 - val_loss: 0.4170 - val_accuracy: 0.8128\n",
      "Epoch 276/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4136 - accuracy: 0.8162 - val_loss: 0.4116 - val_accuracy: 0.8175\n",
      "Epoch 277/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4155 - accuracy: 0.8146 - val_loss: 0.4134 - val_accuracy: 0.8166\n",
      "Epoch 278/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4121 - accuracy: 0.8179 - val_loss: 0.4164 - val_accuracy: 0.8148\n",
      "Epoch 279/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4128 - accuracy: 0.8170 - val_loss: 0.4090 - val_accuracy: 0.8194\n",
      "Epoch 280/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4133 - accuracy: 0.8165 - val_loss: 0.4080 - val_accuracy: 0.8186\n",
      "Epoch 281/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4130 - accuracy: 0.8163 - val_loss: 0.4113 - val_accuracy: 0.8164\n",
      "Epoch 282/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4133 - accuracy: 0.8157 - val_loss: 0.4149 - val_accuracy: 0.8151\n",
      "Epoch 283/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4144 - accuracy: 0.8156 - val_loss: 0.4114 - val_accuracy: 0.8170\n",
      "Epoch 284/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4143 - accuracy: 0.8162 - val_loss: 0.4101 - val_accuracy: 0.8162\n",
      "Epoch 285/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4129 - accuracy: 0.8166 - val_loss: 0.4091 - val_accuracy: 0.8157\n",
      "Epoch 286/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4133 - accuracy: 0.8176 - val_loss: 0.4145 - val_accuracy: 0.8123\n",
      "Epoch 287/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4128 - accuracy: 0.8163 - val_loss: 0.4124 - val_accuracy: 0.8127\n",
      "Epoch 288/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4123 - accuracy: 0.8159 - val_loss: 0.4112 - val_accuracy: 0.8172\n",
      "Epoch 289/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4116 - accuracy: 0.8171 - val_loss: 0.4100 - val_accuracy: 0.8180\n",
      "Epoch 290/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4136 - accuracy: 0.8165 - val_loss: 0.4100 - val_accuracy: 0.8175\n",
      "Epoch 291/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4127 - accuracy: 0.8170 - val_loss: 0.4125 - val_accuracy: 0.8152\n",
      "Epoch 292/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4130 - accuracy: 0.8160 - val_loss: 0.4103 - val_accuracy: 0.8135\n",
      "Epoch 293/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4115 - accuracy: 0.8164 - val_loss: 0.4143 - val_accuracy: 0.8159\n",
      "Epoch 294/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4128 - accuracy: 0.8164 - val_loss: 0.4165 - val_accuracy: 0.8128\n",
      "Epoch 295/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4116 - accuracy: 0.8166 - val_loss: 0.4124 - val_accuracy: 0.8166\n",
      "Epoch 296/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4133 - accuracy: 0.8169 - val_loss: 0.4178 - val_accuracy: 0.8117\n",
      "Epoch 297/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4124 - accuracy: 0.8170 - val_loss: 0.4163 - val_accuracy: 0.8163\n",
      "Epoch 298/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4128 - accuracy: 0.8180 - val_loss: 0.4112 - val_accuracy: 0.8182\n",
      "Epoch 299/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4129 - accuracy: 0.8169 - val_loss: 0.4127 - val_accuracy: 0.8159\n",
      "Epoch 300/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4115 - accuracy: 0.8172 - val_loss: 0.4094 - val_accuracy: 0.8169\n",
      "Epoch 301/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4125 - accuracy: 0.8160 - val_loss: 0.4111 - val_accuracy: 0.8188\n",
      "Epoch 302/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4130 - accuracy: 0.8165 - val_loss: 0.4087 - val_accuracy: 0.8156\n",
      "Epoch 303/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4130 - accuracy: 0.8172 - val_loss: 0.4103 - val_accuracy: 0.8181\n",
      "Epoch 304/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4124 - accuracy: 0.8184 - val_loss: 0.4095 - val_accuracy: 0.8177\n",
      "Epoch 305/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4133 - accuracy: 0.8165 - val_loss: 0.4109 - val_accuracy: 0.8166\n",
      "Epoch 306/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4121 - accuracy: 0.8175 - val_loss: 0.4086 - val_accuracy: 0.8167\n",
      "Epoch 307/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4128 - accuracy: 0.8173 - val_loss: 0.4123 - val_accuracy: 0.8194\n",
      "Epoch 308/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4133 - accuracy: 0.8161 - val_loss: 0.4126 - val_accuracy: 0.8141\n",
      "Epoch 309/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4119 - accuracy: 0.8166 - val_loss: 0.4118 - val_accuracy: 0.8172\n",
      "Epoch 310/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4127 - accuracy: 0.8176 - val_loss: 0.4098 - val_accuracy: 0.8182\n",
      "Epoch 311/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4118 - accuracy: 0.8169 - val_loss: 0.4111 - val_accuracy: 0.8161\n",
      "Epoch 312/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4125 - accuracy: 0.8161 - val_loss: 0.4130 - val_accuracy: 0.8182\n",
      "Epoch 313/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4122 - accuracy: 0.8168 - val_loss: 0.4072 - val_accuracy: 0.8186\n",
      "Epoch 314/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4128 - accuracy: 0.8169 - val_loss: 0.4081 - val_accuracy: 0.8168\n",
      "Epoch 315/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4138 - accuracy: 0.8164 - val_loss: 0.4171 - val_accuracy: 0.8110\n",
      "Epoch 316/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4128 - accuracy: 0.8161 - val_loss: 0.4115 - val_accuracy: 0.8140\n",
      "Epoch 317/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4130 - accuracy: 0.8157 - val_loss: 0.4153 - val_accuracy: 0.8162\n",
      "Epoch 318/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4130 - accuracy: 0.8168 - val_loss: 0.4142 - val_accuracy: 0.8165\n",
      "Epoch 319/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4118 - accuracy: 0.8180 - val_loss: 0.4154 - val_accuracy: 0.8139\n",
      "Epoch 320/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4129 - accuracy: 0.8180 - val_loss: 0.4119 - val_accuracy: 0.8165\n",
      "Epoch 321/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4133 - accuracy: 0.8171 - val_loss: 0.4116 - val_accuracy: 0.8158\n",
      "Epoch 322/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4129 - accuracy: 0.8159 - val_loss: 0.4112 - val_accuracy: 0.8114\n",
      "Epoch 323/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4141 - accuracy: 0.8166 - val_loss: 0.4149 - val_accuracy: 0.8121\n",
      "Epoch 324/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4132 - accuracy: 0.8166 - val_loss: 0.4102 - val_accuracy: 0.8161\n",
      "Epoch 325/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4114 - accuracy: 0.8175 - val_loss: 0.4080 - val_accuracy: 0.8145\n",
      "Epoch 326/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4113 - accuracy: 0.8165 - val_loss: 0.4087 - val_accuracy: 0.8159\n",
      "Epoch 327/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4142 - accuracy: 0.8165 - val_loss: 0.4130 - val_accuracy: 0.8171\n",
      "Epoch 328/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4117 - accuracy: 0.8170 - val_loss: 0.4091 - val_accuracy: 0.8167\n",
      "Epoch 329/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4125 - accuracy: 0.8163 - val_loss: 0.4103 - val_accuracy: 0.8184\n",
      "Epoch 330/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4124 - accuracy: 0.8172 - val_loss: 0.4125 - val_accuracy: 0.8152\n",
      "Epoch 331/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4121 - accuracy: 0.8172 - val_loss: 0.4099 - val_accuracy: 0.8159\n",
      "Epoch 332/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4123 - accuracy: 0.8178 - val_loss: 0.4126 - val_accuracy: 0.8183\n",
      "Epoch 333/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4129 - accuracy: 0.8170 - val_loss: 0.4156 - val_accuracy: 0.8121\n",
      "Epoch 334/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4124 - accuracy: 0.8161 - val_loss: 0.4130 - val_accuracy: 0.8084\n",
      "Epoch 335/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4113 - accuracy: 0.8173 - val_loss: 0.4093 - val_accuracy: 0.8146\n",
      "Epoch 336/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4115 - accuracy: 0.8174 - val_loss: 0.4165 - val_accuracy: 0.8154\n",
      "Epoch 337/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4124 - accuracy: 0.8158 - val_loss: 0.4172 - val_accuracy: 0.8171\n",
      "Epoch 338/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4129 - accuracy: 0.8165 - val_loss: 0.4105 - val_accuracy: 0.8163\n",
      "Epoch 339/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4124 - accuracy: 0.8176 - val_loss: 0.4106 - val_accuracy: 0.8161\n",
      "Epoch 340/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4105 - accuracy: 0.8187 - val_loss: 0.4072 - val_accuracy: 0.8216\n",
      "Epoch 341/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4117 - accuracy: 0.8167 - val_loss: 0.4251 - val_accuracy: 0.8147\n",
      "Epoch 342/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4115 - accuracy: 0.8174 - val_loss: 0.4091 - val_accuracy: 0.8158\n",
      "Epoch 343/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4129 - accuracy: 0.8168 - val_loss: 0.4126 - val_accuracy: 0.8159\n",
      "Epoch 344/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4139 - accuracy: 0.8175 - val_loss: 0.4097 - val_accuracy: 0.8183\n",
      "Epoch 345/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4121 - accuracy: 0.8178 - val_loss: 0.4126 - val_accuracy: 0.8143\n",
      "Epoch 346/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4111 - accuracy: 0.8179 - val_loss: 0.4066 - val_accuracy: 0.8190\n",
      "Epoch 347/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4116 - accuracy: 0.8177 - val_loss: 0.4108 - val_accuracy: 0.8187\n",
      "Epoch 348/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4136 - accuracy: 0.8162 - val_loss: 0.4111 - val_accuracy: 0.8180\n",
      "Epoch 349/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4119 - accuracy: 0.8173 - val_loss: 0.4108 - val_accuracy: 0.8187\n",
      "Epoch 350/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4111 - accuracy: 0.8183 - val_loss: 0.4078 - val_accuracy: 0.8183\n",
      "Epoch 351/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4124 - accuracy: 0.8176 - val_loss: 0.4085 - val_accuracy: 0.8179\n",
      "Epoch 352/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4112 - accuracy: 0.8174 - val_loss: 0.4108 - val_accuracy: 0.8141\n",
      "Epoch 353/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4110 - accuracy: 0.8176 - val_loss: 0.4094 - val_accuracy: 0.8176\n",
      "Epoch 354/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4115 - accuracy: 0.8167 - val_loss: 0.4124 - val_accuracy: 0.8215\n",
      "Epoch 355/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4121 - accuracy: 0.8169 - val_loss: 0.4093 - val_accuracy: 0.8180\n",
      "Epoch 356/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4127 - accuracy: 0.8167 - val_loss: 0.4145 - val_accuracy: 0.8150\n",
      "Epoch 357/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4115 - accuracy: 0.8174 - val_loss: 0.4105 - val_accuracy: 0.8184\n",
      "Epoch 358/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4116 - accuracy: 0.8176 - val_loss: 0.4056 - val_accuracy: 0.8207\n",
      "Epoch 359/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4108 - accuracy: 0.8178 - val_loss: 0.4074 - val_accuracy: 0.8177\n",
      "Epoch 360/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4113 - accuracy: 0.8177 - val_loss: 0.4091 - val_accuracy: 0.8181\n",
      "Epoch 361/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4116 - accuracy: 0.8172 - val_loss: 0.4103 - val_accuracy: 0.8167\n",
      "Epoch 362/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4116 - accuracy: 0.8182 - val_loss: 0.4109 - val_accuracy: 0.8184\n",
      "Epoch 363/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4105 - accuracy: 0.8172 - val_loss: 0.4090 - val_accuracy: 0.8188\n",
      "Epoch 364/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4125 - accuracy: 0.8175 - val_loss: 0.4078 - val_accuracy: 0.8201\n",
      "Epoch 365/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4099 - accuracy: 0.8182 - val_loss: 0.4061 - val_accuracy: 0.8194\n",
      "Epoch 366/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4098 - accuracy: 0.8183 - val_loss: 0.4149 - val_accuracy: 0.8162\n",
      "Epoch 367/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4115 - accuracy: 0.8184 - val_loss: 0.4147 - val_accuracy: 0.8165\n",
      "Epoch 368/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4113 - accuracy: 0.8177 - val_loss: 0.4064 - val_accuracy: 0.8193\n",
      "Epoch 369/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4104 - accuracy: 0.8177 - val_loss: 0.4078 - val_accuracy: 0.8163\n",
      "Epoch 370/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4111 - accuracy: 0.8172 - val_loss: 0.4106 - val_accuracy: 0.8161\n",
      "Epoch 371/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4104 - accuracy: 0.8179 - val_loss: 0.4103 - val_accuracy: 0.8187\n",
      "Epoch 372/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4103 - accuracy: 0.8187 - val_loss: 0.4087 - val_accuracy: 0.8189\n",
      "Epoch 373/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4101 - accuracy: 0.8185 - val_loss: 0.4090 - val_accuracy: 0.8193\n",
      "Epoch 374/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4100 - accuracy: 0.8182 - val_loss: 0.4071 - val_accuracy: 0.8197\n",
      "Epoch 375/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4104 - accuracy: 0.8189 - val_loss: 0.4147 - val_accuracy: 0.8169\n",
      "Epoch 376/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4113 - accuracy: 0.8168 - val_loss: 0.4183 - val_accuracy: 0.8188\n",
      "Epoch 377/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4135 - accuracy: 0.8177 - val_loss: 0.4088 - val_accuracy: 0.8192\n",
      "Epoch 378/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4118 - accuracy: 0.8173 - val_loss: 0.4101 - val_accuracy: 0.8180\n",
      "Epoch 379/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4098 - accuracy: 0.8169 - val_loss: 0.4074 - val_accuracy: 0.8162\n",
      "Epoch 380/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4106 - accuracy: 0.8176 - val_loss: 0.4172 - val_accuracy: 0.8082\n",
      "Epoch 381/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4107 - accuracy: 0.8175 - val_loss: 0.4086 - val_accuracy: 0.8197\n",
      "Epoch 382/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4112 - accuracy: 0.8175 - val_loss: 0.4112 - val_accuracy: 0.8152\n",
      "Epoch 383/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4100 - accuracy: 0.8179 - val_loss: 0.4062 - val_accuracy: 0.8194\n",
      "Epoch 384/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4100 - accuracy: 0.8185 - val_loss: 0.4050 - val_accuracy: 0.8196\n",
      "Epoch 385/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4096 - accuracy: 0.8185 - val_loss: 0.4061 - val_accuracy: 0.8198\n",
      "Epoch 386/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4108 - accuracy: 0.8172 - val_loss: 0.4094 - val_accuracy: 0.8179\n",
      "Epoch 387/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4098 - accuracy: 0.8179 - val_loss: 0.4152 - val_accuracy: 0.8157\n",
      "Epoch 388/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4102 - accuracy: 0.8184 - val_loss: 0.4090 - val_accuracy: 0.8188\n",
      "Epoch 389/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4101 - accuracy: 0.8190 - val_loss: 0.4124 - val_accuracy: 0.8149\n",
      "Epoch 390/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4101 - accuracy: 0.8194 - val_loss: 0.4112 - val_accuracy: 0.8180\n",
      "Epoch 391/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4120 - accuracy: 0.8185 - val_loss: 0.4107 - val_accuracy: 0.8121\n",
      "Epoch 392/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4116 - accuracy: 0.8185 - val_loss: 0.4095 - val_accuracy: 0.8194\n",
      "Epoch 393/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4102 - accuracy: 0.8185 - val_loss: 0.4122 - val_accuracy: 0.8153\n",
      "Epoch 394/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4102 - accuracy: 0.8185 - val_loss: 0.4164 - val_accuracy: 0.8193\n",
      "Epoch 395/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4100 - accuracy: 0.8188 - val_loss: 0.4105 - val_accuracy: 0.8181\n",
      "Epoch 396/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4116 - accuracy: 0.8174 - val_loss: 0.4080 - val_accuracy: 0.8182\n",
      "Epoch 397/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4112 - accuracy: 0.8170 - val_loss: 0.4062 - val_accuracy: 0.8207\n",
      "Epoch 398/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4117 - accuracy: 0.8177 - val_loss: 0.4167 - val_accuracy: 0.8115\n",
      "Epoch 399/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4151 - accuracy: 0.8179 - val_loss: 0.4115 - val_accuracy: 0.8172\n",
      "Epoch 400/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4134 - accuracy: 0.8176 - val_loss: 0.4109 - val_accuracy: 0.8183\n",
      "Epoch 401/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4139 - accuracy: 0.8185 - val_loss: 0.4133 - val_accuracy: 0.8193\n",
      "Epoch 402/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4129 - accuracy: 0.8178 - val_loss: 0.4084 - val_accuracy: 0.8203\n",
      "Epoch 403/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4135 - accuracy: 0.8182 - val_loss: 0.4125 - val_accuracy: 0.8181\n",
      "Epoch 404/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4129 - accuracy: 0.8183 - val_loss: 0.4105 - val_accuracy: 0.8199\n",
      "Epoch 405/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4125 - accuracy: 0.8187 - val_loss: 0.4121 - val_accuracy: 0.8179\n",
      "Epoch 406/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4127 - accuracy: 0.8185 - val_loss: 0.4098 - val_accuracy: 0.8200\n",
      "Epoch 407/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4120 - accuracy: 0.8185 - val_loss: 0.4121 - val_accuracy: 0.8185\n",
      "Epoch 408/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4121 - accuracy: 0.8176 - val_loss: 0.4158 - val_accuracy: 0.8164\n",
      "Epoch 409/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4143 - accuracy: 0.8167 - val_loss: 0.4103 - val_accuracy: 0.8189\n",
      "Epoch 410/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4128 - accuracy: 0.8180 - val_loss: 0.4110 - val_accuracy: 0.8168\n",
      "Epoch 411/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4123 - accuracy: 0.8180 - val_loss: 0.4122 - val_accuracy: 0.8160\n",
      "Epoch 412/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4128 - accuracy: 0.8182 - val_loss: 0.4133 - val_accuracy: 0.8152\n",
      "Epoch 413/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4121 - accuracy: 0.8179 - val_loss: 0.4102 - val_accuracy: 0.8197\n",
      "Epoch 414/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4107 - accuracy: 0.8191 - val_loss: 0.4059 - val_accuracy: 0.8200\n",
      "Epoch 415/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4103 - accuracy: 0.8186 - val_loss: 0.4145 - val_accuracy: 0.8165\n",
      "Epoch 416/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4171 - accuracy: 0.8170 - val_loss: 0.4125 - val_accuracy: 0.8186\n",
      "Epoch 417/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4180 - accuracy: 0.8193 - val_loss: 0.4257 - val_accuracy: 0.8171\n",
      "Epoch 418/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4171 - accuracy: 0.8188 - val_loss: 0.4166 - val_accuracy: 0.8141\n",
      "Epoch 419/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4166 - accuracy: 0.8175 - val_loss: 0.4135 - val_accuracy: 0.8170\n",
      "Epoch 420/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4160 - accuracy: 0.8167 - val_loss: 0.4155 - val_accuracy: 0.8229\n",
      "Epoch 421/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4163 - accuracy: 0.8168 - val_loss: 0.4153 - val_accuracy: 0.8163\n",
      "Epoch 422/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4154 - accuracy: 0.8178 - val_loss: 0.4180 - val_accuracy: 0.8106\n",
      "Epoch 423/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4160 - accuracy: 0.8172 - val_loss: 0.4159 - val_accuracy: 0.8151\n",
      "Epoch 424/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4147 - accuracy: 0.8175 - val_loss: 0.4125 - val_accuracy: 0.8152\n",
      "Epoch 425/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4134 - accuracy: 0.8169 - val_loss: 0.4118 - val_accuracy: 0.8171\n",
      "Epoch 426/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4140 - accuracy: 0.8168 - val_loss: 0.4125 - val_accuracy: 0.8214\n",
      "Epoch 427/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4145 - accuracy: 0.8174 - val_loss: 0.4120 - val_accuracy: 0.8167\n",
      "Epoch 428/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4129 - accuracy: 0.8178 - val_loss: 0.4146 - val_accuracy: 0.8159\n",
      "Epoch 429/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4145 - accuracy: 0.8173 - val_loss: 0.4078 - val_accuracy: 0.8172\n",
      "Epoch 430/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4126 - accuracy: 0.8189 - val_loss: 0.4126 - val_accuracy: 0.8156\n",
      "Epoch 431/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4127 - accuracy: 0.8176 - val_loss: 0.4131 - val_accuracy: 0.8160\n",
      "Epoch 432/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4130 - accuracy: 0.8174 - val_loss: 0.4175 - val_accuracy: 0.8147\n",
      "Epoch 433/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4133 - accuracy: 0.8166 - val_loss: 0.4152 - val_accuracy: 0.8169\n",
      "Epoch 434/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4142 - accuracy: 0.8177 - val_loss: 0.4159 - val_accuracy: 0.8115\n",
      "Epoch 435/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4126 - accuracy: 0.8164 - val_loss: 0.4189 - val_accuracy: 0.8137\n",
      "Epoch 436/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4135 - accuracy: 0.8173 - val_loss: 0.4130 - val_accuracy: 0.8149\n",
      "Epoch 437/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4153 - accuracy: 0.8159 - val_loss: 0.4137 - val_accuracy: 0.8164\n",
      "Epoch 438/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4150 - accuracy: 0.8165 - val_loss: 0.4120 - val_accuracy: 0.8178\n",
      "Epoch 439/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4127 - accuracy: 0.8172 - val_loss: 0.4167 - val_accuracy: 0.8169\n",
      "Epoch 440/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4150 - accuracy: 0.8168 - val_loss: 0.4124 - val_accuracy: 0.8189\n",
      "Epoch 441/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4137 - accuracy: 0.8165 - val_loss: 0.4163 - val_accuracy: 0.8142\n",
      "Epoch 442/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4134 - accuracy: 0.8166 - val_loss: 0.4096 - val_accuracy: 0.8189\n",
      "Epoch 443/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4133 - accuracy: 0.8174 - val_loss: 0.4143 - val_accuracy: 0.8165\n",
      "Epoch 444/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4148 - accuracy: 0.8175 - val_loss: 0.4263 - val_accuracy: 0.8152\n",
      "Epoch 445/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4141 - accuracy: 0.8180 - val_loss: 0.4158 - val_accuracy: 0.8173\n",
      "Epoch 446/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4124 - accuracy: 0.8174 - val_loss: 0.4114 - val_accuracy: 0.8150\n",
      "Epoch 447/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4137 - accuracy: 0.8172 - val_loss: 0.4115 - val_accuracy: 0.8164\n",
      "Epoch 448/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4110 - accuracy: 0.8184 - val_loss: 0.4122 - val_accuracy: 0.8173\n",
      "Epoch 449/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4140 - accuracy: 0.8170 - val_loss: 0.4135 - val_accuracy: 0.8170\n",
      "Epoch 450/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4126 - accuracy: 0.8167 - val_loss: 0.4145 - val_accuracy: 0.8180\n",
      "Epoch 451/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4120 - accuracy: 0.8177 - val_loss: 0.4136 - val_accuracy: 0.8157\n",
      "Epoch 452/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4139 - accuracy: 0.8169 - val_loss: 0.4121 - val_accuracy: 0.8140\n",
      "Epoch 453/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4130 - accuracy: 0.8175 - val_loss: 0.4109 - val_accuracy: 0.8159\n",
      "Epoch 454/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4113 - accuracy: 0.8185 - val_loss: 0.4110 - val_accuracy: 0.8158\n",
      "Epoch 455/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4143 - accuracy: 0.8176 - val_loss: 0.4118 - val_accuracy: 0.8183\n",
      "Epoch 456/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4123 - accuracy: 0.8175 - val_loss: 0.4147 - val_accuracy: 0.8113\n",
      "Epoch 457/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4113 - accuracy: 0.8178 - val_loss: 0.4085 - val_accuracy: 0.8179\n",
      "Epoch 458/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4131 - accuracy: 0.8181 - val_loss: 0.4136 - val_accuracy: 0.8180\n",
      "Epoch 459/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4142 - accuracy: 0.8173 - val_loss: 0.4133 - val_accuracy: 0.8186\n",
      "Epoch 460/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4130 - accuracy: 0.8179 - val_loss: 0.4117 - val_accuracy: 0.8155\n",
      "Epoch 461/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4133 - accuracy: 0.8168 - val_loss: 0.4115 - val_accuracy: 0.8164\n",
      "Epoch 462/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4107 - accuracy: 0.8186 - val_loss: 0.4140 - val_accuracy: 0.8198\n",
      "Epoch 463/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4140 - accuracy: 0.8187 - val_loss: 0.4115 - val_accuracy: 0.8182\n",
      "Epoch 464/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4127 - accuracy: 0.8156 - val_loss: 0.4114 - val_accuracy: 0.8186\n",
      "Epoch 465/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4124 - accuracy: 0.8178 - val_loss: 0.4205 - val_accuracy: 0.8149\n",
      "Epoch 466/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4158 - accuracy: 0.8170 - val_loss: 0.4173 - val_accuracy: 0.8171\n",
      "Epoch 467/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4137 - accuracy: 0.8192 - val_loss: 0.4144 - val_accuracy: 0.8181\n",
      "Epoch 468/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4117 - accuracy: 0.8185 - val_loss: 0.4168 - val_accuracy: 0.8133\n",
      "Epoch 469/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4106 - accuracy: 0.8174 - val_loss: 0.4087 - val_accuracy: 0.8181\n",
      "Epoch 470/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4127 - accuracy: 0.8167 - val_loss: 0.4126 - val_accuracy: 0.8153\n",
      "Epoch 471/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4135 - accuracy: 0.8178 - val_loss: 0.4128 - val_accuracy: 0.8178\n",
      "Epoch 472/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4126 - accuracy: 0.8172 - val_loss: 0.4124 - val_accuracy: 0.8163\n",
      "Epoch 473/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4114 - accuracy: 0.8187 - val_loss: 0.4078 - val_accuracy: 0.8201\n",
      "Epoch 474/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4108 - accuracy: 0.8176 - val_loss: 0.4079 - val_accuracy: 0.8201\n",
      "Epoch 475/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4134 - accuracy: 0.8171 - val_loss: 0.4152 - val_accuracy: 0.8136\n",
      "Epoch 476/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4138 - accuracy: 0.8176 - val_loss: 0.4115 - val_accuracy: 0.8171\n",
      "Epoch 477/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4113 - accuracy: 0.8173 - val_loss: 0.4066 - val_accuracy: 0.8195\n",
      "Epoch 478/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4135 - accuracy: 0.8181 - val_loss: 0.4098 - val_accuracy: 0.8161\n",
      "Epoch 479/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4122 - accuracy: 0.8169 - val_loss: 0.4093 - val_accuracy: 0.8178\n",
      "Epoch 480/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4109 - accuracy: 0.8176 - val_loss: 0.4195 - val_accuracy: 0.8119\n",
      "Epoch 481/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4121 - accuracy: 0.8177 - val_loss: 0.4081 - val_accuracy: 0.8176\n",
      "Epoch 482/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4127 - accuracy: 0.8179 - val_loss: 0.4091 - val_accuracy: 0.8164\n",
      "Epoch 483/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4101 - accuracy: 0.8177 - val_loss: 0.4087 - val_accuracy: 0.8174\n",
      "Epoch 484/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4109 - accuracy: 0.8179 - val_loss: 0.4136 - val_accuracy: 0.8168\n",
      "Epoch 485/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4115 - accuracy: 0.8183 - val_loss: 0.4076 - val_accuracy: 0.8175\n",
      "Epoch 486/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4103 - accuracy: 0.8179 - val_loss: 0.4122 - val_accuracy: 0.8171\n",
      "Epoch 487/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4104 - accuracy: 0.8179 - val_loss: 0.4080 - val_accuracy: 0.8193\n",
      "Epoch 488/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4122 - accuracy: 0.8183 - val_loss: 0.4138 - val_accuracy: 0.8143\n",
      "Epoch 489/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4111 - accuracy: 0.8181 - val_loss: 0.4087 - val_accuracy: 0.8170\n",
      "Epoch 490/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4122 - accuracy: 0.8175 - val_loss: 0.4157 - val_accuracy: 0.8174\n",
      "Epoch 491/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4151 - accuracy: 0.8157 - val_loss: 0.4114 - val_accuracy: 0.8152\n",
      "Epoch 492/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4111 - accuracy: 0.8176 - val_loss: 0.4106 - val_accuracy: 0.8187\n",
      "Epoch 493/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4112 - accuracy: 0.8175 - val_loss: 0.4104 - val_accuracy: 0.8172\n",
      "Epoch 494/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4123 - accuracy: 0.8181 - val_loss: 0.4131 - val_accuracy: 0.8164\n",
      "Epoch 495/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4097 - accuracy: 0.8184 - val_loss: 0.4097 - val_accuracy: 0.8170\n",
      "Epoch 496/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4108 - accuracy: 0.8182 - val_loss: 0.4082 - val_accuracy: 0.8189\n",
      "Epoch 497/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4108 - accuracy: 0.8178 - val_loss: 0.4154 - val_accuracy: 0.8173\n",
      "Epoch 498/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4114 - accuracy: 0.8180 - val_loss: 0.4087 - val_accuracy: 0.8172\n",
      "Epoch 499/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4107 - accuracy: 0.8182 - val_loss: 0.4111 - val_accuracy: 0.8186\n",
      "Epoch 500/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4096 - accuracy: 0.8190 - val_loss: 0.4098 - val_accuracy: 0.8157\n",
      "Epoch 501/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4103 - accuracy: 0.8186 - val_loss: 0.4069 - val_accuracy: 0.8202\n",
      "Epoch 502/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4092 - accuracy: 0.8184 - val_loss: 0.4124 - val_accuracy: 0.8139\n",
      "Epoch 503/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4115 - accuracy: 0.8181 - val_loss: 0.4116 - val_accuracy: 0.8181\n",
      "Epoch 504/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4146 - accuracy: 0.8177 - val_loss: 0.4122 - val_accuracy: 0.8170\n",
      "Epoch 505/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4108 - accuracy: 0.8179 - val_loss: 0.4190 - val_accuracy: 0.8136\n",
      "Epoch 506/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4099 - accuracy: 0.8191 - val_loss: 0.4099 - val_accuracy: 0.8194\n",
      "Epoch 507/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4116 - accuracy: 0.8178 - val_loss: 0.4184 - val_accuracy: 0.8150\n",
      "Epoch 508/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4154 - accuracy: 0.8178 - val_loss: 0.4132 - val_accuracy: 0.8190\n",
      "Epoch 509/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4112 - accuracy: 0.8184 - val_loss: 0.4113 - val_accuracy: 0.8173\n",
      "Epoch 510/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4111 - accuracy: 0.8177 - val_loss: 0.4096 - val_accuracy: 0.8171\n",
      "Epoch 511/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4096 - accuracy: 0.8191 - val_loss: 0.4108 - val_accuracy: 0.8206\n",
      "Epoch 512/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4107 - accuracy: 0.8191 - val_loss: 0.4080 - val_accuracy: 0.8185\n",
      "Epoch 513/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4103 - accuracy: 0.8188 - val_loss: 0.4094 - val_accuracy: 0.8181\n",
      "Epoch 514/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4109 - accuracy: 0.8183 - val_loss: 0.4099 - val_accuracy: 0.8174\n",
      "Epoch 515/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4110 - accuracy: 0.8185 - val_loss: 0.4120 - val_accuracy: 0.8170\n",
      "Epoch 516/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4102 - accuracy: 0.8190 - val_loss: 0.4071 - val_accuracy: 0.8192\n",
      "Epoch 517/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4108 - accuracy: 0.8181 - val_loss: 0.4104 - val_accuracy: 0.8164\n",
      "Epoch 518/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4108 - accuracy: 0.8185 - val_loss: 0.4105 - val_accuracy: 0.8186\n",
      "Epoch 519/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4111 - accuracy: 0.8185 - val_loss: 0.4138 - val_accuracy: 0.8173\n",
      "Epoch 520/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4107 - accuracy: 0.8189 - val_loss: 0.4200 - val_accuracy: 0.8102\n",
      "Epoch 521/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4098 - accuracy: 0.8192 - val_loss: 0.4140 - val_accuracy: 0.8177\n",
      "Epoch 522/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4100 - accuracy: 0.8185 - val_loss: 0.4134 - val_accuracy: 0.8165\n",
      "Epoch 523/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4096 - accuracy: 0.8185 - val_loss: 0.4085 - val_accuracy: 0.8167\n",
      "Epoch 524/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4107 - accuracy: 0.8186 - val_loss: 0.4122 - val_accuracy: 0.8169\n",
      "Epoch 525/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4108 - accuracy: 0.8184 - val_loss: 0.4129 - val_accuracy: 0.8163\n",
      "Epoch 526/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4094 - accuracy: 0.8188 - val_loss: 0.4090 - val_accuracy: 0.8193\n",
      "Epoch 527/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4101 - accuracy: 0.8192 - val_loss: 0.4093 - val_accuracy: 0.8201\n",
      "Epoch 528/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4093 - accuracy: 0.8195 - val_loss: 0.4078 - val_accuracy: 0.8207\n",
      "Epoch 529/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4103 - accuracy: 0.8192 - val_loss: 0.4139 - val_accuracy: 0.8150\n",
      "Epoch 530/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4094 - accuracy: 0.8185 - val_loss: 0.4101 - val_accuracy: 0.8191\n",
      "Epoch 531/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4095 - accuracy: 0.8186 - val_loss: 0.4094 - val_accuracy: 0.8195\n",
      "Epoch 532/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4099 - accuracy: 0.8186 - val_loss: 0.4128 - val_accuracy: 0.8179\n",
      "Epoch 533/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4102 - accuracy: 0.8189 - val_loss: 0.4068 - val_accuracy: 0.8184\n",
      "Epoch 534/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4106 - accuracy: 0.8187 - val_loss: 0.4066 - val_accuracy: 0.8185\n",
      "Epoch 535/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4106 - accuracy: 0.8193 - val_loss: 0.4088 - val_accuracy: 0.8175\n",
      "Epoch 536/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4092 - accuracy: 0.8197 - val_loss: 0.4126 - val_accuracy: 0.8186\n",
      "Epoch 537/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4123 - accuracy: 0.8183 - val_loss: 0.4143 - val_accuracy: 0.8158\n",
      "Epoch 538/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4114 - accuracy: 0.8192 - val_loss: 0.4131 - val_accuracy: 0.8149\n",
      "Epoch 539/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4098 - accuracy: 0.8189 - val_loss: 0.4103 - val_accuracy: 0.8151\n",
      "Epoch 540/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4099 - accuracy: 0.8195 - val_loss: 0.4070 - val_accuracy: 0.8195\n",
      "Epoch 541/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4100 - accuracy: 0.8187 - val_loss: 0.4142 - val_accuracy: 0.8166\n",
      "Epoch 542/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4096 - accuracy: 0.8197 - val_loss: 0.4142 - val_accuracy: 0.8146\n",
      "Epoch 543/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4100 - accuracy: 0.8183 - val_loss: 0.4108 - val_accuracy: 0.8196\n",
      "Epoch 544/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4086 - accuracy: 0.8191 - val_loss: 0.4075 - val_accuracy: 0.8193\n",
      "Epoch 545/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4111 - accuracy: 0.8190 - val_loss: 0.4087 - val_accuracy: 0.8213\n",
      "Epoch 546/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4114 - accuracy: 0.8180 - val_loss: 0.4140 - val_accuracy: 0.8135\n",
      "Epoch 547/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4109 - accuracy: 0.8189 - val_loss: 0.4163 - val_accuracy: 0.8197\n",
      "Epoch 548/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4119 - accuracy: 0.8178 - val_loss: 0.4085 - val_accuracy: 0.8183\n",
      "Epoch 549/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4096 - accuracy: 0.8189 - val_loss: 0.4080 - val_accuracy: 0.8189\n",
      "Epoch 550/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4107 - accuracy: 0.8195 - val_loss: 0.4064 - val_accuracy: 0.8193\n",
      "Epoch 551/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4089 - accuracy: 0.8188 - val_loss: 0.4121 - val_accuracy: 0.8186\n",
      "Epoch 552/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4131 - accuracy: 0.8179 - val_loss: 0.4084 - val_accuracy: 0.8193\n",
      "Epoch 553/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4089 - accuracy: 0.8196 - val_loss: 0.4079 - val_accuracy: 0.8201\n",
      "Epoch 554/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4085 - accuracy: 0.8187 - val_loss: 0.4110 - val_accuracy: 0.8172\n",
      "Epoch 555/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4106 - accuracy: 0.8196 - val_loss: 0.4130 - val_accuracy: 0.8188\n",
      "Epoch 556/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4114 - accuracy: 0.8194 - val_loss: 0.4141 - val_accuracy: 0.8189\n",
      "Epoch 557/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4112 - accuracy: 0.8184 - val_loss: 0.4074 - val_accuracy: 0.8214\n",
      "Epoch 558/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4108 - accuracy: 0.8198 - val_loss: 0.4186 - val_accuracy: 0.8104\n",
      "Epoch 559/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4090 - accuracy: 0.8194 - val_loss: 0.4096 - val_accuracy: 0.8174\n",
      "Epoch 560/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4078 - accuracy: 0.8193 - val_loss: 0.4100 - val_accuracy: 0.8158\n",
      "Epoch 561/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4090 - accuracy: 0.8189 - val_loss: 0.4095 - val_accuracy: 0.8204\n",
      "Epoch 562/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4095 - accuracy: 0.8197 - val_loss: 0.4096 - val_accuracy: 0.8198\n",
      "Epoch 563/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4099 - accuracy: 0.8190 - val_loss: 0.4099 - val_accuracy: 0.8186\n",
      "Epoch 564/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4096 - accuracy: 0.8181 - val_loss: 0.4102 - val_accuracy: 0.8189\n",
      "Epoch 565/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4078 - accuracy: 0.8195 - val_loss: 0.4110 - val_accuracy: 0.8184\n",
      "Epoch 566/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4083 - accuracy: 0.8189 - val_loss: 0.4078 - val_accuracy: 0.8185\n",
      "Epoch 567/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4099 - accuracy: 0.8172 - val_loss: 0.4095 - val_accuracy: 0.8158\n",
      "Epoch 568/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4089 - accuracy: 0.8185 - val_loss: 0.4229 - val_accuracy: 0.8118\n",
      "Epoch 569/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4096 - accuracy: 0.8182 - val_loss: 0.4097 - val_accuracy: 0.8198\n",
      "Epoch 570/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4086 - accuracy: 0.8186 - val_loss: 0.4113 - val_accuracy: 0.8185\n",
      "Epoch 571/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4097 - accuracy: 0.8192 - val_loss: 0.4091 - val_accuracy: 0.8178\n",
      "Epoch 572/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4094 - accuracy: 0.8183 - val_loss: 0.4109 - val_accuracy: 0.8130\n",
      "Epoch 573/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4089 - accuracy: 0.8189 - val_loss: 0.4132 - val_accuracy: 0.8124\n",
      "Epoch 574/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4088 - accuracy: 0.8191 - val_loss: 0.4064 - val_accuracy: 0.8207\n",
      "Epoch 575/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4088 - accuracy: 0.8196 - val_loss: 0.4064 - val_accuracy: 0.8197\n",
      "Epoch 576/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4105 - accuracy: 0.8181 - val_loss: 0.4102 - val_accuracy: 0.8177\n",
      "Epoch 577/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4083 - accuracy: 0.8186 - val_loss: 0.4079 - val_accuracy: 0.8174\n",
      "Epoch 578/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4088 - accuracy: 0.8197 - val_loss: 0.4215 - val_accuracy: 0.8112\n",
      "Epoch 579/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4102 - accuracy: 0.8175 - val_loss: 0.4111 - val_accuracy: 0.8138\n",
      "Epoch 580/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4087 - accuracy: 0.8179 - val_loss: 0.4143 - val_accuracy: 0.8123\n",
      "Epoch 581/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4094 - accuracy: 0.8198 - val_loss: 0.4196 - val_accuracy: 0.8111\n",
      "Epoch 582/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4108 - accuracy: 0.8178 - val_loss: 0.4091 - val_accuracy: 0.8183\n",
      "Epoch 583/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4094 - accuracy: 0.8189 - val_loss: 0.4116 - val_accuracy: 0.8169\n",
      "Epoch 584/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4103 - accuracy: 0.8174 - val_loss: 0.4116 - val_accuracy: 0.8156\n",
      "Epoch 585/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4113 - accuracy: 0.8184 - val_loss: 0.4133 - val_accuracy: 0.8155\n",
      "Epoch 586/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4106 - accuracy: 0.8198 - val_loss: 0.4063 - val_accuracy: 0.8181\n",
      "Epoch 587/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4105 - accuracy: 0.8196 - val_loss: 0.4054 - val_accuracy: 0.8205\n",
      "Epoch 588/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4088 - accuracy: 0.8190 - val_loss: 0.4166 - val_accuracy: 0.8174\n",
      "Epoch 589/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4086 - accuracy: 0.8198 - val_loss: 0.4093 - val_accuracy: 0.8170\n",
      "Epoch 590/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4113 - accuracy: 0.8178 - val_loss: 0.4078 - val_accuracy: 0.8204\n",
      "Epoch 591/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4087 - accuracy: 0.8196 - val_loss: 0.4127 - val_accuracy: 0.8192\n",
      "Epoch 592/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4099 - accuracy: 0.8185 - val_loss: 0.4144 - val_accuracy: 0.8163\n",
      "Epoch 593/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4103 - accuracy: 0.8178 - val_loss: 0.4183 - val_accuracy: 0.8161\n",
      "Epoch 594/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4087 - accuracy: 0.8183 - val_loss: 0.4097 - val_accuracy: 0.8188\n",
      "Epoch 595/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4092 - accuracy: 0.8185 - val_loss: 0.4112 - val_accuracy: 0.8200\n",
      "Epoch 596/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4081 - accuracy: 0.8188 - val_loss: 0.4061 - val_accuracy: 0.8199\n",
      "Epoch 597/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4080 - accuracy: 0.8190 - val_loss: 0.4101 - val_accuracy: 0.8191\n",
      "Epoch 598/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4090 - accuracy: 0.8202 - val_loss: 0.4126 - val_accuracy: 0.8173\n",
      "Epoch 599/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4122 - accuracy: 0.8183 - val_loss: 0.4128 - val_accuracy: 0.8196\n",
      "Epoch 600/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4116 - accuracy: 0.8188 - val_loss: 0.4083 - val_accuracy: 0.8200\n",
      "Epoch 601/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4088 - accuracy: 0.8201 - val_loss: 0.4116 - val_accuracy: 0.8183\n",
      "Epoch 602/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4088 - accuracy: 0.8192 - val_loss: 0.4111 - val_accuracy: 0.8184\n",
      "Epoch 603/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4090 - accuracy: 0.8188 - val_loss: 0.4079 - val_accuracy: 0.8186\n",
      "Epoch 604/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4115 - accuracy: 0.8193 - val_loss: 0.4086 - val_accuracy: 0.8197\n",
      "Epoch 605/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4099 - accuracy: 0.8187 - val_loss: 0.4053 - val_accuracy: 0.8202\n",
      "Epoch 606/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4083 - accuracy: 0.8199 - val_loss: 0.4173 - val_accuracy: 0.8165\n",
      "Epoch 607/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4092 - accuracy: 0.8190 - val_loss: 0.4088 - val_accuracy: 0.8190\n",
      "Epoch 608/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4086 - accuracy: 0.8191 - val_loss: 0.4141 - val_accuracy: 0.8151\n",
      "Epoch 609/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4092 - accuracy: 0.8199 - val_loss: 0.4134 - val_accuracy: 0.8159\n",
      "Epoch 610/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4089 - accuracy: 0.8204 - val_loss: 0.4141 - val_accuracy: 0.8162\n",
      "Epoch 611/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4084 - accuracy: 0.8205 - val_loss: 0.4057 - val_accuracy: 0.8184\n",
      "Epoch 612/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4078 - accuracy: 0.8207 - val_loss: 0.4106 - val_accuracy: 0.8187\n",
      "Epoch 613/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4094 - accuracy: 0.8190 - val_loss: 0.4068 - val_accuracy: 0.8186\n",
      "Epoch 614/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4079 - accuracy: 0.8195 - val_loss: 0.4094 - val_accuracy: 0.8166\n",
      "Epoch 615/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4099 - accuracy: 0.8192 - val_loss: 0.4097 - val_accuracy: 0.8194\n",
      "Epoch 616/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4086 - accuracy: 0.8190 - val_loss: 0.4128 - val_accuracy: 0.8193\n",
      "Epoch 617/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4100 - accuracy: 0.8198 - val_loss: 0.4081 - val_accuracy: 0.8174\n",
      "Epoch 618/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4090 - accuracy: 0.8192 - val_loss: 0.4057 - val_accuracy: 0.8183\n",
      "Epoch 619/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4087 - accuracy: 0.8197 - val_loss: 0.4088 - val_accuracy: 0.8192\n",
      "Epoch 620/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4092 - accuracy: 0.8186 - val_loss: 0.4168 - val_accuracy: 0.8155\n",
      "Epoch 621/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4098 - accuracy: 0.8191 - val_loss: 0.4125 - val_accuracy: 0.8162\n",
      "Epoch 622/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4082 - accuracy: 0.8197 - val_loss: 0.4124 - val_accuracy: 0.8157\n",
      "Epoch 623/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4100 - accuracy: 0.8196 - val_loss: 0.4161 - val_accuracy: 0.8171\n",
      "Epoch 624/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4081 - accuracy: 0.8202 - val_loss: 0.4099 - val_accuracy: 0.8210\n",
      "Epoch 625/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4088 - accuracy: 0.8204 - val_loss: 0.4133 - val_accuracy: 0.8205\n",
      "Epoch 626/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4078 - accuracy: 0.8202 - val_loss: 0.4168 - val_accuracy: 0.8115\n",
      "Epoch 627/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4100 - accuracy: 0.8190 - val_loss: 0.4099 - val_accuracy: 0.8209\n",
      "Epoch 628/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4105 - accuracy: 0.8197 - val_loss: 0.4104 - val_accuracy: 0.8198\n",
      "Epoch 629/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4098 - accuracy: 0.8187 - val_loss: 0.4112 - val_accuracy: 0.8158\n",
      "Epoch 630/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4074 - accuracy: 0.8199 - val_loss: 0.4074 - val_accuracy: 0.8187\n",
      "Epoch 631/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4096 - accuracy: 0.8190 - val_loss: 0.4137 - val_accuracy: 0.8159\n",
      "Epoch 632/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4096 - accuracy: 0.8194 - val_loss: 0.4059 - val_accuracy: 0.8198\n",
      "Epoch 633/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4089 - accuracy: 0.8197 - val_loss: 0.4079 - val_accuracy: 0.8204\n",
      "Epoch 634/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4078 - accuracy: 0.8200 - val_loss: 0.4120 - val_accuracy: 0.8169\n",
      "Epoch 635/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4072 - accuracy: 0.8202 - val_loss: 0.4082 - val_accuracy: 0.8213\n",
      "Epoch 636/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4126 - accuracy: 0.8178 - val_loss: 0.4147 - val_accuracy: 0.8160\n",
      "Epoch 637/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4102 - accuracy: 0.8200 - val_loss: 0.4151 - val_accuracy: 0.8177\n",
      "Epoch 638/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4089 - accuracy: 0.8197 - val_loss: 0.4083 - val_accuracy: 0.8197\n",
      "Epoch 639/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4084 - accuracy: 0.8188 - val_loss: 0.4136 - val_accuracy: 0.8171\n",
      "Epoch 640/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4088 - accuracy: 0.8196 - val_loss: 0.4150 - val_accuracy: 0.8107\n",
      "Epoch 641/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4081 - accuracy: 0.8194 - val_loss: 0.4056 - val_accuracy: 0.8193\n",
      "Epoch 642/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4082 - accuracy: 0.8197 - val_loss: 0.4099 - val_accuracy: 0.8179\n",
      "Epoch 643/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4090 - accuracy: 0.8198 - val_loss: 0.4108 - val_accuracy: 0.8164\n",
      "Epoch 644/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4094 - accuracy: 0.8188 - val_loss: 0.4084 - val_accuracy: 0.8205\n",
      "Epoch 645/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4088 - accuracy: 0.8200 - val_loss: 0.4102 - val_accuracy: 0.8182\n",
      "Epoch 646/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4076 - accuracy: 0.8199 - val_loss: 0.4113 - val_accuracy: 0.8179\n",
      "Epoch 647/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4107 - accuracy: 0.8183 - val_loss: 0.4071 - val_accuracy: 0.8205\n",
      "Epoch 648/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4087 - accuracy: 0.8202 - val_loss: 0.4070 - val_accuracy: 0.8216\n",
      "Epoch 649/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4086 - accuracy: 0.8196 - val_loss: 0.4169 - val_accuracy: 0.8134\n",
      "Epoch 650/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4075 - accuracy: 0.8202 - val_loss: 0.4079 - val_accuracy: 0.8186\n",
      "Epoch 651/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4068 - accuracy: 0.8202 - val_loss: 0.4076 - val_accuracy: 0.8189\n",
      "Epoch 652/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4062 - accuracy: 0.8196 - val_loss: 0.4135 - val_accuracy: 0.8166\n",
      "Epoch 653/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4076 - accuracy: 0.8197 - val_loss: 0.4082 - val_accuracy: 0.8199\n",
      "Epoch 654/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4088 - accuracy: 0.8203 - val_loss: 0.4116 - val_accuracy: 0.8179\n",
      "Epoch 655/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4108 - accuracy: 0.8185 - val_loss: 0.4097 - val_accuracy: 0.8191\n",
      "Epoch 656/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4070 - accuracy: 0.8203 - val_loss: 0.4067 - val_accuracy: 0.8201\n",
      "Epoch 657/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4076 - accuracy: 0.8203 - val_loss: 0.4080 - val_accuracy: 0.8183\n",
      "Epoch 658/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4078 - accuracy: 0.8207 - val_loss: 0.4107 - val_accuracy: 0.8177\n",
      "Epoch 659/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4089 - accuracy: 0.8202 - val_loss: 0.4122 - val_accuracy: 0.8190\n",
      "Epoch 660/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4098 - accuracy: 0.8197 - val_loss: 0.4078 - val_accuracy: 0.8198\n",
      "Epoch 661/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4079 - accuracy: 0.8206 - val_loss: 0.4115 - val_accuracy: 0.8166\n",
      "Epoch 662/1000\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.4098 - accuracy: 0.81 - 1s 5ms/step - loss: 0.4101 - accuracy: 0.8191 - val_loss: 0.4082 - val_accuracy: 0.8192\n",
      "Epoch 663/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4078 - accuracy: 0.8203 - val_loss: 0.4180 - val_accuracy: 0.8143\n",
      "Epoch 664/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4078 - accuracy: 0.8203 - val_loss: 0.4085 - val_accuracy: 0.8173\n",
      "Epoch 665/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4069 - accuracy: 0.8200 - val_loss: 0.4075 - val_accuracy: 0.8190\n",
      "Epoch 666/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4073 - accuracy: 0.8206 - val_loss: 0.4089 - val_accuracy: 0.8189\n",
      "Epoch 667/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4099 - accuracy: 0.8193 - val_loss: 0.4074 - val_accuracy: 0.8193\n",
      "Epoch 668/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4082 - accuracy: 0.8196 - val_loss: 0.4127 - val_accuracy: 0.8172\n",
      "Epoch 669/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4070 - accuracy: 0.8195 - val_loss: 0.4059 - val_accuracy: 0.8199\n",
      "Epoch 670/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4082 - accuracy: 0.8194 - val_loss: 0.4101 - val_accuracy: 0.8191\n",
      "Epoch 671/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4087 - accuracy: 0.8198 - val_loss: 0.4111 - val_accuracy: 0.8178\n",
      "Epoch 672/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4074 - accuracy: 0.8198 - val_loss: 0.4093 - val_accuracy: 0.8174\n",
      "Epoch 673/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4097 - accuracy: 0.8195 - val_loss: 0.4066 - val_accuracy: 0.8187\n",
      "Epoch 674/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4085 - accuracy: 0.8196 - val_loss: 0.4098 - val_accuracy: 0.8184\n",
      "Epoch 675/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4071 - accuracy: 0.8213 - val_loss: 0.4102 - val_accuracy: 0.8196\n",
      "Epoch 676/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4080 - accuracy: 0.8197 - val_loss: 0.4097 - val_accuracy: 0.8174\n",
      "Epoch 677/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4097 - accuracy: 0.8183 - val_loss: 0.4090 - val_accuracy: 0.8187\n",
      "Epoch 678/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4099 - accuracy: 0.8183 - val_loss: 0.4072 - val_accuracy: 0.8205\n",
      "Epoch 679/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4081 - accuracy: 0.8201 - val_loss: 0.4084 - val_accuracy: 0.8171\n",
      "Epoch 680/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4089 - accuracy: 0.8199 - val_loss: 0.4142 - val_accuracy: 0.8169\n",
      "Epoch 681/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4125 - accuracy: 0.8194 - val_loss: 0.4200 - val_accuracy: 0.8144\n",
      "Epoch 682/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4082 - accuracy: 0.8198 - val_loss: 0.4085 - val_accuracy: 0.8192\n",
      "Epoch 683/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4075 - accuracy: 0.8202 - val_loss: 0.4069 - val_accuracy: 0.8194\n",
      "Epoch 684/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4073 - accuracy: 0.8201 - val_loss: 0.4077 - val_accuracy: 0.8200\n",
      "Epoch 685/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4094 - accuracy: 0.8198 - val_loss: 0.4172 - val_accuracy: 0.8136\n",
      "Epoch 686/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4074 - accuracy: 0.8209 - val_loss: 0.4146 - val_accuracy: 0.8156\n",
      "Epoch 687/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4087 - accuracy: 0.8197 - val_loss: 0.4073 - val_accuracy: 0.8187\n",
      "Epoch 688/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4087 - accuracy: 0.8201 - val_loss: 0.4104 - val_accuracy: 0.8212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 689/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4095 - accuracy: 0.8193 - val_loss: 0.4122 - val_accuracy: 0.8164\n",
      "Epoch 690/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4104 - accuracy: 0.8190 - val_loss: 0.4112 - val_accuracy: 0.8177\n",
      "Epoch 691/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4082 - accuracy: 0.8201 - val_loss: 0.4092 - val_accuracy: 0.8183\n",
      "Epoch 692/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4085 - accuracy: 0.8197 - val_loss: 0.4066 - val_accuracy: 0.8185\n",
      "Epoch 693/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4093 - accuracy: 0.8194 - val_loss: 0.4109 - val_accuracy: 0.8194\n",
      "Epoch 694/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4089 - accuracy: 0.8195 - val_loss: 0.4067 - val_accuracy: 0.8200\n",
      "Epoch 695/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4071 - accuracy: 0.8203 - val_loss: 0.4081 - val_accuracy: 0.8199\n",
      "Epoch 696/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4088 - accuracy: 0.8205 - val_loss: 0.4066 - val_accuracy: 0.8209\n",
      "Epoch 697/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4079 - accuracy: 0.8204 - val_loss: 0.4102 - val_accuracy: 0.8186\n",
      "Epoch 698/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4093 - accuracy: 0.8192 - val_loss: 0.4075 - val_accuracy: 0.8192\n",
      "Epoch 699/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4063 - accuracy: 0.8202 - val_loss: 0.4117 - val_accuracy: 0.8165\n",
      "Epoch 700/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4074 - accuracy: 0.8201 - val_loss: 0.4082 - val_accuracy: 0.8184\n",
      "Epoch 701/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4079 - accuracy: 0.8202 - val_loss: 0.4144 - val_accuracy: 0.8210\n",
      "Epoch 702/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4073 - accuracy: 0.8203 - val_loss: 0.4056 - val_accuracy: 0.8199\n",
      "Epoch 703/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4058 - accuracy: 0.8206 - val_loss: 0.4090 - val_accuracy: 0.8197\n",
      "Epoch 704/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4068 - accuracy: 0.8190 - val_loss: 0.4073 - val_accuracy: 0.8164\n",
      "Epoch 705/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4081 - accuracy: 0.8196 - val_loss: 0.4070 - val_accuracy: 0.8194\n",
      "Epoch 706/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4069 - accuracy: 0.8194 - val_loss: 0.4083 - val_accuracy: 0.8182\n",
      "Epoch 707/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4078 - accuracy: 0.8201 - val_loss: 0.4066 - val_accuracy: 0.8189\n",
      "Epoch 708/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4069 - accuracy: 0.8202 - val_loss: 0.4064 - val_accuracy: 0.8199\n",
      "Epoch 709/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4073 - accuracy: 0.8198 - val_loss: 0.4084 - val_accuracy: 0.8206\n",
      "Epoch 710/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4104 - accuracy: 0.8205 - val_loss: 0.4116 - val_accuracy: 0.8179\n",
      "Epoch 711/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4098 - accuracy: 0.8215 - val_loss: 0.4083 - val_accuracy: 0.8191\n",
      "Epoch 712/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4107 - accuracy: 0.8210 - val_loss: 0.4152 - val_accuracy: 0.8143\n",
      "Epoch 713/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4083 - accuracy: 0.8209 - val_loss: 0.4086 - val_accuracy: 0.8188\n",
      "Epoch 714/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4079 - accuracy: 0.8204 - val_loss: 0.4114 - val_accuracy: 0.8195\n",
      "Epoch 715/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4084 - accuracy: 0.8208 - val_loss: 0.4073 - val_accuracy: 0.8200\n",
      "Epoch 716/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4070 - accuracy: 0.8199 - val_loss: 0.4103 - val_accuracy: 0.8182\n",
      "Epoch 717/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4077 - accuracy: 0.8196 - val_loss: 0.4101 - val_accuracy: 0.8183\n",
      "Epoch 718/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4062 - accuracy: 0.8205 - val_loss: 0.4092 - val_accuracy: 0.8165\n",
      "Epoch 719/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4086 - accuracy: 0.8192 - val_loss: 0.4110 - val_accuracy: 0.8185\n",
      "Epoch 720/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4081 - accuracy: 0.8200 - val_loss: 0.4081 - val_accuracy: 0.8192\n",
      "Epoch 721/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4082 - accuracy: 0.8194 - val_loss: 0.4119 - val_accuracy: 0.8104\n",
      "Epoch 722/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4078 - accuracy: 0.8197 - val_loss: 0.4092 - val_accuracy: 0.8175\n",
      "Epoch 723/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4076 - accuracy: 0.8212 - val_loss: 0.4130 - val_accuracy: 0.8186\n",
      "Epoch 724/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4091 - accuracy: 0.8197 - val_loss: 0.4081 - val_accuracy: 0.8197\n",
      "Epoch 725/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4064 - accuracy: 0.8200 - val_loss: 0.4091 - val_accuracy: 0.8180\n",
      "Epoch 726/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4066 - accuracy: 0.8203 - val_loss: 0.4082 - val_accuracy: 0.8165\n",
      "Epoch 727/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4085 - accuracy: 0.8196 - val_loss: 0.4095 - val_accuracy: 0.8196\n",
      "Epoch 728/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4077 - accuracy: 0.8200 - val_loss: 0.4140 - val_accuracy: 0.8179\n",
      "Epoch 729/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4060 - accuracy: 0.8208 - val_loss: 0.4072 - val_accuracy: 0.8180\n",
      "Epoch 730/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4086 - accuracy: 0.8203 - val_loss: 0.4068 - val_accuracy: 0.8232\n",
      "Epoch 731/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4052 - accuracy: 0.8206 - val_loss: 0.4062 - val_accuracy: 0.8192\n",
      "Epoch 732/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4077 - accuracy: 0.8199 - val_loss: 0.4083 - val_accuracy: 0.8195\n",
      "Epoch 733/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4080 - accuracy: 0.8198 - val_loss: 0.4091 - val_accuracy: 0.8173\n",
      "Epoch 734/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4078 - accuracy: 0.8185 - val_loss: 0.4105 - val_accuracy: 0.8160\n",
      "Epoch 735/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4078 - accuracy: 0.8199 - val_loss: 0.4128 - val_accuracy: 0.8182\n",
      "Epoch 736/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4072 - accuracy: 0.8199 - val_loss: 0.4063 - val_accuracy: 0.8193\n",
      "Epoch 737/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4061 - accuracy: 0.8207 - val_loss: 0.4061 - val_accuracy: 0.8173\n",
      "Epoch 738/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4061 - accuracy: 0.8203 - val_loss: 0.4077 - val_accuracy: 0.8204\n",
      "Epoch 739/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4063 - accuracy: 0.8214 - val_loss: 0.4158 - val_accuracy: 0.8188\n",
      "Epoch 740/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4071 - accuracy: 0.8198 - val_loss: 0.4090 - val_accuracy: 0.8162\n",
      "Epoch 741/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4082 - accuracy: 0.8212 - val_loss: 0.4136 - val_accuracy: 0.8187\n",
      "Epoch 742/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4082 - accuracy: 0.8205 - val_loss: 0.4069 - val_accuracy: 0.8206\n",
      "Epoch 743/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4064 - accuracy: 0.8201 - val_loss: 0.4062 - val_accuracy: 0.8201\n",
      "Epoch 744/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4065 - accuracy: 0.8207 - val_loss: 0.4121 - val_accuracy: 0.8181\n",
      "Epoch 745/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4083 - accuracy: 0.8196 - val_loss: 0.4076 - val_accuracy: 0.8186\n",
      "Epoch 746/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4054 - accuracy: 0.8211 - val_loss: 0.4076 - val_accuracy: 0.8197\n",
      "Epoch 747/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4068 - accuracy: 0.8203 - val_loss: 0.4121 - val_accuracy: 0.8168\n",
      "Epoch 748/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4060 - accuracy: 0.8206 - val_loss: 0.4059 - val_accuracy: 0.8199\n",
      "Epoch 749/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4069 - accuracy: 0.8198 - val_loss: 0.4064 - val_accuracy: 0.8184\n",
      "Epoch 750/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4059 - accuracy: 0.8211 - val_loss: 0.4113 - val_accuracy: 0.8179\n",
      "Epoch 751/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4061 - accuracy: 0.8216 - val_loss: 0.4092 - val_accuracy: 0.8201\n",
      "Epoch 752/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4075 - accuracy: 0.8206 - val_loss: 0.4058 - val_accuracy: 0.8201\n",
      "Epoch 753/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4063 - accuracy: 0.8213 - val_loss: 0.4080 - val_accuracy: 0.8199\n",
      "Epoch 754/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4081 - accuracy: 0.8199 - val_loss: 0.4165 - val_accuracy: 0.8172\n",
      "Epoch 755/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4069 - accuracy: 0.8207 - val_loss: 0.4058 - val_accuracy: 0.8213\n",
      "Epoch 756/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4070 - accuracy: 0.8202 - val_loss: 0.4055 - val_accuracy: 0.8209\n",
      "Epoch 757/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4072 - accuracy: 0.8211 - val_loss: 0.4087 - val_accuracy: 0.8175\n",
      "Epoch 758/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4068 - accuracy: 0.8207 - val_loss: 0.4067 - val_accuracy: 0.8199\n",
      "Epoch 759/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4087 - accuracy: 0.8199 - val_loss: 0.4134 - val_accuracy: 0.8173\n",
      "Epoch 760/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4063 - accuracy: 0.8203 - val_loss: 0.4097 - val_accuracy: 0.8177\n",
      "Epoch 761/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4072 - accuracy: 0.8197 - val_loss: 0.4119 - val_accuracy: 0.8148\n",
      "Epoch 762/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4066 - accuracy: 0.8196 - val_loss: 0.4073 - val_accuracy: 0.8179\n",
      "Epoch 763/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4083 - accuracy: 0.8210 - val_loss: 0.4088 - val_accuracy: 0.8232\n",
      "Epoch 764/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4062 - accuracy: 0.8205 - val_loss: 0.4056 - val_accuracy: 0.8235\n",
      "Epoch 765/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4056 - accuracy: 0.8198 - val_loss: 0.4153 - val_accuracy: 0.8128\n",
      "Epoch 766/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4070 - accuracy: 0.8190 - val_loss: 0.4079 - val_accuracy: 0.8189\n",
      "Epoch 767/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4099 - accuracy: 0.8187 - val_loss: 0.4197 - val_accuracy: 0.8135\n",
      "Epoch 768/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4099 - accuracy: 0.8199 - val_loss: 0.4214 - val_accuracy: 0.8132\n",
      "Epoch 769/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4080 - accuracy: 0.8205 - val_loss: 0.4043 - val_accuracy: 0.8229\n",
      "Epoch 770/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4071 - accuracy: 0.8206 - val_loss: 0.4047 - val_accuracy: 0.8202\n",
      "Epoch 771/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4068 - accuracy: 0.8208 - val_loss: 0.4116 - val_accuracy: 0.8204\n",
      "Epoch 772/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4077 - accuracy: 0.8202 - val_loss: 0.4083 - val_accuracy: 0.8170\n",
      "Epoch 773/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4078 - accuracy: 0.8201 - val_loss: 0.4085 - val_accuracy: 0.8178\n",
      "Epoch 774/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4090 - accuracy: 0.8188 - val_loss: 0.4110 - val_accuracy: 0.8174\n",
      "Epoch 775/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4065 - accuracy: 0.8203 - val_loss: 0.4077 - val_accuracy: 0.8176\n",
      "Epoch 776/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4065 - accuracy: 0.8193 - val_loss: 0.4084 - val_accuracy: 0.8196\n",
      "Epoch 777/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4062 - accuracy: 0.8204 - val_loss: 0.4068 - val_accuracy: 0.8184\n",
      "Epoch 778/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4074 - accuracy: 0.8188 - val_loss: 0.4102 - val_accuracy: 0.8186\n",
      "Epoch 779/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4065 - accuracy: 0.8216 - val_loss: 0.4110 - val_accuracy: 0.8207\n",
      "Epoch 780/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4056 - accuracy: 0.8206 - val_loss: 0.4095 - val_accuracy: 0.8207\n",
      "Epoch 781/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4069 - accuracy: 0.8203 - val_loss: 0.4044 - val_accuracy: 0.8204\n",
      "Epoch 782/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4054 - accuracy: 0.8208 - val_loss: 0.4053 - val_accuracy: 0.8184\n",
      "Epoch 783/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4066 - accuracy: 0.8185 - val_loss: 0.4085 - val_accuracy: 0.8190\n",
      "Epoch 784/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4063 - accuracy: 0.8213 - val_loss: 0.4053 - val_accuracy: 0.8217\n",
      "Epoch 785/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4046 - accuracy: 0.8206 - val_loss: 0.4080 - val_accuracy: 0.8191\n",
      "Epoch 786/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4055 - accuracy: 0.8212 - val_loss: 0.4072 - val_accuracy: 0.8219\n",
      "Epoch 787/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4065 - accuracy: 0.8212 - val_loss: 0.4050 - val_accuracy: 0.8208\n",
      "Epoch 788/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4052 - accuracy: 0.8214 - val_loss: 0.4071 - val_accuracy: 0.8177\n",
      "Epoch 789/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4057 - accuracy: 0.8209 - val_loss: 0.4059 - val_accuracy: 0.8204\n",
      "Epoch 790/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4062 - accuracy: 0.8208 - val_loss: 0.4083 - val_accuracy: 0.8179\n",
      "Epoch 791/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4050 - accuracy: 0.8220 - val_loss: 0.4093 - val_accuracy: 0.8187\n",
      "Epoch 792/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4057 - accuracy: 0.8209 - val_loss: 0.4137 - val_accuracy: 0.8153\n",
      "Epoch 793/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4072 - accuracy: 0.8197 - val_loss: 0.4074 - val_accuracy: 0.8200\n",
      "Epoch 794/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4091 - accuracy: 0.8198 - val_loss: 0.4114 - val_accuracy: 0.8168\n",
      "Epoch 795/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4068 - accuracy: 0.8206 - val_loss: 0.4113 - val_accuracy: 0.8162\n",
      "Epoch 796/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4071 - accuracy: 0.8216 - val_loss: 0.4100 - val_accuracy: 0.8188\n",
      "Epoch 797/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4059 - accuracy: 0.8203 - val_loss: 0.4085 - val_accuracy: 0.8204\n",
      "Epoch 798/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4058 - accuracy: 0.8215 - val_loss: 0.4083 - val_accuracy: 0.8226\n",
      "Epoch 799/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4081 - accuracy: 0.8215 - val_loss: 0.4112 - val_accuracy: 0.8198\n",
      "Epoch 800/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4089 - accuracy: 0.8206 - val_loss: 0.4082 - val_accuracy: 0.8151\n",
      "Epoch 801/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4079 - accuracy: 0.8194 - val_loss: 0.4173 - val_accuracy: 0.8148\n",
      "Epoch 802/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4089 - accuracy: 0.8202 - val_loss: 0.4070 - val_accuracy: 0.8210\n",
      "Epoch 803/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4059 - accuracy: 0.8208 - val_loss: 0.4146 - val_accuracy: 0.8180\n",
      "Epoch 804/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4077 - accuracy: 0.8194 - val_loss: 0.4072 - val_accuracy: 0.8180\n",
      "Epoch 805/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4051 - accuracy: 0.8210 - val_loss: 0.4102 - val_accuracy: 0.8168\n",
      "Epoch 806/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4053 - accuracy: 0.8213 - val_loss: 0.4096 - val_accuracy: 0.8179\n",
      "Epoch 807/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4053 - accuracy: 0.8205 - val_loss: 0.4066 - val_accuracy: 0.8194\n",
      "Epoch 808/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4072 - accuracy: 0.8206 - val_loss: 0.4105 - val_accuracy: 0.8188\n",
      "Epoch 809/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4076 - accuracy: 0.8212 - val_loss: 0.4087 - val_accuracy: 0.8183\n",
      "Epoch 810/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4067 - accuracy: 0.8211 - val_loss: 0.4114 - val_accuracy: 0.8174\n",
      "Epoch 811/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4062 - accuracy: 0.8209 - val_loss: 0.4053 - val_accuracy: 0.8215\n",
      "Epoch 812/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4071 - accuracy: 0.8202 - val_loss: 0.4070 - val_accuracy: 0.8183\n",
      "Epoch 813/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4063 - accuracy: 0.8204 - val_loss: 0.4081 - val_accuracy: 0.8210\n",
      "Epoch 814/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4064 - accuracy: 0.8217 - val_loss: 0.4096 - val_accuracy: 0.8186\n",
      "Epoch 815/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4064 - accuracy: 0.8201 - val_loss: 0.4085 - val_accuracy: 0.8189\n",
      "Epoch 816/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4059 - accuracy: 0.8209 - val_loss: 0.4072 - val_accuracy: 0.8201\n",
      "Epoch 817/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4074 - accuracy: 0.8214 - val_loss: 0.4067 - val_accuracy: 0.8199\n",
      "Epoch 818/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4088 - accuracy: 0.8199 - val_loss: 0.4105 - val_accuracy: 0.8217\n",
      "Epoch 819/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4072 - accuracy: 0.8192 - val_loss: 0.4036 - val_accuracy: 0.8216\n",
      "Epoch 820/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4057 - accuracy: 0.8207 - val_loss: 0.4134 - val_accuracy: 0.8196\n",
      "Epoch 821/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4062 - accuracy: 0.8212 - val_loss: 0.4096 - val_accuracy: 0.8226\n",
      "Epoch 822/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4059 - accuracy: 0.8224 - val_loss: 0.4079 - val_accuracy: 0.8186\n",
      "Epoch 823/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4078 - accuracy: 0.8192 - val_loss: 0.4112 - val_accuracy: 0.8182\n",
      "Epoch 824/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4065 - accuracy: 0.8207 - val_loss: 0.4073 - val_accuracy: 0.8193\n",
      "Epoch 825/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4065 - accuracy: 0.8201 - val_loss: 0.4129 - val_accuracy: 0.8171\n",
      "Epoch 826/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4061 - accuracy: 0.8205 - val_loss: 0.4140 - val_accuracy: 0.8137\n",
      "Epoch 827/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4075 - accuracy: 0.8207 - val_loss: 0.4138 - val_accuracy: 0.8144\n",
      "Epoch 828/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4062 - accuracy: 0.8203 - val_loss: 0.4055 - val_accuracy: 0.8204\n",
      "Epoch 829/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4043 - accuracy: 0.8212 - val_loss: 0.4075 - val_accuracy: 0.8180\n",
      "Epoch 830/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4050 - accuracy: 0.8221 - val_loss: 0.4070 - val_accuracy: 0.8207\n",
      "Epoch 831/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4071 - accuracy: 0.8209 - val_loss: 0.4091 - val_accuracy: 0.8201\n",
      "Epoch 832/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4058 - accuracy: 0.8212 - val_loss: 0.4116 - val_accuracy: 0.8161\n",
      "Epoch 833/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4072 - accuracy: 0.8205 - val_loss: 0.4157 - val_accuracy: 0.8161\n",
      "Epoch 834/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4062 - accuracy: 0.8210 - val_loss: 0.4138 - val_accuracy: 0.8191\n",
      "Epoch 835/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4085 - accuracy: 0.8213 - val_loss: 0.4069 - val_accuracy: 0.8174\n",
      "Epoch 836/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4046 - accuracy: 0.8216 - val_loss: 0.4099 - val_accuracy: 0.8197\n",
      "Epoch 837/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4046 - accuracy: 0.8209 - val_loss: 0.4075 - val_accuracy: 0.8175\n",
      "Epoch 838/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4067 - accuracy: 0.8192 - val_loss: 0.4055 - val_accuracy: 0.8197\n",
      "Epoch 839/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4047 - accuracy: 0.8207 - val_loss: 0.4186 - val_accuracy: 0.8130\n",
      "Epoch 840/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4062 - accuracy: 0.8208 - val_loss: 0.4057 - val_accuracy: 0.8213\n",
      "Epoch 841/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4068 - accuracy: 0.8206 - val_loss: 0.4117 - val_accuracy: 0.8178\n",
      "Epoch 842/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4041 - accuracy: 0.8215 - val_loss: 0.4070 - val_accuracy: 0.8214\n",
      "Epoch 843/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4068 - accuracy: 0.8195 - val_loss: 0.4090 - val_accuracy: 0.8188\n",
      "Epoch 844/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4073 - accuracy: 0.8200 - val_loss: 0.4141 - val_accuracy: 0.8149\n",
      "Epoch 845/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4084 - accuracy: 0.8200 - val_loss: 0.4075 - val_accuracy: 0.8209\n",
      "Epoch 846/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4065 - accuracy: 0.8203 - val_loss: 0.4149 - val_accuracy: 0.8135\n",
      "Epoch 847/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4054 - accuracy: 0.8207 - val_loss: 0.4086 - val_accuracy: 0.8195\n",
      "Epoch 848/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4060 - accuracy: 0.8208 - val_loss: 0.4089 - val_accuracy: 0.8206\n",
      "Epoch 849/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4056 - accuracy: 0.8209 - val_loss: 0.4092 - val_accuracy: 0.8204\n",
      "Epoch 850/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4064 - accuracy: 0.8208 - val_loss: 0.4073 - val_accuracy: 0.8217\n",
      "Epoch 851/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4061 - accuracy: 0.8210 - val_loss: 0.4055 - val_accuracy: 0.8197\n",
      "Epoch 852/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4063 - accuracy: 0.8218 - val_loss: 0.4050 - val_accuracy: 0.8189\n",
      "Epoch 853/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4054 - accuracy: 0.8201 - val_loss: 0.4091 - val_accuracy: 0.8189\n",
      "Epoch 854/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4074 - accuracy: 0.8204 - val_loss: 0.4109 - val_accuracy: 0.8191\n",
      "Epoch 855/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4086 - accuracy: 0.8215 - val_loss: 0.4096 - val_accuracy: 0.8208\n",
      "Epoch 856/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4054 - accuracy: 0.8228 - val_loss: 0.4059 - val_accuracy: 0.8184\n",
      "Epoch 857/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4061 - accuracy: 0.8196 - val_loss: 0.4047 - val_accuracy: 0.8202\n",
      "Epoch 858/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4058 - accuracy: 0.8210 - val_loss: 0.4149 - val_accuracy: 0.8166\n",
      "Epoch 859/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4049 - accuracy: 0.8212 - val_loss: 0.4106 - val_accuracy: 0.8165\n",
      "Epoch 860/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4065 - accuracy: 0.8198 - val_loss: 0.4090 - val_accuracy: 0.8214\n",
      "Epoch 861/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4069 - accuracy: 0.8213 - val_loss: 0.4091 - val_accuracy: 0.8204\n",
      "Epoch 862/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4092 - accuracy: 0.8202 - val_loss: 0.4092 - val_accuracy: 0.8186\n",
      "Epoch 863/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4047 - accuracy: 0.8218 - val_loss: 0.4080 - val_accuracy: 0.8184\n",
      "Epoch 864/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4042 - accuracy: 0.8213 - val_loss: 0.4116 - val_accuracy: 0.8187\n",
      "Epoch 865/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4057 - accuracy: 0.8208 - val_loss: 0.4086 - val_accuracy: 0.8181\n",
      "Epoch 866/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4056 - accuracy: 0.8220 - val_loss: 0.4080 - val_accuracy: 0.8163\n",
      "Epoch 867/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4051 - accuracy: 0.8204 - val_loss: 0.4063 - val_accuracy: 0.8210\n",
      "Epoch 868/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4068 - accuracy: 0.8209 - val_loss: 0.4133 - val_accuracy: 0.8169\n",
      "Epoch 869/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4073 - accuracy: 0.8205 - val_loss: 0.4061 - val_accuracy: 0.8188\n",
      "Epoch 870/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4052 - accuracy: 0.8220 - val_loss: 0.4046 - val_accuracy: 0.8197\n",
      "Epoch 871/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4046 - accuracy: 0.8217 - val_loss: 0.4043 - val_accuracy: 0.8223\n",
      "Epoch 872/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4055 - accuracy: 0.8210 - val_loss: 0.4056 - val_accuracy: 0.8205\n",
      "Epoch 873/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4075 - accuracy: 0.8206 - val_loss: 0.4163 - val_accuracy: 0.8189\n",
      "Epoch 874/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4052 - accuracy: 0.8215 - val_loss: 0.4120 - val_accuracy: 0.8193\n",
      "Epoch 875/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4052 - accuracy: 0.8205 - val_loss: 0.4089 - val_accuracy: 0.8186\n",
      "Epoch 876/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4041 - accuracy: 0.8225 - val_loss: 0.4092 - val_accuracy: 0.8200\n",
      "Epoch 877/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4057 - accuracy: 0.8210 - val_loss: 0.4083 - val_accuracy: 0.8170\n",
      "Epoch 878/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4053 - accuracy: 0.8215 - val_loss: 0.4060 - val_accuracy: 0.8214\n",
      "Epoch 879/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4044 - accuracy: 0.8212 - val_loss: 0.4074 - val_accuracy: 0.8196\n",
      "Epoch 880/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4043 - accuracy: 0.8219 - val_loss: 0.4077 - val_accuracy: 0.8187\n",
      "Epoch 881/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4075 - accuracy: 0.8198 - val_loss: 0.4073 - val_accuracy: 0.8184\n",
      "Epoch 882/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4054 - accuracy: 0.8210 - val_loss: 0.4087 - val_accuracy: 0.8209\n",
      "Epoch 883/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4043 - accuracy: 0.8219 - val_loss: 0.4098 - val_accuracy: 0.8172\n",
      "Epoch 884/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4055 - accuracy: 0.8207 - val_loss: 0.4164 - val_accuracy: 0.8145\n",
      "Epoch 885/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4062 - accuracy: 0.8204 - val_loss: 0.4100 - val_accuracy: 0.8175\n",
      "Epoch 886/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4069 - accuracy: 0.8207 - val_loss: 0.4071 - val_accuracy: 0.8184\n",
      "Epoch 887/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4052 - accuracy: 0.8207 - val_loss: 0.4057 - val_accuracy: 0.8197\n",
      "Epoch 888/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4049 - accuracy: 0.8223 - val_loss: 0.4051 - val_accuracy: 0.8203\n",
      "Epoch 889/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4046 - accuracy: 0.8227 - val_loss: 0.4076 - val_accuracy: 0.8177\n",
      "Epoch 890/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4060 - accuracy: 0.8206 - val_loss: 0.4094 - val_accuracy: 0.8191\n",
      "Epoch 891/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4052 - accuracy: 0.8210 - val_loss: 0.4141 - val_accuracy: 0.8179\n",
      "Epoch 892/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4063 - accuracy: 0.8206 - val_loss: 0.4104 - val_accuracy: 0.8192\n",
      "Epoch 893/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4062 - accuracy: 0.8217 - val_loss: 0.4112 - val_accuracy: 0.8166\n",
      "Epoch 894/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4057 - accuracy: 0.8216 - val_loss: 0.4081 - val_accuracy: 0.8171\n",
      "Epoch 895/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4044 - accuracy: 0.8213 - val_loss: 0.4042 - val_accuracy: 0.8202\n",
      "Epoch 896/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4048 - accuracy: 0.8210 - val_loss: 0.4077 - val_accuracy: 0.8204\n",
      "Epoch 897/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4055 - accuracy: 0.8207 - val_loss: 0.4124 - val_accuracy: 0.8148\n",
      "Epoch 898/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4062 - accuracy: 0.8198 - val_loss: 0.4119 - val_accuracy: 0.8158\n",
      "Epoch 899/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4063 - accuracy: 0.8219 - val_loss: 0.4114 - val_accuracy: 0.8187\n",
      "Epoch 900/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4047 - accuracy: 0.8218 - val_loss: 0.4050 - val_accuracy: 0.8189\n",
      "Epoch 901/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4053 - accuracy: 0.8217 - val_loss: 0.4098 - val_accuracy: 0.8182\n",
      "Epoch 902/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4058 - accuracy: 0.8223 - val_loss: 0.4072 - val_accuracy: 0.8199\n",
      "Epoch 903/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4076 - accuracy: 0.8203 - val_loss: 0.4115 - val_accuracy: 0.8207\n",
      "Epoch 904/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4052 - accuracy: 0.8215 - val_loss: 0.4066 - val_accuracy: 0.8187\n",
      "Epoch 905/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4064 - accuracy: 0.8201 - val_loss: 0.4078 - val_accuracy: 0.8206\n",
      "Epoch 906/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4043 - accuracy: 0.8223 - val_loss: 0.4092 - val_accuracy: 0.8176\n",
      "Epoch 907/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4048 - accuracy: 0.8216 - val_loss: 0.4168 - val_accuracy: 0.8148\n",
      "Epoch 908/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4063 - accuracy: 0.8213 - val_loss: 0.4137 - val_accuracy: 0.8168\n",
      "Epoch 909/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4062 - accuracy: 0.8200 - val_loss: 0.4064 - val_accuracy: 0.8215\n",
      "Epoch 910/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4066 - accuracy: 0.8210 - val_loss: 0.4062 - val_accuracy: 0.8189\n",
      "Epoch 911/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4052 - accuracy: 0.8217 - val_loss: 0.4093 - val_accuracy: 0.8183\n",
      "Epoch 912/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4040 - accuracy: 0.8215 - val_loss: 0.4063 - val_accuracy: 0.8207\n",
      "Epoch 913/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4033 - accuracy: 0.8223 - val_loss: 0.4065 - val_accuracy: 0.8207\n",
      "Epoch 914/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4040 - accuracy: 0.8223 - val_loss: 0.4081 - val_accuracy: 0.8166\n",
      "Epoch 915/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4035 - accuracy: 0.8220 - val_loss: 0.4111 - val_accuracy: 0.8135\n",
      "Epoch 916/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4045 - accuracy: 0.8216 - val_loss: 0.4053 - val_accuracy: 0.8190\n",
      "Epoch 917/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4036 - accuracy: 0.8223 - val_loss: 0.4053 - val_accuracy: 0.8208\n",
      "Epoch 918/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4050 - accuracy: 0.8218 - val_loss: 0.4069 - val_accuracy: 0.8187\n",
      "Epoch 919/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4056 - accuracy: 0.8220 - val_loss: 0.4072 - val_accuracy: 0.8201\n",
      "Epoch 920/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4060 - accuracy: 0.8218 - val_loss: 0.4097 - val_accuracy: 0.8203\n",
      "Epoch 921/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4069 - accuracy: 0.8212 - val_loss: 0.4081 - val_accuracy: 0.8227\n",
      "Epoch 922/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4044 - accuracy: 0.8217 - val_loss: 0.4068 - val_accuracy: 0.8171\n",
      "Epoch 923/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4022 - accuracy: 0.8224 - val_loss: 0.4040 - val_accuracy: 0.8205\n",
      "Epoch 924/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4045 - accuracy: 0.8218 - val_loss: 0.4086 - val_accuracy: 0.8207\n",
      "Epoch 925/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4057 - accuracy: 0.8218 - val_loss: 0.4128 - val_accuracy: 0.8174\n",
      "Epoch 926/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4051 - accuracy: 0.8218 - val_loss: 0.4072 - val_accuracy: 0.8214\n",
      "Epoch 927/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4035 - accuracy: 0.8228 - val_loss: 0.4114 - val_accuracy: 0.8171\n",
      "Epoch 928/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4031 - accuracy: 0.8219 - val_loss: 0.4098 - val_accuracy: 0.8163\n",
      "Epoch 929/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4058 - accuracy: 0.8216 - val_loss: 0.4055 - val_accuracy: 0.8213\n",
      "Epoch 930/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4057 - accuracy: 0.8201 - val_loss: 0.4073 - val_accuracy: 0.8187\n",
      "Epoch 931/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4033 - accuracy: 0.8229 - val_loss: 0.4109 - val_accuracy: 0.8193\n",
      "Epoch 932/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4067 - accuracy: 0.8211 - val_loss: 0.4056 - val_accuracy: 0.8204\n",
      "Epoch 933/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4048 - accuracy: 0.8214 - val_loss: 0.4065 - val_accuracy: 0.8199\n",
      "Epoch 934/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4075 - accuracy: 0.8211 - val_loss: 0.4143 - val_accuracy: 0.8176\n",
      "Epoch 935/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4059 - accuracy: 0.8212 - val_loss: 0.4055 - val_accuracy: 0.8204\n",
      "Epoch 936/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4064 - accuracy: 0.8204 - val_loss: 0.4094 - val_accuracy: 0.8199\n",
      "Epoch 937/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4046 - accuracy: 0.8215 - val_loss: 0.4075 - val_accuracy: 0.8167\n",
      "Epoch 938/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4071 - accuracy: 0.8198 - val_loss: 0.4095 - val_accuracy: 0.8182\n",
      "Epoch 939/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4054 - accuracy: 0.8206 - val_loss: 0.4086 - val_accuracy: 0.8209\n",
      "Epoch 940/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4055 - accuracy: 0.8210 - val_loss: 0.4086 - val_accuracy: 0.8183\n",
      "Epoch 941/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4053 - accuracy: 0.8213 - val_loss: 0.4186 - val_accuracy: 0.8167\n",
      "Epoch 942/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4068 - accuracy: 0.8212 - val_loss: 0.4136 - val_accuracy: 0.8164\n",
      "Epoch 943/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4053 - accuracy: 0.8218 - val_loss: 0.4084 - val_accuracy: 0.8197\n",
      "Epoch 944/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4053 - accuracy: 0.8207 - val_loss: 0.4084 - val_accuracy: 0.8202\n",
      "Epoch 945/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4070 - accuracy: 0.8199 - val_loss: 0.4100 - val_accuracy: 0.8175\n",
      "Epoch 946/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4052 - accuracy: 0.8215 - val_loss: 0.4055 - val_accuracy: 0.8188\n",
      "Epoch 947/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4041 - accuracy: 0.8208 - val_loss: 0.4082 - val_accuracy: 0.8186\n",
      "Epoch 948/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4045 - accuracy: 0.8211 - val_loss: 0.4058 - val_accuracy: 0.8214\n",
      "Epoch 949/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4049 - accuracy: 0.8206 - val_loss: 0.4104 - val_accuracy: 0.8193\n",
      "Epoch 950/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4058 - accuracy: 0.8212 - val_loss: 0.4098 - val_accuracy: 0.8193\n",
      "Epoch 951/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4040 - accuracy: 0.8216 - val_loss: 0.4035 - val_accuracy: 0.8221\n",
      "Epoch 952/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4031 - accuracy: 0.8218 - val_loss: 0.4074 - val_accuracy: 0.8193\n",
      "Epoch 953/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4055 - accuracy: 0.8205 - val_loss: 0.4133 - val_accuracy: 0.8179\n",
      "Epoch 954/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4053 - accuracy: 0.8222 - val_loss: 0.4092 - val_accuracy: 0.8184\n",
      "Epoch 955/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4032 - accuracy: 0.8216 - val_loss: 0.4051 - val_accuracy: 0.8198\n",
      "Epoch 956/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4043 - accuracy: 0.8215 - val_loss: 0.4037 - val_accuracy: 0.8213\n",
      "Epoch 957/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4043 - accuracy: 0.8216 - val_loss: 0.4043 - val_accuracy: 0.8210\n",
      "Epoch 958/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4047 - accuracy: 0.8210 - val_loss: 0.4083 - val_accuracy: 0.8212\n",
      "Epoch 959/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4056 - accuracy: 0.8207 - val_loss: 0.4072 - val_accuracy: 0.8193\n",
      "Epoch 960/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4066 - accuracy: 0.8215 - val_loss: 0.4110 - val_accuracy: 0.8199\n",
      "Epoch 961/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4046 - accuracy: 0.8220 - val_loss: 0.4068 - val_accuracy: 0.8195\n",
      "Epoch 962/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4052 - accuracy: 0.8216 - val_loss: 0.4054 - val_accuracy: 0.8190\n",
      "Epoch 963/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4033 - accuracy: 0.8215 - val_loss: 0.4052 - val_accuracy: 0.8210\n",
      "Epoch 964/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4047 - accuracy: 0.8223 - val_loss: 0.4057 - val_accuracy: 0.8240\n",
      "Epoch 965/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4046 - accuracy: 0.8215 - val_loss: 0.4141 - val_accuracy: 0.8151\n",
      "Epoch 966/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4060 - accuracy: 0.8217 - val_loss: 0.4059 - val_accuracy: 0.8205\n",
      "Epoch 967/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4030 - accuracy: 0.8228 - val_loss: 0.4113 - val_accuracy: 0.8174\n",
      "Epoch 968/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4049 - accuracy: 0.8223 - val_loss: 0.4060 - val_accuracy: 0.8197\n",
      "Epoch 969/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4051 - accuracy: 0.8213 - val_loss: 0.4071 - val_accuracy: 0.8191\n",
      "Epoch 970/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4062 - accuracy: 0.8214 - val_loss: 0.4066 - val_accuracy: 0.8203\n",
      "Epoch 971/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4068 - accuracy: 0.8215 - val_loss: 0.4053 - val_accuracy: 0.8191\n",
      "Epoch 972/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4031 - accuracy: 0.8222 - val_loss: 0.4159 - val_accuracy: 0.8179\n",
      "Epoch 973/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4048 - accuracy: 0.8220 - val_loss: 0.4085 - val_accuracy: 0.8183\n",
      "Epoch 974/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4064 - accuracy: 0.8213 - val_loss: 0.4064 - val_accuracy: 0.8199\n",
      "Epoch 975/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4061 - accuracy: 0.8208 - val_loss: 0.4059 - val_accuracy: 0.8197\n",
      "Epoch 976/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4037 - accuracy: 0.8214 - val_loss: 0.4093 - val_accuracy: 0.8230\n",
      "Epoch 977/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4039 - accuracy: 0.8214 - val_loss: 0.4068 - val_accuracy: 0.8191\n",
      "Epoch 978/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4069 - accuracy: 0.8203 - val_loss: 0.4153 - val_accuracy: 0.8189\n",
      "Epoch 979/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4084 - accuracy: 0.8212 - val_loss: 0.4186 - val_accuracy: 0.8142\n",
      "Epoch 980/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4064 - accuracy: 0.8208 - val_loss: 0.4066 - val_accuracy: 0.8201\n",
      "Epoch 981/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4045 - accuracy: 0.8222 - val_loss: 0.4072 - val_accuracy: 0.8235\n",
      "Epoch 982/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4041 - accuracy: 0.8210 - val_loss: 0.4055 - val_accuracy: 0.8199\n",
      "Epoch 983/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4037 - accuracy: 0.8215 - val_loss: 0.4090 - val_accuracy: 0.8165\n",
      "Epoch 984/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4039 - accuracy: 0.8218 - val_loss: 0.4053 - val_accuracy: 0.8193\n",
      "Epoch 985/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4047 - accuracy: 0.8209 - val_loss: 0.4035 - val_accuracy: 0.8203\n",
      "Epoch 986/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4042 - accuracy: 0.8218 - val_loss: 0.4121 - val_accuracy: 0.8184\n",
      "Epoch 987/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4051 - accuracy: 0.8209 - val_loss: 0.4045 - val_accuracy: 0.8185\n",
      "Epoch 988/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4040 - accuracy: 0.8228 - val_loss: 0.4058 - val_accuracy: 0.8193\n",
      "Epoch 989/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4040 - accuracy: 0.8214 - val_loss: 0.4080 - val_accuracy: 0.8179\n",
      "Epoch 990/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4039 - accuracy: 0.8233 - val_loss: 0.4065 - val_accuracy: 0.8190\n",
      "Epoch 991/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4054 - accuracy: 0.8210 - val_loss: 0.4071 - val_accuracy: 0.8214\n",
      "Epoch 992/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4046 - accuracy: 0.8215 - val_loss: 0.4111 - val_accuracy: 0.8161\n",
      "Epoch 993/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4052 - accuracy: 0.8216 - val_loss: 0.4086 - val_accuracy: 0.8194\n",
      "Epoch 994/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4047 - accuracy: 0.8220 - val_loss: 0.4173 - val_accuracy: 0.8181\n",
      "Epoch 995/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4047 - accuracy: 0.8219 - val_loss: 0.4049 - val_accuracy: 0.8206\n",
      "Epoch 996/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4042 - accuracy: 0.8214 - val_loss: 0.4104 - val_accuracy: 0.8156\n",
      "Epoch 997/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4051 - accuracy: 0.8212 - val_loss: 0.4103 - val_accuracy: 0.8181\n",
      "Epoch 998/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4061 - accuracy: 0.8211 - val_loss: 0.4057 - val_accuracy: 0.8198\n",
      "Epoch 999/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4050 - accuracy: 0.8214 - val_loss: 0.4060 - val_accuracy: 0.8206\n",
      "Epoch 1000/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4056 - accuracy: 0.8213 - val_loss: 0.4067 - val_accuracy: 0.8199\n",
      "Epoch 1/1000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 0.5969 - accuracy: 0.7156 - val_loss: 0.5962 - val_accuracy: 0.7165\n",
      "Epoch 2/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5969 - accuracy: 0.7156 - val_loss: 0.5965 - val_accuracy: 0.7165\n",
      "Epoch 3/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5969 - accuracy: 0.7156 - val_loss: 0.5959 - val_accuracy: 0.7165\n",
      "Epoch 4/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5963 - accuracy: 0.7156 - val_loss: 0.5961 - val_accuracy: 0.7165\n",
      "Epoch 5/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5967 - accuracy: 0.7156 - val_loss: 0.5964 - val_accuracy: 0.7165\n",
      "Epoch 6/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5968 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 7/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5952 - accuracy: 0.7156 - val_loss: 0.5960 - val_accuracy: 0.7165\n",
      "Epoch 8/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5923 - accuracy: 0.7156 - val_loss: 0.5842 - val_accuracy: 0.7165\n",
      "Epoch 9/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5924 - accuracy: 0.7156 - val_loss: 0.5962 - val_accuracy: 0.7165\n",
      "Epoch 10/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5967 - accuracy: 0.7156 - val_loss: 0.5962 - val_accuracy: 0.7165\n",
      "Epoch 11/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5917 - accuracy: 0.7156 - val_loss: 0.5845 - val_accuracy: 0.7165\n",
      "Epoch 12/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5937 - accuracy: 0.7156 - val_loss: 0.5927 - val_accuracy: 0.7165\n",
      "Epoch 13/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5927 - accuracy: 0.7156 - val_loss: 0.5898 - val_accuracy: 0.7165\n",
      "Epoch 14/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5866 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 15/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5863 - accuracy: 0.7156 - val_loss: 0.5702 - val_accuracy: 0.7165\n",
      "Epoch 16/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5884 - accuracy: 0.7156 - val_loss: 0.5741 - val_accuracy: 0.7165\n",
      "Epoch 17/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5819 - accuracy: 0.7156 - val_loss: 0.5968 - val_accuracy: 0.7165\n",
      "Epoch 18/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5963 - accuracy: 0.7156 - val_loss: 0.5950 - val_accuracy: 0.7165\n",
      "Epoch 19/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5960 - accuracy: 0.7156 - val_loss: 0.5962 - val_accuracy: 0.7165\n",
      "Epoch 20/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5962 - val_accuracy: 0.7165\n",
      "Epoch 21/1000\n",
      "152/152 [==============================] - ETA: 0s - loss: 0.5976 - accuracy: 0.71 - 1s 5ms/step - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5962 - val_accuracy: 0.7165\n",
      "Epoch 22/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5962 - accuracy: 0.7156 - val_loss: 0.5964 - val_accuracy: 0.7165\n",
      "Epoch 23/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5943 - accuracy: 0.7156 - val_loss: 0.5936 - val_accuracy: 0.7165\n",
      "Epoch 24/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5955 - accuracy: 0.7156 - val_loss: 0.5863 - val_accuracy: 0.7165\n",
      "Epoch 25/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5860 - accuracy: 0.7156 - val_loss: 0.5969 - val_accuracy: 0.7165\n",
      "Epoch 26/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5896 - accuracy: 0.7156 - val_loss: 0.5962 - val_accuracy: 0.7165\n",
      "Epoch 27/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5934 - accuracy: 0.7156 - val_loss: 0.5966 - val_accuracy: 0.7165\n",
      "Epoch 28/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5809 - accuracy: 0.7156 - val_loss: 0.6053 - val_accuracy: 0.7165\n",
      "Epoch 29/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5787 - accuracy: 0.7156 - val_loss: 0.5993 - val_accuracy: 0.7165\n",
      "Epoch 30/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5762 - accuracy: 0.7156 - val_loss: 0.5717 - val_accuracy: 0.7165\n",
      "Epoch 31/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5732 - accuracy: 0.7156 - val_loss: 0.5582 - val_accuracy: 0.7165\n",
      "Epoch 32/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5705 - accuracy: 0.7156 - val_loss: 0.5618 - val_accuracy: 0.7165\n",
      "Epoch 33/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5734 - accuracy: 0.7156 - val_loss: 0.5961 - val_accuracy: 0.7165\n",
      "Epoch 34/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5733 - accuracy: 0.7156 - val_loss: 0.5470 - val_accuracy: 0.7165\n",
      "Epoch 35/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5508 - accuracy: 0.7156 - val_loss: 0.5738 - val_accuracy: 0.7165\n",
      "Epoch 36/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5649 - accuracy: 0.7156 - val_loss: 0.5863 - val_accuracy: 0.7165\n",
      "Epoch 37/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5899 - accuracy: 0.7156 - val_loss: 0.5960 - val_accuracy: 0.7165\n",
      "Epoch 38/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5850 - accuracy: 0.7156 - val_loss: 0.5567 - val_accuracy: 0.7165\n",
      "Epoch 39/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5496 - accuracy: 0.7156 - val_loss: 0.5270 - val_accuracy: 0.7165\n",
      "Epoch 40/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5355 - accuracy: 0.7156 - val_loss: 0.5711 - val_accuracy: 0.7164\n",
      "Epoch 41/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5497 - accuracy: 0.7156 - val_loss: 0.5778 - val_accuracy: 0.7165\n",
      "Epoch 42/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5756 - accuracy: 0.7156 - val_loss: 0.5796 - val_accuracy: 0.7165\n",
      "Epoch 43/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5764 - accuracy: 0.7156 - val_loss: 0.5623 - val_accuracy: 0.7165\n",
      "Epoch 44/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5544 - accuracy: 0.7156 - val_loss: 0.5396 - val_accuracy: 0.7165\n",
      "Epoch 45/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5675 - accuracy: 0.7156 - val_loss: 0.5324 - val_accuracy: 0.7165\n",
      "Epoch 46/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5719 - accuracy: 0.7156 - val_loss: 0.5960 - val_accuracy: 0.7165\n",
      "Epoch 47/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5659 - accuracy: 0.7156 - val_loss: 0.5162 - val_accuracy: 0.7164\n",
      "Epoch 48/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5399 - accuracy: 0.7156 - val_loss: 0.5108 - val_accuracy: 0.7165\n",
      "Epoch 49/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5339 - accuracy: 0.7156 - val_loss: 0.5199 - val_accuracy: 0.7164\n",
      "Epoch 50/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5580 - accuracy: 0.7156 - val_loss: 0.5084 - val_accuracy: 0.7165\n",
      "Epoch 51/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5292 - accuracy: 0.7156 - val_loss: 0.5543 - val_accuracy: 0.7164\n",
      "Epoch 52/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5521 - accuracy: 0.7156 - val_loss: 0.5955 - val_accuracy: 0.7165\n",
      "Epoch 53/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5538 - accuracy: 0.7156 - val_loss: 0.4961 - val_accuracy: 0.7163\n",
      "Epoch 54/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5379 - accuracy: 0.7156 - val_loss: 0.4962 - val_accuracy: 0.7164\n",
      "Epoch 55/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5343 - accuracy: 0.7159 - val_loss: 0.5059 - val_accuracy: 0.7163\n",
      "Epoch 56/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5175 - accuracy: 0.7156 - val_loss: 0.5289 - val_accuracy: 0.7163\n",
      "Epoch 57/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5373 - accuracy: 0.7156 - val_loss: 0.5293 - val_accuracy: 0.7164\n",
      "Epoch 58/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5308 - accuracy: 0.7377 - val_loss: 0.4880 - val_accuracy: 0.7760\n",
      "Epoch 59/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5266 - accuracy: 0.7256 - val_loss: 0.5559 - val_accuracy: 0.7622\n",
      "Epoch 60/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5180 - accuracy: 0.7585 - val_loss: 0.5010 - val_accuracy: 0.7164\n",
      "Epoch 61/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5479 - accuracy: 0.7283 - val_loss: 0.5833 - val_accuracy: 0.7165\n",
      "Epoch 62/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5181 - accuracy: 0.7221 - val_loss: 0.5175 - val_accuracy: 0.7164\n",
      "Epoch 63/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5246 - accuracy: 0.7240 - val_loss: 0.4808 - val_accuracy: 0.7762\n",
      "Epoch 64/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5260 - accuracy: 0.7511 - val_loss: 0.5951 - val_accuracy: 0.7165\n",
      "Epoch 65/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5585 - accuracy: 0.7156 - val_loss: 0.5082 - val_accuracy: 0.7164\n",
      "Epoch 66/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5657 - accuracy: 0.7156 - val_loss: 0.5952 - val_accuracy: 0.7165\n",
      "Epoch 67/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5741 - accuracy: 0.7156 - val_loss: 0.5970 - val_accuracy: 0.7165\n",
      "Epoch 68/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5093 - accuracy: 0.7228 - val_loss: 0.5525 - val_accuracy: 0.7701\n",
      "Epoch 69/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5080 - accuracy: 0.7413 - val_loss: 0.5096 - val_accuracy: 0.7949\n",
      "Epoch 70/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5042 - accuracy: 0.7549 - val_loss: 0.5344 - val_accuracy: 0.7767\n",
      "Epoch 71/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5411 - accuracy: 0.7266 - val_loss: 0.5083 - val_accuracy: 0.7961\n",
      "Epoch 72/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5061 - accuracy: 0.7233 - val_loss: 0.4970 - val_accuracy: 0.8002\n",
      "Epoch 73/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5103 - accuracy: 0.7170 - val_loss: 0.6635 - val_accuracy: 0.7164\n",
      "Epoch 74/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5429 - accuracy: 0.7277 - val_loss: 0.4872 - val_accuracy: 0.8001\n",
      "Epoch 75/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5159 - accuracy: 0.7570 - val_loss: 0.6104 - val_accuracy: 0.7164\n",
      "Epoch 76/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5966 - accuracy: 0.7156 - val_loss: 0.5945 - val_accuracy: 0.7165\n",
      "Epoch 77/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5374 - accuracy: 0.7156 - val_loss: 0.4834 - val_accuracy: 0.7164\n",
      "Epoch 78/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5117 - accuracy: 0.7285 - val_loss: 0.4718 - val_accuracy: 0.7750\n",
      "Epoch 79/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5175 - accuracy: 0.7320 - val_loss: 0.4737 - val_accuracy: 0.7164\n",
      "Epoch 80/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5103 - accuracy: 0.7421 - val_loss: 0.5377 - val_accuracy: 0.7796\n",
      "Epoch 81/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5000 - accuracy: 0.7655 - val_loss: 0.4975 - val_accuracy: 0.7981\n",
      "Epoch 82/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4993 - accuracy: 0.7539 - val_loss: 0.4851 - val_accuracy: 0.7336\n",
      "Epoch 83/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4916 - accuracy: 0.7842 - val_loss: 0.4658 - val_accuracy: 0.7320\n",
      "Epoch 84/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4967 - accuracy: 0.7717 - val_loss: 0.5338 - val_accuracy: 0.7789\n",
      "Epoch 85/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5125 - accuracy: 0.7667 - val_loss: 0.4765 - val_accuracy: 0.8008\n",
      "Epoch 86/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4966 - accuracy: 0.7751 - val_loss: 0.5429 - val_accuracy: 0.7820\n",
      "Epoch 87/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5218 - accuracy: 0.7336 - val_loss: 0.5026 - val_accuracy: 0.7977\n",
      "Epoch 88/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4885 - accuracy: 0.7763 - val_loss: 0.4719 - val_accuracy: 0.7613\n",
      "Epoch 89/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5021 - accuracy: 0.7738 - val_loss: 0.5552 - val_accuracy: 0.7164\n",
      "Epoch 90/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5359 - accuracy: 0.7396 - val_loss: 0.5407 - val_accuracy: 0.7164\n",
      "Epoch 91/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5153 - accuracy: 0.7300 - val_loss: 0.4670 - val_accuracy: 0.7763\n",
      "Epoch 92/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4979 - accuracy: 0.7487 - val_loss: 0.6492 - val_accuracy: 0.7274\n",
      "Epoch 93/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5322 - accuracy: 0.7351 - val_loss: 0.5910 - val_accuracy: 0.7165\n",
      "Epoch 94/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5100 - accuracy: 0.7399 - val_loss: 0.4842 - val_accuracy: 0.7951\n",
      "Epoch 95/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4923 - accuracy: 0.7802 - val_loss: 0.5153 - val_accuracy: 0.7884\n",
      "Epoch 96/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5143 - accuracy: 0.7391 - val_loss: 0.4839 - val_accuracy: 0.8030\n",
      "Epoch 97/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5383 - accuracy: 0.7267 - val_loss: 0.5755 - val_accuracy: 0.7165\n",
      "Epoch 98/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5237 - accuracy: 0.7162 - val_loss: 0.4668 - val_accuracy: 0.7163\n",
      "Epoch 99/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5620 - accuracy: 0.7146 - val_loss: 0.5233 - val_accuracy: 0.7164\n",
      "Epoch 100/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4982 - accuracy: 0.7605 - val_loss: 0.4786 - val_accuracy: 0.7164\n",
      "Epoch 101/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5330 - accuracy: 0.7191 - val_loss: 0.4670 - val_accuracy: 0.7164\n",
      "Epoch 102/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4955 - accuracy: 0.7452 - val_loss: 0.4700 - val_accuracy: 0.7164\n",
      "Epoch 103/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4972 - accuracy: 0.7454 - val_loss: 0.4671 - val_accuracy: 0.7693\n",
      "Epoch 104/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5046 - accuracy: 0.7613 - val_loss: 0.4836 - val_accuracy: 0.8040\n",
      "Epoch 105/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4894 - accuracy: 0.7894 - val_loss: 0.4706 - val_accuracy: 0.8068\n",
      "Epoch 106/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5526 - accuracy: 0.7432 - val_loss: 0.5952 - val_accuracy: 0.7165\n",
      "Epoch 107/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5861 - accuracy: 0.7156 - val_loss: 0.5946 - val_accuracy: 0.7165\n",
      "Epoch 108/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5639 - accuracy: 0.7181 - val_loss: 0.4814 - val_accuracy: 0.8060\n",
      "Epoch 109/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5231 - accuracy: 0.7436 - val_loss: 0.7865 - val_accuracy: 0.2955\n",
      "Epoch 110/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5114 - accuracy: 0.7584 - val_loss: 0.5287 - val_accuracy: 0.7779\n",
      "Epoch 111/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4945 - accuracy: 0.7615 - val_loss: 0.4781 - val_accuracy: 0.8023\n",
      "Epoch 112/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5013 - accuracy: 0.7701 - val_loss: 0.4754 - val_accuracy: 0.7722\n",
      "Epoch 113/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5312 - accuracy: 0.7208 - val_loss: 0.4974 - val_accuracy: 0.8025\n",
      "Epoch 114/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5256 - accuracy: 0.7329 - val_loss: 0.5330 - val_accuracy: 0.7164\n",
      "Epoch 115/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4833 - accuracy: 0.7817 - val_loss: 0.4820 - val_accuracy: 0.8042\n",
      "Epoch 116/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5336 - accuracy: 0.7432 - val_loss: 0.5943 - val_accuracy: 0.7165\n",
      "Epoch 117/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5949 - accuracy: 0.7156 - val_loss: 0.5947 - val_accuracy: 0.7165\n",
      "Epoch 118/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5833 - accuracy: 0.7156 - val_loss: 0.5949 - val_accuracy: 0.7165\n",
      "Epoch 119/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5636 - accuracy: 0.7156 - val_loss: 0.5253 - val_accuracy: 0.7164\n",
      "Epoch 120/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5334 - accuracy: 0.7171 - val_loss: 0.4985 - val_accuracy: 0.7734\n",
      "Epoch 121/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4882 - accuracy: 0.7669 - val_loss: 0.4859 - val_accuracy: 0.8042\n",
      "Epoch 122/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5678 - accuracy: 0.7235 - val_loss: 0.5925 - val_accuracy: 0.7165\n",
      "Epoch 123/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5704 - accuracy: 0.7143 - val_loss: 0.5938 - val_accuracy: 0.7165\n",
      "Epoch 124/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5072 - accuracy: 0.7586 - val_loss: 0.4675 - val_accuracy: 0.8059\n",
      "Epoch 125/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5016 - accuracy: 0.7509 - val_loss: 0.4964 - val_accuracy: 0.7164\n",
      "Epoch 126/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4904 - accuracy: 0.7666 - val_loss: 0.4752 - val_accuracy: 0.7655\n",
      "Epoch 127/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5353 - accuracy: 0.7369 - val_loss: 0.5947 - val_accuracy: 0.7165\n",
      "Epoch 128/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5933 - accuracy: 0.7156 - val_loss: 0.5098 - val_accuracy: 0.7165\n",
      "Epoch 129/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4890 - accuracy: 0.7638 - val_loss: 0.4888 - val_accuracy: 0.6913\n",
      "Epoch 130/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4853 - accuracy: 0.7763 - val_loss: 0.4779 - val_accuracy: 0.8042\n",
      "Epoch 131/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4856 - accuracy: 0.7760 - val_loss: 0.4846 - val_accuracy: 0.8027\n",
      "Epoch 132/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4924 - accuracy: 0.7761 - val_loss: 0.7102 - val_accuracy: 0.3396\n",
      "Epoch 133/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4949 - accuracy: 0.7313 - val_loss: 0.4631 - val_accuracy: 0.7930\n",
      "Epoch 134/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4908 - accuracy: 0.7961 - val_loss: 0.5240 - val_accuracy: 0.7845\n",
      "Epoch 135/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4945 - accuracy: 0.7400 - val_loss: 0.4609 - val_accuracy: 0.7983\n",
      "Epoch 136/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4918 - accuracy: 0.7674 - val_loss: 0.4940 - val_accuracy: 0.7997\n",
      "Epoch 137/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4921 - accuracy: 0.7872 - val_loss: 0.4613 - val_accuracy: 0.7934\n",
      "Epoch 138/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4878 - accuracy: 0.7689 - val_loss: 0.4722 - val_accuracy: 0.7542\n",
      "Epoch 139/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5355 - accuracy: 0.7277 - val_loss: 0.4624 - val_accuracy: 0.7733\n",
      "Epoch 140/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4985 - accuracy: 0.7804 - val_loss: 0.4619 - val_accuracy: 0.8061\n",
      "Epoch 141/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4906 - accuracy: 0.7885 - val_loss: 0.4793 - val_accuracy: 0.8057\n",
      "Epoch 142/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4836 - accuracy: 0.7777 - val_loss: 0.4914 - val_accuracy: 0.8038\n",
      "Epoch 143/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4848 - accuracy: 0.7871 - val_loss: 0.4798 - val_accuracy: 0.8054\n",
      "Epoch 144/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4924 - accuracy: 0.7671 - val_loss: 0.6808 - val_accuracy: 0.3264\n",
      "Epoch 145/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4950 - accuracy: 0.7420 - val_loss: 0.4616 - val_accuracy: 0.7870\n",
      "Epoch 146/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5017 - accuracy: 0.7467 - val_loss: 0.6198 - val_accuracy: 0.7164\n",
      "Epoch 147/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5225 - accuracy: 0.7500 - val_loss: 0.4598 - val_accuracy: 0.7990\n",
      "Epoch 148/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4823 - accuracy: 0.7754 - val_loss: 0.4877 - val_accuracy: 0.8049\n",
      "Epoch 149/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4866 - accuracy: 0.7413 - val_loss: 0.4732 - val_accuracy: 0.7158\n",
      "Epoch 150/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4895 - accuracy: 0.7548 - val_loss: 0.4610 - val_accuracy: 0.8030\n",
      "Epoch 151/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4921 - accuracy: 0.7622 - val_loss: 0.4628 - val_accuracy: 0.7164\n",
      "Epoch 152/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4888 - accuracy: 0.7585 - val_loss: 0.4702 - val_accuracy: 0.7164\n",
      "Epoch 153/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5007 - accuracy: 0.7376 - val_loss: 0.5306 - val_accuracy: 0.7867\n",
      "Epoch 154/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5110 - accuracy: 0.7290 - val_loss: 0.4690 - val_accuracy: 0.7164\n",
      "Epoch 155/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4928 - accuracy: 0.7403 - val_loss: 0.4954 - val_accuracy: 0.7994\n",
      "Epoch 156/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4936 - accuracy: 0.7736 - val_loss: 0.4835 - val_accuracy: 0.7000\n",
      "Epoch 157/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4964 - accuracy: 0.7428 - val_loss: 0.4757 - val_accuracy: 0.8063\n",
      "Epoch 158/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4950 - accuracy: 0.7417 - val_loss: 0.5011 - val_accuracy: 0.6522\n",
      "Epoch 159/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4837 - accuracy: 0.7620 - val_loss: 0.4921 - val_accuracy: 0.8046\n",
      "Epoch 160/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4816 - accuracy: 0.7634 - val_loss: 0.5442 - val_accuracy: 0.5584\n",
      "Epoch 161/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4861 - accuracy: 0.7621 - val_loss: 0.4831 - val_accuracy: 0.7057\n",
      "Epoch 162/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4893 - accuracy: 0.7538 - val_loss: 0.5260 - val_accuracy: 0.7164\n",
      "Epoch 163/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4824 - accuracy: 0.7747 - val_loss: 0.4989 - val_accuracy: 0.7983\n",
      "Epoch 164/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4970 - accuracy: 0.7712 - val_loss: 0.4589 - val_accuracy: 0.7833\n",
      "Epoch 165/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4858 - accuracy: 0.7571 - val_loss: 0.4558 - val_accuracy: 0.7908\n",
      "Epoch 166/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4751 - accuracy: 0.7769 - val_loss: 0.4983 - val_accuracy: 0.8019\n",
      "Epoch 167/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4848 - accuracy: 0.7618 - val_loss: 0.4563 - val_accuracy: 0.7938\n",
      "Epoch 168/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4913 - accuracy: 0.7599 - val_loss: 0.4731 - val_accuracy: 0.8063\n",
      "Epoch 169/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5047 - accuracy: 0.7273 - val_loss: 0.4915 - val_accuracy: 0.7164\n",
      "Epoch 170/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4792 - accuracy: 0.7615 - val_loss: 0.4568 - val_accuracy: 0.7933\n",
      "Epoch 171/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4796 - accuracy: 0.7716 - val_loss: 0.4551 - val_accuracy: 0.7957\n",
      "Epoch 172/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4863 - accuracy: 0.7606 - val_loss: 0.4880 - val_accuracy: 0.8013\n",
      "Epoch 173/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4729 - accuracy: 0.7894 - val_loss: 0.4633 - val_accuracy: 0.8053\n",
      "Epoch 174/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4772 - accuracy: 0.7714 - val_loss: 0.4861 - val_accuracy: 0.8024\n",
      "Epoch 175/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4856 - accuracy: 0.7848 - val_loss: 0.4635 - val_accuracy: 0.8038\n",
      "Epoch 176/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4777 - accuracy: 0.7919 - val_loss: 0.4740 - val_accuracy: 0.8053\n",
      "Epoch 177/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4998 - accuracy: 0.7871 - val_loss: 0.4576 - val_accuracy: 0.7903\n",
      "Epoch 178/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4899 - accuracy: 0.7579 - val_loss: 0.4694 - val_accuracy: 0.7531\n",
      "Epoch 179/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5117 - accuracy: 0.7516 - val_loss: 0.5016 - val_accuracy: 0.7949\n",
      "Epoch 180/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4794 - accuracy: 0.7753 - val_loss: 0.4624 - val_accuracy: 0.8057\n",
      "Epoch 181/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4800 - accuracy: 0.7673 - val_loss: 0.5010 - val_accuracy: 0.6438\n",
      "Epoch 182/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4771 - accuracy: 0.7595 - val_loss: 0.5130 - val_accuracy: 0.7997\n",
      "Epoch 183/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4863 - accuracy: 0.7794 - val_loss: 0.4640 - val_accuracy: 0.8047\n",
      "Epoch 184/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4775 - accuracy: 0.7703 - val_loss: 0.4668 - val_accuracy: 0.8065\n",
      "Epoch 185/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4862 - accuracy: 0.7936 - val_loss: 0.4754 - val_accuracy: 0.7596\n",
      "Epoch 186/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4772 - accuracy: 0.7955 - val_loss: 0.4787 - val_accuracy: 0.8044\n",
      "Epoch 187/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4741 - accuracy: 0.7862 - val_loss: 0.4683 - val_accuracy: 0.8060\n",
      "Epoch 188/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4838 - accuracy: 0.7595 - val_loss: 0.4668 - val_accuracy: 0.8062\n",
      "Epoch 189/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4760 - accuracy: 0.7893 - val_loss: 0.4609 - val_accuracy: 0.7648\n",
      "Epoch 190/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5128 - accuracy: 0.7487 - val_loss: 0.5933 - val_accuracy: 0.7165\n",
      "Epoch 191/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5556 - accuracy: 0.7249 - val_loss: 0.4570 - val_accuracy: 0.7975\n",
      "Epoch 192/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4946 - accuracy: 0.7424 - val_loss: 0.4571 - val_accuracy: 0.8011\n",
      "Epoch 193/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4800 - accuracy: 0.7853 - val_loss: 0.4703 - val_accuracy: 0.8068\n",
      "Epoch 194/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4796 - accuracy: 0.7755 - val_loss: 0.5231 - val_accuracy: 0.7887\n",
      "Epoch 195/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4758 - accuracy: 0.7899 - val_loss: 0.4683 - val_accuracy: 0.7577\n",
      "Epoch 196/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4747 - accuracy: 0.7829 - val_loss: 0.4555 - val_accuracy: 0.7974\n",
      "Epoch 197/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4983 - accuracy: 0.7471 - val_loss: 0.4552 - val_accuracy: 0.7978\n",
      "Epoch 198/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5217 - accuracy: 0.7337 - val_loss: 0.5152 - val_accuracy: 0.7165\n",
      "Epoch 199/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4861 - accuracy: 0.7823 - val_loss: 0.4806 - val_accuracy: 0.8055\n",
      "Epoch 200/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4822 - accuracy: 0.7828 - val_loss: 0.4552 - val_accuracy: 0.7991\n",
      "Epoch 201/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4709 - accuracy: 0.7941 - val_loss: 0.4562 - val_accuracy: 0.7990\n",
      "Epoch 202/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4810 - accuracy: 0.7792 - val_loss: 0.4822 - val_accuracy: 0.8041\n",
      "Epoch 203/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4730 - accuracy: 0.7919 - val_loss: 0.5101 - val_accuracy: 0.6749\n",
      "Epoch 204/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5047 - accuracy: 0.7200 - val_loss: 0.4790 - val_accuracy: 0.8069\n",
      "Epoch 205/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5048 - accuracy: 0.7698 - val_loss: 0.4943 - val_accuracy: 0.8050\n",
      "Epoch 206/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4844 - accuracy: 0.7738 - val_loss: 0.5497 - val_accuracy: 0.6409\n",
      "Epoch 207/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4917 - accuracy: 0.7631 - val_loss: 0.4917 - val_accuracy: 0.8007\n",
      "Epoch 208/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4757 - accuracy: 0.7941 - val_loss: 0.4585 - val_accuracy: 0.8048\n",
      "Epoch 209/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4768 - accuracy: 0.7692 - val_loss: 0.4868 - val_accuracy: 0.8025\n",
      "Epoch 210/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4792 - accuracy: 0.7928 - val_loss: 0.4632 - val_accuracy: 0.7725\n",
      "Epoch 211/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4728 - accuracy: 0.7790 - val_loss: 0.4586 - val_accuracy: 0.7611\n",
      "Epoch 212/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4927 - accuracy: 0.7956 - val_loss: 0.4608 - val_accuracy: 0.7963\n",
      "Epoch 213/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4731 - accuracy: 0.7795 - val_loss: 0.4525 - val_accuracy: 0.7907\n",
      "Epoch 214/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5024 - accuracy: 0.7358 - val_loss: 0.4693 - val_accuracy: 0.8083\n",
      "Epoch 215/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4900 - accuracy: 0.7782 - val_loss: 0.4570 - val_accuracy: 0.8025\n",
      "Epoch 216/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4726 - accuracy: 0.7737 - val_loss: 0.4888 - val_accuracy: 0.8055\n",
      "Epoch 217/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4743 - accuracy: 0.7972 - val_loss: 0.4562 - val_accuracy: 0.8034\n",
      "Epoch 218/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4759 - accuracy: 0.7828 - val_loss: 0.4677 - val_accuracy: 0.8075\n",
      "Epoch 219/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4801 - accuracy: 0.7942 - val_loss: 0.4766 - val_accuracy: 0.8052\n",
      "Epoch 220/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4767 - accuracy: 0.7946 - val_loss: 0.4599 - val_accuracy: 0.8056\n",
      "Epoch 221/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4810 - accuracy: 0.7616 - val_loss: 0.4564 - val_accuracy: 0.7670\n",
      "Epoch 222/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4803 - accuracy: 0.7661 - val_loss: 0.4549 - val_accuracy: 0.7794\n",
      "Epoch 223/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4788 - accuracy: 0.7891 - val_loss: 0.4744 - val_accuracy: 0.8053\n",
      "Epoch 224/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4765 - accuracy: 0.7806 - val_loss: 0.4568 - val_accuracy: 0.7888\n",
      "Epoch 225/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4683 - accuracy: 0.7917 - val_loss: 0.4705 - val_accuracy: 0.8067\n",
      "Epoch 226/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4774 - accuracy: 0.7858 - val_loss: 0.4820 - val_accuracy: 0.8040\n",
      "Epoch 227/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4740 - accuracy: 0.7763 - val_loss: 0.4573 - val_accuracy: 0.7977\n",
      "Epoch 228/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4810 - accuracy: 0.7980 - val_loss: 0.4727 - val_accuracy: 0.8063\n",
      "Epoch 229/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4706 - accuracy: 0.7837 - val_loss: 0.4777 - val_accuracy: 0.8056\n",
      "Epoch 230/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4817 - accuracy: 0.7937 - val_loss: 0.4937 - val_accuracy: 0.7992\n",
      "Epoch 231/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4779 - accuracy: 0.7861 - val_loss: 0.4554 - val_accuracy: 0.8055\n",
      "Epoch 232/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4994 - accuracy: 0.7453 - val_loss: 0.6201 - val_accuracy: 0.7164\n",
      "Epoch 233/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5832 - accuracy: 0.7156 - val_loss: 0.4934 - val_accuracy: 0.7164\n",
      "Epoch 234/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4796 - accuracy: 0.7849 - val_loss: 0.5340 - val_accuracy: 0.7763\n",
      "Epoch 235/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4900 - accuracy: 0.7542 - val_loss: 0.4800 - val_accuracy: 0.7005\n",
      "Epoch 236/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4740 - accuracy: 0.7854 - val_loss: 0.8036 - val_accuracy: 0.3006\n",
      "Epoch 237/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.6009 - accuracy: 0.7021 - val_loss: 0.5918 - val_accuracy: 0.7165\n",
      "Epoch 238/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4884 - accuracy: 0.7330 - val_loss: 0.4768 - val_accuracy: 0.8071\n",
      "Epoch 239/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4701 - accuracy: 0.7818 - val_loss: 0.4741 - val_accuracy: 0.8068\n",
      "Epoch 240/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4699 - accuracy: 0.7951 - val_loss: 0.4569 - val_accuracy: 0.8018\n",
      "Epoch 241/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4737 - accuracy: 0.7842 - val_loss: 0.4666 - val_accuracy: 0.8077\n",
      "Epoch 242/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4754 - accuracy: 0.7914 - val_loss: 0.4575 - val_accuracy: 0.8066\n",
      "Epoch 243/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4816 - accuracy: 0.7900 - val_loss: 0.5006 - val_accuracy: 0.7958\n",
      "Epoch 244/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5014 - accuracy: 0.7448 - val_loss: 0.4529 - val_accuracy: 0.7912\n",
      "Epoch 245/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4767 - accuracy: 0.7899 - val_loss: 0.4765 - val_accuracy: 0.8060\n",
      "Epoch 246/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4777 - accuracy: 0.7948 - val_loss: 0.4655 - val_accuracy: 0.8085\n",
      "Epoch 247/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4785 - accuracy: 0.7678 - val_loss: 0.4654 - val_accuracy: 0.8084\n",
      "Epoch 248/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4733 - accuracy: 0.7767 - val_loss: 0.4568 - val_accuracy: 0.8070\n",
      "Epoch 249/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4917 - accuracy: 0.7936 - val_loss: 0.5361 - val_accuracy: 0.7735\n",
      "Epoch 250/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5220 - accuracy: 0.7724 - val_loss: 0.5721 - val_accuracy: 0.7412\n",
      "Epoch 251/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5504 - accuracy: 0.7586 - val_loss: 0.4987 - val_accuracy: 0.7969\n",
      "Epoch 252/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4725 - accuracy: 0.7860 - val_loss: 0.4679 - val_accuracy: 0.8079\n",
      "Epoch 253/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4745 - accuracy: 0.7656 - val_loss: 0.4792 - val_accuracy: 0.8061\n",
      "Epoch 254/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4945 - accuracy: 0.7408 - val_loss: 0.4766 - val_accuracy: 0.8067\n",
      "Epoch 255/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4693 - accuracy: 0.7881 - val_loss: 0.4690 - val_accuracy: 0.8074\n",
      "Epoch 256/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4731 - accuracy: 0.7947 - val_loss: 0.4552 - val_accuracy: 0.8035\n",
      "Epoch 257/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4768 - accuracy: 0.7722 - val_loss: 0.4529 - val_accuracy: 0.7892\n",
      "Epoch 258/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4782 - accuracy: 0.7709 - val_loss: 0.4675 - val_accuracy: 0.8080\n",
      "Epoch 259/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4735 - accuracy: 0.7838 - val_loss: 0.4827 - val_accuracy: 0.8063\n",
      "Epoch 260/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4779 - accuracy: 0.7994 - val_loss: 0.5043 - val_accuracy: 0.7971\n",
      "Epoch 261/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4833 - accuracy: 0.7976 - val_loss: 0.4602 - val_accuracy: 0.8086\n",
      "Epoch 262/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4722 - accuracy: 0.7928 - val_loss: 0.4522 - val_accuracy: 0.7845\n",
      "Epoch 263/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4724 - accuracy: 0.7727 - val_loss: 0.4897 - val_accuracy: 0.8017\n",
      "Epoch 264/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4758 - accuracy: 0.7715 - val_loss: 0.5043 - val_accuracy: 0.6345\n",
      "Epoch 265/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4801 - accuracy: 0.7858 - val_loss: 0.4575 - val_accuracy: 0.7933\n",
      "Epoch 266/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4725 - accuracy: 0.7908 - val_loss: 0.5000 - val_accuracy: 0.7980\n",
      "Epoch 267/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4815 - accuracy: 0.7762 - val_loss: 0.4569 - val_accuracy: 0.8026\n",
      "Epoch 268/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5161 - accuracy: 0.7214 - val_loss: 0.4859 - val_accuracy: 0.7164\n",
      "Epoch 269/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4694 - accuracy: 0.7671 - val_loss: 0.6591 - val_accuracy: 0.4533\n",
      "Epoch 270/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4750 - accuracy: 0.7599 - val_loss: 0.4637 - val_accuracy: 0.8070\n",
      "Epoch 271/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4823 - accuracy: 0.7552 - val_loss: 0.4545 - val_accuracy: 0.7972\n",
      "Epoch 272/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4701 - accuracy: 0.7790 - val_loss: 0.4547 - val_accuracy: 0.7754\n",
      "Epoch 273/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4805 - accuracy: 0.7359 - val_loss: 0.4765 - val_accuracy: 0.8062\n",
      "Epoch 274/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4785 - accuracy: 0.7594 - val_loss: 0.4937 - val_accuracy: 0.8014\n",
      "Epoch 275/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5023 - accuracy: 0.7443 - val_loss: 0.4763 - val_accuracy: 0.8048\n",
      "Epoch 276/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4705 - accuracy: 0.7659 - val_loss: 0.4852 - val_accuracy: 0.8047\n",
      "Epoch 277/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4774 - accuracy: 0.7589 - val_loss: 0.4602 - val_accuracy: 0.8067\n",
      "Epoch 278/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4669 - accuracy: 0.7720 - val_loss: 0.4558 - val_accuracy: 0.7731\n",
      "Epoch 279/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4697 - accuracy: 0.7735 - val_loss: 0.4611 - val_accuracy: 0.8065\n",
      "Epoch 280/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4765 - accuracy: 0.7925 - val_loss: 0.5838 - val_accuracy: 0.5663\n",
      "Epoch 281/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4739 - accuracy: 0.7776 - val_loss: 0.4589 - val_accuracy: 0.7553\n",
      "Epoch 282/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4710 - accuracy: 0.7770 - val_loss: 0.4628 - val_accuracy: 0.7566\n",
      "Epoch 283/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4784 - accuracy: 0.7565 - val_loss: 0.4865 - val_accuracy: 0.6723\n",
      "Epoch 284/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4835 - accuracy: 0.7357 - val_loss: 0.4601 - val_accuracy: 0.7923\n",
      "Epoch 285/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4789 - accuracy: 0.7643 - val_loss: 0.4665 - val_accuracy: 0.7988\n",
      "Epoch 286/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4945 - accuracy: 0.7749 - val_loss: 0.5654 - val_accuracy: 0.7164\n",
      "Epoch 287/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4778 - accuracy: 0.7795 - val_loss: 0.4597 - val_accuracy: 0.8058\n",
      "Epoch 288/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4861 - accuracy: 0.7275 - val_loss: 0.4698 - val_accuracy: 0.7164\n",
      "Epoch 289/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4739 - accuracy: 0.7567 - val_loss: 0.4696 - val_accuracy: 0.8062\n",
      "Epoch 290/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4712 - accuracy: 0.7889 - val_loss: 0.4561 - val_accuracy: 0.7933\n",
      "Epoch 291/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5204 - accuracy: 0.7312 - val_loss: 0.4854 - val_accuracy: 0.7164\n",
      "Epoch 292/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4740 - accuracy: 0.7779 - val_loss: 0.4601 - val_accuracy: 0.7533\n",
      "Epoch 293/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4762 - accuracy: 0.7741 - val_loss: 0.4935 - val_accuracy: 0.8006\n",
      "Epoch 294/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4673 - accuracy: 0.7858 - val_loss: 0.4732 - val_accuracy: 0.8056\n",
      "Epoch 295/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4898 - accuracy: 0.7433 - val_loss: 0.4577 - val_accuracy: 0.7780\n",
      "Epoch 296/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4829 - accuracy: 0.7631 - val_loss: 0.4806 - val_accuracy: 0.8045\n",
      "Epoch 297/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4740 - accuracy: 0.7704 - val_loss: 0.4554 - val_accuracy: 0.8003\n",
      "Epoch 298/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4749 - accuracy: 0.7908 - val_loss: 0.4674 - val_accuracy: 0.8065\n",
      "Epoch 299/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4719 - accuracy: 0.7928 - val_loss: 0.4892 - val_accuracy: 0.8009\n",
      "Epoch 300/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4900 - accuracy: 0.7941 - val_loss: 0.4792 - val_accuracy: 0.7381\n",
      "Epoch 301/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4798 - accuracy: 0.7720 - val_loss: 0.4556 - val_accuracy: 0.7887\n",
      "Epoch 302/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4673 - accuracy: 0.7883 - val_loss: 0.4681 - val_accuracy: 0.8069\n",
      "Epoch 303/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5057 - accuracy: 0.7394 - val_loss: 0.4611 - val_accuracy: 0.8073\n",
      "Epoch 304/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4758 - accuracy: 0.7953 - val_loss: 0.4774 - val_accuracy: 0.8054\n",
      "Epoch 305/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5265 - accuracy: 0.7328 - val_loss: 0.5894 - val_accuracy: 0.7165\n",
      "Epoch 306/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5536 - accuracy: 0.7156 - val_loss: 0.6401 - val_accuracy: 0.7164\n",
      "Epoch 307/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4745 - accuracy: 0.7717 - val_loss: 0.4617 - val_accuracy: 0.8074\n",
      "Epoch 308/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4740 - accuracy: 0.7936 - val_loss: 0.4766 - val_accuracy: 0.8062\n",
      "Epoch 309/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4761 - accuracy: 0.7910 - val_loss: 0.4539 - val_accuracy: 0.7910\n",
      "Epoch 310/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5163 - accuracy: 0.7313 - val_loss: 0.4709 - val_accuracy: 0.7164\n",
      "Epoch 311/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4718 - accuracy: 0.7852 - val_loss: 0.4544 - val_accuracy: 0.7746\n",
      "Epoch 312/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4843 - accuracy: 0.7736 - val_loss: 0.6003 - val_accuracy: 0.7164\n",
      "Epoch 313/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5516 - accuracy: 0.7251 - val_loss: 0.4586 - val_accuracy: 0.8048\n",
      "Epoch 314/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4817 - accuracy: 0.7455 - val_loss: 0.4523 - val_accuracy: 0.7980\n",
      "Epoch 315/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4702 - accuracy: 0.7751 - val_loss: 0.4639 - val_accuracy: 0.7511\n",
      "Epoch 316/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4752 - accuracy: 0.7732 - val_loss: 0.4844 - val_accuracy: 0.6904\n",
      "Epoch 317/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4749 - accuracy: 0.7629 - val_loss: 0.4536 - val_accuracy: 0.7801\n",
      "Epoch 318/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4686 - accuracy: 0.7805 - val_loss: 0.4714 - val_accuracy: 0.8082\n",
      "Epoch 319/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4677 - accuracy: 0.7885 - val_loss: 0.4875 - val_accuracy: 0.8035\n",
      "Epoch 320/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4743 - accuracy: 0.7925 - val_loss: 0.4609 - val_accuracy: 0.8075\n",
      "Epoch 321/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4779 - accuracy: 0.7634 - val_loss: 0.4769 - val_accuracy: 0.8074\n",
      "Epoch 322/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4820 - accuracy: 0.7996 - val_loss: 0.4668 - val_accuracy: 0.8080\n",
      "Epoch 323/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4655 - accuracy: 0.7922 - val_loss: 0.4515 - val_accuracy: 0.7891\n",
      "Epoch 324/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4756 - accuracy: 0.7992 - val_loss: 0.4516 - val_accuracy: 0.7916\n",
      "Epoch 325/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4839 - accuracy: 0.7834 - val_loss: 0.4574 - val_accuracy: 0.8059\n",
      "Epoch 326/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4723 - accuracy: 0.7656 - val_loss: 0.4538 - val_accuracy: 0.7785\n",
      "Epoch 327/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4720 - accuracy: 0.8027 - val_loss: 0.4847 - val_accuracy: 0.8041\n",
      "Epoch 328/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4804 - accuracy: 0.7698 - val_loss: 0.4653 - val_accuracy: 0.8088\n",
      "Epoch 329/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4655 - accuracy: 0.7930 - val_loss: 0.4515 - val_accuracy: 0.8024\n",
      "Epoch 330/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4707 - accuracy: 0.7869 - val_loss: 0.4505 - val_accuracy: 0.7952\n",
      "Epoch 331/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4685 - accuracy: 0.7792 - val_loss: 0.4589 - val_accuracy: 0.7606\n",
      "Epoch 332/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4703 - accuracy: 0.7937 - val_loss: 0.5822 - val_accuracy: 0.5449\n",
      "Epoch 333/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4722 - accuracy: 0.7635 - val_loss: 0.4511 - val_accuracy: 0.7994\n",
      "Epoch 334/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4811 - accuracy: 0.7909 - val_loss: 0.4639 - val_accuracy: 0.8079\n",
      "Epoch 335/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4839 - accuracy: 0.7644 - val_loss: 0.4728 - val_accuracy: 0.8084\n",
      "Epoch 336/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4741 - accuracy: 0.7895 - val_loss: 0.4554 - val_accuracy: 0.8087\n",
      "Epoch 337/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5101 - accuracy: 0.7445 - val_loss: 0.5079 - val_accuracy: 0.7165\n",
      "Epoch 338/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4761 - accuracy: 0.7709 - val_loss: 0.4796 - val_accuracy: 0.8062\n",
      "Epoch 339/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4744 - accuracy: 0.8009 - val_loss: 0.4738 - val_accuracy: 0.7612\n",
      "Epoch 340/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4780 - accuracy: 0.7714 - val_loss: 0.4688 - val_accuracy: 0.8093\n",
      "Epoch 341/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4726 - accuracy: 0.7899 - val_loss: 0.4503 - val_accuracy: 0.7975\n",
      "Epoch 342/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4683 - accuracy: 0.7900 - val_loss: 0.4695 - val_accuracy: 0.8092\n",
      "Epoch 343/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4699 - accuracy: 0.7905 - val_loss: 0.4594 - val_accuracy: 0.7591\n",
      "Epoch 344/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4667 - accuracy: 0.7900 - val_loss: 0.4532 - val_accuracy: 0.8064\n",
      "Epoch 345/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4879 - accuracy: 0.7543 - val_loss: 0.4539 - val_accuracy: 0.8087\n",
      "Epoch 346/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4646 - accuracy: 0.7983 - val_loss: 0.4756 - val_accuracy: 0.8077\n",
      "Epoch 347/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4744 - accuracy: 0.7686 - val_loss: 0.4648 - val_accuracy: 0.7360\n",
      "Epoch 348/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4984 - accuracy: 0.7192 - val_loss: 0.4624 - val_accuracy: 0.8028\n",
      "Epoch 349/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4781 - accuracy: 0.7634 - val_loss: 0.4559 - val_accuracy: 0.8070\n",
      "Epoch 350/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4659 - accuracy: 0.7906 - val_loss: 0.4620 - val_accuracy: 0.8087\n",
      "Epoch 351/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4730 - accuracy: 0.7687 - val_loss: 0.4832 - val_accuracy: 0.6951\n",
      "Epoch 352/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4782 - accuracy: 0.7920 - val_loss: 0.4686 - val_accuracy: 0.8084\n",
      "Epoch 353/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4716 - accuracy: 0.8005 - val_loss: 0.4595 - val_accuracy: 0.7984\n",
      "Epoch 354/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4728 - accuracy: 0.7928 - val_loss: 0.4898 - val_accuracy: 0.8021\n",
      "Epoch 355/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4769 - accuracy: 0.7990 - val_loss: 0.4840 - val_accuracy: 0.8043\n",
      "Epoch 356/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4684 - accuracy: 0.7936 - val_loss: 0.6961 - val_accuracy: 0.3812\n",
      "Epoch 357/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4705 - accuracy: 0.7776 - val_loss: 0.4585 - val_accuracy: 0.8094\n",
      "Epoch 358/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4948 - accuracy: 0.7597 - val_loss: 0.4761 - val_accuracy: 0.8074\n",
      "Epoch 359/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4661 - accuracy: 0.7970 - val_loss: 0.4768 - val_accuracy: 0.8076\n",
      "Epoch 360/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4642 - accuracy: 0.7816 - val_loss: 0.4516 - val_accuracy: 0.7864\n",
      "Epoch 361/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4700 - accuracy: 0.7839 - val_loss: 0.4687 - val_accuracy: 0.8096\n",
      "Epoch 362/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4713 - accuracy: 0.7792 - val_loss: 0.4503 - val_accuracy: 0.7996\n",
      "Epoch 363/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4668 - accuracy: 0.7971 - val_loss: 0.4800 - val_accuracy: 0.8075\n",
      "Epoch 364/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4713 - accuracy: 0.7943 - val_loss: 0.4598 - val_accuracy: 0.7924\n",
      "Epoch 365/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4662 - accuracy: 0.7817 - val_loss: 0.4663 - val_accuracy: 0.7295\n",
      "Epoch 366/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5194 - accuracy: 0.7407 - val_loss: 0.4739 - val_accuracy: 0.7164\n",
      "Epoch 367/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4708 - accuracy: 0.7645 - val_loss: 0.4519 - val_accuracy: 0.7880\n",
      "Epoch 368/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4731 - accuracy: 0.7972 - val_loss: 0.4507 - val_accuracy: 0.8017\n",
      "Epoch 369/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4760 - accuracy: 0.7936 - val_loss: 0.4614 - val_accuracy: 0.8103\n",
      "Epoch 370/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4786 - accuracy: 0.7819 - val_loss: 0.4675 - val_accuracy: 0.7403\n",
      "Epoch 371/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4766 - accuracy: 0.7574 - val_loss: 0.4510 - val_accuracy: 0.7905\n",
      "Epoch 372/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4682 - accuracy: 0.7917 - val_loss: 0.4521 - val_accuracy: 0.8032\n",
      "Epoch 373/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4801 - accuracy: 0.7572 - val_loss: 0.4613 - val_accuracy: 0.7527\n",
      "Epoch 374/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4687 - accuracy: 0.7844 - val_loss: 0.4507 - val_accuracy: 0.7969\n",
      "Epoch 375/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4804 - accuracy: 0.7708 - val_loss: 0.4617 - val_accuracy: 0.7164\n",
      "Epoch 376/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4700 - accuracy: 0.7658 - val_loss: 0.4602 - val_accuracy: 0.8103\n",
      "Epoch 377/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4700 - accuracy: 0.8025 - val_loss: 0.4827 - val_accuracy: 0.8056\n",
      "Epoch 378/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4755 - accuracy: 0.7900 - val_loss: 0.4636 - val_accuracy: 0.8105\n",
      "Epoch 379/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4759 - accuracy: 0.7756 - val_loss: 0.4797 - val_accuracy: 0.8065\n",
      "Epoch 380/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4684 - accuracy: 0.7962 - val_loss: 0.4606 - val_accuracy: 0.8101\n",
      "Epoch 381/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4821 - accuracy: 0.7439 - val_loss: 0.4575 - val_accuracy: 0.7165\n",
      "Epoch 382/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4708 - accuracy: 0.7918 - val_loss: 0.4850 - val_accuracy: 0.8039\n",
      "Epoch 383/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4733 - accuracy: 0.7761 - val_loss: 0.4540 - val_accuracy: 0.7780\n",
      "Epoch 384/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4730 - accuracy: 0.7690 - val_loss: 0.4528 - val_accuracy: 0.8039\n",
      "Epoch 385/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4672 - accuracy: 0.7695 - val_loss: 0.4509 - val_accuracy: 0.7897\n",
      "Epoch 386/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4707 - accuracy: 0.7915 - val_loss: 0.4786 - val_accuracy: 0.8065\n",
      "Epoch 387/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4821 - accuracy: 0.7865 - val_loss: 0.4604 - val_accuracy: 0.7473\n",
      "Epoch 388/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4671 - accuracy: 0.7881 - val_loss: 0.4500 - val_accuracy: 0.7915\n",
      "Epoch 389/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4730 - accuracy: 0.7656 - val_loss: 0.4707 - val_accuracy: 0.8089\n",
      "Epoch 390/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4732 - accuracy: 0.7849 - val_loss: 0.4619 - val_accuracy: 0.8103\n",
      "Epoch 391/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4878 - accuracy: 0.7864 - val_loss: 0.4685 - val_accuracy: 0.8091\n",
      "Epoch 392/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4800 - accuracy: 0.8043 - val_loss: 0.4903 - val_accuracy: 0.8021\n",
      "Epoch 393/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4704 - accuracy: 0.7932 - val_loss: 0.4773 - val_accuracy: 0.8077\n",
      "Epoch 394/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4644 - accuracy: 0.7892 - val_loss: 0.4778 - val_accuracy: 0.8073\n",
      "Epoch 395/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4728 - accuracy: 0.8019 - val_loss: 0.4588 - val_accuracy: 0.8107\n",
      "Epoch 396/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4755 - accuracy: 0.8012 - val_loss: 0.4943 - val_accuracy: 0.8009\n",
      "Epoch 397/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4701 - accuracy: 0.8022 - val_loss: 0.4547 - val_accuracy: 0.8104\n",
      "Epoch 398/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4678 - accuracy: 0.7894 - val_loss: 0.4669 - val_accuracy: 0.8107\n",
      "Epoch 399/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4758 - accuracy: 0.7695 - val_loss: 0.4566 - val_accuracy: 0.8079\n",
      "Epoch 400/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4695 - accuracy: 0.7961 - val_loss: 0.4660 - val_accuracy: 0.8102\n",
      "Epoch 401/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4660 - accuracy: 0.7965 - val_loss: 0.4923 - val_accuracy: 0.7110\n",
      "Epoch 402/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4821 - accuracy: 0.7872 - val_loss: 0.5453 - val_accuracy: 0.7694\n",
      "Epoch 403/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4961 - accuracy: 0.7953 - val_loss: 0.4786 - val_accuracy: 0.7780\n",
      "Epoch 404/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4787 - accuracy: 0.7674 - val_loss: 0.4736 - val_accuracy: 0.8113\n",
      "Epoch 405/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4820 - accuracy: 0.7563 - val_loss: 0.5654 - val_accuracy: 0.7163\n",
      "Epoch 406/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4729 - accuracy: 0.7855 - val_loss: 0.4601 - val_accuracy: 0.8107\n",
      "Epoch 407/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4664 - accuracy: 0.7888 - val_loss: 0.4503 - val_accuracy: 0.7973\n",
      "Epoch 408/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4734 - accuracy: 0.7677 - val_loss: 0.4532 - val_accuracy: 0.8039\n",
      "Epoch 409/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4673 - accuracy: 0.7910 - val_loss: 0.4593 - val_accuracy: 0.8107\n",
      "Epoch 410/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4661 - accuracy: 0.7976 - val_loss: 0.4541 - val_accuracy: 0.7965\n",
      "Epoch 411/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4679 - accuracy: 0.7754 - val_loss: 0.4518 - val_accuracy: 0.7988\n",
      "Epoch 412/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4630 - accuracy: 0.7907 - val_loss: 0.4515 - val_accuracy: 0.8069\n",
      "Epoch 413/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4711 - accuracy: 0.7954 - val_loss: 0.4503 - val_accuracy: 0.7885\n",
      "Epoch 414/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4655 - accuracy: 0.7960 - val_loss: 0.5683 - val_accuracy: 0.5951\n",
      "Epoch 415/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4723 - accuracy: 0.7950 - val_loss: 0.4770 - val_accuracy: 0.8073\n",
      "Epoch 416/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4790 - accuracy: 0.7609 - val_loss: 0.4510 - val_accuracy: 0.7975\n",
      "Epoch 417/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4754 - accuracy: 0.7574 - val_loss: 0.4640 - val_accuracy: 0.7164\n",
      "Epoch 418/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4751 - accuracy: 0.7493 - val_loss: 0.4506 - val_accuracy: 0.7970\n",
      "Epoch 419/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4666 - accuracy: 0.7915 - val_loss: 0.4533 - val_accuracy: 0.8089\n",
      "Epoch 420/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4713 - accuracy: 0.7709 - val_loss: 0.4514 - val_accuracy: 0.8051\n",
      "Epoch 421/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4675 - accuracy: 0.7903 - val_loss: 0.5265 - val_accuracy: 0.6127\n",
      "Epoch 422/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4745 - accuracy: 0.7866 - val_loss: 0.4534 - val_accuracy: 0.8089\n",
      "Epoch 423/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4676 - accuracy: 0.7950 - val_loss: 0.4513 - val_accuracy: 0.7904\n",
      "Epoch 424/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4791 - accuracy: 0.7901 - val_loss: 0.4495 - val_accuracy: 0.8019\n",
      "Epoch 425/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4701 - accuracy: 0.7817 - val_loss: 0.4567 - val_accuracy: 0.7577\n",
      "Epoch 426/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4714 - accuracy: 0.7682 - val_loss: 0.4609 - val_accuracy: 0.7491\n",
      "Epoch 427/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4679 - accuracy: 0.7967 - val_loss: 0.4559 - val_accuracy: 0.7870\n",
      "Epoch 428/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4649 - accuracy: 0.7769 - val_loss: 0.4589 - val_accuracy: 0.8108\n",
      "Epoch 429/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4722 - accuracy: 0.8008 - val_loss: 0.4839 - val_accuracy: 0.8054\n",
      "Epoch 430/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4691 - accuracy: 0.8026 - val_loss: 0.4549 - val_accuracy: 0.8100\n",
      "Epoch 431/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4712 - accuracy: 0.8028 - val_loss: 0.4540 - val_accuracy: 0.8071\n",
      "Epoch 432/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4693 - accuracy: 0.7833 - val_loss: 0.4573 - val_accuracy: 0.8021\n",
      "Epoch 433/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4629 - accuracy: 0.7856 - val_loss: 0.4551 - val_accuracy: 0.7664\n",
      "Epoch 434/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4639 - accuracy: 0.7777 - val_loss: 0.5170 - val_accuracy: 0.6484\n",
      "Epoch 435/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4774 - accuracy: 0.7351 - val_loss: 0.5076 - val_accuracy: 0.6369\n",
      "Epoch 436/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4734 - accuracy: 0.7966 - val_loss: 0.4648 - val_accuracy: 0.7615\n",
      "Epoch 437/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4676 - accuracy: 0.7831 - val_loss: 0.4622 - val_accuracy: 0.8107\n",
      "Epoch 438/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4676 - accuracy: 0.7914 - val_loss: 0.4564 - val_accuracy: 0.8098\n",
      "Epoch 439/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4715 - accuracy: 0.7907 - val_loss: 0.4687 - val_accuracy: 0.8094\n",
      "Epoch 440/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4645 - accuracy: 0.7969 - val_loss: 0.4517 - val_accuracy: 0.7936\n",
      "Epoch 441/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4652 - accuracy: 0.8034 - val_loss: 0.4791 - val_accuracy: 0.8070\n",
      "Epoch 442/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4759 - accuracy: 0.7795 - val_loss: 0.4698 - val_accuracy: 0.7164\n",
      "Epoch 443/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4654 - accuracy: 0.7926 - val_loss: 0.6628 - val_accuracy: 0.3946\n",
      "Epoch 444/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4707 - accuracy: 0.7882 - val_loss: 0.4753 - val_accuracy: 0.8077\n",
      "Epoch 445/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4652 - accuracy: 0.7847 - val_loss: 0.4939 - val_accuracy: 0.8036\n",
      "Epoch 446/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4693 - accuracy: 0.7942 - val_loss: 0.4526 - val_accuracy: 0.7749\n",
      "Epoch 447/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4696 - accuracy: 0.8020 - val_loss: 0.4647 - val_accuracy: 0.8101\n",
      "Epoch 448/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4715 - accuracy: 0.7915 - val_loss: 0.5185 - val_accuracy: 0.7890\n",
      "Epoch 449/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4665 - accuracy: 0.7827 - val_loss: 0.4610 - val_accuracy: 0.8102\n",
      "Epoch 450/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4633 - accuracy: 0.7818 - val_loss: 0.4839 - val_accuracy: 0.8069\n",
      "Epoch 451/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4735 - accuracy: 0.7843 - val_loss: 0.4532 - val_accuracy: 0.8027\n",
      "Epoch 452/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4687 - accuracy: 0.7728 - val_loss: 0.4590 - val_accuracy: 0.7533\n",
      "Epoch 453/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4713 - accuracy: 0.7575 - val_loss: 0.4619 - val_accuracy: 0.8097\n",
      "Epoch 454/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4766 - accuracy: 0.7828 - val_loss: 0.4968 - val_accuracy: 0.7164\n",
      "Epoch 455/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4969 - accuracy: 0.7488 - val_loss: 0.4559 - val_accuracy: 0.7721\n",
      "Epoch 456/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4967 - accuracy: 0.7607 - val_loss: 0.4767 - val_accuracy: 0.8069\n",
      "Epoch 457/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4716 - accuracy: 0.7980 - val_loss: 0.4946 - val_accuracy: 0.8003\n",
      "Epoch 458/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4725 - accuracy: 0.7798 - val_loss: 0.4597 - val_accuracy: 0.7553\n",
      "Epoch 459/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4697 - accuracy: 0.7646 - val_loss: 0.4683 - val_accuracy: 0.8086\n",
      "Epoch 460/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4725 - accuracy: 0.8048 - val_loss: 0.4547 - val_accuracy: 0.8035\n",
      "Epoch 461/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4730 - accuracy: 0.7669 - val_loss: 0.4564 - val_accuracy: 0.8090\n",
      "Epoch 462/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4722 - accuracy: 0.8023 - val_loss: 0.4726 - val_accuracy: 0.8084\n",
      "Epoch 463/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4687 - accuracy: 0.8044 - val_loss: 0.4788 - val_accuracy: 0.8067\n",
      "Epoch 464/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4687 - accuracy: 0.7816 - val_loss: 0.4660 - val_accuracy: 0.8086\n",
      "Epoch 465/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4850 - accuracy: 0.7529 - val_loss: 0.4565 - val_accuracy: 0.7596\n",
      "Epoch 466/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4716 - accuracy: 0.7643 - val_loss: 0.4584 - val_accuracy: 0.7163\n",
      "Epoch 467/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4715 - accuracy: 0.7993 - val_loss: 0.4648 - val_accuracy: 0.7499\n",
      "Epoch 468/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4921 - accuracy: 0.7363 - val_loss: 0.4890 - val_accuracy: 0.7164\n",
      "Epoch 469/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4673 - accuracy: 0.7880 - val_loss: 0.4527 - val_accuracy: 0.8042\n",
      "Epoch 470/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4641 - accuracy: 0.7889 - val_loss: 0.4602 - val_accuracy: 0.7579\n",
      "Epoch 471/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4704 - accuracy: 0.7757 - val_loss: 0.4909 - val_accuracy: 0.8023\n",
      "Epoch 472/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4668 - accuracy: 0.7884 - val_loss: 0.4668 - val_accuracy: 0.8090\n",
      "Epoch 473/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4702 - accuracy: 0.7838 - val_loss: 0.4520 - val_accuracy: 0.8043\n",
      "Epoch 474/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4700 - accuracy: 0.7643 - val_loss: 0.4645 - val_accuracy: 0.7508\n",
      "Epoch 475/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4740 - accuracy: 0.7652 - val_loss: 0.4509 - val_accuracy: 0.8012\n",
      "Epoch 476/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4649 - accuracy: 0.7927 - val_loss: 0.4616 - val_accuracy: 0.8094\n",
      "Epoch 477/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4665 - accuracy: 0.7951 - val_loss: 0.4575 - val_accuracy: 0.8089\n",
      "Epoch 478/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4647 - accuracy: 0.7880 - val_loss: 0.4517 - val_accuracy: 0.7967\n",
      "Epoch 479/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4671 - accuracy: 0.7991 - val_loss: 0.4576 - val_accuracy: 0.8090\n",
      "Epoch 480/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4631 - accuracy: 0.7926 - val_loss: 0.4507 - val_accuracy: 0.7911\n",
      "Epoch 481/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4683 - accuracy: 0.7972 - val_loss: 0.4749 - val_accuracy: 0.7427\n",
      "Epoch 482/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4632 - accuracy: 0.7833 - val_loss: 0.4547 - val_accuracy: 0.8059\n",
      "Epoch 483/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4669 - accuracy: 0.7858 - val_loss: 0.4721 - val_accuracy: 0.8085\n",
      "Epoch 484/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4652 - accuracy: 0.7849 - val_loss: 0.4613 - val_accuracy: 0.7613\n",
      "Epoch 485/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4732 - accuracy: 0.7498 - val_loss: 0.4514 - val_accuracy: 0.7914\n",
      "Epoch 486/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4637 - accuracy: 0.7908 - val_loss: 0.4591 - val_accuracy: 0.8084\n",
      "Epoch 487/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4654 - accuracy: 0.7972 - val_loss: 0.4891 - val_accuracy: 0.7090\n",
      "Epoch 488/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4692 - accuracy: 0.7929 - val_loss: 0.4517 - val_accuracy: 0.8016\n",
      "Epoch 489/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4622 - accuracy: 0.7877 - val_loss: 0.6724 - val_accuracy: 0.4281\n",
      "Epoch 490/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4920 - accuracy: 0.7323 - val_loss: 0.4710 - val_accuracy: 0.8079\n",
      "Epoch 491/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4738 - accuracy: 0.7816 - val_loss: 0.4707 - val_accuracy: 0.8079\n",
      "Epoch 492/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4677 - accuracy: 0.7779 - val_loss: 0.4725 - val_accuracy: 0.7319\n",
      "Epoch 493/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4651 - accuracy: 0.7888 - val_loss: 0.4562 - val_accuracy: 0.7870\n",
      "Epoch 494/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4753 - accuracy: 0.7797 - val_loss: 0.6263 - val_accuracy: 0.7164\n",
      "Epoch 495/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5454 - accuracy: 0.7153 - val_loss: 0.5069 - val_accuracy: 0.7165\n",
      "Epoch 496/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5020 - accuracy: 0.7349 - val_loss: 0.5494 - val_accuracy: 0.5950\n",
      "Epoch 497/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4742 - accuracy: 0.7419 - val_loss: 0.4745 - val_accuracy: 0.8072\n",
      "Epoch 498/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4626 - accuracy: 0.7888 - val_loss: 0.4556 - val_accuracy: 0.8052\n",
      "Epoch 499/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4656 - accuracy: 0.7804 - val_loss: 0.4553 - val_accuracy: 0.8048\n",
      "Epoch 500/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4671 - accuracy: 0.7748 - val_loss: 0.4567 - val_accuracy: 0.8056\n",
      "Epoch 501/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4732 - accuracy: 0.7861 - val_loss: 0.4796 - val_accuracy: 0.7092\n",
      "Epoch 502/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4686 - accuracy: 0.7747 - val_loss: 0.4589 - val_accuracy: 0.8076\n",
      "Epoch 503/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4665 - accuracy: 0.7897 - val_loss: 0.5259 - val_accuracy: 0.6992\n",
      "Epoch 504/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4807 - accuracy: 0.7671 - val_loss: 0.4557 - val_accuracy: 0.8064\n",
      "Epoch 505/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4662 - accuracy: 0.7657 - val_loss: 0.4516 - val_accuracy: 0.8004\n",
      "Epoch 506/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4673 - accuracy: 0.7919 - val_loss: 0.4573 - val_accuracy: 0.8079\n",
      "Epoch 507/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4682 - accuracy: 0.7866 - val_loss: 0.4537 - val_accuracy: 0.8033\n",
      "Epoch 508/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4721 - accuracy: 0.7483 - val_loss: 0.4570 - val_accuracy: 0.8050\n",
      "Epoch 509/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4654 - accuracy: 0.7753 - val_loss: 0.4528 - val_accuracy: 0.7786\n",
      "Epoch 510/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4811 - accuracy: 0.7332 - val_loss: 0.4576 - val_accuracy: 0.7984\n",
      "Epoch 511/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4680 - accuracy: 0.7788 - val_loss: 0.4513 - val_accuracy: 0.7925\n",
      "Epoch 512/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4628 - accuracy: 0.7808 - val_loss: 0.4592 - val_accuracy: 0.8090\n",
      "Epoch 513/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4638 - accuracy: 0.7936 - val_loss: 0.4835 - val_accuracy: 0.8055\n",
      "Epoch 514/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4650 - accuracy: 0.7856 - val_loss: 0.4587 - val_accuracy: 0.7647\n",
      "Epoch 515/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4646 - accuracy: 0.7853 - val_loss: 0.4694 - val_accuracy: 0.7257\n",
      "Epoch 516/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4728 - accuracy: 0.7421 - val_loss: 0.5763 - val_accuracy: 0.7164\n",
      "Epoch 517/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4989 - accuracy: 0.7314 - val_loss: 0.4610 - val_accuracy: 0.8080\n",
      "Epoch 518/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4767 - accuracy: 0.7888 - val_loss: 0.4611 - val_accuracy: 0.7801\n",
      "Epoch 519/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4693 - accuracy: 0.7956 - val_loss: 0.4672 - val_accuracy: 0.8074\n",
      "Epoch 520/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4703 - accuracy: 0.7794 - val_loss: 0.4607 - val_accuracy: 0.7163\n",
      "Epoch 521/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4718 - accuracy: 0.7538 - val_loss: 0.4534 - val_accuracy: 0.8013\n",
      "Epoch 522/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4638 - accuracy: 0.7687 - val_loss: 0.4637 - val_accuracy: 0.7371\n",
      "Epoch 523/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4639 - accuracy: 0.7825 - val_loss: 0.4607 - val_accuracy: 0.8056\n",
      "Epoch 524/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4647 - accuracy: 0.7963 - val_loss: 0.4540 - val_accuracy: 0.8015\n",
      "Epoch 525/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4676 - accuracy: 0.8018 - val_loss: 0.4541 - val_accuracy: 0.8025\n",
      "Epoch 526/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4718 - accuracy: 0.7765 - val_loss: 0.4537 - val_accuracy: 0.8027\n",
      "Epoch 527/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4736 - accuracy: 0.7881 - val_loss: 0.4656 - val_accuracy: 0.8082\n",
      "Epoch 528/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4680 - accuracy: 0.7975 - val_loss: 0.4846 - val_accuracy: 0.8034\n",
      "Epoch 529/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4755 - accuracy: 0.7994 - val_loss: 0.4506 - val_accuracy: 0.7921\n",
      "Epoch 530/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4646 - accuracy: 0.7956 - val_loss: 0.4752 - val_accuracy: 0.7204\n",
      "Epoch 531/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4641 - accuracy: 0.7862 - val_loss: 0.4524 - val_accuracy: 0.7832\n",
      "Epoch 532/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4681 - accuracy: 0.7764 - val_loss: 0.4538 - val_accuracy: 0.8017\n",
      "Epoch 533/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4669 - accuracy: 0.7622 - val_loss: 0.5524 - val_accuracy: 0.5642\n",
      "Epoch 534/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4661 - accuracy: 0.7671 - val_loss: 0.4532 - val_accuracy: 0.8017\n",
      "Epoch 535/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4676 - accuracy: 0.7909 - val_loss: 0.4672 - val_accuracy: 0.7769\n",
      "Epoch 536/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4665 - accuracy: 0.7941 - val_loss: 0.4609 - val_accuracy: 0.8087\n",
      "Epoch 537/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4857 - accuracy: 0.7549 - val_loss: 0.4658 - val_accuracy: 0.7164\n",
      "Epoch 538/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4725 - accuracy: 0.7835 - val_loss: 0.4508 - val_accuracy: 0.7918\n",
      "Epoch 539/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4672 - accuracy: 0.7906 - val_loss: 0.4515 - val_accuracy: 0.7963\n",
      "Epoch 540/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4698 - accuracy: 0.7947 - val_loss: 0.4544 - val_accuracy: 0.8043\n",
      "Epoch 541/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4749 - accuracy: 0.7595 - val_loss: 0.4525 - val_accuracy: 0.8014\n",
      "Epoch 542/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4737 - accuracy: 0.7896 - val_loss: 0.4510 - val_accuracy: 0.7900\n",
      "Epoch 543/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4677 - accuracy: 0.7856 - val_loss: 0.4560 - val_accuracy: 0.8075\n",
      "Epoch 544/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4775 - accuracy: 0.8000 - val_loss: 0.5005 - val_accuracy: 0.7962\n",
      "Epoch 545/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4811 - accuracy: 0.7894 - val_loss: 0.4534 - val_accuracy: 0.8036\n",
      "Epoch 546/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4698 - accuracy: 0.7739 - val_loss: 0.4538 - val_accuracy: 0.8054\n",
      "Epoch 547/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4640 - accuracy: 0.7885 - val_loss: 0.4512 - val_accuracy: 0.7975\n",
      "Epoch 548/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4643 - accuracy: 0.7804 - val_loss: 0.4593 - val_accuracy: 0.8084\n",
      "Epoch 549/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4729 - accuracy: 0.8030 - val_loss: 0.4659 - val_accuracy: 0.7642\n",
      "Epoch 550/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4722 - accuracy: 0.7811 - val_loss: 0.4540 - val_accuracy: 0.7955\n",
      "Epoch 551/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4680 - accuracy: 0.8023 - val_loss: 0.4554 - val_accuracy: 0.7740\n",
      "Epoch 552/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4722 - accuracy: 0.8031 - val_loss: 0.4699 - val_accuracy: 0.8081\n",
      "Epoch 553/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4856 - accuracy: 0.8006 - val_loss: 0.4618 - val_accuracy: 0.8095\n",
      "Epoch 554/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4718 - accuracy: 0.7807 - val_loss: 0.4539 - val_accuracy: 0.7695\n",
      "Epoch 555/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4609 - accuracy: 0.7853 - val_loss: 0.4515 - val_accuracy: 0.7851\n",
      "Epoch 556/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4641 - accuracy: 0.8001 - val_loss: 0.4666 - val_accuracy: 0.8088\n",
      "Epoch 557/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4695 - accuracy: 0.8040 - val_loss: 0.4722 - val_accuracy: 0.8084\n",
      "Epoch 558/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4762 - accuracy: 0.7958 - val_loss: 0.4873 - val_accuracy: 0.8035\n",
      "Epoch 559/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4723 - accuracy: 0.7983 - val_loss: 0.4726 - val_accuracy: 0.8085\n",
      "Epoch 560/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4764 - accuracy: 0.7941 - val_loss: 0.4571 - val_accuracy: 0.7586\n",
      "Epoch 561/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4712 - accuracy: 0.7727 - val_loss: 0.4512 - val_accuracy: 0.8042\n",
      "Epoch 562/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4710 - accuracy: 0.7991 - val_loss: 0.4858 - val_accuracy: 0.8054\n",
      "Epoch 563/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4675 - accuracy: 0.8020 - val_loss: 0.4802 - val_accuracy: 0.8082\n",
      "Epoch 564/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4723 - accuracy: 0.7915 - val_loss: 0.4864 - val_accuracy: 0.6914\n",
      "Epoch 565/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4777 - accuracy: 0.7906 - val_loss: 0.4945 - val_accuracy: 0.7996\n",
      "Epoch 566/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4676 - accuracy: 0.7889 - val_loss: 0.4546 - val_accuracy: 0.8060\n",
      "Epoch 567/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4621 - accuracy: 0.7933 - val_loss: 0.4547 - val_accuracy: 0.7793\n",
      "Epoch 568/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4651 - accuracy: 0.7759 - val_loss: 0.4560 - val_accuracy: 0.7948\n",
      "Epoch 569/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4629 - accuracy: 0.7891 - val_loss: 0.4688 - val_accuracy: 0.8103\n",
      "Epoch 570/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4618 - accuracy: 0.7863 - val_loss: 0.4499 - val_accuracy: 0.8026\n",
      "Epoch 571/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4645 - accuracy: 0.7910 - val_loss: 0.4499 - val_accuracy: 0.7959\n",
      "Epoch 572/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4700 - accuracy: 0.7996 - val_loss: 0.4611 - val_accuracy: 0.8103\n",
      "Epoch 573/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4722 - accuracy: 0.7590 - val_loss: 0.6231 - val_accuracy: 0.4200\n",
      "Epoch 574/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4658 - accuracy: 0.7917 - val_loss: 0.4712 - val_accuracy: 0.8091\n",
      "Epoch 575/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4685 - accuracy: 0.7768 - val_loss: 0.5504 - val_accuracy: 0.5847\n",
      "Epoch 576/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4652 - accuracy: 0.7743 - val_loss: 0.4492 - val_accuracy: 0.7917\n",
      "Epoch 577/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4614 - accuracy: 0.7867 - val_loss: 0.4564 - val_accuracy: 0.8095\n",
      "Epoch 578/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4674 - accuracy: 0.8034 - val_loss: 0.4540 - val_accuracy: 0.8070\n",
      "Epoch 579/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4687 - accuracy: 0.7882 - val_loss: 0.4542 - val_accuracy: 0.8089\n",
      "Epoch 580/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4622 - accuracy: 0.7958 - val_loss: 0.4503 - val_accuracy: 0.8024\n",
      "Epoch 581/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4754 - accuracy: 0.7474 - val_loss: 0.4705 - val_accuracy: 0.8100\n",
      "Epoch 582/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4671 - accuracy: 0.7925 - val_loss: 0.4540 - val_accuracy: 0.7803\n",
      "Epoch 583/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4666 - accuracy: 0.7958 - val_loss: 0.4630 - val_accuracy: 0.8105\n",
      "Epoch 584/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4622 - accuracy: 0.8018 - val_loss: 0.4550 - val_accuracy: 0.8086\n",
      "Epoch 585/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4651 - accuracy: 0.7827 - val_loss: 0.4579 - val_accuracy: 0.8086\n",
      "Epoch 586/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4793 - accuracy: 0.7586 - val_loss: 0.4636 - val_accuracy: 0.7164\n",
      "Epoch 587/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4635 - accuracy: 0.7957 - val_loss: 0.4533 - val_accuracy: 0.8074\n",
      "Epoch 588/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4697 - accuracy: 0.7641 - val_loss: 0.4585 - val_accuracy: 0.8087\n",
      "Epoch 589/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4645 - accuracy: 0.7961 - val_loss: 0.4684 - val_accuracy: 0.8088\n",
      "Epoch 590/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4673 - accuracy: 0.7932 - val_loss: 0.4657 - val_accuracy: 0.8095\n",
      "Epoch 591/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4635 - accuracy: 0.7878 - val_loss: 0.4734 - val_accuracy: 0.7090\n",
      "Epoch 592/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4754 - accuracy: 0.7453 - val_loss: 0.5077 - val_accuracy: 0.6560\n",
      "Epoch 593/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4698 - accuracy: 0.7829 - val_loss: 0.4602 - val_accuracy: 0.8095\n",
      "Epoch 594/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4603 - accuracy: 0.7827 - val_loss: 0.4497 - val_accuracy: 0.7952\n",
      "Epoch 595/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4719 - accuracy: 0.7636 - val_loss: 0.4790 - val_accuracy: 0.6904\n",
      "Epoch 596/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4689 - accuracy: 0.7821 - val_loss: 0.4490 - val_accuracy: 0.7968\n",
      "Epoch 597/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4663 - accuracy: 0.7859 - val_loss: 0.5232 - val_accuracy: 0.7885\n",
      "Epoch 598/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4749 - accuracy: 0.7938 - val_loss: 0.4720 - val_accuracy: 0.8086\n",
      "Epoch 599/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4655 - accuracy: 0.7935 - val_loss: 0.4690 - val_accuracy: 0.8090\n",
      "Epoch 600/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4696 - accuracy: 0.7847 - val_loss: 0.4553 - val_accuracy: 0.8078\n",
      "Epoch 601/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4693 - accuracy: 0.7774 - val_loss: 0.4713 - val_accuracy: 0.8082\n",
      "Epoch 602/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4782 - accuracy: 0.7540 - val_loss: 0.5024 - val_accuracy: 0.7164\n",
      "Epoch 603/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4784 - accuracy: 0.7584 - val_loss: 0.4499 - val_accuracy: 0.7957\n",
      "Epoch 604/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4675 - accuracy: 0.7741 - val_loss: 0.4528 - val_accuracy: 0.8071\n",
      "Epoch 605/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4640 - accuracy: 0.7830 - val_loss: 0.4551 - val_accuracy: 0.7662\n",
      "Epoch 606/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4726 - accuracy: 0.7569 - val_loss: 0.4548 - val_accuracy: 0.7787\n",
      "Epoch 607/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4711 - accuracy: 0.7807 - val_loss: 0.4817 - val_accuracy: 0.7589\n",
      "Epoch 608/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4683 - accuracy: 0.7765 - val_loss: 0.4524 - val_accuracy: 0.8018\n",
      "Epoch 609/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4699 - accuracy: 0.7921 - val_loss: 0.4753 - val_accuracy: 0.8071\n",
      "Epoch 610/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4642 - accuracy: 0.7934 - val_loss: 0.4515 - val_accuracy: 0.8017\n",
      "Epoch 611/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4767 - accuracy: 0.7998 - val_loss: 0.4721 - val_accuracy: 0.8080\n",
      "Epoch 612/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4723 - accuracy: 0.8016 - val_loss: 0.4704 - val_accuracy: 0.8085\n",
      "Epoch 613/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4690 - accuracy: 0.7920 - val_loss: 0.4783 - val_accuracy: 0.7022\n",
      "Epoch 614/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4700 - accuracy: 0.7757 - val_loss: 0.5036 - val_accuracy: 0.7977\n",
      "Epoch 615/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4677 - accuracy: 0.7851 - val_loss: 0.4506 - val_accuracy: 0.7846\n",
      "Epoch 616/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4634 - accuracy: 0.7727 - val_loss: 0.4549 - val_accuracy: 0.8079\n",
      "Epoch 617/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4644 - accuracy: 0.7821 - val_loss: 0.4563 - val_accuracy: 0.8094\n",
      "Epoch 618/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4671 - accuracy: 0.7667 - val_loss: 0.4511 - val_accuracy: 0.7831\n",
      "Epoch 619/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4651 - accuracy: 0.7876 - val_loss: 0.4495 - val_accuracy: 0.7959\n",
      "Epoch 620/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4627 - accuracy: 0.7938 - val_loss: 0.4541 - val_accuracy: 0.7826\n",
      "Epoch 621/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4653 - accuracy: 0.7844 - val_loss: 0.4642 - val_accuracy: 0.7379\n",
      "Epoch 622/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4634 - accuracy: 0.7880 - val_loss: 0.4510 - val_accuracy: 0.7838\n",
      "Epoch 623/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4646 - accuracy: 0.7751 - val_loss: 0.4535 - val_accuracy: 0.8011\n",
      "Epoch 624/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4659 - accuracy: 0.7899 - val_loss: 0.4578 - val_accuracy: 0.8087\n",
      "Epoch 625/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4657 - accuracy: 0.7666 - val_loss: 0.4691 - val_accuracy: 0.8086\n",
      "Epoch 626/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4667 - accuracy: 0.7892 - val_loss: 0.4549 - val_accuracy: 0.8069\n",
      "Epoch 627/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4668 - accuracy: 0.8033 - val_loss: 0.4521 - val_accuracy: 0.8012\n",
      "Epoch 628/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4684 - accuracy: 0.7532 - val_loss: 0.4507 - val_accuracy: 0.7924\n",
      "Epoch 629/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4703 - accuracy: 0.7994 - val_loss: 0.4510 - val_accuracy: 0.7977\n",
      "Epoch 630/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4668 - accuracy: 0.7904 - val_loss: 0.4653 - val_accuracy: 0.7407\n",
      "Epoch 631/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4705 - accuracy: 0.7942 - val_loss: 0.4519 - val_accuracy: 0.8025\n",
      "Epoch 632/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4688 - accuracy: 0.7936 - val_loss: 0.4558 - val_accuracy: 0.8057\n",
      "Epoch 633/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4681 - accuracy: 0.8006 - val_loss: 0.4595 - val_accuracy: 0.8079\n",
      "Epoch 634/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4681 - accuracy: 0.7911 - val_loss: 0.4526 - val_accuracy: 0.7766\n",
      "Epoch 635/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4635 - accuracy: 0.7947 - val_loss: 0.5120 - val_accuracy: 0.6632\n",
      "Epoch 636/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4733 - accuracy: 0.7970 - val_loss: 0.4557 - val_accuracy: 0.8077\n",
      "Epoch 637/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4617 - accuracy: 0.7819 - val_loss: 0.4527 - val_accuracy: 0.7846\n",
      "Epoch 638/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5078 - accuracy: 0.7229 - val_loss: 0.4855 - val_accuracy: 0.7164\n",
      "Epoch 639/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4668 - accuracy: 0.7669 - val_loss: 0.4534 - val_accuracy: 0.8043\n",
      "Epoch 640/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4644 - accuracy: 0.7968 - val_loss: 0.4661 - val_accuracy: 0.8085\n",
      "Epoch 641/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4657 - accuracy: 0.8020 - val_loss: 0.4584 - val_accuracy: 0.8082\n",
      "Epoch 642/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4813 - accuracy: 0.7629 - val_loss: 0.4801 - val_accuracy: 0.7164\n",
      "Epoch 643/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4805 - accuracy: 0.7271 - val_loss: 0.4547 - val_accuracy: 0.7862\n",
      "Epoch 644/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4702 - accuracy: 0.7736 - val_loss: 0.4727 - val_accuracy: 0.8075\n",
      "Epoch 645/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4616 - accuracy: 0.7924 - val_loss: 0.4775 - val_accuracy: 0.8077\n",
      "Epoch 646/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4799 - accuracy: 0.8041 - val_loss: 0.4622 - val_accuracy: 0.8083\n",
      "Epoch 647/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4655 - accuracy: 0.7853 - val_loss: 0.4590 - val_accuracy: 0.7521\n",
      "Epoch 648/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4711 - accuracy: 0.8016 - val_loss: 0.4594 - val_accuracy: 0.8083\n",
      "Epoch 649/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4719 - accuracy: 0.7515 - val_loss: 0.4529 - val_accuracy: 0.7736\n",
      "Epoch 650/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4704 - accuracy: 0.7926 - val_loss: 0.4584 - val_accuracy: 0.8086\n",
      "Epoch 651/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4630 - accuracy: 0.7826 - val_loss: 0.4757 - val_accuracy: 0.8078\n",
      "Epoch 652/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4660 - accuracy: 0.7962 - val_loss: 0.4504 - val_accuracy: 0.7956\n",
      "Epoch 653/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4705 - accuracy: 0.7942 - val_loss: 0.4878 - val_accuracy: 0.8024\n",
      "Epoch 654/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4693 - accuracy: 0.7872 - val_loss: 0.4816 - val_accuracy: 0.6963\n",
      "Epoch 655/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4654 - accuracy: 0.7870 - val_loss: 0.4670 - val_accuracy: 0.8085\n",
      "Epoch 656/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4683 - accuracy: 0.7843 - val_loss: 0.4712 - val_accuracy: 0.8079\n",
      "Epoch 657/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4756 - accuracy: 0.8055 - val_loss: 0.4614 - val_accuracy: 0.8018\n",
      "Epoch 658/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4653 - accuracy: 0.7771 - val_loss: 0.4499 - val_accuracy: 0.7854\n",
      "Epoch 659/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4678 - accuracy: 0.8057 - val_loss: 0.4596 - val_accuracy: 0.7844\n",
      "Epoch 660/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4606 - accuracy: 0.7842 - val_loss: 0.4729 - val_accuracy: 0.8085\n",
      "Epoch 661/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4838 - accuracy: 0.8010 - val_loss: 0.5200 - val_accuracy: 0.7841\n",
      "Epoch 662/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4809 - accuracy: 0.8021 - val_loss: 0.4807 - val_accuracy: 0.7413\n",
      "Epoch 663/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4611 - accuracy: 0.7907 - val_loss: 0.4510 - val_accuracy: 0.7865\n",
      "Epoch 664/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4676 - accuracy: 0.8045 - val_loss: 0.4692 - val_accuracy: 0.8088\n",
      "Epoch 665/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4674 - accuracy: 0.8013 - val_loss: 0.4528 - val_accuracy: 0.8061\n",
      "Epoch 666/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4638 - accuracy: 0.8001 - val_loss: 0.4490 - val_accuracy: 0.7922\n",
      "Epoch 667/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4676 - accuracy: 0.7689 - val_loss: 0.4726 - val_accuracy: 0.7309\n",
      "Epoch 668/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4661 - accuracy: 0.7714 - val_loss: 0.5336 - val_accuracy: 0.6124\n",
      "Epoch 669/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4733 - accuracy: 0.7568 - val_loss: 0.4544 - val_accuracy: 0.8066\n",
      "Epoch 670/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4673 - accuracy: 0.7890 - val_loss: 0.4592 - val_accuracy: 0.8094\n",
      "Epoch 671/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4665 - accuracy: 0.7970 - val_loss: 0.4719 - val_accuracy: 0.8085\n",
      "Epoch 672/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4670 - accuracy: 0.7882 - val_loss: 0.4602 - val_accuracy: 0.8094\n",
      "Epoch 673/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4675 - accuracy: 0.8040 - val_loss: 0.4590 - val_accuracy: 0.8099\n",
      "Epoch 674/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4605 - accuracy: 0.7971 - val_loss: 0.4503 - val_accuracy: 0.7996\n",
      "Epoch 675/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4778 - accuracy: 0.7467 - val_loss: 0.4543 - val_accuracy: 0.7732\n",
      "Epoch 676/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4631 - accuracy: 0.7808 - val_loss: 0.4574 - val_accuracy: 0.8097\n",
      "Epoch 677/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4748 - accuracy: 0.8040 - val_loss: 0.4587 - val_accuracy: 0.8098\n",
      "Epoch 678/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4652 - accuracy: 0.7941 - val_loss: 0.5771 - val_accuracy: 0.5682\n",
      "Epoch 679/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4691 - accuracy: 0.7486 - val_loss: 0.4500 - val_accuracy: 0.7997\n",
      "Epoch 680/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4738 - accuracy: 0.8000 - val_loss: 0.4580 - val_accuracy: 0.8093\n",
      "Epoch 681/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4647 - accuracy: 0.7814 - val_loss: 0.4909 - val_accuracy: 0.8027\n",
      "Epoch 682/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4739 - accuracy: 0.7929 - val_loss: 0.4775 - val_accuracy: 0.8076\n",
      "Epoch 683/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4781 - accuracy: 0.8005 - val_loss: 0.4926 - val_accuracy: 0.8018\n",
      "Epoch 684/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4895 - accuracy: 0.7949 - val_loss: 0.5045 - val_accuracy: 0.7973\n",
      "Epoch 685/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4701 - accuracy: 0.8031 - val_loss: 0.4736 - val_accuracy: 0.8083\n",
      "Epoch 686/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4759 - accuracy: 0.8047 - val_loss: 0.4809 - val_accuracy: 0.8057\n",
      "Epoch 687/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4749 - accuracy: 0.8048 - val_loss: 0.4913 - val_accuracy: 0.8015\n",
      "Epoch 688/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4666 - accuracy: 0.8000 - val_loss: 0.4615 - val_accuracy: 0.7545\n",
      "Epoch 689/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4763 - accuracy: 0.7388 - val_loss: 0.4784 - val_accuracy: 0.6973\n",
      "Epoch 690/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4639 - accuracy: 0.7864 - val_loss: 0.4508 - val_accuracy: 0.7989\n",
      "Epoch 691/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4719 - accuracy: 0.7691 - val_loss: 0.4487 - val_accuracy: 0.7907\n",
      "Epoch 692/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4719 - accuracy: 0.8005 - val_loss: 0.4533 - val_accuracy: 0.7931\n",
      "Epoch 693/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4594 - accuracy: 0.7975 - val_loss: 0.4524 - val_accuracy: 0.8071\n",
      "Epoch 694/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4789 - accuracy: 0.7746 - val_loss: 0.4540 - val_accuracy: 0.7664\n",
      "Epoch 695/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4660 - accuracy: 0.7564 - val_loss: 0.4498 - val_accuracy: 0.7839\n",
      "Epoch 696/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4707 - accuracy: 0.7677 - val_loss: 0.4631 - val_accuracy: 0.8102\n",
      "Epoch 697/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4656 - accuracy: 0.7822 - val_loss: 0.4517 - val_accuracy: 0.7857\n",
      "Epoch 698/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4691 - accuracy: 0.7917 - val_loss: 0.4849 - val_accuracy: 0.8040\n",
      "Epoch 699/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4661 - accuracy: 0.7875 - val_loss: 0.4629 - val_accuracy: 0.7334\n",
      "Epoch 700/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4664 - accuracy: 0.7741 - val_loss: 0.4662 - val_accuracy: 0.8099\n",
      "Epoch 701/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4683 - accuracy: 0.7731 - val_loss: 0.4510 - val_accuracy: 0.7769\n",
      "Epoch 702/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5559 - accuracy: 0.7161 - val_loss: 0.5885 - val_accuracy: 0.7165\n",
      "Epoch 703/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4887 - accuracy: 0.7599 - val_loss: 0.5151 - val_accuracy: 0.6582\n",
      "Epoch 704/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4665 - accuracy: 0.7868 - val_loss: 0.4673 - val_accuracy: 0.8092\n",
      "Epoch 705/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4677 - accuracy: 0.7687 - val_loss: 0.4508 - val_accuracy: 0.7869\n",
      "Epoch 706/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4618 - accuracy: 0.7797 - val_loss: 0.4513 - val_accuracy: 0.8028\n",
      "Epoch 707/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4640 - accuracy: 0.7896 - val_loss: 0.4769 - val_accuracy: 0.8087\n",
      "Epoch 708/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4657 - accuracy: 0.7951 - val_loss: 0.4655 - val_accuracy: 0.8101\n",
      "Epoch 709/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4708 - accuracy: 0.7543 - val_loss: 0.4614 - val_accuracy: 0.8078\n",
      "Epoch 710/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4591 - accuracy: 0.7905 - val_loss: 0.4505 - val_accuracy: 0.7813\n",
      "Epoch 711/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4657 - accuracy: 0.7976 - val_loss: 0.4640 - val_accuracy: 0.8094\n",
      "Epoch 712/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4692 - accuracy: 0.7763 - val_loss: 0.4528 - val_accuracy: 0.8067\n",
      "Epoch 713/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4744 - accuracy: 0.8065 - val_loss: 0.4652 - val_accuracy: 0.8091\n",
      "Epoch 714/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4743 - accuracy: 0.8007 - val_loss: 0.4840 - val_accuracy: 0.8051\n",
      "Epoch 715/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4672 - accuracy: 0.7844 - val_loss: 0.4672 - val_accuracy: 0.8090\n",
      "Epoch 716/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4638 - accuracy: 0.7970 - val_loss: 0.4511 - val_accuracy: 0.8023\n",
      "Epoch 717/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4687 - accuracy: 0.7592 - val_loss: 0.4556 - val_accuracy: 0.7701\n",
      "Epoch 718/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4616 - accuracy: 0.7996 - val_loss: 0.4524 - val_accuracy: 0.8068\n",
      "Epoch 719/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4750 - accuracy: 0.8003 - val_loss: 0.4967 - val_accuracy: 0.7988\n",
      "Epoch 720/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4650 - accuracy: 0.7865 - val_loss: 0.4545 - val_accuracy: 0.7650\n",
      "Epoch 721/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4619 - accuracy: 0.7887 - val_loss: 0.4923 - val_accuracy: 0.8012\n",
      "Epoch 722/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4632 - accuracy: 0.7995 - val_loss: 0.4503 - val_accuracy: 0.7987\n",
      "Epoch 723/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4662 - accuracy: 0.7686 - val_loss: 0.4513 - val_accuracy: 0.8032\n",
      "Epoch 724/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4668 - accuracy: 0.8032 - val_loss: 0.4686 - val_accuracy: 0.8088\n",
      "Epoch 725/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4721 - accuracy: 0.8067 - val_loss: 0.4565 - val_accuracy: 0.8069\n",
      "Epoch 726/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4702 - accuracy: 0.8056 - val_loss: 0.4650 - val_accuracy: 0.8092\n",
      "Epoch 727/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4692 - accuracy: 0.7964 - val_loss: 0.4531 - val_accuracy: 0.8076\n",
      "Epoch 728/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4693 - accuracy: 0.7904 - val_loss: 0.4494 - val_accuracy: 0.7851\n",
      "Epoch 729/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4668 - accuracy: 0.7971 - val_loss: 0.4513 - val_accuracy: 0.7940\n",
      "Epoch 730/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4621 - accuracy: 0.7921 - val_loss: 0.4542 - val_accuracy: 0.7700\n",
      "Epoch 731/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4839 - accuracy: 0.7800 - val_loss: 0.5849 - val_accuracy: 0.7164\n",
      "Epoch 732/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4746 - accuracy: 0.7481 - val_loss: 0.4639 - val_accuracy: 0.8093\n",
      "Epoch 733/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4639 - accuracy: 0.7802 - val_loss: 0.4543 - val_accuracy: 0.8084\n",
      "Epoch 734/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4619 - accuracy: 0.7908 - val_loss: 0.4707 - val_accuracy: 0.7314\n",
      "Epoch 735/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4663 - accuracy: 0.7749 - val_loss: 0.4533 - val_accuracy: 0.8079\n",
      "Epoch 736/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4641 - accuracy: 0.7957 - val_loss: 0.4548 - val_accuracy: 0.8081\n",
      "Epoch 737/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4641 - accuracy: 0.8026 - val_loss: 0.4512 - val_accuracy: 0.7944\n",
      "Epoch 738/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4596 - accuracy: 0.7902 - val_loss: 0.4538 - val_accuracy: 0.7786\n",
      "Epoch 739/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4630 - accuracy: 0.8041 - val_loss: 0.4687 - val_accuracy: 0.8093\n",
      "Epoch 740/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4731 - accuracy: 0.7617 - val_loss: 0.4828 - val_accuracy: 0.8065\n",
      "Epoch 741/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4665 - accuracy: 0.7891 - val_loss: 0.4517 - val_accuracy: 0.8041\n",
      "Epoch 742/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4665 - accuracy: 0.7784 - val_loss: 0.4537 - val_accuracy: 0.8080\n",
      "Epoch 743/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4715 - accuracy: 0.8012 - val_loss: 0.4542 - val_accuracy: 0.8085\n",
      "Epoch 744/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4649 - accuracy: 0.7807 - val_loss: 0.4541 - val_accuracy: 0.7996\n",
      "Epoch 745/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4696 - accuracy: 0.7632 - val_loss: 0.4707 - val_accuracy: 0.8094\n",
      "Epoch 746/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4639 - accuracy: 0.7884 - val_loss: 0.4569 - val_accuracy: 0.7586\n",
      "Epoch 747/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4693 - accuracy: 0.7861 - val_loss: 0.4550 - val_accuracy: 0.7974\n",
      "Epoch 748/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4598 - accuracy: 0.7950 - val_loss: 0.4617 - val_accuracy: 0.8090\n",
      "Epoch 749/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4705 - accuracy: 0.7890 - val_loss: 0.4525 - val_accuracy: 0.8027\n",
      "Epoch 750/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4677 - accuracy: 0.7677 - val_loss: 0.4563 - val_accuracy: 0.8066\n",
      "Epoch 751/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4748 - accuracy: 0.8007 - val_loss: 0.4857 - val_accuracy: 0.8040\n",
      "Epoch 752/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4760 - accuracy: 0.7784 - val_loss: 0.4752 - val_accuracy: 0.8089\n",
      "Epoch 753/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4708 - accuracy: 0.7651 - val_loss: 0.4692 - val_accuracy: 0.7456\n",
      "Epoch 754/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4613 - accuracy: 0.7932 - val_loss: 0.4528 - val_accuracy: 0.8073\n",
      "Epoch 755/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4609 - accuracy: 0.8010 - val_loss: 0.4515 - val_accuracy: 0.8027\n",
      "Epoch 756/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4647 - accuracy: 0.7691 - val_loss: 0.4500 - val_accuracy: 0.7920\n",
      "Epoch 757/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4624 - accuracy: 0.8033 - val_loss: 0.4527 - val_accuracy: 0.8055\n",
      "Epoch 758/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4657 - accuracy: 0.7733 - val_loss: 0.4514 - val_accuracy: 0.8046\n",
      "Epoch 759/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4636 - accuracy: 0.8056 - val_loss: 0.4637 - val_accuracy: 0.8099\n",
      "Epoch 760/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4639 - accuracy: 0.7822 - val_loss: 0.4508 - val_accuracy: 0.7805\n",
      "Epoch 761/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4625 - accuracy: 0.7984 - val_loss: 0.4524 - val_accuracy: 0.8017\n",
      "Epoch 762/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4677 - accuracy: 0.7902 - val_loss: 0.4611 - val_accuracy: 0.8095\n",
      "Epoch 763/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4612 - accuracy: 0.7981 - val_loss: 0.4508 - val_accuracy: 0.7960\n",
      "Epoch 764/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4680 - accuracy: 0.7607 - val_loss: 0.4643 - val_accuracy: 0.8094\n",
      "Epoch 765/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5174 - accuracy: 0.7501 - val_loss: 0.5867 - val_accuracy: 0.7165\n",
      "Epoch 766/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4893 - accuracy: 0.7594 - val_loss: 0.4713 - val_accuracy: 0.7332\n",
      "Epoch 767/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4652 - accuracy: 0.7813 - val_loss: 0.4701 - val_accuracy: 0.8093\n",
      "Epoch 768/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4714 - accuracy: 0.7980 - val_loss: 0.4507 - val_accuracy: 0.8019\n",
      "Epoch 769/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4668 - accuracy: 0.8042 - val_loss: 0.4589 - val_accuracy: 0.8095\n",
      "Epoch 770/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4686 - accuracy: 0.7933 - val_loss: 0.4643 - val_accuracy: 0.8097\n",
      "Epoch 771/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4629 - accuracy: 0.7907 - val_loss: 0.4528 - val_accuracy: 0.8073\n",
      "Epoch 772/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4705 - accuracy: 0.7975 - val_loss: 0.4653 - val_accuracy: 0.8097\n",
      "Epoch 773/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4643 - accuracy: 0.7964 - val_loss: 0.4594 - val_accuracy: 0.7694\n",
      "Epoch 774/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4639 - accuracy: 0.7901 - val_loss: 0.4798 - val_accuracy: 0.7109\n",
      "Epoch 775/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4729 - accuracy: 0.7548 - val_loss: 0.4548 - val_accuracy: 0.8089\n",
      "Epoch 776/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4803 - accuracy: 0.8039 - val_loss: 0.4909 - val_accuracy: 0.8015\n",
      "Epoch 777/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4770 - accuracy: 0.8016 - val_loss: 0.4560 - val_accuracy: 0.7909\n",
      "Epoch 778/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4626 - accuracy: 0.7843 - val_loss: 0.4506 - val_accuracy: 0.7919\n",
      "Epoch 779/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4608 - accuracy: 0.7975 - val_loss: 0.4568 - val_accuracy: 0.8096\n",
      "Epoch 780/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4632 - accuracy: 0.7867 - val_loss: 0.4536 - val_accuracy: 0.8089\n",
      "Epoch 781/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4632 - accuracy: 0.7893 - val_loss: 0.4499 - val_accuracy: 0.7815\n",
      "Epoch 782/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4662 - accuracy: 0.7731 - val_loss: 0.4541 - val_accuracy: 0.7659\n",
      "Epoch 783/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4713 - accuracy: 0.7846 - val_loss: 0.4822 - val_accuracy: 0.7163\n",
      "Epoch 784/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4737 - accuracy: 0.7510 - val_loss: 0.4522 - val_accuracy: 0.8031\n",
      "Epoch 785/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4628 - accuracy: 0.7901 - val_loss: 0.4519 - val_accuracy: 0.7946\n",
      "Epoch 786/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4732 - accuracy: 0.7857 - val_loss: 0.4576 - val_accuracy: 0.7548\n",
      "Epoch 787/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4725 - accuracy: 0.7581 - val_loss: 0.4544 - val_accuracy: 0.7822\n",
      "Epoch 788/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4612 - accuracy: 0.7942 - val_loss: 0.4502 - val_accuracy: 0.8001\n",
      "Epoch 789/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4733 - accuracy: 0.7596 - val_loss: 0.4650 - val_accuracy: 0.8099\n",
      "Epoch 790/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4612 - accuracy: 0.8016 - val_loss: 0.4502 - val_accuracy: 0.7971\n",
      "Epoch 791/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4690 - accuracy: 0.7995 - val_loss: 0.4750 - val_accuracy: 0.8081\n",
      "Epoch 792/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4712 - accuracy: 0.8071 - val_loss: 0.4696 - val_accuracy: 0.8090\n",
      "Epoch 793/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4649 - accuracy: 0.7775 - val_loss: 0.4533 - val_accuracy: 0.7928\n",
      "Epoch 794/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4652 - accuracy: 0.8011 - val_loss: 0.4652 - val_accuracy: 0.8097\n",
      "Epoch 795/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4701 - accuracy: 0.7702 - val_loss: 0.4939 - val_accuracy: 0.8095\n",
      "Epoch 796/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4666 - accuracy: 0.7787 - val_loss: 0.4503 - val_accuracy: 0.7998\n",
      "Epoch 797/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4604 - accuracy: 0.7778 - val_loss: 0.4524 - val_accuracy: 0.8076\n",
      "Epoch 798/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4701 - accuracy: 0.7876 - val_loss: 0.4510 - val_accuracy: 0.7775\n",
      "Epoch 799/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5781 - accuracy: 0.7139 - val_loss: 0.5872 - val_accuracy: 0.7165\n",
      "Epoch 800/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5187 - accuracy: 0.7264 - val_loss: 0.4563 - val_accuracy: 0.8032\n",
      "Epoch 801/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4722 - accuracy: 0.7412 - val_loss: 0.4789 - val_accuracy: 0.7006\n",
      "Epoch 802/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4659 - accuracy: 0.7665 - val_loss: 0.4510 - val_accuracy: 0.8042\n",
      "Epoch 803/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4667 - accuracy: 0.7657 - val_loss: 0.4520 - val_accuracy: 0.8071\n",
      "Epoch 804/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4669 - accuracy: 0.7709 - val_loss: 0.4775 - val_accuracy: 0.7320\n",
      "Epoch 805/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4660 - accuracy: 0.7813 - val_loss: 0.4489 - val_accuracy: 0.7869\n",
      "Epoch 806/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4798 - accuracy: 0.7383 - val_loss: 0.4518 - val_accuracy: 0.7772\n",
      "Epoch 807/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4746 - accuracy: 0.7460 - val_loss: 0.4514 - val_accuracy: 0.7823\n",
      "Epoch 808/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4666 - accuracy: 0.7723 - val_loss: 0.4519 - val_accuracy: 0.7997\n",
      "Epoch 809/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4648 - accuracy: 0.7897 - val_loss: 0.4828 - val_accuracy: 0.8055\n",
      "Epoch 810/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4735 - accuracy: 0.7741 - val_loss: 0.4544 - val_accuracy: 0.8083\n",
      "Epoch 811/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4682 - accuracy: 0.7930 - val_loss: 0.4524 - val_accuracy: 0.8038\n",
      "Epoch 812/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4633 - accuracy: 0.7924 - val_loss: 0.4515 - val_accuracy: 0.7980\n",
      "Epoch 813/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4635 - accuracy: 0.7938 - val_loss: 0.4554 - val_accuracy: 0.8054\n",
      "Epoch 814/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4634 - accuracy: 0.7759 - val_loss: 0.4512 - val_accuracy: 0.7789\n",
      "Epoch 815/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4662 - accuracy: 0.7782 - val_loss: 0.4527 - val_accuracy: 0.8004\n",
      "Epoch 816/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4651 - accuracy: 0.7717 - val_loss: 0.4697 - val_accuracy: 0.8084\n",
      "Epoch 817/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4809 - accuracy: 0.7382 - val_loss: 0.4541 - val_accuracy: 0.7657\n",
      "Epoch 818/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4639 - accuracy: 0.7802 - val_loss: 0.4500 - val_accuracy: 0.7834\n",
      "Epoch 819/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4899 - accuracy: 0.7599 - val_loss: 0.4799 - val_accuracy: 0.7164\n",
      "Epoch 820/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4702 - accuracy: 0.7621 - val_loss: 0.4644 - val_accuracy: 0.7346\n",
      "Epoch 821/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4654 - accuracy: 0.7586 - val_loss: 0.4503 - val_accuracy: 0.7868\n",
      "Epoch 822/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4636 - accuracy: 0.7772 - val_loss: 0.4519 - val_accuracy: 0.7788\n",
      "Epoch 823/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4640 - accuracy: 0.7927 - val_loss: 0.4576 - val_accuracy: 0.7851\n",
      "Epoch 824/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4778 - accuracy: 0.7233 - val_loss: 0.4619 - val_accuracy: 0.7163\n",
      "Epoch 825/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4660 - accuracy: 0.7753 - val_loss: 0.4963 - val_accuracy: 0.8004\n",
      "Epoch 826/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4739 - accuracy: 0.7948 - val_loss: 0.4741 - val_accuracy: 0.8083\n",
      "Epoch 827/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4757 - accuracy: 0.7589 - val_loss: 0.4511 - val_accuracy: 0.7873\n",
      "Epoch 828/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4639 - accuracy: 0.7741 - val_loss: 0.4544 - val_accuracy: 0.7722\n",
      "Epoch 829/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4624 - accuracy: 0.8011 - val_loss: 0.4524 - val_accuracy: 0.8050\n",
      "Epoch 830/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4596 - accuracy: 0.7981 - val_loss: 0.4508 - val_accuracy: 0.7904\n",
      "Epoch 831/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4675 - accuracy: 0.7712 - val_loss: 0.4637 - val_accuracy: 0.8094\n",
      "Epoch 832/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4631 - accuracy: 0.7948 - val_loss: 0.4829 - val_accuracy: 0.7214\n",
      "Epoch 833/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4645 - accuracy: 0.7713 - val_loss: 0.4781 - val_accuracy: 0.8078\n",
      "Epoch 834/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4720 - accuracy: 0.7873 - val_loss: 0.5210 - val_accuracy: 0.7847\n",
      "Epoch 835/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4764 - accuracy: 0.7965 - val_loss: 0.4642 - val_accuracy: 0.8089\n",
      "Epoch 836/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4775 - accuracy: 0.7778 - val_loss: 0.4722 - val_accuracy: 0.8090\n",
      "Epoch 837/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4598 - accuracy: 0.7983 - val_loss: 0.4644 - val_accuracy: 0.8093\n",
      "Epoch 838/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4647 - accuracy: 0.7941 - val_loss: 0.4529 - val_accuracy: 0.7746\n",
      "Epoch 839/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4694 - accuracy: 0.7525 - val_loss: 0.4579 - val_accuracy: 0.8082\n",
      "Epoch 840/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4633 - accuracy: 0.7969 - val_loss: 0.4963 - val_accuracy: 0.7998\n",
      "Epoch 841/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4796 - accuracy: 0.8037 - val_loss: 0.4562 - val_accuracy: 0.8079\n",
      "Epoch 842/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4605 - accuracy: 0.7892 - val_loss: 0.4571 - val_accuracy: 0.8066\n",
      "Epoch 843/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4685 - accuracy: 0.7691 - val_loss: 0.6249 - val_accuracy: 0.4324\n",
      "Epoch 844/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4651 - accuracy: 0.7834 - val_loss: 0.4530 - val_accuracy: 0.8050\n",
      "Epoch 845/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4691 - accuracy: 0.7758 - val_loss: 0.4692 - val_accuracy: 0.8081\n",
      "Epoch 846/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4803 - accuracy: 0.8002 - val_loss: 0.4565 - val_accuracy: 0.8087\n",
      "Epoch 847/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4690 - accuracy: 0.8059 - val_loss: 0.4729 - val_accuracy: 0.8077\n",
      "Epoch 848/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4636 - accuracy: 0.8016 - val_loss: 0.4727 - val_accuracy: 0.8085\n",
      "Epoch 849/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4689 - accuracy: 0.7671 - val_loss: 0.4510 - val_accuracy: 0.7884\n",
      "Epoch 850/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4747 - accuracy: 0.7320 - val_loss: 0.4514 - val_accuracy: 0.7855\n",
      "Epoch 851/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4650 - accuracy: 0.7812 - val_loss: 0.4505 - val_accuracy: 0.7945\n",
      "Epoch 852/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4606 - accuracy: 0.7923 - val_loss: 0.4503 - val_accuracy: 0.7977\n",
      "Epoch 853/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4676 - accuracy: 0.7854 - val_loss: 0.4724 - val_accuracy: 0.8083\n",
      "Epoch 854/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4698 - accuracy: 0.7621 - val_loss: 0.4735 - val_accuracy: 0.8076\n",
      "Epoch 855/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4649 - accuracy: 0.8060 - val_loss: 0.4669 - val_accuracy: 0.8086\n",
      "Epoch 856/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4669 - accuracy: 0.7870 - val_loss: 0.4582 - val_accuracy: 0.7684\n",
      "Epoch 857/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4665 - accuracy: 0.7783 - val_loss: 0.4694 - val_accuracy: 0.7114\n",
      "Epoch 858/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4629 - accuracy: 0.7688 - val_loss: 0.4517 - val_accuracy: 0.7987\n",
      "Epoch 859/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4605 - accuracy: 0.7878 - val_loss: 0.4507 - val_accuracy: 0.7962\n",
      "Epoch 860/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4692 - accuracy: 0.8042 - val_loss: 0.4638 - val_accuracy: 0.8089\n",
      "Epoch 861/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4682 - accuracy: 0.8070 - val_loss: 0.4720 - val_accuracy: 0.8076\n",
      "Epoch 862/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4693 - accuracy: 0.8057 - val_loss: 0.4543 - val_accuracy: 0.8035\n",
      "Epoch 863/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4680 - accuracy: 0.8049 - val_loss: 0.4644 - val_accuracy: 0.8090\n",
      "Epoch 864/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4743 - accuracy: 0.8027 - val_loss: 0.4667 - val_accuracy: 0.8090\n",
      "Epoch 865/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4658 - accuracy: 0.7753 - val_loss: 0.4544 - val_accuracy: 0.7718\n",
      "Epoch 866/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4786 - accuracy: 0.7484 - val_loss: 0.5063 - val_accuracy: 0.7165\n",
      "Epoch 867/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4775 - accuracy: 0.7571 - val_loss: 0.4507 - val_accuracy: 0.7967\n",
      "Epoch 868/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4671 - accuracy: 0.7999 - val_loss: 0.4530 - val_accuracy: 0.7850\n",
      "Epoch 869/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4713 - accuracy: 0.7717 - val_loss: 0.4646 - val_accuracy: 0.8089\n",
      "Epoch 870/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4603 - accuracy: 0.7936 - val_loss: 0.4520 - val_accuracy: 0.8030\n",
      "Epoch 871/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4697 - accuracy: 0.7850 - val_loss: 0.4662 - val_accuracy: 0.7843\n",
      "Epoch 872/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4657 - accuracy: 0.8052 - val_loss: 0.4716 - val_accuracy: 0.8081\n",
      "Epoch 873/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4734 - accuracy: 0.7871 - val_loss: 0.4506 - val_accuracy: 0.7987\n",
      "Epoch 874/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4616 - accuracy: 0.7978 - val_loss: 0.4530 - val_accuracy: 0.8045\n",
      "Epoch 875/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4682 - accuracy: 0.8035 - val_loss: 0.4929 - val_accuracy: 0.8008\n",
      "Epoch 876/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4745 - accuracy: 0.7920 - val_loss: 0.4644 - val_accuracy: 0.8094\n",
      "Epoch 877/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4626 - accuracy: 0.7837 - val_loss: 0.4540 - val_accuracy: 0.7643\n",
      "Epoch 878/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5378 - accuracy: 0.7307 - val_loss: 0.5925 - val_accuracy: 0.7165\n",
      "Epoch 879/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.5928 - accuracy: 0.7156 - val_loss: 0.5854 - val_accuracy: 0.7165\n",
      "Epoch 880/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4967 - accuracy: 0.7390 - val_loss: 0.4503 - val_accuracy: 0.7830\n",
      "Epoch 881/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4613 - accuracy: 0.7788 - val_loss: 0.4615 - val_accuracy: 0.8089\n",
      "Epoch 882/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4646 - accuracy: 0.8047 - val_loss: 0.4696 - val_accuracy: 0.8084\n",
      "Epoch 883/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4667 - accuracy: 0.7803 - val_loss: 0.6345 - val_accuracy: 0.7163\n",
      "Epoch 884/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4769 - accuracy: 0.7336 - val_loss: 0.6066 - val_accuracy: 0.7163\n",
      "Epoch 885/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4854 - accuracy: 0.7258 - val_loss: 0.4637 - val_accuracy: 0.7163\n",
      "Epoch 886/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4685 - accuracy: 0.7996 - val_loss: 0.4693 - val_accuracy: 0.8087\n",
      "Epoch 887/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4776 - accuracy: 0.8061 - val_loss: 0.4764 - val_accuracy: 0.8069\n",
      "Epoch 888/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4769 - accuracy: 0.8066 - val_loss: 0.4730 - val_accuracy: 0.8081\n",
      "Epoch 889/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4626 - accuracy: 0.7981 - val_loss: 0.4684 - val_accuracy: 0.8090\n",
      "Epoch 890/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4625 - accuracy: 0.7790 - val_loss: 0.4550 - val_accuracy: 0.8065\n",
      "Epoch 891/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4618 - accuracy: 0.7718 - val_loss: 0.4822 - val_accuracy: 0.7314\n",
      "Epoch 892/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4617 - accuracy: 0.7974 - val_loss: 0.4508 - val_accuracy: 0.7882\n",
      "Epoch 893/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4661 - accuracy: 0.7787 - val_loss: 0.4771 - val_accuracy: 0.8069\n",
      "Epoch 894/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4601 - accuracy: 0.7953 - val_loss: 0.4502 - val_accuracy: 0.7961\n",
      "Epoch 895/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4648 - accuracy: 0.7733 - val_loss: 0.4869 - val_accuracy: 0.6727\n",
      "Epoch 896/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4733 - accuracy: 0.7674 - val_loss: 0.4634 - val_accuracy: 0.8093\n",
      "Epoch 897/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4686 - accuracy: 0.7621 - val_loss: 0.4545 - val_accuracy: 0.7965\n",
      "Epoch 898/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4642 - accuracy: 0.7827 - val_loss: 0.4511 - val_accuracy: 0.7795\n",
      "Epoch 899/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4622 - accuracy: 0.7719 - val_loss: 0.4510 - val_accuracy: 0.7992\n",
      "Epoch 900/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4632 - accuracy: 0.7698 - val_loss: 0.5219 - val_accuracy: 0.6494\n",
      "Epoch 901/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4677 - accuracy: 0.7454 - val_loss: 0.4558 - val_accuracy: 0.7642\n",
      "Epoch 902/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4579 - accuracy: 0.7831 - val_loss: 0.4569 - val_accuracy: 0.8096\n",
      "Epoch 903/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4811 - accuracy: 0.7458 - val_loss: 0.4521 - val_accuracy: 0.7788\n",
      "Epoch 904/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4642 - accuracy: 0.7979 - val_loss: 0.4569 - val_accuracy: 0.8096\n",
      "Epoch 905/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4689 - accuracy: 0.7746 - val_loss: 0.4581 - val_accuracy: 0.7629\n",
      "Epoch 906/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4584 - accuracy: 0.7836 - val_loss: 0.4496 - val_accuracy: 0.7945\n",
      "Epoch 907/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4590 - accuracy: 0.7816 - val_loss: 0.4514 - val_accuracy: 0.7801\n",
      "Epoch 908/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4589 - accuracy: 0.7813 - val_loss: 0.4549 - val_accuracy: 0.7651\n",
      "Epoch 909/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4587 - accuracy: 0.7926 - val_loss: 0.4627 - val_accuracy: 0.8100\n",
      "Epoch 910/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4650 - accuracy: 0.8052 - val_loss: 0.4518 - val_accuracy: 0.7933\n",
      "Epoch 911/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4700 - accuracy: 0.7578 - val_loss: 0.4529 - val_accuracy: 0.8075\n",
      "Epoch 912/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4641 - accuracy: 0.7974 - val_loss: 0.4645 - val_accuracy: 0.8094\n",
      "Epoch 913/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4707 - accuracy: 0.7867 - val_loss: 0.4746 - val_accuracy: 0.8091\n",
      "Epoch 914/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4587 - accuracy: 0.7967 - val_loss: 0.4617 - val_accuracy: 0.8101\n",
      "Epoch 915/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4658 - accuracy: 0.7951 - val_loss: 0.4563 - val_accuracy: 0.8081\n",
      "Epoch 916/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4639 - accuracy: 0.7931 - val_loss: 0.4511 - val_accuracy: 0.8005\n",
      "Epoch 917/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4684 - accuracy: 0.8062 - val_loss: 0.4538 - val_accuracy: 0.8081\n",
      "Epoch 918/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4603 - accuracy: 0.8006 - val_loss: 0.4540 - val_accuracy: 0.8087\n",
      "Epoch 919/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4682 - accuracy: 0.8021 - val_loss: 0.4496 - val_accuracy: 0.7980\n",
      "Epoch 920/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4669 - accuracy: 0.8072 - val_loss: 0.4628 - val_accuracy: 0.8100\n",
      "Epoch 921/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4640 - accuracy: 0.8040 - val_loss: 0.4608 - val_accuracy: 0.8104\n",
      "Epoch 922/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4609 - accuracy: 0.7803 - val_loss: 0.4584 - val_accuracy: 0.7558\n",
      "Epoch 923/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4602 - accuracy: 0.7881 - val_loss: 0.4500 - val_accuracy: 0.8027\n",
      "Epoch 924/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4622 - accuracy: 0.7891 - val_loss: 0.4698 - val_accuracy: 0.8095\n",
      "Epoch 925/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4651 - accuracy: 0.7887 - val_loss: 0.5415 - val_accuracy: 0.5860\n",
      "Epoch 926/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4990 - accuracy: 0.7252 - val_loss: 0.4577 - val_accuracy: 0.8076\n",
      "Epoch 927/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4624 - accuracy: 0.7992 - val_loss: 0.4586 - val_accuracy: 0.7582\n",
      "Epoch 928/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4645 - accuracy: 0.7802 - val_loss: 0.4496 - val_accuracy: 0.8022\n",
      "Epoch 929/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4633 - accuracy: 0.7950 - val_loss: 0.4499 - val_accuracy: 0.7987\n",
      "Epoch 930/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4697 - accuracy: 0.7663 - val_loss: 0.4502 - val_accuracy: 0.8031\n",
      "Epoch 931/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4623 - accuracy: 0.8027 - val_loss: 0.4524 - val_accuracy: 0.7931\n",
      "Epoch 932/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4681 - accuracy: 0.7533 - val_loss: 0.4561 - val_accuracy: 0.8050\n",
      "Epoch 933/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4616 - accuracy: 0.7765 - val_loss: 0.4507 - val_accuracy: 0.7818\n",
      "Epoch 934/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4686 - accuracy: 0.7858 - val_loss: 0.4745 - val_accuracy: 0.8077\n",
      "Epoch 935/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4669 - accuracy: 0.7607 - val_loss: 0.4534 - val_accuracy: 0.7681\n",
      "Epoch 936/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4618 - accuracy: 0.7793 - val_loss: 0.4491 - val_accuracy: 0.7897\n",
      "Epoch 937/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4586 - accuracy: 0.7910 - val_loss: 0.4571 - val_accuracy: 0.8095\n",
      "Epoch 938/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4639 - accuracy: 0.8053 - val_loss: 0.4550 - val_accuracy: 0.8096\n",
      "Epoch 939/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4646 - accuracy: 0.7653 - val_loss: 0.4506 - val_accuracy: 0.7903\n",
      "Epoch 940/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4772 - accuracy: 0.7306 - val_loss: 0.4560 - val_accuracy: 0.7993\n",
      "Epoch 941/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4652 - accuracy: 0.7813 - val_loss: 0.4561 - val_accuracy: 0.8099\n",
      "Epoch 942/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4712 - accuracy: 0.7591 - val_loss: 0.4601 - val_accuracy: 0.8099\n",
      "Epoch 943/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4740 - accuracy: 0.7706 - val_loss: 0.4538 - val_accuracy: 0.8072\n",
      "Epoch 944/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4617 - accuracy: 0.8002 - val_loss: 0.4531 - val_accuracy: 0.7718\n",
      "Epoch 945/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4615 - accuracy: 0.7863 - val_loss: 0.5496 - val_accuracy: 0.6322\n",
      "Epoch 946/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4749 - accuracy: 0.7456 - val_loss: 0.4663 - val_accuracy: 0.8094\n",
      "Epoch 947/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4739 - accuracy: 0.7943 - val_loss: 0.4750 - val_accuracy: 0.8076\n",
      "Epoch 948/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4682 - accuracy: 0.7748 - val_loss: 0.4524 - val_accuracy: 0.7815\n",
      "Epoch 949/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4603 - accuracy: 0.7938 - val_loss: 0.4492 - val_accuracy: 0.7863\n",
      "Epoch 950/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4597 - accuracy: 0.7839 - val_loss: 0.4536 - val_accuracy: 0.8073\n",
      "Epoch 951/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4685 - accuracy: 0.7809 - val_loss: 0.4496 - val_accuracy: 0.7929\n",
      "Epoch 952/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4668 - accuracy: 0.7669 - val_loss: 0.4545 - val_accuracy: 0.8085\n",
      "Epoch 953/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4650 - accuracy: 0.8007 - val_loss: 0.4499 - val_accuracy: 0.7987\n",
      "Epoch 954/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4715 - accuracy: 0.7666 - val_loss: 0.4794 - val_accuracy: 0.8061\n",
      "Epoch 955/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4622 - accuracy: 0.7998 - val_loss: 0.4501 - val_accuracy: 0.7997\n",
      "Epoch 956/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4655 - accuracy: 0.7729 - val_loss: 0.4517 - val_accuracy: 0.7781\n",
      "Epoch 957/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4641 - accuracy: 0.7775 - val_loss: 0.4557 - val_accuracy: 0.8053\n",
      "Epoch 958/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4614 - accuracy: 0.7967 - val_loss: 0.4531 - val_accuracy: 0.8075\n",
      "Epoch 959/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4602 - accuracy: 0.7960 - val_loss: 0.4837 - val_accuracy: 0.8055\n",
      "Epoch 960/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4651 - accuracy: 0.7878 - val_loss: 0.4542 - val_accuracy: 0.7619\n",
      "Epoch 961/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4616 - accuracy: 0.7674 - val_loss: 0.4498 - val_accuracy: 0.7830\n",
      "Epoch 962/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4593 - accuracy: 0.7920 - val_loss: 0.4637 - val_accuracy: 0.7379\n",
      "Epoch 963/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4644 - accuracy: 0.7607 - val_loss: 0.4522 - val_accuracy: 0.8041\n",
      "Epoch 964/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4654 - accuracy: 0.7954 - val_loss: 0.4613 - val_accuracy: 0.7514\n",
      "Epoch 965/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4619 - accuracy: 0.7897 - val_loss: 0.4643 - val_accuracy: 0.8097\n",
      "Epoch 966/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4613 - accuracy: 0.7910 - val_loss: 0.4734 - val_accuracy: 0.8086\n",
      "Epoch 967/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4644 - accuracy: 0.7662 - val_loss: 0.4545 - val_accuracy: 0.7863\n",
      "Epoch 968/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4658 - accuracy: 0.7732 - val_loss: 0.4501 - val_accuracy: 0.7893\n",
      "Epoch 969/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4675 - accuracy: 0.8030 - val_loss: 0.4881 - val_accuracy: 0.8032\n",
      "Epoch 970/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4659 - accuracy: 0.7818 - val_loss: 0.4752 - val_accuracy: 0.6965\n",
      "Epoch 971/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4933 - accuracy: 0.7218 - val_loss: 0.4541 - val_accuracy: 0.7997\n",
      "Epoch 972/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4651 - accuracy: 0.7905 - val_loss: 0.4603 - val_accuracy: 0.8097\n",
      "Epoch 973/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4675 - accuracy: 0.7712 - val_loss: 0.4508 - val_accuracy: 0.7877\n",
      "Epoch 974/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4649 - accuracy: 0.7867 - val_loss: 0.4586 - val_accuracy: 0.8091\n",
      "Epoch 975/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4688 - accuracy: 0.7497 - val_loss: 0.4635 - val_accuracy: 0.8097\n",
      "Epoch 976/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4645 - accuracy: 0.7861 - val_loss: 0.4726 - val_accuracy: 0.8085\n",
      "Epoch 977/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4663 - accuracy: 0.7848 - val_loss: 0.4539 - val_accuracy: 0.7742\n",
      "Epoch 978/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4634 - accuracy: 0.7994 - val_loss: 0.4549 - val_accuracy: 0.8096\n",
      "Epoch 979/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4631 - accuracy: 0.7992 - val_loss: 0.4500 - val_accuracy: 0.7929\n",
      "Epoch 980/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4635 - accuracy: 0.7675 - val_loss: 0.4566 - val_accuracy: 0.8098\n",
      "Epoch 981/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4782 - accuracy: 0.8058 - val_loss: 0.4550 - val_accuracy: 0.8058\n",
      "Epoch 982/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4666 - accuracy: 0.8076 - val_loss: 0.4564 - val_accuracy: 0.8100\n",
      "Epoch 983/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4692 - accuracy: 0.7635 - val_loss: 0.4506 - val_accuracy: 0.7940\n",
      "Epoch 984/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4578 - accuracy: 0.7980 - val_loss: 0.4528 - val_accuracy: 0.8073\n",
      "Epoch 985/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4681 - accuracy: 0.7858 - val_loss: 0.4802 - val_accuracy: 0.8060\n",
      "Epoch 986/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4664 - accuracy: 0.7943 - val_loss: 0.4589 - val_accuracy: 0.7475\n",
      "Epoch 987/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4613 - accuracy: 0.7799 - val_loss: 0.4537 - val_accuracy: 0.8058\n",
      "Epoch 988/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4688 - accuracy: 0.7611 - val_loss: 0.4501 - val_accuracy: 0.8039\n",
      "Epoch 989/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4683 - accuracy: 0.8071 - val_loss: 0.4531 - val_accuracy: 0.8084\n",
      "Epoch 990/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4606 - accuracy: 0.7924 - val_loss: 0.4535 - val_accuracy: 0.7692\n",
      "Epoch 991/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4635 - accuracy: 0.7760 - val_loss: 0.4593 - val_accuracy: 0.7501\n",
      "Epoch 992/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4790 - accuracy: 0.7280 - val_loss: 0.4563 - val_accuracy: 0.7163\n",
      "Epoch 993/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4679 - accuracy: 0.7857 - val_loss: 0.4668 - val_accuracy: 0.8093\n",
      "Epoch 994/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4644 - accuracy: 0.8033 - val_loss: 0.4795 - val_accuracy: 0.7168\n",
      "Epoch 995/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4706 - accuracy: 0.7558 - val_loss: 0.4755 - val_accuracy: 0.7221\n",
      "Epoch 996/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4669 - accuracy: 0.7587 - val_loss: 0.4553 - val_accuracy: 0.8082\n",
      "Epoch 997/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4668 - accuracy: 0.7807 - val_loss: 0.4718 - val_accuracy: 0.8092\n",
      "Epoch 998/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4603 - accuracy: 0.7842 - val_loss: 0.4905 - val_accuracy: 0.6932\n",
      "Epoch 999/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4610 - accuracy: 0.7768 - val_loss: 0.4546 - val_accuracy: 0.8073\n",
      "Epoch 1000/1000\n",
      "152/152 [==============================] - 1s 5ms/step - loss: 0.4671 - accuracy: 0.7680 - val_loss: 0.4585 - val_accuracy: 0.8092\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1024\n",
    "\n",
    "name=\"Simple-1-layer-network\"\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        keras.layers.Flatten(),        \n",
    "        keras.layers.Dense(64, activation='sigmoid'),\n",
    "        keras.layers.Dense(1, activation='sigmoid')\n",
    "    ],name=name\n",
    ")\n",
    "\n",
    "# Save weights for comparability\n",
    "model.save_weights('model.h5')\n",
    "\n",
    "model.load_weights('model.h5')\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=SGD(learning_rate=0.00001), metrics=[\"accuracy\"])\n",
    "\n",
    "history_lr_00001=model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_val,y_val))\n",
    "\n",
    "model.load_weights('model.h5')\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=SGD(learning_rate=0.0001), metrics=[\"accuracy\"])\n",
    "\n",
    "history_lr_0001=model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_val,y_val))\n",
    "\n",
    "model.load_weights('model.h5')\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=SGD(learning_rate=0.001), metrics=[\"accuracy\"])\n",
    "\n",
    "history_lr_001=model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_val,y_val))\n",
    "\n",
    "model.load_weights('model.h5')\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=SGD(learning_rate=0.01), metrics=[\"accuracy\"])\n",
    "\n",
    "history_lr_01=model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_a8baf68c_cec5_11eb_ac08_40e230e37f37\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >loss</th>        <th class=\"col_heading level0 col1\" >accuracy</th>        <th class=\"col_heading level0 col2\" >val_loss</th>        <th class=\"col_heading level0 col3\" >val_accuracy</th>    </tr>    <tr>        <th class=\"index_name level0\" >learning rate</th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_a8baf68c_cec5_11eb_ac08_40e230e37f37level0_row0\" class=\"row_heading level0 row0\" >0.00001</th>\n",
       "                        <td id=\"T_a8baf68c_cec5_11eb_ac08_40e230e37f37row0_col0\" class=\"data row0 col0\" >45.71%</td>\n",
       "                        <td id=\"T_a8baf68c_cec5_11eb_ac08_40e230e37f37row0_col1\" class=\"data row0 col1\" >79.79%</td>\n",
       "                        <td id=\"T_a8baf68c_cec5_11eb_ac08_40e230e37f37row0_col2\" class=\"data row0 col2\" >45.68%</td>\n",
       "                        <td id=\"T_a8baf68c_cec5_11eb_ac08_40e230e37f37row0_col3\" class=\"data row0 col3\" >79.65%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a8baf68c_cec5_11eb_ac08_40e230e37f37level0_row1\" class=\"row_heading level0 row1\" >0.0001</th>\n",
       "                        <td id=\"T_a8baf68c_cec5_11eb_ac08_40e230e37f37row1_col0\" class=\"data row1 col0\" >40.40%</td>\n",
       "                        <td id=\"T_a8baf68c_cec5_11eb_ac08_40e230e37f37row1_col1\" class=\"data row1 col1\" >82.30%</td>\n",
       "                        <td id=\"T_a8baf68c_cec5_11eb_ac08_40e230e37f37row1_col2\" class=\"data row1 col2\" >41.52%</td>\n",
       "                        <td id=\"T_a8baf68c_cec5_11eb_ac08_40e230e37f37row1_col3\" class=\"data row1 col3\" >81.53%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a8baf68c_cec5_11eb_ac08_40e230e37f37level0_row2\" class=\"row_heading level0 row2\" >0.001</th>\n",
       "                        <td id=\"T_a8baf68c_cec5_11eb_ac08_40e230e37f37row2_col0\" class=\"data row2 col0\" >40.56%</td>\n",
       "                        <td id=\"T_a8baf68c_cec5_11eb_ac08_40e230e37f37row2_col1\" class=\"data row2 col1\" >82.13%</td>\n",
       "                        <td id=\"T_a8baf68c_cec5_11eb_ac08_40e230e37f37row2_col2\" class=\"data row2 col2\" >40.67%</td>\n",
       "                        <td id=\"T_a8baf68c_cec5_11eb_ac08_40e230e37f37row2_col3\" class=\"data row2 col3\" >81.99%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a8baf68c_cec5_11eb_ac08_40e230e37f37level0_row3\" class=\"row_heading level0 row3\" >0.01</th>\n",
       "                        <td id=\"T_a8baf68c_cec5_11eb_ac08_40e230e37f37row3_col0\" class=\"data row3 col0\" >46.71%</td>\n",
       "                        <td id=\"T_a8baf68c_cec5_11eb_ac08_40e230e37f37row3_col1\" class=\"data row3 col1\" >76.80%</td>\n",
       "                        <td id=\"T_a8baf68c_cec5_11eb_ac08_40e230e37f37row3_col2\" class=\"data row3 col2\" >45.85%</td>\n",
       "                        <td id=\"T_a8baf68c_cec5_11eb_ac08_40e230e37f37row3_col3\" class=\"data row3 col3\" >80.92%</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1dc30af1288>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['learning rate' ,'loss', 'accuracy', 'val_loss', 'val_accuracy']\n",
    "df_simple_nets = pd.DataFrame(columns = columns)\n",
    "\n",
    "df_temp00001 = pd.DataFrame([['0.00001',\n",
    "                              history_lr_00001.history['loss'][-1],\n",
    "                              history_lr_00001.history['accuracy'][-1],\n",
    "                              history_lr_00001.history['val_loss'][-1],\n",
    "                              history_lr_00001.history['val_accuracy'][-1]]], \n",
    "                    columns = columns)\n",
    "df_temp0001 = pd.DataFrame([['0.0001',\n",
    "                             history_lr_0001.history['loss'][-1],\n",
    "                             history_lr_0001.history['accuracy'][-1],\n",
    "                             history_lr_0001.history['val_loss'][-1],\n",
    "                             history_lr_0001.history['val_accuracy'][-1]]], \n",
    "                    columns = columns)\n",
    "df_temp001 = pd.DataFrame([['0.001',\n",
    "                            history_lr_001.history['loss'][-1],\n",
    "                            history_lr_001.history['accuracy'][-1],\n",
    "                            history_lr_001.history['val_loss'][-1],\n",
    "                            history_lr_001.history['val_accuracy'][-1]]], \n",
    "                    columns = columns)\n",
    "df_temp01 = pd.DataFrame([['0.01',\n",
    "                           history_lr_01.history['loss'][-1],\n",
    "                           history_lr_01.history['accuracy'][-1],\n",
    "                           history_lr_01.history['val_loss'][-1],\n",
    "                           history_lr_01.history['val_accuracy'][-1]]], \n",
    "                    columns = columns)\n",
    "\n",
    "df_simple_nets = df_simple_nets.append(df_temp00001)\n",
    "df_simple_nets = df_simple_nets.append(df_temp0001)\n",
    "df_simple_nets = df_simple_nets.append(df_temp001)\n",
    "df_simple_nets = df_simple_nets.append(df_temp01)\n",
    "df_simple_nets = df_simple_nets.set_index('learning rate')\n",
    "\n",
    "df_simple_nets = df_simple_nets.style.format({\n",
    "    'loss': '{:,.2%}'.format,\n",
    "    'accuracy': '{:,.2%}'.format,\n",
    "    'val_loss': '{:,.2%}'.format,\n",
    "    'val_accuracy': '{:,.2%}'.format,\n",
    "})\n",
    "\n",
    "df_simple_nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learnings\n",
    "While the accuracy is very similar for all learning rates, the learning rate of 0.001 resulted in the lowest train & validation loss, while also having a slightly higher accuracy than the other leaning rates.\n",
    "\n",
    "Following we plot the accuracy, loss and the confusion matrix for the learningn rate 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot accuracy\n",
    "plt = acc_plot(history_lr_01)\n",
    "plt.show()\n",
    "\n",
    "# plot loss\n",
    "plt = loss_plot(history_lr_01)\n",
    "plt.show()\n",
    "\n",
    "# plot confuction matrix\n",
    "plt=conf_matrix(model, x_test, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_lr_00001.history['accuracy'], alpha=.8)\n",
    "\n",
    "plt.plot(history_lr_0001.history['accuracy'], alpha=.8)\n",
    "\n",
    "plt.plot(history_lr_001.history['accuracy'], alpha=.8)\n",
    "\n",
    "plt.plot(history_lr_01.history['accuracy'], alpha=.8)\n",
    "\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['0.00001', '0.0001', '0.001', '0.01'], loc='lower right')\n",
    "plt.title('train accuracy per learning rate')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history_lr_00001.history['val_accuracy'], alpha=.8)\n",
    "\n",
    "plt.plot(history_lr_0001.history['val_accuracy'], alpha=.8)\n",
    "\n",
    "plt.plot(history_lr_001.history['val_accuracy'], alpha=.8)\n",
    "\n",
    "plt.plot(history_lr_01.history['val_accuracy'], alpha=.8)\n",
    "\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['0.00001', '0.0001', '0.001', '0.01'], loc='lower right')\n",
    "plt.title('validation accuracy per learning rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on test data\n",
      "651/651 [==============================] - 1s 1ms/step - loss: 0.4629 - accuracy: 0.8065\n",
      "test loss 0.46,\n",
      "test acc: 0.81\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data using `evaluate`\n",
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(x_test, y_test, batch_size=128)\n",
    "print(F\"test loss {results[0]:.2f},\\ntest acc: {results[1]:1.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try more hidden nodes and adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-layer-64\n",
      "Epoch 1/250\n",
      "152/152 - 3s - loss: 127.7808 - accuracy: 0.6694 - val_loss: 69.7047 - val_accuracy: 0.7164\n",
      "Epoch 2/250\n",
      "152/152 - 1s - loss: 29.1338 - accuracy: 0.7005 - val_loss: 12.2812 - val_accuracy: 0.7972\n",
      "Epoch 3/250\n",
      "152/152 - 1s - loss: 21.8506 - accuracy: 0.7283 - val_loss: 8.6981 - val_accuracy: 0.8057\n",
      "Epoch 4/250\n",
      "152/152 - 1s - loss: 16.6813 - accuracy: 0.7372 - val_loss: 10.8355 - val_accuracy: 0.7727\n",
      "Epoch 5/250\n",
      "152/152 - 1s - loss: 20.2493 - accuracy: 0.7182 - val_loss: 5.8832 - val_accuracy: 0.7927\n",
      "Epoch 6/250\n",
      "152/152 - 1s - loss: 18.3606 - accuracy: 0.7108 - val_loss: 19.2136 - val_accuracy: 0.7434\n",
      "Epoch 7/250\n",
      "152/152 - 1s - loss: 14.7778 - accuracy: 0.7208 - val_loss: 33.8230 - val_accuracy: 0.3023\n",
      "Epoch 8/250\n",
      "152/152 - 1s - loss: 12.5844 - accuracy: 0.7414 - val_loss: 4.6980 - val_accuracy: 0.7997\n",
      "Epoch 9/250\n",
      "152/152 - 1s - loss: 19.1114 - accuracy: 0.7187 - val_loss: 4.9341 - val_accuracy: 0.7919\n",
      "Epoch 10/250\n",
      "152/152 - 1s - loss: 8.7091 - accuracy: 0.7240 - val_loss: 3.4611 - val_accuracy: 0.7972\n",
      "Epoch 11/250\n",
      "152/152 - 1s - loss: 7.9408 - accuracy: 0.7210 - val_loss: 12.1110 - val_accuracy: 0.7337\n",
      "Epoch 12/250\n",
      "152/152 - 1s - loss: 11.6927 - accuracy: 0.6887 - val_loss: 12.2815 - val_accuracy: 0.7458\n",
      "Epoch 13/250\n",
      "152/152 - 1s - loss: 4.5759 - accuracy: 0.7724 - val_loss: 2.0994 - val_accuracy: 0.8038\n",
      "Epoch 14/250\n",
      "152/152 - 1s - loss: 5.3625 - accuracy: 0.7283 - val_loss: 2.0909 - val_accuracy: 0.7996\n",
      "Epoch 15/250\n",
      "152/152 - 1s - loss: 6.3700 - accuracy: 0.6954 - val_loss: 4.8989 - val_accuracy: 0.7639\n",
      "Epoch 16/250\n",
      "152/152 - 1s - loss: 4.2479 - accuracy: 0.7345 - val_loss: 2.3239 - val_accuracy: 0.7926\n",
      "Epoch 17/250\n",
      "152/152 - 1s - loss: 4.9685 - accuracy: 0.7249 - val_loss: 6.4549 - val_accuracy: 0.7383\n",
      "Epoch 18/250\n",
      "152/152 - 1s - loss: 2.9093 - accuracy: 0.7458 - val_loss: 1.3198 - val_accuracy: 0.7912\n",
      "Epoch 19/250\n",
      "152/152 - 1s - loss: 4.9042 - accuracy: 0.7283 - val_loss: 1.2187 - val_accuracy: 0.7917\n",
      "Epoch 20/250\n",
      "152/152 - 1s - loss: 2.4613 - accuracy: 0.7369 - val_loss: 1.0200 - val_accuracy: 0.7918\n",
      "Epoch 21/250\n",
      "152/152 - 1s - loss: 3.5138 - accuracy: 0.6920 - val_loss: 2.3345 - val_accuracy: 0.7712\n",
      "Epoch 22/250\n",
      "152/152 - 1s - loss: 1.6630 - accuracy: 0.7665 - val_loss: 0.8165 - val_accuracy: 0.7891\n",
      "Epoch 23/250\n",
      "152/152 - 1s - loss: 2.2874 - accuracy: 0.7177 - val_loss: 1.0356 - val_accuracy: 0.7830\n",
      "Epoch 24/250\n",
      "152/152 - 1s - loss: 1.7976 - accuracy: 0.7406 - val_loss: 0.8303 - val_accuracy: 0.7938\n",
      "Epoch 25/250\n",
      "152/152 - 1s - loss: 1.6972 - accuracy: 0.7333 - val_loss: 5.9925 - val_accuracy: 0.7164\n",
      "Epoch 26/250\n",
      "152/152 - 1s - loss: 1.3429 - accuracy: 0.7461 - val_loss: 2.1687 - val_accuracy: 0.3970\n",
      "Epoch 27/250\n",
      "152/152 - 1s - loss: 1.0222 - accuracy: 0.7496 - val_loss: 0.9085 - val_accuracy: 0.7624\n",
      "Epoch 28/250\n",
      "152/152 - 1s - loss: 1.5541 - accuracy: 0.7182 - val_loss: 0.6128 - val_accuracy: 0.7896\n",
      "Epoch 29/250\n",
      "152/152 - 1s - loss: 1.1906 - accuracy: 0.7475 - val_loss: 0.5599 - val_accuracy: 0.7946\n",
      "Epoch 30/250\n",
      "152/152 - 1s - loss: 0.6955 - accuracy: 0.7598 - val_loss: 0.5247 - val_accuracy: 0.7913\n",
      "Epoch 31/250\n",
      "152/152 - 1s - loss: 0.5192 - accuracy: 0.7872 - val_loss: 0.5455 - val_accuracy: 0.7615\n",
      "Epoch 32/250\n",
      "152/152 - 1s - loss: 0.7139 - accuracy: 0.7454 - val_loss: 1.0640 - val_accuracy: 0.5115\n",
      "Epoch 33/250\n",
      "152/152 - 1s - loss: 0.6220 - accuracy: 0.7622 - val_loss: 0.4707 - val_accuracy: 0.7968\n",
      "Epoch 34/250\n",
      "152/152 - 1s - loss: 0.4585 - accuracy: 0.7992 - val_loss: 0.4496 - val_accuracy: 0.8023\n",
      "Epoch 35/250\n",
      "152/152 - 1s - loss: 0.4601 - accuracy: 0.7966 - val_loss: 0.4611 - val_accuracy: 0.7957\n",
      "Epoch 36/250\n",
      "152/152 - 1s - loss: 0.4690 - accuracy: 0.7939 - val_loss: 0.4393 - val_accuracy: 0.8055\n",
      "Epoch 37/250\n",
      "152/152 - 1s - loss: 0.7817 - accuracy: 0.7362 - val_loss: 0.4373 - val_accuracy: 0.8082\n",
      "Epoch 38/250\n",
      "152/152 - 1s - loss: 0.4349 - accuracy: 0.8078 - val_loss: 0.4246 - val_accuracy: 0.8088\n",
      "Epoch 39/250\n",
      "152/152 - 1s - loss: 0.4247 - accuracy: 0.8115 - val_loss: 0.4723 - val_accuracy: 0.7891\n",
      "Epoch 40/250\n",
      "152/152 - 1s - loss: 0.4264 - accuracy: 0.8102 - val_loss: 0.4289 - val_accuracy: 0.8108\n",
      "Epoch 41/250\n",
      "152/152 - 1s - loss: 0.4294 - accuracy: 0.8088 - val_loss: 0.4257 - val_accuracy: 0.8092\n",
      "Epoch 42/250\n",
      "152/152 - 1s - loss: 0.4242 - accuracy: 0.8112 - val_loss: 0.4374 - val_accuracy: 0.8056\n",
      "Epoch 43/250\n",
      "152/152 - 1s - loss: 0.4215 - accuracy: 0.8131 - val_loss: 0.4187 - val_accuracy: 0.8108\n",
      "Epoch 44/250\n",
      "152/152 - 1s - loss: 0.4209 - accuracy: 0.8127 - val_loss: 0.4285 - val_accuracy: 0.8099\n",
      "Epoch 45/250\n",
      "152/152 - 1s - loss: 0.4126 - accuracy: 0.8168 - val_loss: 0.4092 - val_accuracy: 0.8184\n",
      "Epoch 46/250\n",
      "152/152 - 1s - loss: 0.4172 - accuracy: 0.8143 - val_loss: 0.4072 - val_accuracy: 0.8199\n",
      "Epoch 47/250\n",
      "152/152 - 1s - loss: 0.4154 - accuracy: 0.8162 - val_loss: 0.4081 - val_accuracy: 0.8207\n",
      "Epoch 48/250\n",
      "152/152 - 1s - loss: 0.4121 - accuracy: 0.8175 - val_loss: 0.4393 - val_accuracy: 0.8053\n",
      "Epoch 49/250\n",
      "152/152 - 1s - loss: 0.4150 - accuracy: 0.8170 - val_loss: 0.4346 - val_accuracy: 0.8036\n",
      "Epoch 50/250\n",
      "152/152 - 1s - loss: 0.4149 - accuracy: 0.8169 - val_loss: 0.4187 - val_accuracy: 0.8120\n",
      "Epoch 51/250\n",
      "152/152 - 1s - loss: 0.4129 - accuracy: 0.8171 - val_loss: 0.4255 - val_accuracy: 0.8100\n",
      "Epoch 52/250\n",
      "152/152 - 1s - loss: 0.4093 - accuracy: 0.8201 - val_loss: 0.4067 - val_accuracy: 0.8222\n",
      "Epoch 53/250\n",
      "152/152 - 1s - loss: 0.4066 - accuracy: 0.8211 - val_loss: 0.4164 - val_accuracy: 0.8162\n",
      "Epoch 54/250\n",
      "152/152 - 1s - loss: 0.4066 - accuracy: 0.8216 - val_loss: 0.4089 - val_accuracy: 0.8222\n",
      "Epoch 55/250\n",
      "152/152 - 1s - loss: 0.4083 - accuracy: 0.8201 - val_loss: 0.4082 - val_accuracy: 0.8213\n",
      "Epoch 56/250\n",
      "152/152 - 1s - loss: 0.4050 - accuracy: 0.8226 - val_loss: 0.4086 - val_accuracy: 0.8215\n",
      "Epoch 57/250\n",
      "152/152 - 1s - loss: 0.4114 - accuracy: 0.8200 - val_loss: 0.3995 - val_accuracy: 0.8264\n",
      "Epoch 58/250\n",
      "152/152 - 1s - loss: 0.4056 - accuracy: 0.8222 - val_loss: 0.4052 - val_accuracy: 0.8218\n",
      "Epoch 59/250\n",
      "152/152 - 1s - loss: 0.4068 - accuracy: 0.8208 - val_loss: 0.4096 - val_accuracy: 0.8189\n",
      "Epoch 60/250\n",
      "152/152 - 1s - loss: 0.4079 - accuracy: 0.8202 - val_loss: 0.4052 - val_accuracy: 0.8216\n",
      "Epoch 61/250\n",
      "152/152 - 1s - loss: 0.4017 - accuracy: 0.8244 - val_loss: 0.3970 - val_accuracy: 0.8253\n",
      "Epoch 62/250\n",
      "152/152 - 1s - loss: 0.4023 - accuracy: 0.8233 - val_loss: 0.3958 - val_accuracy: 0.8250\n",
      "Epoch 63/250\n",
      "152/152 - 1s - loss: 0.4072 - accuracy: 0.8210 - val_loss: 0.3974 - val_accuracy: 0.8246\n",
      "Epoch 64/250\n",
      "152/152 - 1s - loss: 0.4081 - accuracy: 0.8209 - val_loss: 0.3991 - val_accuracy: 0.8235\n",
      "Epoch 65/250\n",
      "152/152 - 1s - loss: 0.4056 - accuracy: 0.8221 - val_loss: 0.3972 - val_accuracy: 0.8253\n",
      "Epoch 66/250\n",
      "152/152 - 1s - loss: 0.4045 - accuracy: 0.8222 - val_loss: 0.3950 - val_accuracy: 0.8249\n",
      "Epoch 67/250\n",
      "152/152 - 1s - loss: 0.4016 - accuracy: 0.8240 - val_loss: 0.3972 - val_accuracy: 0.8254\n",
      "Epoch 68/250\n",
      "152/152 - 1s - loss: 0.4097 - accuracy: 0.8201 - val_loss: 0.4098 - val_accuracy: 0.8204\n",
      "Epoch 69/250\n",
      "152/152 - 1s - loss: 0.4029 - accuracy: 0.8233 - val_loss: 0.3961 - val_accuracy: 0.8260\n",
      "Epoch 70/250\n",
      "152/152 - 1s - loss: 0.4058 - accuracy: 0.8207 - val_loss: 0.4015 - val_accuracy: 0.8232\n",
      "Epoch 71/250\n",
      "152/152 - 1s - loss: 0.4100 - accuracy: 0.8202 - val_loss: 0.4039 - val_accuracy: 0.8242\n",
      "Epoch 72/250\n",
      "152/152 - 1s - loss: 0.4058 - accuracy: 0.8221 - val_loss: 0.3955 - val_accuracy: 0.8250\n",
      "Epoch 73/250\n",
      "152/152 - 1s - loss: 0.4045 - accuracy: 0.8225 - val_loss: 0.4011 - val_accuracy: 0.8264\n",
      "Epoch 74/250\n",
      "152/152 - 1s - loss: 0.4035 - accuracy: 0.8232 - val_loss: 0.4565 - val_accuracy: 0.8084\n",
      "Epoch 75/250\n",
      "152/152 - 1s - loss: 0.4048 - accuracy: 0.8214 - val_loss: 0.4244 - val_accuracy: 0.8139\n",
      "Epoch 76/250\n",
      "152/152 - 1s - loss: 0.4090 - accuracy: 0.8200 - val_loss: 0.4445 - val_accuracy: 0.8098\n",
      "Epoch 77/250\n",
      "152/152 - 1s - loss: 0.4113 - accuracy: 0.8194 - val_loss: 0.4118 - val_accuracy: 0.8186\n",
      "Epoch 78/250\n",
      "152/152 - 1s - loss: 0.4085 - accuracy: 0.8205 - val_loss: 0.3972 - val_accuracy: 0.8243\n",
      "Epoch 79/250\n",
      "152/152 - 1s - loss: 0.4050 - accuracy: 0.8221 - val_loss: 0.4016 - val_accuracy: 0.8223\n",
      "Epoch 80/250\n",
      "152/152 - 1s - loss: 0.4039 - accuracy: 0.8226 - val_loss: 0.3977 - val_accuracy: 0.8241\n",
      "Epoch 81/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 - 1s - loss: 0.4052 - accuracy: 0.8223 - val_loss: 0.4075 - val_accuracy: 0.8208\n",
      "Epoch 82/250\n",
      "152/152 - 1s - loss: 0.4053 - accuracy: 0.8222 - val_loss: 0.4054 - val_accuracy: 0.8206\n",
      "Epoch 83/250\n",
      "152/152 - 1s - loss: 0.4071 - accuracy: 0.8216 - val_loss: 0.3968 - val_accuracy: 0.8253\n",
      "Epoch 84/250\n",
      "152/152 - 1s - loss: 0.4131 - accuracy: 0.8196 - val_loss: 0.4375 - val_accuracy: 0.8118\n",
      "Epoch 85/250\n",
      "152/152 - 1s - loss: 0.4162 - accuracy: 0.8185 - val_loss: 0.4380 - val_accuracy: 0.8147\n",
      "Epoch 86/250\n",
      "152/152 - 1s - loss: 0.4034 - accuracy: 0.8227 - val_loss: 0.3940 - val_accuracy: 0.8244\n",
      "Epoch 87/250\n",
      "152/152 - 1s - loss: 0.4110 - accuracy: 0.8202 - val_loss: 0.4319 - val_accuracy: 0.8144\n",
      "Epoch 88/250\n",
      "152/152 - 1s - loss: 0.4040 - accuracy: 0.8227 - val_loss: 0.4062 - val_accuracy: 0.8182\n",
      "Epoch 89/250\n",
      "152/152 - 1s - loss: 0.4018 - accuracy: 0.8237 - val_loss: 0.3974 - val_accuracy: 0.8249\n",
      "Epoch 90/250\n",
      "152/152 - 1s - loss: 0.4004 - accuracy: 0.8239 - val_loss: 0.4025 - val_accuracy: 0.8232\n",
      "Epoch 91/250\n",
      "152/152 - 1s - loss: 0.4091 - accuracy: 0.8213 - val_loss: 0.4024 - val_accuracy: 0.8240\n",
      "Epoch 92/250\n",
      "152/152 - 1s - loss: 0.4028 - accuracy: 0.8235 - val_loss: 0.4036 - val_accuracy: 0.8231\n",
      "Epoch 93/250\n",
      "152/152 - 1s - loss: 0.4074 - accuracy: 0.8222 - val_loss: 0.4137 - val_accuracy: 0.8215\n",
      "Epoch 94/250\n",
      "152/152 - 1s - loss: 0.4085 - accuracy: 0.8213 - val_loss: 0.4038 - val_accuracy: 0.8243\n",
      "Epoch 95/250\n",
      "152/152 - 1s - loss: 0.4096 - accuracy: 0.8214 - val_loss: 0.3955 - val_accuracy: 0.8260\n",
      "Epoch 96/250\n",
      "152/152 - 1s - loss: 0.4009 - accuracy: 0.8236 - val_loss: 0.3950 - val_accuracy: 0.8258\n",
      "Epoch 97/250\n",
      "152/152 - 1s - loss: 0.4083 - accuracy: 0.8208 - val_loss: 0.4066 - val_accuracy: 0.8210\n",
      "Epoch 98/250\n",
      "152/152 - 1s - loss: 0.4093 - accuracy: 0.8209 - val_loss: 0.4057 - val_accuracy: 0.8190\n",
      "Epoch 99/250\n",
      "152/152 - 1s - loss: 0.3991 - accuracy: 0.8244 - val_loss: 0.3950 - val_accuracy: 0.8252\n",
      "Epoch 100/250\n",
      "152/152 - 1s - loss: 0.4126 - accuracy: 0.8207 - val_loss: 0.4478 - val_accuracy: 0.8216\n",
      "Epoch 101/250\n",
      "152/152 - 1s - loss: 0.4034 - accuracy: 0.8234 - val_loss: 0.3972 - val_accuracy: 0.8267\n",
      "Epoch 102/250\n",
      "152/152 - 1s - loss: 0.4079 - accuracy: 0.8219 - val_loss: 0.3967 - val_accuracy: 0.8260\n",
      "Epoch 103/250\n",
      "152/152 - 1s - loss: 0.4020 - accuracy: 0.8239 - val_loss: 0.4082 - val_accuracy: 0.8226\n",
      "Epoch 104/250\n",
      "152/152 - 1s - loss: 0.4226 - accuracy: 0.8158 - val_loss: 0.4245 - val_accuracy: 0.7980\n",
      "Epoch 105/250\n",
      "152/152 - 1s - loss: 0.4126 - accuracy: 0.8181 - val_loss: 0.4122 - val_accuracy: 0.8196\n",
      "Epoch 106/250\n",
      "152/152 - 1s - loss: 0.4095 - accuracy: 0.8208 - val_loss: 0.4275 - val_accuracy: 0.8167\n",
      "Epoch 107/250\n",
      "152/152 - 1s - loss: 0.4108 - accuracy: 0.8206 - val_loss: 0.4041 - val_accuracy: 0.8229\n",
      "Epoch 108/250\n",
      "152/152 - 1s - loss: 0.4107 - accuracy: 0.8202 - val_loss: 0.4139 - val_accuracy: 0.8174\n",
      "Epoch 109/250\n",
      "152/152 - 1s - loss: 0.4064 - accuracy: 0.8220 - val_loss: 0.4033 - val_accuracy: 0.8240\n",
      "Epoch 110/250\n",
      "152/152 - 1s - loss: 0.4076 - accuracy: 0.8218 - val_loss: 0.4002 - val_accuracy: 0.8245\n",
      "Epoch 111/250\n",
      "152/152 - 1s - loss: 0.4055 - accuracy: 0.8215 - val_loss: 0.4103 - val_accuracy: 0.8192\n",
      "Epoch 112/250\n",
      "152/152 - 1s - loss: 0.4145 - accuracy: 0.8190 - val_loss: 0.4224 - val_accuracy: 0.8204\n",
      "Epoch 113/250\n",
      "152/152 - 1s - loss: 0.4074 - accuracy: 0.8215 - val_loss: 0.4125 - val_accuracy: 0.8216\n",
      "Epoch 114/250\n",
      "152/152 - 1s - loss: 0.4044 - accuracy: 0.8225 - val_loss: 0.3984 - val_accuracy: 0.8260\n",
      "Epoch 115/250\n",
      "152/152 - 1s - loss: 0.4013 - accuracy: 0.8238 - val_loss: 0.4070 - val_accuracy: 0.8215\n",
      "Epoch 116/250\n",
      "152/152 - 1s - loss: 0.4014 - accuracy: 0.8238 - val_loss: 0.4040 - val_accuracy: 0.8250\n",
      "Epoch 117/250\n",
      "152/152 - 1s - loss: 0.4023 - accuracy: 0.8232 - val_loss: 0.4146 - val_accuracy: 0.8192\n",
      "Epoch 118/250\n",
      "152/152 - 1s - loss: 0.4037 - accuracy: 0.8226 - val_loss: 0.3964 - val_accuracy: 0.8258\n",
      "Epoch 119/250\n",
      "152/152 - 1s - loss: 0.4014 - accuracy: 0.8230 - val_loss: 0.4027 - val_accuracy: 0.8249\n",
      "Epoch 120/250\n",
      "152/152 - 1s - loss: 0.4037 - accuracy: 0.8230 - val_loss: 0.4073 - val_accuracy: 0.8221\n",
      "Epoch 121/250\n",
      "152/152 - 1s - loss: 0.4031 - accuracy: 0.8236 - val_loss: 0.3985 - val_accuracy: 0.8224\n",
      "Epoch 122/250\n",
      "152/152 - 1s - loss: 0.4031 - accuracy: 0.8236 - val_loss: 0.4150 - val_accuracy: 0.8159\n",
      "Epoch 123/250\n",
      "152/152 - 1s - loss: 0.4026 - accuracy: 0.8236 - val_loss: 0.3985 - val_accuracy: 0.8253\n",
      "Epoch 124/250\n",
      "152/152 - 1s - loss: 0.4045 - accuracy: 0.8226 - val_loss: 0.4035 - val_accuracy: 0.8206\n",
      "Epoch 125/250\n",
      "152/152 - 1s - loss: 0.4007 - accuracy: 0.8245 - val_loss: 0.4010 - val_accuracy: 0.8239\n",
      "Epoch 126/250\n",
      "152/152 - 1s - loss: 0.4008 - accuracy: 0.8243 - val_loss: 0.3964 - val_accuracy: 0.8258\n",
      "Epoch 127/250\n",
      "152/152 - 1s - loss: 0.3994 - accuracy: 0.8249 - val_loss: 0.3988 - val_accuracy: 0.8265\n",
      "Epoch 128/250\n",
      "152/152 - 1s - loss: 0.4000 - accuracy: 0.8246 - val_loss: 0.4074 - val_accuracy: 0.8211\n",
      "Epoch 129/250\n",
      "152/152 - 1s - loss: 0.4023 - accuracy: 0.8235 - val_loss: 0.3985 - val_accuracy: 0.8256\n",
      "Epoch 130/250\n",
      "152/152 - 1s - loss: 0.4024 - accuracy: 0.8241 - val_loss: 0.3981 - val_accuracy: 0.8253\n",
      "Epoch 131/250\n",
      "152/152 - 1s - loss: 0.4023 - accuracy: 0.8237 - val_loss: 0.4234 - val_accuracy: 0.8146\n",
      "Epoch 132/250\n",
      "152/152 - 1s - loss: 0.4090 - accuracy: 0.8215 - val_loss: 0.3950 - val_accuracy: 0.8275\n",
      "Epoch 133/250\n",
      "152/152 - 1s - loss: 0.4013 - accuracy: 0.8243 - val_loss: 0.3958 - val_accuracy: 0.8259\n",
      "Epoch 134/250\n",
      "152/152 - 1s - loss: 0.3951 - accuracy: 0.8265 - val_loss: 0.3963 - val_accuracy: 0.8268\n",
      "Epoch 135/250\n",
      "152/152 - 1s - loss: 0.4065 - accuracy: 0.8219 - val_loss: 0.3964 - val_accuracy: 0.8265\n",
      "Epoch 136/250\n",
      "152/152 - 1s - loss: 0.3963 - accuracy: 0.8265 - val_loss: 0.3963 - val_accuracy: 0.8269\n",
      "Epoch 137/250\n",
      "152/152 - 1s - loss: 0.3990 - accuracy: 0.8250 - val_loss: 0.3963 - val_accuracy: 0.8266\n",
      "Epoch 138/250\n",
      "152/152 - 1s - loss: 0.3970 - accuracy: 0.8260 - val_loss: 0.4098 - val_accuracy: 0.8220\n",
      "Epoch 139/250\n",
      "152/152 - 1s - loss: 0.4004 - accuracy: 0.8253 - val_loss: 0.3972 - val_accuracy: 0.8252\n",
      "Epoch 140/250\n",
      "152/152 - 1s - loss: 0.3971 - accuracy: 0.8263 - val_loss: 0.4068 - val_accuracy: 0.8251\n",
      "Epoch 141/250\n",
      "152/152 - 1s - loss: 0.4014 - accuracy: 0.8241 - val_loss: 0.3972 - val_accuracy: 0.8277\n",
      "Epoch 142/250\n",
      "152/152 - 1s - loss: 0.4026 - accuracy: 0.8239 - val_loss: 0.4011 - val_accuracy: 0.8241\n",
      "Epoch 143/250\n",
      "152/152 - 1s - loss: 0.3974 - accuracy: 0.8266 - val_loss: 0.4218 - val_accuracy: 0.8150\n",
      "Epoch 144/250\n",
      "152/152 - 1s - loss: 0.3951 - accuracy: 0.8271 - val_loss: 0.3953 - val_accuracy: 0.8272\n",
      "Epoch 145/250\n",
      "152/152 - 1s - loss: 0.3985 - accuracy: 0.8261 - val_loss: 0.4006 - val_accuracy: 0.8256\n",
      "Epoch 146/250\n",
      "152/152 - 1s - loss: 0.4002 - accuracy: 0.8247 - val_loss: 0.3953 - val_accuracy: 0.8268\n",
      "Epoch 147/250\n",
      "152/152 - 1s - loss: 0.3976 - accuracy: 0.8256 - val_loss: 0.3972 - val_accuracy: 0.8249\n",
      "Epoch 148/250\n",
      "152/152 - 1s - loss: 0.3947 - accuracy: 0.8275 - val_loss: 0.4054 - val_accuracy: 0.8246\n",
      "Epoch 149/250\n",
      "152/152 - 1s - loss: 0.4023 - accuracy: 0.8250 - val_loss: 0.4090 - val_accuracy: 0.8142\n",
      "Epoch 150/250\n",
      "152/152 - 1s - loss: 0.3948 - accuracy: 0.8271 - val_loss: 0.3957 - val_accuracy: 0.8262\n",
      "Epoch 151/250\n",
      "152/152 - 1s - loss: 0.4013 - accuracy: 0.8254 - val_loss: 0.4024 - val_accuracy: 0.8219\n",
      "Epoch 152/250\n",
      "152/152 - 1s - loss: 0.3955 - accuracy: 0.8273 - val_loss: 0.3953 - val_accuracy: 0.8262\n",
      "Epoch 153/250\n",
      "152/152 - 1s - loss: 0.3930 - accuracy: 0.8280 - val_loss: 0.3947 - val_accuracy: 0.8281\n",
      "Epoch 154/250\n",
      "152/152 - 1s - loss: 0.3960 - accuracy: 0.8270 - val_loss: 0.4230 - val_accuracy: 0.8152\n",
      "Epoch 155/250\n",
      "152/152 - 1s - loss: 0.3985 - accuracy: 0.8264 - val_loss: 0.3986 - val_accuracy: 0.8265\n",
      "Epoch 156/250\n",
      "152/152 - 1s - loss: 0.4012 - accuracy: 0.8254 - val_loss: 0.3955 - val_accuracy: 0.8269\n",
      "Epoch 157/250\n",
      "152/152 - 1s - loss: 0.3950 - accuracy: 0.8274 - val_loss: 0.3975 - val_accuracy: 0.8262\n",
      "Epoch 158/250\n",
      "152/152 - 1s - loss: 0.3927 - accuracy: 0.8277 - val_loss: 0.4132 - val_accuracy: 0.8205\n",
      "Epoch 159/250\n",
      "152/152 - 1s - loss: 0.3919 - accuracy: 0.8288 - val_loss: 0.4148 - val_accuracy: 0.8213\n",
      "Epoch 160/250\n",
      "152/152 - 1s - loss: 0.4008 - accuracy: 0.8249 - val_loss: 0.4343 - val_accuracy: 0.8104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/250\n",
      "152/152 - 1s - loss: 0.3952 - accuracy: 0.8271 - val_loss: 0.4021 - val_accuracy: 0.8244\n",
      "Epoch 162/250\n",
      "152/152 - 1s - loss: 0.3970 - accuracy: 0.8267 - val_loss: 0.4056 - val_accuracy: 0.8270\n",
      "Epoch 163/250\n",
      "152/152 - 1s - loss: 0.3917 - accuracy: 0.8286 - val_loss: 0.4006 - val_accuracy: 0.8235\n",
      "Epoch 164/250\n",
      "152/152 - 1s - loss: 0.3983 - accuracy: 0.8265 - val_loss: 0.4278 - val_accuracy: 0.8165\n",
      "Epoch 165/250\n",
      "152/152 - 1s - loss: 0.3902 - accuracy: 0.8284 - val_loss: 0.4016 - val_accuracy: 0.8238\n",
      "Epoch 166/250\n",
      "152/152 - 1s - loss: 0.3946 - accuracy: 0.8264 - val_loss: 0.3968 - val_accuracy: 0.8245\n",
      "Epoch 167/250\n",
      "152/152 - 1s - loss: 0.3959 - accuracy: 0.8259 - val_loss: 0.4085 - val_accuracy: 0.8210\n",
      "Epoch 168/250\n",
      "152/152 - 1s - loss: 0.4025 - accuracy: 0.8232 - val_loss: 0.3994 - val_accuracy: 0.8252\n",
      "Epoch 169/250\n",
      "152/152 - 1s - loss: 0.4047 - accuracy: 0.8214 - val_loss: 0.4022 - val_accuracy: 0.8241\n",
      "Epoch 170/250\n",
      "152/152 - 1s - loss: 0.3919 - accuracy: 0.8279 - val_loss: 0.4007 - val_accuracy: 0.8268\n",
      "Epoch 171/250\n",
      "152/152 - 1s - loss: 0.3992 - accuracy: 0.8263 - val_loss: 0.3991 - val_accuracy: 0.8241\n",
      "Epoch 172/250\n",
      "152/152 - 1s - loss: 0.3998 - accuracy: 0.8254 - val_loss: 0.3993 - val_accuracy: 0.8233\n",
      "Epoch 173/250\n",
      "152/152 - 1s - loss: 0.3982 - accuracy: 0.8245 - val_loss: 0.4031 - val_accuracy: 0.8256\n",
      "Epoch 174/250\n",
      "152/152 - 1s - loss: 0.3955 - accuracy: 0.8260 - val_loss: 0.4107 - val_accuracy: 0.8224\n",
      "Epoch 175/250\n",
      "152/152 - 1s - loss: 0.3982 - accuracy: 0.8259 - val_loss: 0.3949 - val_accuracy: 0.8271\n",
      "Epoch 176/250\n",
      "152/152 - 1s - loss: 0.3989 - accuracy: 0.8256 - val_loss: 0.4024 - val_accuracy: 0.8245\n",
      "Epoch 177/250\n",
      "152/152 - 1s - loss: 0.3956 - accuracy: 0.8254 - val_loss: 0.3999 - val_accuracy: 0.8234\n",
      "Epoch 178/250\n",
      "152/152 - 1s - loss: 0.3940 - accuracy: 0.8262 - val_loss: 0.4137 - val_accuracy: 0.8192\n",
      "Epoch 179/250\n",
      "152/152 - 1s - loss: 0.3947 - accuracy: 0.8260 - val_loss: 0.3999 - val_accuracy: 0.8232\n",
      "Epoch 180/250\n",
      "152/152 - 1s - loss: 0.4003 - accuracy: 0.8247 - val_loss: 0.4022 - val_accuracy: 0.8234\n",
      "Epoch 181/250\n",
      "152/152 - 1s - loss: 0.3936 - accuracy: 0.8263 - val_loss: 0.4052 - val_accuracy: 0.8194\n",
      "Epoch 182/250\n",
      "152/152 - 1s - loss: 0.3954 - accuracy: 0.8255 - val_loss: 0.4221 - val_accuracy: 0.8147\n",
      "Epoch 183/250\n",
      "152/152 - 1s - loss: 0.3952 - accuracy: 0.8266 - val_loss: 0.4028 - val_accuracy: 0.8218\n",
      "Epoch 184/250\n",
      "152/152 - 1s - loss: 0.3977 - accuracy: 0.8251 - val_loss: 0.3995 - val_accuracy: 0.8238\n",
      "Epoch 185/250\n",
      "152/152 - 1s - loss: 0.3956 - accuracy: 0.8270 - val_loss: 0.4033 - val_accuracy: 0.8227\n",
      "Epoch 186/250\n",
      "152/152 - 1s - loss: 0.4009 - accuracy: 0.8243 - val_loss: 0.4309 - val_accuracy: 0.8190\n",
      "Epoch 187/250\n",
      "152/152 - 1s - loss: 0.3947 - accuracy: 0.8268 - val_loss: 0.4117 - val_accuracy: 0.8236\n",
      "Epoch 188/250\n",
      "152/152 - 1s - loss: 0.3959 - accuracy: 0.8262 - val_loss: 0.4022 - val_accuracy: 0.8208\n",
      "Epoch 189/250\n",
      "152/152 - 1s - loss: 0.3954 - accuracy: 0.8261 - val_loss: 0.4168 - val_accuracy: 0.8139\n",
      "Epoch 190/250\n",
      "152/152 - 1s - loss: 0.3963 - accuracy: 0.8260 - val_loss: 0.3998 - val_accuracy: 0.8255\n",
      "Epoch 191/250\n",
      "152/152 - 1s - loss: 0.3944 - accuracy: 0.8264 - val_loss: 0.4130 - val_accuracy: 0.8193\n",
      "Epoch 192/250\n",
      "152/152 - 1s - loss: 0.3986 - accuracy: 0.8252 - val_loss: 0.3979 - val_accuracy: 0.8250\n",
      "Epoch 193/250\n",
      "152/152 - 1s - loss: 0.3940 - accuracy: 0.8271 - val_loss: 0.3980 - val_accuracy: 0.8250\n",
      "Epoch 194/250\n",
      "152/152 - 1s - loss: 0.3956 - accuracy: 0.8255 - val_loss: 0.4012 - val_accuracy: 0.8232\n",
      "Epoch 195/250\n",
      "152/152 - 1s - loss: 0.3926 - accuracy: 0.8276 - val_loss: 0.4094 - val_accuracy: 0.8207\n",
      "Epoch 196/250\n",
      "152/152 - 1s - loss: 0.3950 - accuracy: 0.8268 - val_loss: 0.4154 - val_accuracy: 0.8186\n",
      "Epoch 197/250\n",
      "152/152 - 1s - loss: 0.3956 - accuracy: 0.8262 - val_loss: 0.4045 - val_accuracy: 0.8237\n",
      "Epoch 198/250\n",
      "152/152 - 1s - loss: 0.3918 - accuracy: 0.8275 - val_loss: 0.4046 - val_accuracy: 0.8206\n",
      "Epoch 199/250\n",
      "152/152 - 1s - loss: 0.3944 - accuracy: 0.8261 - val_loss: 0.4030 - val_accuracy: 0.8199\n",
      "Epoch 200/250\n",
      "152/152 - 1s - loss: 0.3939 - accuracy: 0.8264 - val_loss: 0.3998 - val_accuracy: 0.8238\n",
      "Epoch 201/250\n",
      "152/152 - 1s - loss: 0.3934 - accuracy: 0.8276 - val_loss: 0.3989 - val_accuracy: 0.8245\n",
      "Epoch 202/250\n",
      "152/152 - 1s - loss: 0.3963 - accuracy: 0.8254 - val_loss: 0.4056 - val_accuracy: 0.8192\n",
      "Epoch 203/250\n",
      "152/152 - 1s - loss: 0.3940 - accuracy: 0.8271 - val_loss: 0.3987 - val_accuracy: 0.8243\n",
      "Epoch 204/250\n",
      "152/152 - 1s - loss: 0.3990 - accuracy: 0.8252 - val_loss: 0.4040 - val_accuracy: 0.8223\n",
      "Epoch 205/250\n",
      "152/152 - 1s - loss: 0.3941 - accuracy: 0.8271 - val_loss: 0.4066 - val_accuracy: 0.8226\n",
      "Epoch 206/250\n",
      "152/152 - 1s - loss: 0.3984 - accuracy: 0.8256 - val_loss: 0.4008 - val_accuracy: 0.8217\n",
      "Epoch 207/250\n",
      "152/152 - 1s - loss: 0.3948 - accuracy: 0.8267 - val_loss: 0.4081 - val_accuracy: 0.8184\n",
      "Epoch 208/250\n",
      "152/152 - 1s - loss: 0.3955 - accuracy: 0.8261 - val_loss: 0.4013 - val_accuracy: 0.8223\n",
      "Epoch 209/250\n",
      "152/152 - 1s - loss: 0.3909 - accuracy: 0.8290 - val_loss: 0.3994 - val_accuracy: 0.8229\n",
      "Epoch 210/250\n",
      "152/152 - 1s - loss: 0.3924 - accuracy: 0.8281 - val_loss: 0.4032 - val_accuracy: 0.8207\n",
      "Epoch 211/250\n",
      "152/152 - 1s - loss: 0.3926 - accuracy: 0.8279 - val_loss: 0.4023 - val_accuracy: 0.8228\n",
      "Epoch 212/250\n",
      "152/152 - 1s - loss: 0.3926 - accuracy: 0.8273 - val_loss: 0.4009 - val_accuracy: 0.8245\n",
      "Epoch 213/250\n",
      "152/152 - 1s - loss: 0.3939 - accuracy: 0.8277 - val_loss: 0.4031 - val_accuracy: 0.8201\n",
      "Epoch 214/250\n",
      "152/152 - 1s - loss: 0.3960 - accuracy: 0.8262 - val_loss: 0.3998 - val_accuracy: 0.8230\n",
      "Epoch 215/250\n",
      "152/152 - 1s - loss: 0.3950 - accuracy: 0.8270 - val_loss: 0.4023 - val_accuracy: 0.8239\n",
      "Epoch 216/250\n",
      "152/152 - 1s - loss: 0.3950 - accuracy: 0.8262 - val_loss: 0.4012 - val_accuracy: 0.8221\n",
      "Epoch 217/250\n",
      "152/152 - 1s - loss: 0.3923 - accuracy: 0.8275 - val_loss: 0.4061 - val_accuracy: 0.8203\n",
      "Epoch 218/250\n",
      "152/152 - 1s - loss: 0.3904 - accuracy: 0.8290 - val_loss: 0.3991 - val_accuracy: 0.8226\n",
      "Epoch 219/250\n",
      "152/152 - 1s - loss: 0.3907 - accuracy: 0.8279 - val_loss: 0.4080 - val_accuracy: 0.8238\n",
      "Epoch 220/250\n",
      "152/152 - 1s - loss: 0.3952 - accuracy: 0.8269 - val_loss: 0.4191 - val_accuracy: 0.8128\n",
      "Epoch 221/250\n",
      "152/152 - 1s - loss: 0.3966 - accuracy: 0.8269 - val_loss: 0.3985 - val_accuracy: 0.8233\n",
      "Epoch 222/250\n",
      "152/152 - 1s - loss: 0.3920 - accuracy: 0.8287 - val_loss: 0.4000 - val_accuracy: 0.8236\n",
      "Epoch 223/250\n",
      "152/152 - 1s - loss: 0.3975 - accuracy: 0.8271 - val_loss: 0.4045 - val_accuracy: 0.8216\n",
      "Epoch 224/250\n",
      "152/152 - 1s - loss: 0.3944 - accuracy: 0.8278 - val_loss: 0.4417 - val_accuracy: 0.8191\n",
      "Epoch 225/250\n",
      "152/152 - 1s - loss: 0.3915 - accuracy: 0.8281 - val_loss: 0.4062 - val_accuracy: 0.8244\n",
      "Epoch 226/250\n",
      "152/152 - 1s - loss: 0.3929 - accuracy: 0.8278 - val_loss: 0.4022 - val_accuracy: 0.8232\n",
      "Epoch 227/250\n",
      "152/152 - 1s - loss: 0.3918 - accuracy: 0.8286 - val_loss: 0.4004 - val_accuracy: 0.8239\n",
      "Epoch 228/250\n",
      "152/152 - 1s - loss: 0.3934 - accuracy: 0.8279 - val_loss: 0.4049 - val_accuracy: 0.8243\n",
      "Epoch 229/250\n",
      "152/152 - 1s - loss: 0.3908 - accuracy: 0.8284 - val_loss: 0.4028 - val_accuracy: 0.8209\n",
      "Epoch 230/250\n",
      "152/152 - 1s - loss: 0.3906 - accuracy: 0.8292 - val_loss: 0.3989 - val_accuracy: 0.8238\n",
      "Epoch 231/250\n",
      "152/152 - 1s - loss: 0.3919 - accuracy: 0.8290 - val_loss: 0.4281 - val_accuracy: 0.8150\n",
      "Epoch 232/250\n",
      "152/152 - 1s - loss: 0.3919 - accuracy: 0.8283 - val_loss: 0.4099 - val_accuracy: 0.8180\n",
      "Epoch 233/250\n",
      "152/152 - 1s - loss: 0.3931 - accuracy: 0.8276 - val_loss: 0.4230 - val_accuracy: 0.8128\n",
      "Epoch 234/250\n",
      "152/152 - 1s - loss: 0.3899 - accuracy: 0.8284 - val_loss: 0.3998 - val_accuracy: 0.8239\n",
      "Epoch 235/250\n",
      "152/152 - 1s - loss: 0.3943 - accuracy: 0.8278 - val_loss: 0.4366 - val_accuracy: 0.8201\n",
      "Epoch 236/250\n",
      "152/152 - 1s - loss: 0.3927 - accuracy: 0.8280 - val_loss: 0.4141 - val_accuracy: 0.8145\n",
      "Epoch 237/250\n",
      "152/152 - 1s - loss: 0.3919 - accuracy: 0.8283 - val_loss: 0.4052 - val_accuracy: 0.8204\n",
      "Epoch 238/250\n",
      "152/152 - 1s - loss: 0.3914 - accuracy: 0.8288 - val_loss: 0.4094 - val_accuracy: 0.8233\n",
      "Epoch 239/250\n",
      "152/152 - 1s - loss: 0.3917 - accuracy: 0.8278 - val_loss: 0.4053 - val_accuracy: 0.8220\n",
      "Epoch 240/250\n",
      "152/152 - 1s - loss: 0.3986 - accuracy: 0.8264 - val_loss: 0.4080 - val_accuracy: 0.8226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/250\n",
      "152/152 - 1s - loss: 0.3914 - accuracy: 0.8282 - val_loss: 0.4173 - val_accuracy: 0.8169\n",
      "Epoch 242/250\n",
      "152/152 - 1s - loss: 0.3915 - accuracy: 0.8288 - val_loss: 0.4131 - val_accuracy: 0.8191\n",
      "Epoch 243/250\n",
      "152/152 - 1s - loss: 0.3932 - accuracy: 0.8279 - val_loss: 0.4008 - val_accuracy: 0.8232\n",
      "Epoch 244/250\n",
      "152/152 - 1s - loss: 0.3917 - accuracy: 0.8284 - val_loss: 0.4506 - val_accuracy: 0.8189\n",
      "Epoch 245/250\n",
      "152/152 - 1s - loss: 0.3960 - accuracy: 0.8272 - val_loss: 0.4197 - val_accuracy: 0.8104\n",
      "Epoch 246/250\n",
      "152/152 - 1s - loss: 0.3901 - accuracy: 0.8292 - val_loss: 0.3986 - val_accuracy: 0.8240\n",
      "Epoch 247/250\n",
      "152/152 - 1s - loss: 0.3904 - accuracy: 0.8285 - val_loss: 0.4046 - val_accuracy: 0.8239\n",
      "Epoch 248/250\n",
      "152/152 - 1s - loss: 0.3907 - accuracy: 0.8289 - val_loss: 0.4092 - val_accuracy: 0.8241\n",
      "Epoch 249/250\n",
      "152/152 - 1s - loss: 0.3920 - accuracy: 0.8282 - val_loss: 0.4010 - val_accuracy: 0.8243\n",
      "Epoch 250/250\n",
      "152/152 - 1s - loss: 0.3894 - accuracy: 0.8294 - val_loss: 0.4016 - val_accuracy: 0.8236\n",
      "1-layer-128\n",
      "Epoch 1/250\n",
      "152/152 - 1s - loss: 148.1827 - accuracy: 0.6554 - val_loss: 22.9373 - val_accuracy: 0.7576\n",
      "Epoch 2/250\n",
      "152/152 - 1s - loss: 21.4261 - accuracy: 0.7218 - val_loss: 22.4611 - val_accuracy: 0.7464\n",
      "Epoch 3/250\n",
      "152/152 - 1s - loss: 18.1955 - accuracy: 0.7259 - val_loss: 10.9803 - val_accuracy: 0.6401\n",
      "Epoch 4/250\n",
      "152/152 - 1s - loss: 17.5692 - accuracy: 0.7182 - val_loss: 5.4948 - val_accuracy: 0.8086\n",
      "Epoch 5/250\n",
      "152/152 - 1s - loss: 9.2984 - accuracy: 0.7442 - val_loss: 49.2733 - val_accuracy: 0.2861\n",
      "Epoch 6/250\n",
      "152/152 - 1s - loss: 11.2328 - accuracy: 0.7139 - val_loss: 14.4999 - val_accuracy: 0.7287\n",
      "Epoch 7/250\n",
      "152/152 - 1s - loss: 6.8923 - accuracy: 0.7407 - val_loss: 29.5144 - val_accuracy: 0.2865\n",
      "Epoch 8/250\n",
      "152/152 - 1s - loss: 8.2385 - accuracy: 0.7275 - val_loss: 2.3437 - val_accuracy: 0.7176\n",
      "Epoch 9/250\n",
      "152/152 - 1s - loss: 4.6796 - accuracy: 0.7233 - val_loss: 1.6152 - val_accuracy: 0.7962\n",
      "Epoch 10/250\n",
      "152/152 - 1s - loss: 4.8868 - accuracy: 0.7079 - val_loss: 3.0588 - val_accuracy: 0.6804\n",
      "Epoch 11/250\n",
      "152/152 - 1s - loss: 3.0056 - accuracy: 0.7452 - val_loss: 1.2756 - val_accuracy: 0.7854\n",
      "Epoch 12/250\n",
      "152/152 - 1s - loss: 3.3672 - accuracy: 0.7162 - val_loss: 2.8727 - val_accuracy: 0.5827\n",
      "Epoch 13/250\n",
      "152/152 - 1s - loss: 3.3385 - accuracy: 0.7266 - val_loss: 5.1770 - val_accuracy: 0.7239\n",
      "Epoch 14/250\n",
      "152/152 - 1s - loss: 2.4991 - accuracy: 0.7367 - val_loss: 1.3051 - val_accuracy: 0.7809\n",
      "Epoch 15/250\n",
      "152/152 - 1s - loss: 2.5630 - accuracy: 0.7122 - val_loss: 1.1144 - val_accuracy: 0.7922\n",
      "Epoch 16/250\n",
      "152/152 - 1s - loss: 1.3616 - accuracy: 0.7446 - val_loss: 2.2171 - val_accuracy: 0.5232\n",
      "Epoch 17/250\n",
      "152/152 - 1s - loss: 1.7884 - accuracy: 0.7226 - val_loss: 0.9954 - val_accuracy: 0.7842\n",
      "Epoch 18/250\n",
      "152/152 - 1s - loss: 1.1354 - accuracy: 0.7497 - val_loss: 0.6510 - val_accuracy: 0.6314\n",
      "Epoch 19/250\n",
      "152/152 - 1s - loss: 0.4656 - accuracy: 0.7652 - val_loss: 0.4500 - val_accuracy: 0.7856\n",
      "Epoch 20/250\n",
      "152/152 - 1s - loss: 0.4473 - accuracy: 0.7852 - val_loss: 0.4422 - val_accuracy: 0.7948\n",
      "Epoch 21/250\n",
      "152/152 - 1s - loss: 0.4438 - accuracy: 0.7928 - val_loss: 0.4397 - val_accuracy: 0.8005\n",
      "Epoch 22/250\n",
      "152/152 - 1s - loss: 0.4391 - accuracy: 0.8000 - val_loss: 0.4360 - val_accuracy: 0.8074\n",
      "Epoch 23/250\n",
      "152/152 - 1s - loss: 0.4358 - accuracy: 0.8052 - val_loss: 0.4307 - val_accuracy: 0.8040\n",
      "Epoch 24/250\n",
      "152/152 - 1s - loss: 0.4329 - accuracy: 0.8074 - val_loss: 0.4277 - val_accuracy: 0.8098\n",
      "Epoch 25/250\n",
      "152/152 - 1s - loss: 0.4310 - accuracy: 0.8089 - val_loss: 0.4266 - val_accuracy: 0.8070\n",
      "Epoch 26/250\n",
      "152/152 - 1s - loss: 0.4284 - accuracy: 0.8117 - val_loss: 0.4229 - val_accuracy: 0.8158\n",
      "Epoch 27/250\n",
      "152/152 - 1s - loss: 0.4258 - accuracy: 0.8131 - val_loss: 0.4200 - val_accuracy: 0.8156\n",
      "Epoch 28/250\n",
      "152/152 - 1s - loss: 0.4239 - accuracy: 0.8145 - val_loss: 0.4186 - val_accuracy: 0.8148\n",
      "Epoch 29/250\n",
      "152/152 - 1s - loss: 0.4221 - accuracy: 0.8148 - val_loss: 0.4157 - val_accuracy: 0.8171\n",
      "Epoch 30/250\n",
      "152/152 - 1s - loss: 0.4196 - accuracy: 0.8156 - val_loss: 0.4186 - val_accuracy: 0.8149\n",
      "Epoch 31/250\n",
      "152/152 - 1s - loss: 0.4194 - accuracy: 0.8162 - val_loss: 0.4144 - val_accuracy: 0.8189\n",
      "Epoch 32/250\n",
      "152/152 - 1s - loss: 0.4170 - accuracy: 0.8169 - val_loss: 0.4116 - val_accuracy: 0.8192\n",
      "Epoch 33/250\n",
      "152/152 - 1s - loss: 0.4158 - accuracy: 0.8174 - val_loss: 0.4108 - val_accuracy: 0.8202\n",
      "Epoch 34/250\n",
      "152/152 - 1s - loss: 0.4136 - accuracy: 0.8177 - val_loss: 0.4083 - val_accuracy: 0.8194\n",
      "Epoch 35/250\n",
      "152/152 - 1s - loss: 0.4136 - accuracy: 0.8185 - val_loss: 0.4082 - val_accuracy: 0.8193\n",
      "Epoch 36/250\n",
      "152/152 - 1s - loss: 0.4109 - accuracy: 0.8188 - val_loss: 0.4121 - val_accuracy: 0.8188\n",
      "Epoch 37/250\n",
      "152/152 - 1s - loss: 0.4099 - accuracy: 0.8195 - val_loss: 0.4053 - val_accuracy: 0.8207\n",
      "Epoch 38/250\n",
      "152/152 - 1s - loss: 0.4106 - accuracy: 0.8194 - val_loss: 0.4333 - val_accuracy: 0.8158\n",
      "Epoch 39/250\n",
      "152/152 - 1s - loss: 0.4117 - accuracy: 0.8185 - val_loss: 0.4032 - val_accuracy: 0.8209\n",
      "Epoch 40/250\n",
      "152/152 - 1s - loss: 0.4105 - accuracy: 0.8187 - val_loss: 0.4125 - val_accuracy: 0.8158\n",
      "Epoch 41/250\n",
      "152/152 - 1s - loss: 0.4076 - accuracy: 0.8199 - val_loss: 0.4020 - val_accuracy: 0.8209\n",
      "Epoch 42/250\n",
      "152/152 - 1s - loss: 0.4076 - accuracy: 0.8205 - val_loss: 0.4025 - val_accuracy: 0.8222\n",
      "Epoch 43/250\n",
      "152/152 - 1s - loss: 0.4064 - accuracy: 0.8209 - val_loss: 0.4041 - val_accuracy: 0.8210\n",
      "Epoch 44/250\n",
      "152/152 - 1s - loss: 0.4053 - accuracy: 0.8215 - val_loss: 0.4007 - val_accuracy: 0.8238\n",
      "Epoch 45/250\n",
      "152/152 - 1s - loss: 0.4081 - accuracy: 0.8201 - val_loss: 0.4030 - val_accuracy: 0.8232\n",
      "Epoch 46/250\n",
      "152/152 - 1s - loss: 0.4045 - accuracy: 0.8218 - val_loss: 0.3996 - val_accuracy: 0.8223\n",
      "Epoch 47/250\n",
      "152/152 - 1s - loss: 0.4065 - accuracy: 0.8207 - val_loss: 0.4025 - val_accuracy: 0.8193\n",
      "Epoch 48/250\n",
      "152/152 - 1s - loss: 0.4077 - accuracy: 0.8209 - val_loss: 0.4057 - val_accuracy: 0.8209\n",
      "Epoch 49/250\n",
      "152/152 - 1s - loss: 0.4076 - accuracy: 0.8213 - val_loss: 0.4070 - val_accuracy: 0.8180\n",
      "Epoch 50/250\n",
      "152/152 - 1s - loss: 0.4050 - accuracy: 0.8217 - val_loss: 0.4026 - val_accuracy: 0.8249\n",
      "Epoch 51/250\n",
      "152/152 - 1s - loss: 0.4047 - accuracy: 0.8219 - val_loss: 0.3977 - val_accuracy: 0.8251\n",
      "Epoch 52/250\n",
      "152/152 - 1s - loss: 0.4076 - accuracy: 0.8215 - val_loss: 0.4179 - val_accuracy: 0.8163\n",
      "Epoch 53/250\n",
      "152/152 - 1s - loss: 0.4077 - accuracy: 0.8208 - val_loss: 0.4019 - val_accuracy: 0.8260\n",
      "Epoch 54/250\n",
      "152/152 - 1s - loss: 0.4014 - accuracy: 0.8244 - val_loss: 0.3978 - val_accuracy: 0.8257\n",
      "Epoch 55/250\n",
      "152/152 - 1s - loss: 0.4107 - accuracy: 0.8206 - val_loss: 0.4015 - val_accuracy: 0.8224\n",
      "Epoch 56/250\n",
      "152/152 - 1s - loss: 0.4010 - accuracy: 0.8242 - val_loss: 0.3972 - val_accuracy: 0.8261\n",
      "Epoch 57/250\n",
      "152/152 - 1s - loss: 0.4008 - accuracy: 0.8240 - val_loss: 0.3969 - val_accuracy: 0.8245\n",
      "Epoch 58/250\n",
      "152/152 - 1s - loss: 0.4045 - accuracy: 0.8236 - val_loss: 0.3947 - val_accuracy: 0.8265\n",
      "Epoch 59/250\n",
      "152/152 - 1s - loss: 0.4033 - accuracy: 0.8234 - val_loss: 0.4107 - val_accuracy: 0.8241\n",
      "Epoch 60/250\n",
      "152/152 - 1s - loss: 0.4051 - accuracy: 0.8232 - val_loss: 0.3981 - val_accuracy: 0.8276\n",
      "Epoch 61/250\n",
      "152/152 - 1s - loss: 0.4012 - accuracy: 0.8250 - val_loss: 0.3955 - val_accuracy: 0.8258\n",
      "Epoch 62/250\n",
      "152/152 - 1s - loss: 0.4034 - accuracy: 0.8232 - val_loss: 0.3952 - val_accuracy: 0.8270\n",
      "Epoch 63/250\n",
      "152/152 - 1s - loss: 0.4087 - accuracy: 0.8219 - val_loss: 0.4882 - val_accuracy: 0.7747\n",
      "Epoch 64/250\n",
      "152/152 - 1s - loss: 0.4055 - accuracy: 0.8237 - val_loss: 0.4070 - val_accuracy: 0.8236\n",
      "Epoch 65/250\n",
      "152/152 - 1s - loss: 0.4012 - accuracy: 0.8242 - val_loss: 0.3977 - val_accuracy: 0.8223\n",
      "Epoch 66/250\n",
      "152/152 - 1s - loss: 0.4055 - accuracy: 0.8239 - val_loss: 0.3948 - val_accuracy: 0.8260\n",
      "Epoch 67/250\n",
      "152/152 - 1s - loss: 0.4028 - accuracy: 0.8253 - val_loss: 0.3991 - val_accuracy: 0.8269\n",
      "Epoch 68/250\n",
      "152/152 - 1s - loss: 0.4164 - accuracy: 0.8196 - val_loss: 0.4044 - val_accuracy: 0.8262\n",
      "Epoch 69/250\n",
      "152/152 - 1s - loss: 0.4083 - accuracy: 0.8219 - val_loss: 0.3982 - val_accuracy: 0.8269\n",
      "Epoch 70/250\n",
      "152/152 - 1s - loss: 0.3998 - accuracy: 0.8254 - val_loss: 0.4064 - val_accuracy: 0.8218\n",
      "Epoch 71/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 - 1s - loss: 0.4080 - accuracy: 0.8222 - val_loss: 0.4110 - val_accuracy: 0.8221\n",
      "Epoch 72/250\n",
      "152/152 - 1s - loss: 0.4020 - accuracy: 0.8253 - val_loss: 0.4316 - val_accuracy: 0.8153\n",
      "Epoch 73/250\n",
      "152/152 - 1s - loss: 0.4001 - accuracy: 0.8253 - val_loss: 0.4081 - val_accuracy: 0.8233\n",
      "Epoch 74/250\n",
      "152/152 - 1s - loss: 0.4061 - accuracy: 0.8237 - val_loss: 0.4125 - val_accuracy: 0.8213\n",
      "Epoch 75/250\n",
      "152/152 - 1s - loss: 0.4083 - accuracy: 0.8232 - val_loss: 0.4017 - val_accuracy: 0.8274\n",
      "Epoch 76/250\n",
      "152/152 - 1s - loss: 0.4054 - accuracy: 0.8242 - val_loss: 0.4369 - val_accuracy: 0.8169\n",
      "Epoch 77/250\n",
      "152/152 - 1s - loss: 0.3984 - accuracy: 0.8266 - val_loss: 0.3945 - val_accuracy: 0.8291\n",
      "Epoch 78/250\n",
      "152/152 - 1s - loss: 0.4013 - accuracy: 0.8254 - val_loss: 0.4519 - val_accuracy: 0.8076\n",
      "Epoch 79/250\n",
      "152/152 - 1s - loss: 0.4056 - accuracy: 0.8241 - val_loss: 0.4260 - val_accuracy: 0.8212\n",
      "Epoch 80/250\n",
      "152/152 - 1s - loss: 0.4004 - accuracy: 0.8254 - val_loss: 0.3967 - val_accuracy: 0.8273\n",
      "Epoch 81/250\n",
      "152/152 - 1s - loss: 0.4008 - accuracy: 0.8254 - val_loss: 0.4079 - val_accuracy: 0.8265\n",
      "Epoch 82/250\n",
      "152/152 - 1s - loss: 0.4058 - accuracy: 0.8242 - val_loss: 0.3969 - val_accuracy: 0.8241\n",
      "Epoch 83/250\n",
      "152/152 - 1s - loss: 0.4074 - accuracy: 0.8230 - val_loss: 0.4024 - val_accuracy: 0.8259\n",
      "Epoch 84/250\n",
      "152/152 - 1s - loss: 0.4033 - accuracy: 0.8237 - val_loss: 0.4152 - val_accuracy: 0.8245\n",
      "Epoch 85/250\n",
      "152/152 - 1s - loss: 0.4055 - accuracy: 0.8217 - val_loss: 0.3968 - val_accuracy: 0.8253\n",
      "Epoch 86/250\n",
      "152/152 - 1s - loss: 0.4055 - accuracy: 0.8233 - val_loss: 0.3992 - val_accuracy: 0.8249\n",
      "Epoch 87/250\n",
      "152/152 - 1s - loss: 0.4029 - accuracy: 0.8238 - val_loss: 0.3988 - val_accuracy: 0.8241\n",
      "Epoch 88/250\n",
      "152/152 - 1s - loss: 0.4018 - accuracy: 0.8248 - val_loss: 0.3997 - val_accuracy: 0.8222\n",
      "Epoch 89/250\n",
      "152/152 - 1s - loss: 0.4036 - accuracy: 0.8237 - val_loss: 0.3975 - val_accuracy: 0.8248\n",
      "Epoch 90/250\n",
      "152/152 - 1s - loss: 0.4013 - accuracy: 0.8241 - val_loss: 0.3952 - val_accuracy: 0.8266\n",
      "Epoch 91/250\n",
      "152/152 - 1s - loss: 0.4035 - accuracy: 0.8237 - val_loss: 0.4234 - val_accuracy: 0.8156\n",
      "Epoch 92/250\n",
      "152/152 - 1s - loss: 0.4035 - accuracy: 0.8225 - val_loss: 0.3971 - val_accuracy: 0.8268\n",
      "Epoch 93/250\n",
      "152/152 - 1s - loss: 0.4011 - accuracy: 0.8237 - val_loss: 0.4056 - val_accuracy: 0.8215\n",
      "Epoch 94/250\n",
      "152/152 - 1s - loss: 0.4050 - accuracy: 0.8225 - val_loss: 0.3980 - val_accuracy: 0.8212\n",
      "Epoch 95/250\n",
      "152/152 - 1s - loss: 0.4070 - accuracy: 0.8214 - val_loss: 0.4045 - val_accuracy: 0.8214\n",
      "Epoch 96/250\n",
      "152/152 - 1s - loss: 0.4013 - accuracy: 0.8236 - val_loss: 0.4050 - val_accuracy: 0.8187\n",
      "Epoch 97/250\n",
      "152/152 - 1s - loss: 0.4090 - accuracy: 0.8213 - val_loss: 0.3999 - val_accuracy: 0.8254\n",
      "Epoch 98/250\n",
      "152/152 - 1s - loss: 0.3983 - accuracy: 0.8247 - val_loss: 0.3966 - val_accuracy: 0.8258\n",
      "Epoch 99/250\n",
      "152/152 - 1s - loss: 0.4026 - accuracy: 0.8233 - val_loss: 0.3959 - val_accuracy: 0.8261\n",
      "Epoch 100/250\n",
      "152/152 - 1s - loss: 0.4079 - accuracy: 0.8221 - val_loss: 0.3980 - val_accuracy: 0.8247\n",
      "Epoch 101/250\n",
      "152/152 - 1s - loss: 0.4011 - accuracy: 0.8233 - val_loss: 0.3950 - val_accuracy: 0.8265\n",
      "Epoch 102/250\n",
      "152/152 - 1s - loss: 0.4008 - accuracy: 0.8244 - val_loss: 0.4071 - val_accuracy: 0.8226\n",
      "Epoch 103/250\n",
      "152/152 - 1s - loss: 0.3980 - accuracy: 0.8248 - val_loss: 0.4006 - val_accuracy: 0.8219\n",
      "Epoch 104/250\n",
      "152/152 - 1s - loss: 0.4036 - accuracy: 0.8240 - val_loss: 0.3949 - val_accuracy: 0.8262\n",
      "Epoch 105/250\n",
      "152/152 - 1s - loss: 0.4044 - accuracy: 0.8229 - val_loss: 0.4102 - val_accuracy: 0.8213\n",
      "Epoch 106/250\n",
      "152/152 - 1s - loss: 0.4016 - accuracy: 0.8237 - val_loss: 0.3981 - val_accuracy: 0.8251\n",
      "Epoch 107/250\n",
      "152/152 - 1s - loss: 0.4025 - accuracy: 0.8236 - val_loss: 0.4029 - val_accuracy: 0.8207\n",
      "Epoch 108/250\n",
      "152/152 - 1s - loss: 0.4077 - accuracy: 0.8219 - val_loss: 0.4025 - val_accuracy: 0.8240\n",
      "Epoch 109/250\n",
      "152/152 - 1s - loss: 0.3994 - accuracy: 0.8244 - val_loss: 0.4098 - val_accuracy: 0.8183\n",
      "Epoch 110/250\n",
      "152/152 - 1s - loss: 0.4019 - accuracy: 0.8244 - val_loss: 0.3955 - val_accuracy: 0.8272\n",
      "Epoch 111/250\n",
      "152/152 - 1s - loss: 0.4010 - accuracy: 0.8244 - val_loss: 0.3965 - val_accuracy: 0.8249\n",
      "Epoch 112/250\n",
      "152/152 - 1s - loss: 0.4013 - accuracy: 0.8236 - val_loss: 0.4256 - val_accuracy: 0.8192\n",
      "Epoch 113/250\n",
      "152/152 - 1s - loss: 0.3982 - accuracy: 0.8252 - val_loss: 0.4103 - val_accuracy: 0.8241\n",
      "Epoch 114/250\n",
      "152/152 - 1s - loss: 0.3985 - accuracy: 0.8251 - val_loss: 0.3954 - val_accuracy: 0.8266\n",
      "Epoch 115/250\n",
      "152/152 - 1s - loss: 0.3990 - accuracy: 0.8258 - val_loss: 0.3973 - val_accuracy: 0.8248\n",
      "Epoch 116/250\n",
      "152/152 - 1s - loss: 0.3957 - accuracy: 0.8260 - val_loss: 0.4005 - val_accuracy: 0.8210\n",
      "Epoch 117/250\n",
      "152/152 - 1s - loss: 0.4066 - accuracy: 0.8225 - val_loss: 0.4053 - val_accuracy: 0.8225\n",
      "Epoch 118/250\n",
      "152/152 - 1s - loss: 0.3974 - accuracy: 0.8250 - val_loss: 0.3984 - val_accuracy: 0.8249\n",
      "Epoch 119/250\n",
      "152/152 - 1s - loss: 0.4013 - accuracy: 0.8251 - val_loss: 0.3977 - val_accuracy: 0.8228\n",
      "Epoch 120/250\n",
      "152/152 - 1s - loss: 0.3964 - accuracy: 0.8260 - val_loss: 0.3976 - val_accuracy: 0.8251\n",
      "Epoch 121/250\n",
      "152/152 - 1s - loss: 0.3984 - accuracy: 0.8250 - val_loss: 0.4060 - val_accuracy: 0.8230\n",
      "Epoch 122/250\n",
      "152/152 - 1s - loss: 0.3986 - accuracy: 0.8261 - val_loss: 0.4054 - val_accuracy: 0.8244\n",
      "Epoch 123/250\n",
      "152/152 - 1s - loss: 0.4024 - accuracy: 0.8246 - val_loss: 0.4149 - val_accuracy: 0.8115\n",
      "Epoch 124/250\n",
      "152/152 - 1s - loss: 0.4023 - accuracy: 0.8248 - val_loss: 0.4041 - val_accuracy: 0.8243\n",
      "Epoch 125/250\n",
      "152/152 - 1s - loss: 0.3972 - accuracy: 0.8258 - val_loss: 0.3952 - val_accuracy: 0.8270\n",
      "Epoch 126/250\n",
      "152/152 - 1s - loss: 0.3948 - accuracy: 0.8267 - val_loss: 0.4117 - val_accuracy: 0.8189\n",
      "Epoch 127/250\n",
      "152/152 - 1s - loss: 0.3965 - accuracy: 0.8265 - val_loss: 0.4137 - val_accuracy: 0.8195\n",
      "Epoch 128/250\n",
      "152/152 - 1s - loss: 0.4048 - accuracy: 0.8229 - val_loss: 0.3990 - val_accuracy: 0.8261\n",
      "Epoch 129/250\n",
      "152/152 - 1s - loss: 0.3948 - accuracy: 0.8270 - val_loss: 0.4029 - val_accuracy: 0.8227\n",
      "Epoch 130/250\n",
      "152/152 - 1s - loss: 0.3997 - accuracy: 0.8255 - val_loss: 0.4006 - val_accuracy: 0.8222\n",
      "Epoch 131/250\n",
      "152/152 - 1s - loss: 0.3976 - accuracy: 0.8262 - val_loss: 0.4672 - val_accuracy: 0.8140\n",
      "Epoch 132/250\n",
      "152/152 - 1s - loss: 0.3999 - accuracy: 0.8252 - val_loss: 0.3997 - val_accuracy: 0.8223\n",
      "Epoch 133/250\n",
      "152/152 - 1s - loss: 0.3959 - accuracy: 0.8269 - val_loss: 0.4317 - val_accuracy: 0.8152\n",
      "Epoch 134/250\n",
      "152/152 - 1s - loss: 0.4106 - accuracy: 0.8220 - val_loss: 0.4489 - val_accuracy: 0.8018\n",
      "Epoch 135/250\n",
      "152/152 - 1s - loss: 0.4026 - accuracy: 0.8238 - val_loss: 0.3982 - val_accuracy: 0.8234\n",
      "Epoch 136/250\n",
      "152/152 - 1s - loss: 0.3964 - accuracy: 0.8270 - val_loss: 0.4130 - val_accuracy: 0.8217\n",
      "Epoch 137/250\n",
      "152/152 - 1s - loss: 0.3969 - accuracy: 0.8257 - val_loss: 0.4113 - val_accuracy: 0.8231\n",
      "Epoch 138/250\n",
      "152/152 - 1s - loss: 0.3938 - accuracy: 0.8275 - val_loss: 0.3997 - val_accuracy: 0.8213\n",
      "Epoch 139/250\n",
      "152/152 - 1s - loss: 0.3982 - accuracy: 0.8257 - val_loss: 0.4077 - val_accuracy: 0.8210\n",
      "Epoch 140/250\n",
      "152/152 - 1s - loss: 0.3931 - accuracy: 0.8277 - val_loss: 0.4004 - val_accuracy: 0.8252\n",
      "Epoch 141/250\n",
      "152/152 - 1s - loss: 0.3953 - accuracy: 0.8271 - val_loss: 0.4303 - val_accuracy: 0.8178\n",
      "Epoch 142/250\n",
      "152/152 - 1s - loss: 0.3993 - accuracy: 0.8259 - val_loss: 0.3965 - val_accuracy: 0.8259\n",
      "Epoch 143/250\n",
      "152/152 - 1s - loss: 0.4022 - accuracy: 0.8249 - val_loss: 0.4061 - val_accuracy: 0.8213\n",
      "Epoch 144/250\n",
      "152/152 - 1s - loss: 0.3957 - accuracy: 0.8265 - val_loss: 0.4033 - val_accuracy: 0.8226\n",
      "Epoch 145/250\n",
      "152/152 - 1s - loss: 0.3928 - accuracy: 0.8289 - val_loss: 0.3966 - val_accuracy: 0.8271\n",
      "Epoch 146/250\n",
      "152/152 - 1s - loss: 0.3941 - accuracy: 0.8279 - val_loss: 0.3971 - val_accuracy: 0.8253\n",
      "Epoch 147/250\n",
      "152/152 - 1s - loss: 0.4016 - accuracy: 0.8252 - val_loss: 0.3966 - val_accuracy: 0.8241\n",
      "Epoch 148/250\n",
      "152/152 - 1s - loss: 0.3946 - accuracy: 0.8274 - val_loss: 0.3980 - val_accuracy: 0.8245\n",
      "Epoch 149/250\n",
      "152/152 - 1s - loss: 0.3943 - accuracy: 0.8275 - val_loss: 0.4163 - val_accuracy: 0.8206\n",
      "Epoch 150/250\n",
      "152/152 - 1s - loss: 0.4002 - accuracy: 0.8258 - val_loss: 0.4340 - val_accuracy: 0.8073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/250\n",
      "152/152 - 1s - loss: 0.3923 - accuracy: 0.8277 - val_loss: 0.4058 - val_accuracy: 0.8228\n",
      "Epoch 152/250\n",
      "152/152 - 1s - loss: 0.3968 - accuracy: 0.8271 - val_loss: 0.4213 - val_accuracy: 0.8174\n",
      "Epoch 153/250\n",
      "152/152 - 1s - loss: 0.3981 - accuracy: 0.8262 - val_loss: 0.3980 - val_accuracy: 0.8233\n",
      "Epoch 154/250\n",
      "152/152 - 1s - loss: 0.3912 - accuracy: 0.8286 - val_loss: 0.4004 - val_accuracy: 0.8234\n",
      "Epoch 155/250\n",
      "152/152 - 1s - loss: 0.3911 - accuracy: 0.8286 - val_loss: 0.4013 - val_accuracy: 0.8230\n",
      "Epoch 156/250\n",
      "152/152 - 1s - loss: 0.3952 - accuracy: 0.8275 - val_loss: 0.4241 - val_accuracy: 0.8151\n",
      "Epoch 157/250\n",
      "152/152 - 1s - loss: 0.3970 - accuracy: 0.8270 - val_loss: 0.4019 - val_accuracy: 0.8243\n",
      "Epoch 158/250\n",
      "152/152 - 1s - loss: 0.3953 - accuracy: 0.8280 - val_loss: 0.4032 - val_accuracy: 0.8256\n",
      "Epoch 159/250\n",
      "152/152 - 1s - loss: 0.3940 - accuracy: 0.8278 - val_loss: 0.3972 - val_accuracy: 0.8253\n",
      "Epoch 160/250\n",
      "152/152 - 1s - loss: 0.3927 - accuracy: 0.8285 - val_loss: 0.4058 - val_accuracy: 0.8254\n",
      "Epoch 161/250\n",
      "152/152 - 1s - loss: 0.3958 - accuracy: 0.8272 - val_loss: 0.4033 - val_accuracy: 0.8247\n",
      "Epoch 162/250\n",
      "152/152 - 1s - loss: 0.3944 - accuracy: 0.8275 - val_loss: 0.3986 - val_accuracy: 0.8241\n",
      "Epoch 163/250\n",
      "152/152 - 1s - loss: 0.3914 - accuracy: 0.8292 - val_loss: 0.4134 - val_accuracy: 0.8219\n",
      "Epoch 164/250\n",
      "152/152 - 1s - loss: 0.3934 - accuracy: 0.8281 - val_loss: 0.4205 - val_accuracy: 0.8142\n",
      "Epoch 165/250\n",
      "152/152 - 1s - loss: 0.4005 - accuracy: 0.8248 - val_loss: 0.3952 - val_accuracy: 0.8266\n",
      "Epoch 166/250\n",
      "152/152 - 1s - loss: 0.3969 - accuracy: 0.8270 - val_loss: 0.4231 - val_accuracy: 0.8138\n",
      "Epoch 167/250\n",
      "152/152 - 1s - loss: 0.3937 - accuracy: 0.8286 - val_loss: 0.3999 - val_accuracy: 0.8226\n",
      "Epoch 168/250\n",
      "152/152 - 1s - loss: 0.3971 - accuracy: 0.8267 - val_loss: 0.4010 - val_accuracy: 0.8242\n",
      "Epoch 169/250\n",
      "152/152 - 1s - loss: 0.3906 - accuracy: 0.8294 - val_loss: 0.4017 - val_accuracy: 0.8220\n",
      "Epoch 170/250\n",
      "152/152 - 1s - loss: 0.3948 - accuracy: 0.8275 - val_loss: 0.4064 - val_accuracy: 0.8245\n",
      "Epoch 171/250\n",
      "152/152 - 1s - loss: 0.3930 - accuracy: 0.8289 - val_loss: 0.4020 - val_accuracy: 0.8214\n",
      "Epoch 172/250\n",
      "152/152 - 1s - loss: 0.3912 - accuracy: 0.8291 - val_loss: 0.3985 - val_accuracy: 0.8265\n",
      "Epoch 173/250\n",
      "152/152 - 1s - loss: 0.3918 - accuracy: 0.8291 - val_loss: 0.4061 - val_accuracy: 0.8225\n",
      "Epoch 174/250\n",
      "152/152 - 1s - loss: 0.3908 - accuracy: 0.8294 - val_loss: 0.4004 - val_accuracy: 0.8244\n",
      "Epoch 175/250\n",
      "152/152 - 1s - loss: 0.3931 - accuracy: 0.8285 - val_loss: 0.4056 - val_accuracy: 0.8208\n",
      "Epoch 176/250\n",
      "152/152 - 1s - loss: 0.3925 - accuracy: 0.8286 - val_loss: 0.4093 - val_accuracy: 0.8172\n",
      "Epoch 177/250\n",
      "152/152 - 1s - loss: 0.3900 - accuracy: 0.8298 - val_loss: 0.3985 - val_accuracy: 0.8223\n",
      "Epoch 178/250\n",
      "152/152 - 1s - loss: 0.3902 - accuracy: 0.8302 - val_loss: 0.3972 - val_accuracy: 0.8253\n",
      "Epoch 179/250\n",
      "152/152 - 1s - loss: 0.3946 - accuracy: 0.8277 - val_loss: 0.3970 - val_accuracy: 0.8262\n",
      "Epoch 180/250\n",
      "152/152 - 1s - loss: 0.3888 - accuracy: 0.8301 - val_loss: 0.3970 - val_accuracy: 0.8258\n",
      "Epoch 181/250\n",
      "152/152 - 1s - loss: 0.3960 - accuracy: 0.8276 - val_loss: 0.4423 - val_accuracy: 0.8017\n",
      "Epoch 182/250\n",
      "152/152 - 1s - loss: 0.3934 - accuracy: 0.8286 - val_loss: 0.4073 - val_accuracy: 0.8220\n",
      "Epoch 183/250\n",
      "152/152 - 1s - loss: 0.3959 - accuracy: 0.8276 - val_loss: 0.4008 - val_accuracy: 0.8257\n",
      "Epoch 184/250\n",
      "152/152 - 1s - loss: 0.3897 - accuracy: 0.8294 - val_loss: 0.4048 - val_accuracy: 0.8248\n",
      "Epoch 185/250\n",
      "152/152 - 1s - loss: 0.3903 - accuracy: 0.8296 - val_loss: 0.4023 - val_accuracy: 0.8193\n",
      "Epoch 186/250\n",
      "152/152 - 1s - loss: 0.3875 - accuracy: 0.8310 - val_loss: 0.3990 - val_accuracy: 0.8237\n",
      "Epoch 187/250\n",
      "152/152 - 1s - loss: 0.3915 - accuracy: 0.8303 - val_loss: 0.4067 - val_accuracy: 0.8206\n",
      "Epoch 188/250\n",
      "152/152 - 1s - loss: 0.3902 - accuracy: 0.8303 - val_loss: 0.3983 - val_accuracy: 0.8273\n",
      "Epoch 189/250\n",
      "152/152 - 1s - loss: 0.3929 - accuracy: 0.8296 - val_loss: 0.4002 - val_accuracy: 0.8256\n",
      "Epoch 190/250\n",
      "152/152 - 1s - loss: 0.3931 - accuracy: 0.8291 - val_loss: 0.3984 - val_accuracy: 0.8255\n",
      "Epoch 191/250\n",
      "152/152 - 1s - loss: 0.3918 - accuracy: 0.8293 - val_loss: 0.3986 - val_accuracy: 0.8257\n",
      "Epoch 192/250\n",
      "152/152 - 1s - loss: 0.3897 - accuracy: 0.8301 - val_loss: 0.4071 - val_accuracy: 0.8234\n",
      "Epoch 193/250\n",
      "152/152 - 1s - loss: 0.3923 - accuracy: 0.8292 - val_loss: 0.4020 - val_accuracy: 0.8244\n",
      "Epoch 194/250\n",
      "152/152 - 1s - loss: 0.3891 - accuracy: 0.8305 - val_loss: 0.4031 - val_accuracy: 0.8234\n",
      "Epoch 195/250\n",
      "152/152 - 1s - loss: 0.3898 - accuracy: 0.8302 - val_loss: 0.3976 - val_accuracy: 0.8261\n",
      "Epoch 196/250\n",
      "152/152 - 1s - loss: 0.3905 - accuracy: 0.8305 - val_loss: 0.3985 - val_accuracy: 0.8268\n",
      "Epoch 197/250\n",
      "152/152 - 1s - loss: 0.3921 - accuracy: 0.8294 - val_loss: 0.4000 - val_accuracy: 0.8254\n",
      "Epoch 198/250\n",
      "152/152 - 1s - loss: 0.3902 - accuracy: 0.8303 - val_loss: 0.3983 - val_accuracy: 0.8265\n",
      "Epoch 199/250\n",
      "152/152 - 1s - loss: 0.3885 - accuracy: 0.8306 - val_loss: 0.4411 - val_accuracy: 0.8038\n",
      "Epoch 200/250\n",
      "152/152 - 1s - loss: 0.3926 - accuracy: 0.8291 - val_loss: 0.3995 - val_accuracy: 0.8271\n",
      "Epoch 201/250\n",
      "152/152 - 1s - loss: 0.3888 - accuracy: 0.8308 - val_loss: 0.3988 - val_accuracy: 0.8262\n",
      "Epoch 202/250\n",
      "152/152 - 1s - loss: 0.3894 - accuracy: 0.8313 - val_loss: 0.4024 - val_accuracy: 0.8234\n",
      "Epoch 203/250\n",
      "152/152 - 1s - loss: 0.3931 - accuracy: 0.8297 - val_loss: 0.4618 - val_accuracy: 0.7900\n",
      "Epoch 204/250\n",
      "152/152 - 1s - loss: 0.3930 - accuracy: 0.8294 - val_loss: 0.4160 - val_accuracy: 0.8189\n",
      "Epoch 205/250\n",
      "152/152 - 1s - loss: 0.3888 - accuracy: 0.8314 - val_loss: 0.3966 - val_accuracy: 0.8262\n",
      "Epoch 206/250\n",
      "152/152 - 1s - loss: 0.3884 - accuracy: 0.8314 - val_loss: 0.4175 - val_accuracy: 0.8183\n",
      "Epoch 207/250\n",
      "152/152 - 1s - loss: 0.3946 - accuracy: 0.8283 - val_loss: 0.4014 - val_accuracy: 0.8206\n",
      "Epoch 208/250\n",
      "152/152 - 1s - loss: 0.3867 - accuracy: 0.8314 - val_loss: 0.4032 - val_accuracy: 0.8259\n",
      "Epoch 209/250\n",
      "152/152 - 1s - loss: 0.3915 - accuracy: 0.8299 - val_loss: 0.3998 - val_accuracy: 0.8229\n",
      "Epoch 210/250\n",
      "152/152 - 1s - loss: 0.3841 - accuracy: 0.8326 - val_loss: 0.3992 - val_accuracy: 0.8234\n",
      "Epoch 211/250\n",
      "152/152 - 1s - loss: 0.3871 - accuracy: 0.8315 - val_loss: 0.3974 - val_accuracy: 0.8251\n",
      "Epoch 212/250\n",
      "152/152 - 1s - loss: 0.3966 - accuracy: 0.8265 - val_loss: 0.4007 - val_accuracy: 0.8238\n",
      "Epoch 213/250\n",
      "152/152 - 1s - loss: 0.3868 - accuracy: 0.8318 - val_loss: 0.4043 - val_accuracy: 0.8268\n",
      "Epoch 214/250\n",
      "152/152 - 1s - loss: 0.3858 - accuracy: 0.8330 - val_loss: 0.4163 - val_accuracy: 0.8228\n",
      "Epoch 215/250\n",
      "152/152 - 1s - loss: 0.3862 - accuracy: 0.8319 - val_loss: 0.4067 - val_accuracy: 0.8219\n",
      "Epoch 216/250\n",
      "152/152 - 1s - loss: 0.3885 - accuracy: 0.8317 - val_loss: 0.4324 - val_accuracy: 0.8211\n",
      "Epoch 217/250\n",
      "152/152 - 1s - loss: 0.3954 - accuracy: 0.8282 - val_loss: 0.4010 - val_accuracy: 0.8241\n",
      "Epoch 218/250\n",
      "152/152 - 1s - loss: 0.3838 - accuracy: 0.8321 - val_loss: 0.4111 - val_accuracy: 0.8204\n",
      "Epoch 219/250\n",
      "152/152 - 1s - loss: 0.3858 - accuracy: 0.8326 - val_loss: 0.4112 - val_accuracy: 0.8193\n",
      "Epoch 220/250\n",
      "152/152 - 1s - loss: 0.3854 - accuracy: 0.8331 - val_loss: 0.4143 - val_accuracy: 0.8183\n",
      "Epoch 221/250\n",
      "152/152 - 1s - loss: 0.3852 - accuracy: 0.8326 - val_loss: 0.4097 - val_accuracy: 0.8205\n",
      "Epoch 222/250\n",
      "152/152 - 1s - loss: 0.3892 - accuracy: 0.8308 - val_loss: 0.4069 - val_accuracy: 0.8242\n",
      "Epoch 223/250\n",
      "152/152 - 1s - loss: 0.3940 - accuracy: 0.8292 - val_loss: 0.4064 - val_accuracy: 0.8230\n",
      "Epoch 224/250\n",
      "152/152 - 1s - loss: 0.3924 - accuracy: 0.8298 - val_loss: 0.3984 - val_accuracy: 0.8256\n",
      "Epoch 225/250\n",
      "152/152 - 1s - loss: 0.3871 - accuracy: 0.8320 - val_loss: 0.4170 - val_accuracy: 0.8152\n",
      "Epoch 226/250\n",
      "152/152 - 1s - loss: 0.3890 - accuracy: 0.8313 - val_loss: 0.4027 - val_accuracy: 0.8232\n",
      "Epoch 227/250\n",
      "152/152 - 1s - loss: 0.3852 - accuracy: 0.8330 - val_loss: 0.4035 - val_accuracy: 0.8265\n",
      "Epoch 228/250\n",
      "152/152 - 1s - loss: 0.3902 - accuracy: 0.8306 - val_loss: 0.4169 - val_accuracy: 0.8119\n",
      "Epoch 229/250\n",
      "152/152 - 1s - loss: 0.3900 - accuracy: 0.8312 - val_loss: 0.4136 - val_accuracy: 0.8196\n",
      "Epoch 230/250\n",
      "152/152 - 1s - loss: 0.3871 - accuracy: 0.8321 - val_loss: 0.4231 - val_accuracy: 0.8170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 231/250\n",
      "152/152 - 1s - loss: 0.3856 - accuracy: 0.8326 - val_loss: 0.4031 - val_accuracy: 0.8272\n",
      "Epoch 232/250\n",
      "152/152 - 1s - loss: 0.3834 - accuracy: 0.8331 - val_loss: 0.4003 - val_accuracy: 0.8250\n",
      "Epoch 233/250\n",
      "152/152 - 1s - loss: 0.3856 - accuracy: 0.8331 - val_loss: 0.4072 - val_accuracy: 0.8233\n",
      "Epoch 234/250\n",
      "152/152 - 1s - loss: 0.3892 - accuracy: 0.8315 - val_loss: 0.3975 - val_accuracy: 0.8265\n",
      "Epoch 235/250\n",
      "152/152 - 1s - loss: 0.3854 - accuracy: 0.8330 - val_loss: 0.3995 - val_accuracy: 0.8257\n",
      "Epoch 236/250\n",
      "152/152 - 1s - loss: 0.3873 - accuracy: 0.8320 - val_loss: 0.4031 - val_accuracy: 0.8240\n",
      "Epoch 237/250\n",
      "152/152 - 1s - loss: 0.3904 - accuracy: 0.8314 - val_loss: 0.4136 - val_accuracy: 0.8239\n",
      "Epoch 238/250\n",
      "152/152 - 1s - loss: 0.3879 - accuracy: 0.8318 - val_loss: 0.4016 - val_accuracy: 0.8226\n",
      "Epoch 239/250\n",
      "152/152 - 1s - loss: 0.3892 - accuracy: 0.8310 - val_loss: 0.4000 - val_accuracy: 0.8252\n",
      "Epoch 240/250\n",
      "152/152 - 1s - loss: 0.3853 - accuracy: 0.8325 - val_loss: 0.4032 - val_accuracy: 0.8240\n",
      "Epoch 241/250\n",
      "152/152 - 1s - loss: 0.3878 - accuracy: 0.8316 - val_loss: 0.4014 - val_accuracy: 0.8236\n",
      "Epoch 242/250\n",
      "152/152 - 1s - loss: 0.3857 - accuracy: 0.8333 - val_loss: 0.4030 - val_accuracy: 0.8233\n",
      "Epoch 243/250\n",
      "152/152 - 1s - loss: 0.3983 - accuracy: 0.8281 - val_loss: 0.4227 - val_accuracy: 0.8162\n",
      "Epoch 244/250\n",
      "152/152 - 1s - loss: 0.3876 - accuracy: 0.8322 - val_loss: 0.4037 - val_accuracy: 0.8256\n",
      "Epoch 245/250\n",
      "152/152 - 1s - loss: 0.3859 - accuracy: 0.8326 - val_loss: 0.4015 - val_accuracy: 0.8274\n",
      "Epoch 246/250\n",
      "152/152 - 1s - loss: 0.3819 - accuracy: 0.8343 - val_loss: 0.4031 - val_accuracy: 0.8232\n",
      "Epoch 247/250\n",
      "152/152 - 1s - loss: 0.3884 - accuracy: 0.8319 - val_loss: 0.4036 - val_accuracy: 0.8250\n",
      "Epoch 248/250\n",
      "152/152 - 1s - loss: 0.3916 - accuracy: 0.8296 - val_loss: 0.4010 - val_accuracy: 0.8267\n",
      "Epoch 249/250\n",
      "152/152 - 1s - loss: 0.3811 - accuracy: 0.8350 - val_loss: 0.4181 - val_accuracy: 0.8232\n",
      "Epoch 250/250\n",
      "152/152 - 1s - loss: 0.3839 - accuracy: 0.8341 - val_loss: 0.3984 - val_accuracy: 0.8265\n",
      "1-layer-256\n",
      "Epoch 1/250\n",
      "152/152 - 1s - loss: 125.0373 - accuracy: 0.6507 - val_loss: 1.8123 - val_accuracy: 0.7403\n",
      "Epoch 2/250\n",
      "152/152 - 1s - loss: 1.8619 - accuracy: 0.7211 - val_loss: 0.6937 - val_accuracy: 0.7842\n",
      "Epoch 3/250\n",
      "152/152 - 1s - loss: 0.5755 - accuracy: 0.7849 - val_loss: 0.5571 - val_accuracy: 0.7662\n",
      "Epoch 4/250\n",
      "152/152 - 1s - loss: 0.5131 - accuracy: 0.7823 - val_loss: 0.5096 - val_accuracy: 0.7776\n",
      "Epoch 5/250\n",
      "152/152 - 1s - loss: 0.5249 - accuracy: 0.7725 - val_loss: 0.4702 - val_accuracy: 0.7872\n",
      "Epoch 6/250\n",
      "152/152 - 1s - loss: 0.4817 - accuracy: 0.7868 - val_loss: 0.4537 - val_accuracy: 0.8004\n",
      "Epoch 7/250\n",
      "152/152 - 1s - loss: 0.4792 - accuracy: 0.7863 - val_loss: 0.4473 - val_accuracy: 0.8036\n",
      "Epoch 8/250\n",
      "152/152 - 1s - loss: 0.4546 - accuracy: 0.7963 - val_loss: 0.4325 - val_accuracy: 0.8020\n",
      "Epoch 9/250\n",
      "152/152 - 1s - loss: 0.4573 - accuracy: 0.7957 - val_loss: 0.4310 - val_accuracy: 0.7997\n",
      "Epoch 10/250\n",
      "152/152 - 1s - loss: 0.4617 - accuracy: 0.7939 - val_loss: 0.4370 - val_accuracy: 0.7941\n",
      "Epoch 11/250\n",
      "152/152 - 1s - loss: 0.4316 - accuracy: 0.8066 - val_loss: 0.4190 - val_accuracy: 0.8127\n",
      "Epoch 12/250\n",
      "152/152 - 1s - loss: 0.4386 - accuracy: 0.8030 - val_loss: 0.4353 - val_accuracy: 0.8011\n",
      "Epoch 13/250\n",
      "152/152 - 1s - loss: 0.4319 - accuracy: 0.8063 - val_loss: 0.4211 - val_accuracy: 0.8029\n",
      "Epoch 14/250\n",
      "152/152 - 1s - loss: 0.4262 - accuracy: 0.8093 - val_loss: 0.4215 - val_accuracy: 0.8149\n",
      "Epoch 15/250\n",
      "152/152 - 1s - loss: 0.4265 - accuracy: 0.8086 - val_loss: 0.4197 - val_accuracy: 0.8062\n",
      "Epoch 16/250\n",
      "152/152 - 1s - loss: 0.4236 - accuracy: 0.8098 - val_loss: 0.4317 - val_accuracy: 0.8007\n",
      "Epoch 17/250\n",
      "152/152 - 1s - loss: 0.4248 - accuracy: 0.8095 - val_loss: 0.4562 - val_accuracy: 0.7974\n",
      "Epoch 18/250\n",
      "152/152 - 1s - loss: 0.4212 - accuracy: 0.8112 - val_loss: 0.4143 - val_accuracy: 0.8165\n",
      "Epoch 19/250\n",
      "152/152 - 1s - loss: 0.4237 - accuracy: 0.8105 - val_loss: 0.4128 - val_accuracy: 0.8160\n",
      "Epoch 20/250\n",
      "152/152 - 1s - loss: 0.4168 - accuracy: 0.8139 - val_loss: 0.4084 - val_accuracy: 0.8171\n",
      "Epoch 21/250\n",
      "152/152 - 1s - loss: 0.4170 - accuracy: 0.8139 - val_loss: 0.4106 - val_accuracy: 0.8146\n",
      "Epoch 22/250\n",
      "152/152 - 1s - loss: 0.4227 - accuracy: 0.8113 - val_loss: 0.4043 - val_accuracy: 0.8186\n",
      "Epoch 23/250\n",
      "152/152 - 1s - loss: 0.4123 - accuracy: 0.8152 - val_loss: 0.4131 - val_accuracy: 0.8122\n",
      "Epoch 24/250\n",
      "152/152 - 1s - loss: 0.4105 - accuracy: 0.8166 - val_loss: 0.4037 - val_accuracy: 0.8187\n",
      "Epoch 25/250\n",
      "152/152 - 1s - loss: 0.4088 - accuracy: 0.8173 - val_loss: 0.4026 - val_accuracy: 0.8202\n",
      "Epoch 26/250\n",
      "152/152 - 1s - loss: 0.4091 - accuracy: 0.8177 - val_loss: 0.4282 - val_accuracy: 0.8125\n",
      "Epoch 27/250\n",
      "152/152 - 1s - loss: 0.4132 - accuracy: 0.8167 - val_loss: 0.4169 - val_accuracy: 0.8162\n",
      "Epoch 28/250\n",
      "152/152 - 1s - loss: 0.4114 - accuracy: 0.8174 - val_loss: 0.4073 - val_accuracy: 0.8173\n",
      "Epoch 29/250\n",
      "152/152 - 1s - loss: 0.4092 - accuracy: 0.8183 - val_loss: 0.4035 - val_accuracy: 0.8213\n",
      "Epoch 30/250\n",
      "152/152 - 1s - loss: 0.4128 - accuracy: 0.8174 - val_loss: 0.4012 - val_accuracy: 0.8226\n",
      "Epoch 31/250\n",
      "152/152 - 1s - loss: 0.4093 - accuracy: 0.8190 - val_loss: 0.4019 - val_accuracy: 0.8208\n",
      "Epoch 32/250\n",
      "152/152 - 1s - loss: 0.4107 - accuracy: 0.8179 - val_loss: 0.4016 - val_accuracy: 0.8210\n",
      "Epoch 33/250\n",
      "152/152 - 1s - loss: 0.4060 - accuracy: 0.8201 - val_loss: 0.4138 - val_accuracy: 0.8156\n",
      "Epoch 34/250\n",
      "152/152 - 1s - loss: 0.4083 - accuracy: 0.8192 - val_loss: 0.4092 - val_accuracy: 0.8144\n",
      "Epoch 35/250\n",
      "152/152 - 1s - loss: 0.4112 - accuracy: 0.8186 - val_loss: 0.4010 - val_accuracy: 0.8233\n",
      "Epoch 36/250\n",
      "152/152 - 1s - loss: 0.4088 - accuracy: 0.8200 - val_loss: 0.4204 - val_accuracy: 0.8113\n",
      "Epoch 37/250\n",
      "152/152 - 1s - loss: 0.4083 - accuracy: 0.8189 - val_loss: 0.4590 - val_accuracy: 0.7986\n",
      "Epoch 38/250\n",
      "152/152 - 1s - loss: 0.4090 - accuracy: 0.8205 - val_loss: 0.4000 - val_accuracy: 0.8236\n",
      "Epoch 39/250\n",
      "152/152 - 1s - loss: 0.4135 - accuracy: 0.8186 - val_loss: 0.4001 - val_accuracy: 0.8228\n",
      "Epoch 40/250\n",
      "152/152 - 1s - loss: 0.4051 - accuracy: 0.8211 - val_loss: 0.4011 - val_accuracy: 0.8214\n",
      "Epoch 41/250\n",
      "152/152 - 1s - loss: 0.4057 - accuracy: 0.8211 - val_loss: 0.4001 - val_accuracy: 0.8224\n",
      "Epoch 42/250\n",
      "152/152 - 1s - loss: 0.4077 - accuracy: 0.8210 - val_loss: 0.3992 - val_accuracy: 0.8239\n",
      "Epoch 43/250\n",
      "152/152 - 1s - loss: 0.4076 - accuracy: 0.8205 - val_loss: 0.4034 - val_accuracy: 0.8218\n",
      "Epoch 44/250\n",
      "152/152 - 1s - loss: 0.4100 - accuracy: 0.8201 - val_loss: 0.4224 - val_accuracy: 0.8170\n",
      "Epoch 45/250\n",
      "152/152 - 1s - loss: 0.4144 - accuracy: 0.8179 - val_loss: 0.4021 - val_accuracy: 0.8205\n",
      "Epoch 46/250\n",
      "152/152 - 1s - loss: 0.4064 - accuracy: 0.8212 - val_loss: 0.4013 - val_accuracy: 0.8224\n",
      "Epoch 47/250\n",
      "152/152 - 1s - loss: 0.4065 - accuracy: 0.8209 - val_loss: 0.4089 - val_accuracy: 0.8214\n",
      "Epoch 48/250\n",
      "152/152 - 1s - loss: 0.4101 - accuracy: 0.8199 - val_loss: 0.3997 - val_accuracy: 0.8245\n",
      "Epoch 49/250\n",
      "152/152 - 1s - loss: 0.4057 - accuracy: 0.8223 - val_loss: 0.4022 - val_accuracy: 0.8196\n",
      "Epoch 50/250\n",
      "152/152 - 1s - loss: 0.4085 - accuracy: 0.8205 - val_loss: 0.4117 - val_accuracy: 0.8195\n",
      "Epoch 51/250\n",
      "152/152 - 1s - loss: 0.4088 - accuracy: 0.8205 - val_loss: 0.4046 - val_accuracy: 0.8200\n",
      "Epoch 52/250\n",
      "152/152 - 1s - loss: 0.4071 - accuracy: 0.8207 - val_loss: 0.4053 - val_accuracy: 0.8223\n",
      "Epoch 53/250\n",
      "152/152 - 1s - loss: 0.4042 - accuracy: 0.8218 - val_loss: 0.4401 - val_accuracy: 0.8145\n",
      "Epoch 54/250\n",
      "152/152 - 1s - loss: 0.4114 - accuracy: 0.8201 - val_loss: 0.4037 - val_accuracy: 0.8212\n",
      "Epoch 55/250\n",
      "152/152 - 1s - loss: 0.4031 - accuracy: 0.8228 - val_loss: 0.3994 - val_accuracy: 0.8227\n",
      "Epoch 56/250\n",
      "152/152 - 1s - loss: 0.4124 - accuracy: 0.8188 - val_loss: 0.4049 - val_accuracy: 0.8224\n",
      "Epoch 57/250\n",
      "152/152 - 1s - loss: 0.4122 - accuracy: 0.8199 - val_loss: 0.4007 - val_accuracy: 0.8235\n",
      "Epoch 58/250\n",
      "152/152 - 1s - loss: 0.4038 - accuracy: 0.8231 - val_loss: 0.4108 - val_accuracy: 0.8215\n",
      "Epoch 59/250\n",
      "152/152 - 1s - loss: 0.4058 - accuracy: 0.8220 - val_loss: 0.4209 - val_accuracy: 0.8143\n",
      "Epoch 60/250\n",
      "152/152 - 1s - loss: 0.4047 - accuracy: 0.8220 - val_loss: 0.4242 - val_accuracy: 0.8039\n",
      "Epoch 61/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 - 1s - loss: 0.4070 - accuracy: 0.8210 - val_loss: 0.4211 - val_accuracy: 0.8179\n",
      "Epoch 62/250\n",
      "152/152 - 1s - loss: 0.4111 - accuracy: 0.8197 - val_loss: 0.4074 - val_accuracy: 0.8215\n",
      "Epoch 63/250\n",
      "152/152 - 1s - loss: 0.4068 - accuracy: 0.8195 - val_loss: 0.4056 - val_accuracy: 0.8191\n",
      "Epoch 64/250\n",
      "152/152 - 1s - loss: 0.4112 - accuracy: 0.8173 - val_loss: 0.4014 - val_accuracy: 0.8231\n",
      "Epoch 65/250\n",
      "152/152 - 1s - loss: 0.4066 - accuracy: 0.8205 - val_loss: 0.4185 - val_accuracy: 0.8139\n",
      "Epoch 66/250\n",
      "152/152 - 1s - loss: 0.4082 - accuracy: 0.8197 - val_loss: 0.4148 - val_accuracy: 0.8160\n",
      "Epoch 67/250\n",
      "152/152 - 1s - loss: 0.4094 - accuracy: 0.8192 - val_loss: 0.4249 - val_accuracy: 0.8108\n",
      "Epoch 68/250\n",
      "152/152 - 1s - loss: 0.4090 - accuracy: 0.8190 - val_loss: 0.4021 - val_accuracy: 0.8188\n",
      "Epoch 69/250\n",
      "152/152 - 1s - loss: 0.4091 - accuracy: 0.8195 - val_loss: 0.4033 - val_accuracy: 0.8196\n",
      "Epoch 70/250\n",
      "152/152 - 1s - loss: 0.4112 - accuracy: 0.8187 - val_loss: 0.3996 - val_accuracy: 0.8227\n",
      "Epoch 71/250\n",
      "152/152 - 1s - loss: 0.4057 - accuracy: 0.8212 - val_loss: 0.4098 - val_accuracy: 0.8179\n",
      "Epoch 72/250\n",
      "152/152 - 1s - loss: 0.4094 - accuracy: 0.8196 - val_loss: 0.4226 - val_accuracy: 0.8094\n",
      "Epoch 73/250\n",
      "152/152 - 1s - loss: 0.4056 - accuracy: 0.8211 - val_loss: 0.4326 - val_accuracy: 0.8107\n",
      "Epoch 74/250\n",
      "152/152 - 1s - loss: 0.4061 - accuracy: 0.8201 - val_loss: 0.4138 - val_accuracy: 0.8168\n",
      "Epoch 75/250\n",
      "152/152 - 1s - loss: 0.4029 - accuracy: 0.8222 - val_loss: 0.3994 - val_accuracy: 0.8214\n",
      "Epoch 76/250\n",
      "152/152 - 1s - loss: 0.4098 - accuracy: 0.8193 - val_loss: 0.3994 - val_accuracy: 0.8220\n",
      "Epoch 77/250\n",
      "152/152 - 1s - loss: 0.4057 - accuracy: 0.8215 - val_loss: 0.4558 - val_accuracy: 0.8099\n",
      "Epoch 78/250\n",
      "152/152 - 1s - loss: 0.4079 - accuracy: 0.8203 - val_loss: 0.4038 - val_accuracy: 0.8195\n",
      "Epoch 79/250\n",
      "152/152 - 1s - loss: 0.4156 - accuracy: 0.8191 - val_loss: 0.4230 - val_accuracy: 0.8133\n",
      "Epoch 80/250\n",
      "152/152 - 1s - loss: 0.4189 - accuracy: 0.8142 - val_loss: 0.4672 - val_accuracy: 0.7994\n",
      "Epoch 81/250\n",
      "152/152 - 1s - loss: 0.4126 - accuracy: 0.8171 - val_loss: 0.4109 - val_accuracy: 0.8191\n",
      "Epoch 82/250\n",
      "152/152 - 1s - loss: 0.4112 - accuracy: 0.8168 - val_loss: 0.4096 - val_accuracy: 0.8194\n",
      "Epoch 83/250\n",
      "152/152 - 1s - loss: 0.4134 - accuracy: 0.8166 - val_loss: 0.4070 - val_accuracy: 0.8189\n",
      "Epoch 84/250\n",
      "152/152 - 1s - loss: 0.4111 - accuracy: 0.8185 - val_loss: 0.4097 - val_accuracy: 0.8158\n",
      "Epoch 85/250\n",
      "152/152 - 1s - loss: 0.4087 - accuracy: 0.8193 - val_loss: 0.4136 - val_accuracy: 0.8157\n",
      "Epoch 86/250\n",
      "152/152 - 1s - loss: 0.4103 - accuracy: 0.8183 - val_loss: 0.4173 - val_accuracy: 0.8147\n",
      "Epoch 87/250\n",
      "152/152 - 1s - loss: 0.4061 - accuracy: 0.8200 - val_loss: 0.4062 - val_accuracy: 0.8196\n",
      "Epoch 88/250\n",
      "152/152 - 1s - loss: 0.4067 - accuracy: 0.8200 - val_loss: 0.4025 - val_accuracy: 0.8223\n",
      "Epoch 89/250\n",
      "152/152 - 1s - loss: 0.4062 - accuracy: 0.8204 - val_loss: 0.4034 - val_accuracy: 0.8208\n",
      "Epoch 90/250\n",
      "152/152 - 1s - loss: 0.4055 - accuracy: 0.8191 - val_loss: 0.4029 - val_accuracy: 0.8195\n",
      "Epoch 91/250\n",
      "152/152 - 1s - loss: 0.4050 - accuracy: 0.8201 - val_loss: 0.4064 - val_accuracy: 0.8194\n",
      "Epoch 92/250\n",
      "152/152 - 1s - loss: 0.4076 - accuracy: 0.8187 - val_loss: 0.4017 - val_accuracy: 0.8215\n",
      "Epoch 93/250\n",
      "152/152 - 1s - loss: 0.4064 - accuracy: 0.8197 - val_loss: 0.4036 - val_accuracy: 0.8204\n",
      "Epoch 94/250\n",
      "152/152 - 1s - loss: 0.4052 - accuracy: 0.8197 - val_loss: 0.4324 - val_accuracy: 0.8089\n",
      "Epoch 95/250\n",
      "152/152 - 1s - loss: 0.4059 - accuracy: 0.8187 - val_loss: 0.4251 - val_accuracy: 0.8100\n",
      "Epoch 96/250\n",
      "152/152 - 1s - loss: 0.4105 - accuracy: 0.8177 - val_loss: 0.4041 - val_accuracy: 0.8175\n",
      "Epoch 97/250\n",
      "152/152 - 1s - loss: 0.4067 - accuracy: 0.8192 - val_loss: 0.4237 - val_accuracy: 0.8133\n",
      "Epoch 98/250\n",
      "152/152 - 1s - loss: 0.4047 - accuracy: 0.8205 - val_loss: 0.4059 - val_accuracy: 0.8201\n",
      "Epoch 99/250\n",
      "152/152 - 1s - loss: 0.4048 - accuracy: 0.8198 - val_loss: 0.4138 - val_accuracy: 0.8163\n",
      "Epoch 100/250\n",
      "152/152 - 1s - loss: 0.4072 - accuracy: 0.8192 - val_loss: 0.4178 - val_accuracy: 0.8133\n",
      "Epoch 101/250\n",
      "152/152 - 1s - loss: 0.4048 - accuracy: 0.8199 - val_loss: 0.4081 - val_accuracy: 0.8199\n",
      "Epoch 102/250\n",
      "152/152 - 1s - loss: 0.4061 - accuracy: 0.8196 - val_loss: 0.4167 - val_accuracy: 0.8172\n",
      "Epoch 103/250\n",
      "152/152 - 1s - loss: 0.4075 - accuracy: 0.8187 - val_loss: 0.4088 - val_accuracy: 0.8196\n",
      "Epoch 104/250\n",
      "152/152 - 1s - loss: 0.4046 - accuracy: 0.8198 - val_loss: 0.4282 - val_accuracy: 0.8122\n",
      "Epoch 105/250\n",
      "152/152 - 1s - loss: 0.4091 - accuracy: 0.8187 - val_loss: 0.4265 - val_accuracy: 0.8094\n",
      "Epoch 106/250\n",
      "152/152 - 1s - loss: 0.4050 - accuracy: 0.8202 - val_loss: 0.4120 - val_accuracy: 0.8114\n",
      "Epoch 107/250\n",
      "152/152 - 1s - loss: 0.4076 - accuracy: 0.8198 - val_loss: 0.4071 - val_accuracy: 0.8195\n",
      "Epoch 108/250\n",
      "152/152 - 1s - loss: 0.4107 - accuracy: 0.8175 - val_loss: 0.4211 - val_accuracy: 0.8119\n",
      "Epoch 109/250\n",
      "152/152 - 1s - loss: 0.4053 - accuracy: 0.8198 - val_loss: 0.4041 - val_accuracy: 0.8190\n",
      "Epoch 110/250\n",
      "152/152 - 1s - loss: 0.4021 - accuracy: 0.8207 - val_loss: 0.4065 - val_accuracy: 0.8164\n",
      "Epoch 111/250\n",
      "152/152 - 1s - loss: 0.4016 - accuracy: 0.8210 - val_loss: 0.4041 - val_accuracy: 0.8205\n",
      "Epoch 112/250\n",
      "152/152 - 1s - loss: 0.4031 - accuracy: 0.8206 - val_loss: 0.4066 - val_accuracy: 0.8205\n",
      "Epoch 113/250\n",
      "152/152 - 1s - loss: 0.4020 - accuracy: 0.8218 - val_loss: 0.4019 - val_accuracy: 0.8206\n",
      "Epoch 114/250\n",
      "152/152 - 1s - loss: 0.4092 - accuracy: 0.8183 - val_loss: 0.4112 - val_accuracy: 0.8160\n",
      "Epoch 115/250\n",
      "152/152 - 1s - loss: 0.4030 - accuracy: 0.8205 - val_loss: 0.4043 - val_accuracy: 0.8209\n",
      "Epoch 116/250\n",
      "152/152 - 1s - loss: 0.4062 - accuracy: 0.8198 - val_loss: 0.4214 - val_accuracy: 0.8114\n",
      "Epoch 117/250\n",
      "152/152 - 1s - loss: 0.4060 - accuracy: 0.8202 - val_loss: 0.4065 - val_accuracy: 0.8150\n",
      "Epoch 118/250\n",
      "152/152 - 1s - loss: 0.4015 - accuracy: 0.8214 - val_loss: 0.4114 - val_accuracy: 0.8167\n",
      "Epoch 119/250\n",
      "152/152 - 1s - loss: 0.4053 - accuracy: 0.8197 - val_loss: 0.4046 - val_accuracy: 0.8206\n",
      "Epoch 120/250\n",
      "152/152 - 1s - loss: 0.4035 - accuracy: 0.8209 - val_loss: 0.4242 - val_accuracy: 0.8149\n",
      "Epoch 121/250\n",
      "152/152 - 1s - loss: 0.4021 - accuracy: 0.8211 - val_loss: 0.4019 - val_accuracy: 0.8208\n",
      "Epoch 122/250\n",
      "152/152 - 1s - loss: 0.4033 - accuracy: 0.8208 - val_loss: 0.4098 - val_accuracy: 0.8176\n",
      "Epoch 123/250\n",
      "152/152 - 1s - loss: 0.4010 - accuracy: 0.8210 - val_loss: 0.4029 - val_accuracy: 0.8179\n",
      "Epoch 124/250\n",
      "152/152 - 1s - loss: 0.4022 - accuracy: 0.8216 - val_loss: 0.4089 - val_accuracy: 0.8155\n",
      "Epoch 125/250\n",
      "152/152 - 1s - loss: 0.4051 - accuracy: 0.8199 - val_loss: 0.4035 - val_accuracy: 0.8181\n",
      "Epoch 126/250\n",
      "152/152 - 1s - loss: 0.4022 - accuracy: 0.8216 - val_loss: 0.4190 - val_accuracy: 0.8152\n",
      "Epoch 127/250\n",
      "152/152 - 1s - loss: 0.4048 - accuracy: 0.8203 - val_loss: 0.4036 - val_accuracy: 0.8182\n",
      "Epoch 128/250\n",
      "152/152 - 1s - loss: 0.4008 - accuracy: 0.8217 - val_loss: 0.4129 - val_accuracy: 0.8142\n",
      "Epoch 129/250\n",
      "152/152 - 1s - loss: 0.4026 - accuracy: 0.8223 - val_loss: 0.4050 - val_accuracy: 0.8204\n",
      "Epoch 130/250\n",
      "152/152 - 1s - loss: 0.4031 - accuracy: 0.8209 - val_loss: 0.4036 - val_accuracy: 0.8178\n",
      "Epoch 131/250\n",
      "152/152 - 1s - loss: 0.4076 - accuracy: 0.8201 - val_loss: 0.4090 - val_accuracy: 0.8174\n",
      "Epoch 132/250\n",
      "152/152 - 1s - loss: 0.4023 - accuracy: 0.8211 - val_loss: 0.4032 - val_accuracy: 0.8179\n",
      "Epoch 133/250\n",
      "152/152 - 1s - loss: 0.4033 - accuracy: 0.8205 - val_loss: 0.4071 - val_accuracy: 0.8176\n",
      "Epoch 134/250\n",
      "152/152 - 1s - loss: 0.4010 - accuracy: 0.8217 - val_loss: 0.4060 - val_accuracy: 0.8209\n",
      "Epoch 135/250\n",
      "152/152 - 1s - loss: 0.4022 - accuracy: 0.8212 - val_loss: 0.4036 - val_accuracy: 0.8203\n",
      "Epoch 136/250\n",
      "152/152 - 1s - loss: 0.4046 - accuracy: 0.8206 - val_loss: 0.4072 - val_accuracy: 0.8180\n",
      "Epoch 137/250\n",
      "152/152 - 1s - loss: 0.4069 - accuracy: 0.8191 - val_loss: 0.4171 - val_accuracy: 0.8168\n",
      "Epoch 138/250\n",
      "152/152 - 1s - loss: 0.3990 - accuracy: 0.8228 - val_loss: 0.4132 - val_accuracy: 0.8114\n",
      "Epoch 139/250\n",
      "152/152 - 1s - loss: 0.4000 - accuracy: 0.8221 - val_loss: 0.4443 - val_accuracy: 0.8063\n",
      "Epoch 140/250\n",
      "152/152 - 1s - loss: 0.4023 - accuracy: 0.8204 - val_loss: 0.4040 - val_accuracy: 0.8217\n",
      "Epoch 141/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 - 1s - loss: 0.4021 - accuracy: 0.8216 - val_loss: 0.4165 - val_accuracy: 0.8167\n",
      "Epoch 142/250\n",
      "152/152 - 1s - loss: 0.3999 - accuracy: 0.8224 - val_loss: 0.4108 - val_accuracy: 0.8158\n",
      "Epoch 143/250\n",
      "152/152 - 1s - loss: 0.4015 - accuracy: 0.8213 - val_loss: 0.4026 - val_accuracy: 0.8204\n",
      "Epoch 144/250\n",
      "152/152 - 1s - loss: 0.3999 - accuracy: 0.8217 - val_loss: 0.4055 - val_accuracy: 0.8202\n",
      "Epoch 145/250\n",
      "152/152 - 1s - loss: 0.4032 - accuracy: 0.8214 - val_loss: 0.4090 - val_accuracy: 0.8137\n",
      "Epoch 146/250\n",
      "152/152 - 1s - loss: 0.4009 - accuracy: 0.8225 - val_loss: 0.4118 - val_accuracy: 0.8176\n",
      "Epoch 147/250\n",
      "152/152 - 1s - loss: 0.4006 - accuracy: 0.8217 - val_loss: 0.4079 - val_accuracy: 0.8144\n",
      "Epoch 148/250\n",
      "152/152 - 1s - loss: 0.4015 - accuracy: 0.8221 - val_loss: 0.4218 - val_accuracy: 0.8140\n",
      "Epoch 149/250\n",
      "152/152 - 1s - loss: 0.4012 - accuracy: 0.8221 - val_loss: 0.4066 - val_accuracy: 0.8196\n",
      "Epoch 150/250\n",
      "152/152 - 1s - loss: 0.4041 - accuracy: 0.8208 - val_loss: 0.4452 - val_accuracy: 0.8049\n",
      "Epoch 151/250\n",
      "152/152 - 1s - loss: 0.4088 - accuracy: 0.8197 - val_loss: 0.4055 - val_accuracy: 0.8205\n",
      "Epoch 152/250\n",
      "152/152 - 1s - loss: 0.4000 - accuracy: 0.8229 - val_loss: 0.4027 - val_accuracy: 0.8206\n",
      "Epoch 153/250\n",
      "152/152 - 1s - loss: 0.4069 - accuracy: 0.8202 - val_loss: 0.4053 - val_accuracy: 0.8172\n",
      "Epoch 154/250\n",
      "152/152 - 1s - loss: 0.4017 - accuracy: 0.8216 - val_loss: 0.4270 - val_accuracy: 0.8135\n",
      "Epoch 155/250\n",
      "152/152 - 1s - loss: 0.4012 - accuracy: 0.8217 - val_loss: 0.4061 - val_accuracy: 0.8209\n",
      "Epoch 156/250\n",
      "152/152 - 1s - loss: 0.4018 - accuracy: 0.8217 - val_loss: 0.4083 - val_accuracy: 0.8162\n",
      "Epoch 157/250\n",
      "152/152 - 1s - loss: 0.3998 - accuracy: 0.8227 - val_loss: 0.4120 - val_accuracy: 0.8123\n",
      "Epoch 158/250\n",
      "152/152 - 1s - loss: 0.4006 - accuracy: 0.8220 - val_loss: 0.4072 - val_accuracy: 0.8185\n",
      "Epoch 159/250\n",
      "152/152 - 1s - loss: 0.4004 - accuracy: 0.8218 - val_loss: 0.4057 - val_accuracy: 0.8198\n",
      "Epoch 160/250\n",
      "152/152 - 1s - loss: 0.4020 - accuracy: 0.8215 - val_loss: 0.4160 - val_accuracy: 0.8155\n",
      "Epoch 161/250\n",
      "152/152 - 1s - loss: 0.3985 - accuracy: 0.8229 - val_loss: 0.4163 - val_accuracy: 0.8167\n",
      "Epoch 162/250\n",
      "152/152 - 1s - loss: 0.3993 - accuracy: 0.8227 - val_loss: 0.4062 - val_accuracy: 0.8169\n",
      "Epoch 163/250\n",
      "152/152 - 1s - loss: 0.3987 - accuracy: 0.8228 - val_loss: 0.4044 - val_accuracy: 0.8167\n",
      "Epoch 164/250\n",
      "152/152 - 1s - loss: 0.3996 - accuracy: 0.8217 - val_loss: 0.4192 - val_accuracy: 0.8135\n",
      "Epoch 165/250\n",
      "152/152 - 1s - loss: 0.4005 - accuracy: 0.8227 - val_loss: 0.4162 - val_accuracy: 0.8160\n",
      "Epoch 166/250\n",
      "152/152 - 1s - loss: 0.4051 - accuracy: 0.8209 - val_loss: 0.4130 - val_accuracy: 0.8171\n",
      "Epoch 167/250\n",
      "152/152 - 1s - loss: 0.4000 - accuracy: 0.8224 - val_loss: 0.4046 - val_accuracy: 0.8203\n",
      "Epoch 168/250\n",
      "152/152 - 1s - loss: 0.3999 - accuracy: 0.8219 - val_loss: 0.4187 - val_accuracy: 0.8152\n",
      "Epoch 169/250\n",
      "152/152 - 1s - loss: 0.4053 - accuracy: 0.8207 - val_loss: 0.4069 - val_accuracy: 0.8149\n",
      "Epoch 170/250\n",
      "152/152 - 1s - loss: 0.3989 - accuracy: 0.8229 - val_loss: 0.4069 - val_accuracy: 0.8196\n",
      "Epoch 171/250\n",
      "152/152 - 1s - loss: 0.3994 - accuracy: 0.8227 - val_loss: 0.4060 - val_accuracy: 0.8172\n",
      "Epoch 172/250\n",
      "152/152 - 1s - loss: 0.3985 - accuracy: 0.8228 - val_loss: 0.4236 - val_accuracy: 0.8117\n",
      "Epoch 173/250\n",
      "152/152 - 1s - loss: 0.4039 - accuracy: 0.8215 - val_loss: 0.4049 - val_accuracy: 0.8208\n",
      "Epoch 174/250\n",
      "152/152 - 1s - loss: 0.4005 - accuracy: 0.8228 - val_loss: 0.4064 - val_accuracy: 0.8203\n",
      "Epoch 175/250\n",
      "152/152 - 1s - loss: 0.3997 - accuracy: 0.8225 - val_loss: 0.4044 - val_accuracy: 0.8155\n",
      "Epoch 176/250\n",
      "152/152 - 1s - loss: 0.4015 - accuracy: 0.8227 - val_loss: 0.4046 - val_accuracy: 0.8195\n",
      "Epoch 177/250\n",
      "152/152 - 1s - loss: 0.3985 - accuracy: 0.8226 - val_loss: 0.4038 - val_accuracy: 0.8200\n",
      "Epoch 178/250\n",
      "152/152 - 1s - loss: 0.4006 - accuracy: 0.8225 - val_loss: 0.4028 - val_accuracy: 0.8198\n",
      "Epoch 179/250\n",
      "152/152 - 1s - loss: 0.4010 - accuracy: 0.8221 - val_loss: 0.4071 - val_accuracy: 0.8202\n",
      "Epoch 180/250\n",
      "152/152 - 1s - loss: 0.4019 - accuracy: 0.8220 - val_loss: 0.4037 - val_accuracy: 0.8210\n",
      "Epoch 181/250\n",
      "152/152 - 1s - loss: 0.3969 - accuracy: 0.8235 - val_loss: 0.4039 - val_accuracy: 0.8201\n",
      "Epoch 182/250\n",
      "152/152 - 1s - loss: 0.4034 - accuracy: 0.8217 - val_loss: 0.4048 - val_accuracy: 0.8188\n",
      "Epoch 183/250\n",
      "152/152 - 1s - loss: 0.4034 - accuracy: 0.8220 - val_loss: 0.4040 - val_accuracy: 0.8170\n",
      "Epoch 184/250\n",
      "152/152 - 1s - loss: 0.3982 - accuracy: 0.8231 - val_loss: 0.4075 - val_accuracy: 0.8191\n",
      "Epoch 185/250\n",
      "152/152 - 1s - loss: 0.4017 - accuracy: 0.8220 - val_loss: 0.4075 - val_accuracy: 0.8209\n",
      "Epoch 186/250\n",
      "152/152 - 1s - loss: 0.3990 - accuracy: 0.8231 - val_loss: 0.4041 - val_accuracy: 0.8190\n",
      "Epoch 187/250\n",
      "152/152 - 1s - loss: 0.3980 - accuracy: 0.8237 - val_loss: 0.4197 - val_accuracy: 0.8184\n",
      "Epoch 188/250\n",
      "152/152 - 1s - loss: 0.4020 - accuracy: 0.8225 - val_loss: 0.4043 - val_accuracy: 0.8207\n",
      "Epoch 189/250\n",
      "152/152 - 1s - loss: 0.3975 - accuracy: 0.8237 - val_loss: 0.4199 - val_accuracy: 0.8161\n",
      "Epoch 190/250\n",
      "152/152 - 1s - loss: 0.3979 - accuracy: 0.8237 - val_loss: 0.4080 - val_accuracy: 0.8145\n",
      "Epoch 191/250\n",
      "152/152 - 1s - loss: 0.4032 - accuracy: 0.8217 - val_loss: 0.4095 - val_accuracy: 0.8157\n",
      "Epoch 192/250\n",
      "152/152 - 1s - loss: 0.3987 - accuracy: 0.8227 - val_loss: 0.4096 - val_accuracy: 0.8188\n",
      "Epoch 193/250\n",
      "152/152 - 1s - loss: 0.3976 - accuracy: 0.8232 - val_loss: 0.4153 - val_accuracy: 0.8175\n",
      "Epoch 194/250\n",
      "152/152 - 1s - loss: 0.3991 - accuracy: 0.8231 - val_loss: 0.4043 - val_accuracy: 0.8205\n",
      "Epoch 195/250\n",
      "152/152 - 1s - loss: 0.3974 - accuracy: 0.8240 - val_loss: 0.4054 - val_accuracy: 0.8192\n",
      "Epoch 196/250\n",
      "152/152 - 1s - loss: 0.4008 - accuracy: 0.8225 - val_loss: 0.4069 - val_accuracy: 0.8169\n",
      "Epoch 197/250\n",
      "152/152 - 1s - loss: 0.4014 - accuracy: 0.8226 - val_loss: 0.4184 - val_accuracy: 0.8145\n",
      "Epoch 198/250\n",
      "152/152 - 1s - loss: 0.3990 - accuracy: 0.8232 - val_loss: 0.4098 - val_accuracy: 0.8183\n",
      "Epoch 199/250\n",
      "152/152 - 1s - loss: 0.3977 - accuracy: 0.8237 - val_loss: 0.4099 - val_accuracy: 0.8136\n",
      "Epoch 200/250\n",
      "152/152 - 1s - loss: 0.3975 - accuracy: 0.8237 - val_loss: 0.4039 - val_accuracy: 0.8204\n",
      "Epoch 201/250\n",
      "152/152 - 1s - loss: 0.3984 - accuracy: 0.8238 - val_loss: 0.4142 - val_accuracy: 0.8164\n",
      "Epoch 202/250\n",
      "152/152 - 1s - loss: 0.4023 - accuracy: 0.8217 - val_loss: 0.4071 - val_accuracy: 0.8196\n",
      "Epoch 203/250\n",
      "152/152 - 1s - loss: 0.3978 - accuracy: 0.8235 - val_loss: 0.4072 - val_accuracy: 0.8203\n",
      "Epoch 204/250\n",
      "152/152 - 1s - loss: 0.3953 - accuracy: 0.8247 - val_loss: 0.4034 - val_accuracy: 0.8192\n",
      "Epoch 205/250\n",
      "152/152 - 1s - loss: 0.3963 - accuracy: 0.8243 - val_loss: 0.4064 - val_accuracy: 0.8180\n",
      "Epoch 206/250\n",
      "152/152 - 1s - loss: 0.4034 - accuracy: 0.8216 - val_loss: 0.4184 - val_accuracy: 0.8188\n",
      "Epoch 207/250\n",
      "152/152 - 1s - loss: 0.3989 - accuracy: 0.8230 - val_loss: 0.4142 - val_accuracy: 0.8158\n",
      "Epoch 208/250\n",
      "152/152 - 1s - loss: 0.3972 - accuracy: 0.8240 - val_loss: 0.4079 - val_accuracy: 0.8162\n",
      "Epoch 209/250\n",
      "152/152 - 1s - loss: 0.4001 - accuracy: 0.8227 - val_loss: 0.4041 - val_accuracy: 0.8199\n",
      "Epoch 210/250\n",
      "152/152 - 1s - loss: 0.3993 - accuracy: 0.8233 - val_loss: 0.4043 - val_accuracy: 0.8178\n",
      "Epoch 211/250\n",
      "152/152 - 1s - loss: 0.3969 - accuracy: 0.8234 - val_loss: 0.4066 - val_accuracy: 0.8207\n",
      "Epoch 212/250\n",
      "152/152 - 1s - loss: 0.3966 - accuracy: 0.8242 - val_loss: 0.4206 - val_accuracy: 0.8172\n",
      "Epoch 213/250\n",
      "152/152 - 1s - loss: 0.3979 - accuracy: 0.8232 - val_loss: 0.4036 - val_accuracy: 0.8188\n",
      "Epoch 214/250\n",
      "152/152 - 1s - loss: 0.3983 - accuracy: 0.8236 - val_loss: 0.4052 - val_accuracy: 0.8183\n",
      "Epoch 215/250\n",
      "152/152 - 1s - loss: 0.3978 - accuracy: 0.8242 - val_loss: 0.4101 - val_accuracy: 0.8180\n",
      "Epoch 216/250\n",
      "152/152 - 1s - loss: 0.3999 - accuracy: 0.8228 - val_loss: 0.4130 - val_accuracy: 0.8149\n",
      "Epoch 217/250\n",
      "152/152 - 1s - loss: 0.3993 - accuracy: 0.8234 - val_loss: 0.4195 - val_accuracy: 0.8158\n",
      "Epoch 218/250\n",
      "152/152 - 1s - loss: 0.4048 - accuracy: 0.8219 - val_loss: 0.4113 - val_accuracy: 0.8143\n",
      "Epoch 219/250\n",
      "152/152 - 1s - loss: 0.3963 - accuracy: 0.8241 - val_loss: 0.4356 - val_accuracy: 0.8083\n",
      "Epoch 220/250\n",
      "152/152 - 1s - loss: 0.4004 - accuracy: 0.8235 - val_loss: 0.4044 - val_accuracy: 0.8200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 221/250\n",
      "152/152 - 1s - loss: 0.3989 - accuracy: 0.8234 - val_loss: 0.4041 - val_accuracy: 0.8195\n",
      "Epoch 222/250\n",
      "152/152 - 1s - loss: 0.3972 - accuracy: 0.8248 - val_loss: 0.4082 - val_accuracy: 0.8197\n",
      "Epoch 223/250\n",
      "152/152 - 1s - loss: 0.4017 - accuracy: 0.8228 - val_loss: 0.4069 - val_accuracy: 0.8195\n",
      "Epoch 224/250\n",
      "152/152 - 1s - loss: 0.3951 - accuracy: 0.8241 - val_loss: 0.4048 - val_accuracy: 0.8186\n",
      "Epoch 225/250\n",
      "152/152 - 1s - loss: 0.3956 - accuracy: 0.8245 - val_loss: 0.4104 - val_accuracy: 0.8196\n",
      "Epoch 226/250\n",
      "152/152 - 1s - loss: 0.3987 - accuracy: 0.8234 - val_loss: 0.4068 - val_accuracy: 0.8171\n",
      "Epoch 227/250\n",
      "152/152 - 1s - loss: 0.3960 - accuracy: 0.8245 - val_loss: 0.4226 - val_accuracy: 0.8147\n",
      "Epoch 228/250\n",
      "152/152 - 1s - loss: 0.4002 - accuracy: 0.8232 - val_loss: 0.4045 - val_accuracy: 0.8200\n",
      "Epoch 229/250\n",
      "152/152 - 1s - loss: 0.3968 - accuracy: 0.8238 - val_loss: 0.4063 - val_accuracy: 0.8174\n",
      "Epoch 230/250\n",
      "152/152 - 1s - loss: 0.3972 - accuracy: 0.8242 - val_loss: 0.4182 - val_accuracy: 0.8126\n",
      "Epoch 231/250\n",
      "152/152 - 1s - loss: 0.3989 - accuracy: 0.8238 - val_loss: 0.4257 - val_accuracy: 0.8090\n",
      "Epoch 232/250\n",
      "152/152 - 1s - loss: 0.3978 - accuracy: 0.8237 - val_loss: 0.4066 - val_accuracy: 0.8193\n",
      "Epoch 233/250\n",
      "152/152 - 1s - loss: 0.3957 - accuracy: 0.8239 - val_loss: 0.4102 - val_accuracy: 0.8118\n",
      "Epoch 234/250\n",
      "152/152 - 1s - loss: 0.3989 - accuracy: 0.8229 - val_loss: 0.4079 - val_accuracy: 0.8200\n",
      "Epoch 235/250\n",
      "152/152 - 1s - loss: 0.3953 - accuracy: 0.8244 - val_loss: 0.4218 - val_accuracy: 0.8117\n",
      "Epoch 236/250\n",
      "152/152 - 1s - loss: 0.3940 - accuracy: 0.8249 - val_loss: 0.4052 - val_accuracy: 0.8199\n",
      "Epoch 237/250\n",
      "152/152 - 1s - loss: 0.3983 - accuracy: 0.8238 - val_loss: 0.4155 - val_accuracy: 0.8157\n",
      "Epoch 238/250\n",
      "152/152 - 1s - loss: 0.3952 - accuracy: 0.8246 - val_loss: 0.4113 - val_accuracy: 0.8146\n",
      "Epoch 239/250\n",
      "152/152 - 1s - loss: 0.4000 - accuracy: 0.8237 - val_loss: 0.4069 - val_accuracy: 0.8166\n",
      "Epoch 240/250\n",
      "152/152 - 1s - loss: 0.3965 - accuracy: 0.8245 - val_loss: 0.4136 - val_accuracy: 0.8160\n",
      "Epoch 241/250\n",
      "152/152 - 1s - loss: 0.3957 - accuracy: 0.8245 - val_loss: 0.4132 - val_accuracy: 0.8187\n",
      "Epoch 242/250\n",
      "152/152 - 1s - loss: 0.3966 - accuracy: 0.8242 - val_loss: 0.4202 - val_accuracy: 0.8164\n",
      "Epoch 243/250\n",
      "152/152 - 1s - loss: 0.3953 - accuracy: 0.8250 - val_loss: 0.4083 - val_accuracy: 0.8188\n",
      "Epoch 244/250\n",
      "152/152 - 1s - loss: 0.3964 - accuracy: 0.8241 - val_loss: 0.4051 - val_accuracy: 0.8189\n",
      "Epoch 245/250\n",
      "152/152 - 1s - loss: 0.3939 - accuracy: 0.8255 - val_loss: 0.4127 - val_accuracy: 0.8134\n",
      "Epoch 246/250\n",
      "152/152 - 1s - loss: 0.3957 - accuracy: 0.8243 - val_loss: 0.4202 - val_accuracy: 0.8148\n",
      "Epoch 247/250\n",
      "152/152 - 1s - loss: 0.4023 - accuracy: 0.8224 - val_loss: 0.4041 - val_accuracy: 0.8197\n",
      "Epoch 248/250\n",
      "152/152 - 1s - loss: 0.3985 - accuracy: 0.8233 - val_loss: 0.4044 - val_accuracy: 0.8195\n",
      "Epoch 249/250\n",
      "152/152 - 1s - loss: 0.3951 - accuracy: 0.8253 - val_loss: 0.4099 - val_accuracy: 0.8163\n",
      "Epoch 250/250\n",
      "152/152 - 1s - loss: 0.4036 - accuracy: 0.8225 - val_loss: 0.4075 - val_accuracy: 0.8169\n",
      "1-layer-512\n",
      "Epoch 1/250\n",
      "152/152 - 1s - loss: 200.4189 - accuracy: 0.6449 - val_loss: 5.7396 - val_accuracy: 0.7503\n",
      "Epoch 2/250\n",
      "152/152 - 1s - loss: 6.1549 - accuracy: 0.6909 - val_loss: 9.1880 - val_accuracy: 0.7307\n",
      "Epoch 3/250\n",
      "152/152 - 1s - loss: 4.0978 - accuracy: 0.7399 - val_loss: 1.6921 - val_accuracy: 0.7819\n",
      "Epoch 4/250\n",
      "152/152 - 1s - loss: 3.8393 - accuracy: 0.7212 - val_loss: 1.9903 - val_accuracy: 0.7612\n",
      "Epoch 5/250\n",
      "152/152 - 1s - loss: 3.2551 - accuracy: 0.7325 - val_loss: 11.9420 - val_accuracy: 0.2892\n",
      "Epoch 6/250\n",
      "152/152 - 1s - loss: 2.8326 - accuracy: 0.7357 - val_loss: 1.0659 - val_accuracy: 0.7970\n",
      "Epoch 7/250\n",
      "152/152 - 1s - loss: 2.6169 - accuracy: 0.7283 - val_loss: 4.5056 - val_accuracy: 0.3266\n",
      "Epoch 8/250\n",
      "152/152 - 1s - loss: 3.8174 - accuracy: 0.6892 - val_loss: 4.2460 - val_accuracy: 0.7408\n",
      "Epoch 9/250\n",
      "152/152 - 1s - loss: 1.5847 - accuracy: 0.7714 - val_loss: 0.8059 - val_accuracy: 0.7951\n",
      "Epoch 10/250\n",
      "152/152 - 1s - loss: 2.7146 - accuracy: 0.7131 - val_loss: 0.8911 - val_accuracy: 0.8013\n",
      "Epoch 11/250\n",
      "152/152 - 1s - loss: 2.4790 - accuracy: 0.7300 - val_loss: 0.9793 - val_accuracy: 0.7858\n",
      "Epoch 12/250\n",
      "152/152 - 1s - loss: 2.1702 - accuracy: 0.7375 - val_loss: 0.7857 - val_accuracy: 0.7984\n",
      "Epoch 13/250\n",
      "152/152 - 2s - loss: 2.1559 - accuracy: 0.7048 - val_loss: 1.1249 - val_accuracy: 0.7874\n",
      "Epoch 14/250\n",
      "152/152 - 1s - loss: 1.3727 - accuracy: 0.7488 - val_loss: 1.4769 - val_accuracy: 0.6136\n",
      "Epoch 15/250\n",
      "152/152 - 1s - loss: 1.4412 - accuracy: 0.7182 - val_loss: 0.8205 - val_accuracy: 0.7851\n",
      "Epoch 16/250\n",
      "152/152 - 1s - loss: 1.3207 - accuracy: 0.7338 - val_loss: 1.2384 - val_accuracy: 0.6559\n",
      "Epoch 17/250\n",
      "152/152 - 1s - loss: 0.6522 - accuracy: 0.7867 - val_loss: 0.6756 - val_accuracy: 0.7275\n",
      "Epoch 18/250\n",
      "152/152 - 1s - loss: 1.3793 - accuracy: 0.6921 - val_loss: 0.6482 - val_accuracy: 0.7941\n",
      "Epoch 19/250\n",
      "152/152 - 1s - loss: 0.5885 - accuracy: 0.7911 - val_loss: 0.4914 - val_accuracy: 0.7953\n",
      "Epoch 20/250\n",
      "152/152 - 1s - loss: 0.7959 - accuracy: 0.7497 - val_loss: 1.9945 - val_accuracy: 0.7201\n",
      "Epoch 21/250\n",
      "152/152 - 1s - loss: 0.7098 - accuracy: 0.7636 - val_loss: 0.5269 - val_accuracy: 0.7831\n",
      "Epoch 22/250\n",
      "152/152 - 1s - loss: 0.4875 - accuracy: 0.7920 - val_loss: 0.4627 - val_accuracy: 0.7922\n",
      "Epoch 23/250\n",
      "152/152 - 1s - loss: 0.4797 - accuracy: 0.7904 - val_loss: 0.5122 - val_accuracy: 0.7807\n",
      "Epoch 24/250\n",
      "152/152 - 1s - loss: 0.4850 - accuracy: 0.7876 - val_loss: 0.5210 - val_accuracy: 0.7765\n",
      "Epoch 25/250\n",
      "152/152 - 1s - loss: 0.4902 - accuracy: 0.7872 - val_loss: 0.5116 - val_accuracy: 0.7783\n",
      "Epoch 26/250\n",
      "152/152 - 1s - loss: 0.5995 - accuracy: 0.7705 - val_loss: 0.8425 - val_accuracy: 0.7331\n",
      "Epoch 27/250\n",
      "152/152 - 1s - loss: 0.5075 - accuracy: 0.7821 - val_loss: 0.4556 - val_accuracy: 0.8011\n",
      "Epoch 28/250\n",
      "152/152 - 1s - loss: 0.9451 - accuracy: 0.7621 - val_loss: 0.4777 - val_accuracy: 0.7839\n",
      "Epoch 29/250\n",
      "152/152 - 1s - loss: 0.9567 - accuracy: 0.7945 - val_loss: 0.4542 - val_accuracy: 0.7894\n",
      "Epoch 30/250\n",
      "152/152 - 1s - loss: 0.5688 - accuracy: 0.7840 - val_loss: 0.4651 - val_accuracy: 0.8038\n",
      "Epoch 31/250\n",
      "152/152 - 1s - loss: 0.4460 - accuracy: 0.7994 - val_loss: 0.4455 - val_accuracy: 0.8029\n",
      "Epoch 32/250\n",
      "152/152 - 1s - loss: 0.4444 - accuracy: 0.7997 - val_loss: 0.4646 - val_accuracy: 0.8040\n",
      "Epoch 33/250\n",
      "152/152 - 1s - loss: 0.4494 - accuracy: 0.7976 - val_loss: 0.4441 - val_accuracy: 0.8038\n",
      "Epoch 34/250\n",
      "152/152 - 1s - loss: 0.4424 - accuracy: 0.7995 - val_loss: 0.4529 - val_accuracy: 0.8043\n",
      "Epoch 35/250\n",
      "152/152 - 1s - loss: 0.4522 - accuracy: 0.7963 - val_loss: 0.5144 - val_accuracy: 0.7658\n",
      "Epoch 36/250\n",
      "152/152 - 1s - loss: 0.4449 - accuracy: 0.7979 - val_loss: 0.4381 - val_accuracy: 0.7944\n",
      "Epoch 37/250\n",
      "152/152 - 1s - loss: 0.4416 - accuracy: 0.8001 - val_loss: 0.4427 - val_accuracy: 0.7895\n",
      "Epoch 38/250\n",
      "152/152 - 1s - loss: 0.4449 - accuracy: 0.7984 - val_loss: 0.4364 - val_accuracy: 0.8008\n",
      "Epoch 39/250\n",
      "152/152 - 1s - loss: 0.4396 - accuracy: 0.8006 - val_loss: 0.4453 - val_accuracy: 0.7867\n",
      "Epoch 40/250\n",
      "152/152 - 1s - loss: 0.4395 - accuracy: 0.8002 - val_loss: 0.4369 - val_accuracy: 0.8030\n",
      "Epoch 41/250\n",
      "152/152 - 1s - loss: 0.4381 - accuracy: 0.8010 - val_loss: 0.4368 - val_accuracy: 0.8032\n",
      "Epoch 42/250\n",
      "152/152 - 1s - loss: 0.4387 - accuracy: 0.8006 - val_loss: 0.4362 - val_accuracy: 0.7945\n",
      "Epoch 43/250\n",
      "152/152 - 1s - loss: 0.4379 - accuracy: 0.8012 - val_loss: 0.4355 - val_accuracy: 0.7958\n",
      "Epoch 44/250\n",
      "152/152 - 1s - loss: 0.4412 - accuracy: 0.7994 - val_loss: 0.4562 - val_accuracy: 0.8070\n",
      "Epoch 45/250\n",
      "152/152 - 1s - loss: 0.4391 - accuracy: 0.8005 - val_loss: 0.4653 - val_accuracy: 0.8088\n",
      "Epoch 46/250\n",
      "152/152 - 1s - loss: 0.4350 - accuracy: 0.8022 - val_loss: 0.4280 - val_accuracy: 0.8027\n",
      "Epoch 47/250\n",
      "152/152 - 1s - loss: 0.4321 - accuracy: 0.8038 - val_loss: 0.4247 - val_accuracy: 0.8024\n",
      "Epoch 48/250\n",
      "152/152 - 1s - loss: 0.4269 - accuracy: 0.8061 - val_loss: 0.4399 - val_accuracy: 0.8032\n",
      "Epoch 49/250\n",
      "152/152 - 1s - loss: 0.4258 - accuracy: 0.8053 - val_loss: 0.4226 - val_accuracy: 0.8046\n",
      "Epoch 50/250\n",
      "152/152 - 1s - loss: 0.4223 - accuracy: 0.8069 - val_loss: 0.4153 - val_accuracy: 0.8088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/250\n",
      "152/152 - 1s - loss: 0.4217 - accuracy: 0.8070 - val_loss: 0.4151 - val_accuracy: 0.8084\n",
      "Epoch 52/250\n",
      "152/152 - 1s - loss: 0.4195 - accuracy: 0.8075 - val_loss: 0.4394 - val_accuracy: 0.7961\n",
      "Epoch 53/250\n",
      "152/152 - 1s - loss: 0.4218 - accuracy: 0.8060 - val_loss: 0.4223 - val_accuracy: 0.8069\n",
      "Epoch 54/250\n",
      "152/152 - 1s - loss: 0.4193 - accuracy: 0.8086 - val_loss: 0.4168 - val_accuracy: 0.8080\n",
      "Epoch 55/250\n",
      "152/152 - 1s - loss: 0.4229 - accuracy: 0.8072 - val_loss: 0.4229 - val_accuracy: 0.8080\n",
      "Epoch 56/250\n",
      "152/152 - 1s - loss: 0.4192 - accuracy: 0.8085 - val_loss: 0.4281 - val_accuracy: 0.8038\n",
      "Epoch 57/250\n",
      "152/152 - 1s - loss: 0.4170 - accuracy: 0.8099 - val_loss: 0.4168 - val_accuracy: 0.8088\n",
      "Epoch 58/250\n",
      "152/152 - 1s - loss: 0.4229 - accuracy: 0.8074 - val_loss: 0.4159 - val_accuracy: 0.8090\n",
      "Epoch 59/250\n",
      "152/152 - 1s - loss: 0.4200 - accuracy: 0.8089 - val_loss: 0.4191 - val_accuracy: 0.8076\n",
      "Epoch 60/250\n",
      "152/152 - 1s - loss: 0.4192 - accuracy: 0.8096 - val_loss: 0.4173 - val_accuracy: 0.8077\n",
      "Epoch 61/250\n",
      "152/152 - 1s - loss: 0.4191 - accuracy: 0.8088 - val_loss: 0.4199 - val_accuracy: 0.8084\n",
      "Epoch 62/250\n",
      "152/152 - 1s - loss: 0.4234 - accuracy: 0.8071 - val_loss: 0.4135 - val_accuracy: 0.8100\n",
      "Epoch 63/250\n",
      "152/152 - 1s - loss: 0.4181 - accuracy: 0.8096 - val_loss: 0.4170 - val_accuracy: 0.8097\n",
      "Epoch 64/250\n",
      "152/152 - 1s - loss: 0.4201 - accuracy: 0.8079 - val_loss: 0.4210 - val_accuracy: 0.8080\n",
      "Epoch 65/250\n",
      "152/152 - 1s - loss: 0.4206 - accuracy: 0.8089 - val_loss: 0.4201 - val_accuracy: 0.8101\n",
      "Epoch 66/250\n",
      "152/152 - 1s - loss: 0.4217 - accuracy: 0.8081 - val_loss: 0.4120 - val_accuracy: 0.8107\n",
      "Epoch 67/250\n",
      "152/152 - 1s - loss: 0.4174 - accuracy: 0.8104 - val_loss: 0.4120 - val_accuracy: 0.8120\n",
      "Epoch 68/250\n",
      "152/152 - 1s - loss: 0.4232 - accuracy: 0.8080 - val_loss: 0.4131 - val_accuracy: 0.8129\n",
      "Epoch 69/250\n",
      "152/152 - 1s - loss: 0.4180 - accuracy: 0.8100 - val_loss: 0.4150 - val_accuracy: 0.8083\n",
      "Epoch 70/250\n",
      "152/152 - 1s - loss: 0.4227 - accuracy: 0.8086 - val_loss: 0.4129 - val_accuracy: 0.8097\n",
      "Epoch 71/250\n",
      "152/152 - 1s - loss: 0.4175 - accuracy: 0.8101 - val_loss: 0.4201 - val_accuracy: 0.8101\n",
      "Epoch 72/250\n",
      "152/152 - 1s - loss: 0.4186 - accuracy: 0.8104 - val_loss: 0.4198 - val_accuracy: 0.8106\n",
      "Epoch 73/250\n",
      "152/152 - 1s - loss: 0.4180 - accuracy: 0.8100 - val_loss: 0.4327 - val_accuracy: 0.8045\n",
      "Epoch 74/250\n",
      "152/152 - 1s - loss: 0.4190 - accuracy: 0.8107 - val_loss: 0.4201 - val_accuracy: 0.8098\n",
      "Epoch 75/250\n",
      "152/152 - 1s - loss: 0.4171 - accuracy: 0.8107 - val_loss: 0.4164 - val_accuracy: 0.8118\n",
      "Epoch 76/250\n",
      "152/152 - 1s - loss: 0.4236 - accuracy: 0.8092 - val_loss: 0.4237 - val_accuracy: 0.8084\n",
      "Epoch 77/250\n",
      "152/152 - 1s - loss: 0.4218 - accuracy: 0.8089 - val_loss: 0.4191 - val_accuracy: 0.8114\n",
      "Epoch 78/250\n",
      "152/152 - 1s - loss: 0.4215 - accuracy: 0.8084 - val_loss: 0.4136 - val_accuracy: 0.8111\n",
      "Epoch 79/250\n",
      "152/152 - 1s - loss: 0.4166 - accuracy: 0.8107 - val_loss: 0.4117 - val_accuracy: 0.8141\n",
      "Epoch 80/250\n",
      "152/152 - 1s - loss: 0.4181 - accuracy: 0.8111 - val_loss: 0.4192 - val_accuracy: 0.8095\n",
      "Epoch 81/250\n",
      "152/152 - 1s - loss: 0.4177 - accuracy: 0.8114 - val_loss: 0.4140 - val_accuracy: 0.8103\n",
      "Epoch 82/250\n",
      "152/152 - 1s - loss: 0.4200 - accuracy: 0.8108 - val_loss: 0.4314 - val_accuracy: 0.8041\n",
      "Epoch 83/250\n",
      "152/152 - 1s - loss: 0.4211 - accuracy: 0.8095 - val_loss: 0.4155 - val_accuracy: 0.8150\n",
      "Epoch 84/250\n",
      "152/152 - 1s - loss: 0.4210 - accuracy: 0.8097 - val_loss: 0.4116 - val_accuracy: 0.8126\n",
      "Epoch 85/250\n",
      "152/152 - 1s - loss: 0.4207 - accuracy: 0.8102 - val_loss: 0.4770 - val_accuracy: 0.7818\n",
      "Epoch 86/250\n",
      "152/152 - 1s - loss: 0.4214 - accuracy: 0.8106 - val_loss: 0.4307 - val_accuracy: 0.8067\n",
      "Epoch 87/250\n",
      "152/152 - 1s - loss: 0.4185 - accuracy: 0.8111 - val_loss: 0.4375 - val_accuracy: 0.8071\n",
      "Epoch 88/250\n",
      "152/152 - 1s - loss: 0.4365 - accuracy: 0.7641 - val_loss: 0.4338 - val_accuracy: 0.8098\n",
      "Epoch 89/250\n",
      "152/152 - 1s - loss: 0.4346 - accuracy: 0.8078 - val_loss: 0.4285 - val_accuracy: 0.8093\n",
      "Epoch 90/250\n",
      "152/152 - 1s - loss: 0.4290 - accuracy: 0.8085 - val_loss: 0.4271 - val_accuracy: 0.8097\n",
      "Epoch 91/250\n",
      "152/152 - 1s - loss: 0.4311 - accuracy: 0.8065 - val_loss: 0.4222 - val_accuracy: 0.8105\n",
      "Epoch 92/250\n",
      "152/152 - 1s - loss: 0.4287 - accuracy: 0.8072 - val_loss: 0.4246 - val_accuracy: 0.8066\n",
      "Epoch 93/250\n",
      "152/152 - 1s - loss: 0.4224 - accuracy: 0.8096 - val_loss: 0.4390 - val_accuracy: 0.8039\n",
      "Epoch 94/250\n",
      "152/152 - 1s - loss: 0.4246 - accuracy: 0.8085 - val_loss: 0.4227 - val_accuracy: 0.8061\n",
      "Epoch 95/250\n",
      "152/152 - 1s - loss: 0.4215 - accuracy: 0.8094 - val_loss: 0.4229 - val_accuracy: 0.8100\n",
      "Epoch 96/250\n",
      "152/152 - 1s - loss: 0.4210 - accuracy: 0.8101 - val_loss: 0.4164 - val_accuracy: 0.8108\n",
      "Epoch 97/250\n",
      "152/152 - 1s - loss: 0.4214 - accuracy: 0.8097 - val_loss: 0.4234 - val_accuracy: 0.8064\n",
      "Epoch 98/250\n",
      "152/152 - 1s - loss: 0.4231 - accuracy: 0.8094 - val_loss: 0.4147 - val_accuracy: 0.8112\n",
      "Epoch 99/250\n",
      "152/152 - 1s - loss: 0.4192 - accuracy: 0.8100 - val_loss: 0.4149 - val_accuracy: 0.8103\n",
      "Epoch 100/250\n",
      "152/152 - 1s - loss: 0.4190 - accuracy: 0.8109 - val_loss: 0.4145 - val_accuracy: 0.8106\n",
      "Epoch 101/250\n",
      "152/152 - 1s - loss: 0.4267 - accuracy: 0.8074 - val_loss: 0.4150 - val_accuracy: 0.8090\n",
      "Epoch 102/250\n",
      "152/152 - 1s - loss: 0.4197 - accuracy: 0.8103 - val_loss: 0.4144 - val_accuracy: 0.8115\n",
      "Epoch 103/250\n",
      "152/152 - 1s - loss: 0.4198 - accuracy: 0.8098 - val_loss: 0.4155 - val_accuracy: 0.8080\n",
      "Epoch 104/250\n",
      "152/152 - 1s - loss: 0.4174 - accuracy: 0.8112 - val_loss: 0.4225 - val_accuracy: 0.8108\n",
      "Epoch 105/250\n",
      "152/152 - 1s - loss: 0.4228 - accuracy: 0.8093 - val_loss: 0.4210 - val_accuracy: 0.8038\n",
      "Epoch 106/250\n",
      "152/152 - 1s - loss: 0.4234 - accuracy: 0.8091 - val_loss: 0.4272 - val_accuracy: 0.8043\n",
      "Epoch 107/250\n",
      "152/152 - 1s - loss: 0.4231 - accuracy: 0.8090 - val_loss: 0.4169 - val_accuracy: 0.8109\n",
      "Epoch 108/250\n",
      "152/152 - 1s - loss: 0.4179 - accuracy: 0.8111 - val_loss: 0.4194 - val_accuracy: 0.8099\n",
      "Epoch 109/250\n",
      "152/152 - 1s - loss: 0.4186 - accuracy: 0.8105 - val_loss: 0.4147 - val_accuracy: 0.8112\n",
      "Epoch 110/250\n",
      "152/152 - 1s - loss: 0.4175 - accuracy: 0.8109 - val_loss: 0.4203 - val_accuracy: 0.8107\n",
      "Epoch 111/250\n",
      "152/152 - 1s - loss: 0.4177 - accuracy: 0.8110 - val_loss: 0.4140 - val_accuracy: 0.8104\n",
      "Epoch 112/250\n",
      "152/152 - 1s - loss: 0.4204 - accuracy: 0.8097 - val_loss: 0.4187 - val_accuracy: 0.8105\n",
      "Epoch 113/250\n",
      "152/152 - 1s - loss: 0.4169 - accuracy: 0.8111 - val_loss: 0.4155 - val_accuracy: 0.8110\n",
      "Epoch 114/250\n",
      "152/152 - 1s - loss: 0.4189 - accuracy: 0.8107 - val_loss: 0.4491 - val_accuracy: 0.8009\n",
      "Epoch 115/250\n",
      "152/152 - 1s - loss: 0.4226 - accuracy: 0.8094 - val_loss: 0.4258 - val_accuracy: 0.8066\n",
      "Epoch 116/250\n",
      "152/152 - 1s - loss: 0.4175 - accuracy: 0.8109 - val_loss: 0.4258 - val_accuracy: 0.8108\n",
      "Epoch 117/250\n",
      "152/152 - 1s - loss: 0.4181 - accuracy: 0.8108 - val_loss: 0.4165 - val_accuracy: 0.8084\n",
      "Epoch 118/250\n",
      "152/152 - 1s - loss: 0.4181 - accuracy: 0.8108 - val_loss: 0.4151 - val_accuracy: 0.8115\n",
      "Epoch 119/250\n",
      "152/152 - 1s - loss: 0.4230 - accuracy: 0.8095 - val_loss: 0.4148 - val_accuracy: 0.8107\n",
      "Epoch 120/250\n",
      "152/152 - 1s - loss: 0.4233 - accuracy: 0.8086 - val_loss: 0.4168 - val_accuracy: 0.8107\n",
      "Epoch 121/250\n",
      "152/152 - 1s - loss: 0.4178 - accuracy: 0.8113 - val_loss: 0.4245 - val_accuracy: 0.8104\n",
      "Epoch 122/250\n",
      "152/152 - 1s - loss: 0.4195 - accuracy: 0.8108 - val_loss: 0.4222 - val_accuracy: 0.8106\n",
      "Epoch 123/250\n",
      "152/152 - 1s - loss: 0.4197 - accuracy: 0.8110 - val_loss: 0.4149 - val_accuracy: 0.8113\n",
      "Epoch 124/250\n",
      "152/152 - 1s - loss: 0.4202 - accuracy: 0.8099 - val_loss: 0.4259 - val_accuracy: 0.8056\n",
      "Epoch 125/250\n",
      "152/152 - 1s - loss: 0.4199 - accuracy: 0.8106 - val_loss: 0.4150 - val_accuracy: 0.8091\n",
      "Epoch 126/250\n",
      "152/152 - 1s - loss: 0.4173 - accuracy: 0.8117 - val_loss: 0.4140 - val_accuracy: 0.8099\n",
      "Epoch 127/250\n",
      "152/152 - 1s - loss: 0.4186 - accuracy: 0.8112 - val_loss: 0.4259 - val_accuracy: 0.8078\n",
      "Epoch 128/250\n",
      "152/152 - 1s - loss: 0.4178 - accuracy: 0.8114 - val_loss: 0.4167 - val_accuracy: 0.8083\n",
      "Epoch 129/250\n",
      "152/152 - 1s - loss: 0.4175 - accuracy: 0.8115 - val_loss: 0.4194 - val_accuracy: 0.8076\n",
      "Epoch 130/250\n",
      "152/152 - 1s - loss: 0.4252 - accuracy: 0.8086 - val_loss: 0.4203 - val_accuracy: 0.8083\n",
      "Epoch 131/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 - 1s - loss: 0.4171 - accuracy: 0.8115 - val_loss: 0.4225 - val_accuracy: 0.8079\n",
      "Epoch 132/250\n",
      "152/152 - 1s - loss: 0.4175 - accuracy: 0.8112 - val_loss: 0.4187 - val_accuracy: 0.8111\n",
      "Epoch 133/250\n",
      "152/152 - 1s - loss: 0.4188 - accuracy: 0.8113 - val_loss: 0.4149 - val_accuracy: 0.8112\n",
      "Epoch 134/250\n",
      "152/152 - 1s - loss: 0.4164 - accuracy: 0.8119 - val_loss: 0.4169 - val_accuracy: 0.8113\n",
      "Epoch 135/250\n",
      "152/152 - 1s - loss: 0.4197 - accuracy: 0.8107 - val_loss: 0.4157 - val_accuracy: 0.8087\n",
      "Epoch 136/250\n",
      "152/152 - 1s - loss: 0.4184 - accuracy: 0.8111 - val_loss: 0.4219 - val_accuracy: 0.8095\n",
      "Epoch 137/250\n",
      "152/152 - 1s - loss: 0.4162 - accuracy: 0.8119 - val_loss: 0.4161 - val_accuracy: 0.8087\n",
      "Epoch 138/250\n",
      "152/152 - 1s - loss: 0.4164 - accuracy: 0.8119 - val_loss: 0.4145 - val_accuracy: 0.8092\n",
      "Epoch 139/250\n",
      "152/152 - 1s - loss: 0.4179 - accuracy: 0.8110 - val_loss: 0.4292 - val_accuracy: 0.8059\n",
      "Epoch 140/250\n",
      "152/152 - 1s - loss: 0.4156 - accuracy: 0.8120 - val_loss: 0.4170 - val_accuracy: 0.8090\n",
      "Epoch 141/250\n",
      "152/152 - 1s - loss: 0.4156 - accuracy: 0.8126 - val_loss: 0.4141 - val_accuracy: 0.8099\n",
      "Epoch 142/250\n",
      "152/152 - 1s - loss: 0.4172 - accuracy: 0.8119 - val_loss: 0.4143 - val_accuracy: 0.8101\n",
      "Epoch 143/250\n",
      "152/152 - 1s - loss: 0.4168 - accuracy: 0.8118 - val_loss: 0.4327 - val_accuracy: 0.8080\n",
      "Epoch 144/250\n",
      "152/152 - 1s - loss: 0.4169 - accuracy: 0.8123 - val_loss: 0.4147 - val_accuracy: 0.8099\n",
      "Epoch 145/250\n",
      "152/152 - 1s - loss: 0.4222 - accuracy: 0.8099 - val_loss: 0.4196 - val_accuracy: 0.8109\n",
      "Epoch 146/250\n",
      "152/152 - 1s - loss: 0.4171 - accuracy: 0.8121 - val_loss: 0.4151 - val_accuracy: 0.8088\n",
      "Epoch 147/250\n",
      "152/152 - 1s - loss: 0.4171 - accuracy: 0.8115 - val_loss: 0.4203 - val_accuracy: 0.8110\n",
      "Epoch 148/250\n",
      "152/152 - 1s - loss: 0.4182 - accuracy: 0.8114 - val_loss: 0.4397 - val_accuracy: 0.8055\n",
      "Epoch 149/250\n",
      "152/152 - 1s - loss: 0.4190 - accuracy: 0.8113 - val_loss: 0.4148 - val_accuracy: 0.8104\n",
      "Epoch 150/250\n",
      "152/152 - 1s - loss: 0.4156 - accuracy: 0.8125 - val_loss: 0.4222 - val_accuracy: 0.8075\n",
      "Epoch 151/250\n",
      "152/152 - 1s - loss: 0.4178 - accuracy: 0.8112 - val_loss: 0.4193 - val_accuracy: 0.8109\n",
      "Epoch 152/250\n",
      "152/152 - 1s - loss: 0.4171 - accuracy: 0.8123 - val_loss: 0.4387 - val_accuracy: 0.8069\n",
      "Epoch 153/250\n",
      "152/152 - 1s - loss: 0.4200 - accuracy: 0.8109 - val_loss: 0.4291 - val_accuracy: 0.8081\n",
      "Epoch 154/250\n",
      "152/152 - 1s - loss: 0.4155 - accuracy: 0.8122 - val_loss: 0.4143 - val_accuracy: 0.8095\n",
      "Epoch 155/250\n",
      "152/152 - 1s - loss: 0.4191 - accuracy: 0.8113 - val_loss: 0.4156 - val_accuracy: 0.8100\n",
      "Epoch 156/250\n",
      "152/152 - 1s - loss: 0.4152 - accuracy: 0.8124 - val_loss: 0.4161 - val_accuracy: 0.8083\n",
      "Epoch 157/250\n",
      "152/152 - 1s - loss: 0.4166 - accuracy: 0.8120 - val_loss: 0.4147 - val_accuracy: 0.8090\n",
      "Epoch 158/250\n",
      "152/152 - 1s - loss: 0.4155 - accuracy: 0.8129 - val_loss: 0.4145 - val_accuracy: 0.8096\n",
      "Epoch 159/250\n",
      "152/152 - 1s - loss: 0.4183 - accuracy: 0.8121 - val_loss: 0.4150 - val_accuracy: 0.8110\n",
      "Epoch 160/250\n",
      "152/152 - 1s - loss: 0.4160 - accuracy: 0.8129 - val_loss: 0.4410 - val_accuracy: 0.8034\n",
      "Epoch 161/250\n",
      "152/152 - 1s - loss: 0.4163 - accuracy: 0.8125 - val_loss: 0.4154 - val_accuracy: 0.8091\n",
      "Epoch 162/250\n",
      "152/152 - 1s - loss: 0.4211 - accuracy: 0.8107 - val_loss: 0.4153 - val_accuracy: 0.8103\n",
      "Epoch 163/250\n",
      "152/152 - 1s - loss: 0.4162 - accuracy: 0.8126 - val_loss: 0.4395 - val_accuracy: 0.8063\n",
      "Epoch 164/250\n",
      "152/152 - 1s - loss: 0.4152 - accuracy: 0.8123 - val_loss: 0.4227 - val_accuracy: 0.8060\n",
      "Epoch 165/250\n",
      "152/152 - 1s - loss: 0.4174 - accuracy: 0.8119 - val_loss: 0.4186 - val_accuracy: 0.8080\n",
      "Epoch 166/250\n",
      "152/152 - 1s - loss: 0.4146 - accuracy: 0.8125 - val_loss: 0.4198 - val_accuracy: 0.8102\n",
      "Epoch 167/250\n",
      "152/152 - 1s - loss: 0.4141 - accuracy: 0.8126 - val_loss: 0.4147 - val_accuracy: 0.8098\n",
      "Epoch 168/250\n",
      "152/152 - 1s - loss: 0.4167 - accuracy: 0.8124 - val_loss: 0.4145 - val_accuracy: 0.8093\n",
      "Epoch 169/250\n",
      "152/152 - 1s - loss: 0.4141 - accuracy: 0.8130 - val_loss: 0.4151 - val_accuracy: 0.8088\n",
      "Epoch 170/250\n",
      "152/152 - 1s - loss: 0.4160 - accuracy: 0.8123 - val_loss: 0.4149 - val_accuracy: 0.8090\n",
      "Epoch 171/250\n",
      "152/152 - 1s - loss: 0.4137 - accuracy: 0.8128 - val_loss: 0.4152 - val_accuracy: 0.8108\n",
      "Epoch 172/250\n",
      "152/152 - 1s - loss: 0.4152 - accuracy: 0.8125 - val_loss: 0.4175 - val_accuracy: 0.8085\n",
      "Epoch 173/250\n",
      "152/152 - 1s - loss: 0.4150 - accuracy: 0.8124 - val_loss: 0.4164 - val_accuracy: 0.8088\n",
      "Epoch 174/250\n",
      "152/152 - 1s - loss: 0.4179 - accuracy: 0.8119 - val_loss: 0.4155 - val_accuracy: 0.8105\n",
      "Epoch 175/250\n",
      "152/152 - 1s - loss: 0.4179 - accuracy: 0.8117 - val_loss: 0.4155 - val_accuracy: 0.8082\n",
      "Epoch 176/250\n",
      "152/152 - 1s - loss: 0.4141 - accuracy: 0.8131 - val_loss: 0.4150 - val_accuracy: 0.8094\n",
      "Epoch 177/250\n",
      "152/152 - 1s - loss: 0.4153 - accuracy: 0.8129 - val_loss: 0.4163 - val_accuracy: 0.8079\n",
      "Epoch 178/250\n",
      "152/152 - 1s - loss: 0.4208 - accuracy: 0.8108 - val_loss: 0.4146 - val_accuracy: 0.8094\n",
      "Epoch 179/250\n",
      "152/152 - 1s - loss: 0.4166 - accuracy: 0.8121 - val_loss: 0.4157 - val_accuracy: 0.8084\n",
      "Epoch 180/250\n",
      "152/152 - 1s - loss: 0.4145 - accuracy: 0.8127 - val_loss: 0.4319 - val_accuracy: 0.8102\n",
      "Epoch 181/250\n",
      "152/152 - 1s - loss: 0.4158 - accuracy: 0.8127 - val_loss: 0.4156 - val_accuracy: 0.8105\n",
      "Epoch 182/250\n",
      "152/152 - 1s - loss: 0.4188 - accuracy: 0.8116 - val_loss: 0.4213 - val_accuracy: 0.8096\n",
      "Epoch 183/250\n",
      "152/152 - 1s - loss: 0.4172 - accuracy: 0.8125 - val_loss: 0.4167 - val_accuracy: 0.8091\n",
      "Epoch 184/250\n",
      "152/152 - 1s - loss: 0.4139 - accuracy: 0.8128 - val_loss: 0.4248 - val_accuracy: 0.8083\n",
      "Epoch 185/250\n",
      "152/152 - 1s - loss: 0.4176 - accuracy: 0.8117 - val_loss: 0.4260 - val_accuracy: 0.8054\n",
      "Epoch 186/250\n",
      "152/152 - 1s - loss: 0.4183 - accuracy: 0.8123 - val_loss: 0.4170 - val_accuracy: 0.8088\n",
      "Epoch 187/250\n",
      "152/152 - 1s - loss: 0.4131 - accuracy: 0.8134 - val_loss: 0.4154 - val_accuracy: 0.8103\n",
      "Epoch 188/250\n",
      "152/152 - 1s - loss: 0.4146 - accuracy: 0.8132 - val_loss: 0.4151 - val_accuracy: 0.8102\n",
      "Epoch 189/250\n",
      "152/152 - 1s - loss: 0.4169 - accuracy: 0.8126 - val_loss: 0.4248 - val_accuracy: 0.8085\n",
      "Epoch 190/250\n",
      "152/152 - 1s - loss: 0.4154 - accuracy: 0.8123 - val_loss: 0.4256 - val_accuracy: 0.8050\n",
      "Epoch 191/250\n",
      "152/152 - 1s - loss: 0.4159 - accuracy: 0.8118 - val_loss: 0.4151 - val_accuracy: 0.8096\n",
      "Epoch 192/250\n",
      "152/152 - 1s - loss: 0.4166 - accuracy: 0.8126 - val_loss: 0.4150 - val_accuracy: 0.8091\n",
      "Epoch 193/250\n",
      "152/152 - 1s - loss: 0.4148 - accuracy: 0.8128 - val_loss: 0.4166 - val_accuracy: 0.8110\n",
      "Epoch 194/250\n",
      "152/152 - 1s - loss: 0.4167 - accuracy: 0.8127 - val_loss: 0.4204 - val_accuracy: 0.8100\n",
      "Epoch 195/250\n",
      "152/152 - 1s - loss: 0.4159 - accuracy: 0.8121 - val_loss: 0.4148 - val_accuracy: 0.8093\n",
      "Epoch 196/250\n",
      "152/152 - 1s - loss: 0.4140 - accuracy: 0.8131 - val_loss: 0.4158 - val_accuracy: 0.8091\n",
      "Epoch 197/250\n",
      "152/152 - 1s - loss: 0.4148 - accuracy: 0.8130 - val_loss: 0.4154 - val_accuracy: 0.8101\n",
      "Epoch 198/250\n",
      "152/152 - 1s - loss: 0.4154 - accuracy: 0.8127 - val_loss: 0.4156 - val_accuracy: 0.8094\n",
      "Epoch 199/250\n",
      "152/152 - 1s - loss: 0.4150 - accuracy: 0.8130 - val_loss: 0.4180 - val_accuracy: 0.8108\n",
      "Epoch 200/250\n",
      "152/152 - 1s - loss: 0.4143 - accuracy: 0.8133 - val_loss: 0.4235 - val_accuracy: 0.8100\n",
      "Epoch 201/250\n",
      "152/152 - 1s - loss: 0.4160 - accuracy: 0.8129 - val_loss: 0.4338 - val_accuracy: 0.8042\n",
      "Epoch 202/250\n",
      "152/152 - 1s - loss: 0.4144 - accuracy: 0.8138 - val_loss: 0.4207 - val_accuracy: 0.8084\n",
      "Epoch 203/250\n",
      "152/152 - 1s - loss: 0.4142 - accuracy: 0.8131 - val_loss: 0.4163 - val_accuracy: 0.8105\n",
      "Epoch 204/250\n",
      "152/152 - 1s - loss: 0.4168 - accuracy: 0.8121 - val_loss: 0.4153 - val_accuracy: 0.8093\n",
      "Epoch 205/250\n",
      "152/152 - 1s - loss: 0.4145 - accuracy: 0.8128 - val_loss: 0.4170 - val_accuracy: 0.8096\n",
      "Epoch 206/250\n",
      "152/152 - 1s - loss: 0.4140 - accuracy: 0.8130 - val_loss: 0.4177 - val_accuracy: 0.8104\n",
      "Epoch 207/250\n",
      "152/152 - 1s - loss: 0.4152 - accuracy: 0.8129 - val_loss: 0.4152 - val_accuracy: 0.8095\n",
      "Epoch 208/250\n",
      "152/152 - 1s - loss: 0.4143 - accuracy: 0.8133 - val_loss: 0.4390 - val_accuracy: 0.8038\n",
      "Epoch 209/250\n",
      "152/152 - 1s - loss: 0.4154 - accuracy: 0.8130 - val_loss: 0.4158 - val_accuracy: 0.8092\n",
      "Epoch 210/250\n",
      "152/152 - 1s - loss: 0.4185 - accuracy: 0.8123 - val_loss: 0.4150 - val_accuracy: 0.8096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 211/250\n",
      "152/152 - 1s - loss: 0.4158 - accuracy: 0.8127 - val_loss: 0.4160 - val_accuracy: 0.8100\n",
      "Epoch 212/250\n",
      "152/152 - 1s - loss: 0.4168 - accuracy: 0.8127 - val_loss: 0.4314 - val_accuracy: 0.8050\n",
      "Epoch 213/250\n",
      "152/152 - 1s - loss: 0.4136 - accuracy: 0.8137 - val_loss: 0.4153 - val_accuracy: 0.8095\n",
      "Epoch 214/250\n",
      "152/152 - 1s - loss: 0.4140 - accuracy: 0.8138 - val_loss: 0.4196 - val_accuracy: 0.8080\n",
      "Epoch 215/250\n",
      "152/152 - 1s - loss: 0.4142 - accuracy: 0.8136 - val_loss: 0.4174 - val_accuracy: 0.8075\n",
      "Epoch 216/250\n",
      "152/152 - 1s - loss: 0.4143 - accuracy: 0.8132 - val_loss: 0.4159 - val_accuracy: 0.8097\n",
      "Epoch 217/250\n",
      "152/152 - 1s - loss: 0.4150 - accuracy: 0.8129 - val_loss: 0.4173 - val_accuracy: 0.8102\n",
      "Epoch 218/250\n",
      "152/152 - 1s - loss: 0.4144 - accuracy: 0.8131 - val_loss: 0.4175 - val_accuracy: 0.8076\n",
      "Epoch 219/250\n",
      "152/152 - 1s - loss: 0.4165 - accuracy: 0.8127 - val_loss: 0.4343 - val_accuracy: 0.8055\n",
      "Epoch 220/250\n",
      "152/152 - 1s - loss: 0.4161 - accuracy: 0.8123 - val_loss: 0.4154 - val_accuracy: 0.8093\n",
      "Epoch 221/250\n",
      "152/152 - 1s - loss: 0.4128 - accuracy: 0.8146 - val_loss: 0.4167 - val_accuracy: 0.8098\n",
      "Epoch 222/250\n",
      "152/152 - 1s - loss: 0.4140 - accuracy: 0.8133 - val_loss: 0.4201 - val_accuracy: 0.8096\n",
      "Epoch 223/250\n",
      "152/152 - 1s - loss: 0.4129 - accuracy: 0.8138 - val_loss: 0.4152 - val_accuracy: 0.8092\n",
      "Epoch 224/250\n",
      "152/152 - 1s - loss: 0.4129 - accuracy: 0.8138 - val_loss: 0.4190 - val_accuracy: 0.8083\n",
      "Epoch 225/250\n",
      "152/152 - 1s - loss: 0.4117 - accuracy: 0.8145 - val_loss: 0.4161 - val_accuracy: 0.8094\n",
      "Epoch 226/250\n",
      "152/152 - 1s - loss: 0.4181 - accuracy: 0.8131 - val_loss: 0.4174 - val_accuracy: 0.8071\n",
      "Epoch 227/250\n",
      "152/152 - 1s - loss: 0.4136 - accuracy: 0.8138 - val_loss: 0.4172 - val_accuracy: 0.8078\n",
      "Epoch 228/250\n",
      "152/152 - 1s - loss: 0.4142 - accuracy: 0.8133 - val_loss: 0.4154 - val_accuracy: 0.8093\n",
      "Epoch 229/250\n",
      "152/152 - 1s - loss: 0.4129 - accuracy: 0.8137 - val_loss: 0.4276 - val_accuracy: 0.8070\n",
      "Epoch 230/250\n",
      "152/152 - 1s - loss: 0.4126 - accuracy: 0.8140 - val_loss: 0.4189 - val_accuracy: 0.8097\n",
      "Epoch 231/250\n",
      "152/152 - 1s - loss: 0.4139 - accuracy: 0.8144 - val_loss: 0.4185 - val_accuracy: 0.8085\n",
      "Epoch 232/250\n",
      "152/152 - 1s - loss: 0.4128 - accuracy: 0.8141 - val_loss: 0.4188 - val_accuracy: 0.8082\n",
      "Epoch 233/250\n",
      "152/152 - 1s - loss: 0.4150 - accuracy: 0.8132 - val_loss: 0.4176 - val_accuracy: 0.8093\n",
      "Epoch 234/250\n",
      "152/152 - 1s - loss: 0.4131 - accuracy: 0.8137 - val_loss: 0.4227 - val_accuracy: 0.8093\n",
      "Epoch 235/250\n",
      "152/152 - 1s - loss: 0.4155 - accuracy: 0.8134 - val_loss: 0.4161 - val_accuracy: 0.8096\n",
      "Epoch 236/250\n",
      "152/152 - 1s - loss: 0.4149 - accuracy: 0.8133 - val_loss: 0.4167 - val_accuracy: 0.8096\n",
      "Epoch 237/250\n",
      "152/152 - 1s - loss: 0.4177 - accuracy: 0.8126 - val_loss: 0.4196 - val_accuracy: 0.8099\n",
      "Epoch 238/250\n",
      "152/152 - 1s - loss: 0.4135 - accuracy: 0.8140 - val_loss: 0.4174 - val_accuracy: 0.8069\n",
      "Epoch 239/250\n",
      "152/152 - 1s - loss: 0.4151 - accuracy: 0.8137 - val_loss: 0.4165 - val_accuracy: 0.8094\n",
      "Epoch 240/250\n",
      "152/152 - 1s - loss: 0.4135 - accuracy: 0.8134 - val_loss: 0.4157 - val_accuracy: 0.8087\n",
      "Epoch 241/250\n",
      "152/152 - 1s - loss: 0.4132 - accuracy: 0.8140 - val_loss: 0.4180 - val_accuracy: 0.8097\n",
      "Epoch 242/250\n",
      "152/152 - 1s - loss: 0.4126 - accuracy: 0.8139 - val_loss: 0.4239 - val_accuracy: 0.8095\n",
      "Epoch 243/250\n",
      "152/152 - 1s - loss: 0.4155 - accuracy: 0.8132 - val_loss: 0.4161 - val_accuracy: 0.8097\n",
      "Epoch 244/250\n",
      "152/152 - 1s - loss: 0.4129 - accuracy: 0.8145 - val_loss: 0.4311 - val_accuracy: 0.8072\n",
      "Epoch 245/250\n",
      "152/152 - 1s - loss: 0.4132 - accuracy: 0.8141 - val_loss: 0.4299 - val_accuracy: 0.8064\n",
      "Epoch 246/250\n",
      "152/152 - 1s - loss: 0.4160 - accuracy: 0.8134 - val_loss: 0.4169 - val_accuracy: 0.8094\n",
      "Epoch 247/250\n",
      "152/152 - 1s - loss: 0.4131 - accuracy: 0.8142 - val_loss: 0.4181 - val_accuracy: 0.8092\n",
      "Epoch 248/250\n",
      "152/152 - 1s - loss: 0.4124 - accuracy: 0.8143 - val_loss: 0.4173 - val_accuracy: 0.8095\n",
      "Epoch 249/250\n",
      "152/152 - 1s - loss: 0.4135 - accuracy: 0.8140 - val_loss: 0.4239 - val_accuracy: 0.8096\n",
      "Epoch 250/250\n",
      "152/152 - 1s - loss: 0.4131 - accuracy: 0.8140 - val_loss: 0.4185 - val_accuracy: 0.8080\n",
      "1-layer-2048\n",
      "Epoch 1/250\n",
      "152/152 - 2s - loss: 601.1031 - accuracy: 0.6399 - val_loss: 194.6924 - val_accuracy: 0.7164\n",
      "Epoch 2/250\n",
      "152/152 - 2s - loss: 39.5566 - accuracy: 0.7182 - val_loss: 14.8724 - val_accuracy: 0.8023\n",
      "Epoch 3/250\n",
      "152/152 - 2s - loss: 30.4246 - accuracy: 0.7246 - val_loss: 11.9062 - val_accuracy: 0.8042\n",
      "Epoch 4/250\n",
      "152/152 - 2s - loss: 23.1582 - accuracy: 0.7218 - val_loss: 19.1645 - val_accuracy: 0.7598\n",
      "Epoch 5/250\n",
      "152/152 - 2s - loss: 40.7707 - accuracy: 0.6933 - val_loss: 11.3153 - val_accuracy: 0.7461\n",
      "Epoch 6/250\n",
      "152/152 - 2s - loss: 5.6783 - accuracy: 0.7981 - val_loss: 2.9556 - val_accuracy: 0.8067\n",
      "Epoch 7/250\n",
      "152/152 - 2s - loss: 8.4447 - accuracy: 0.7299 - val_loss: 2.3484 - val_accuracy: 0.8076\n",
      "Epoch 8/250\n",
      "152/152 - 2s - loss: 12.0844 - accuracy: 0.6974 - val_loss: 4.3749 - val_accuracy: 0.7720\n",
      "Epoch 9/250\n",
      "152/152 - 2s - loss: 3.5885 - accuracy: 0.7495 - val_loss: 11.9011 - val_accuracy: 0.7163\n",
      "Epoch 10/250\n",
      "152/152 - 2s - loss: 4.4234 - accuracy: 0.7082 - val_loss: 1.4809 - val_accuracy: 0.8086\n",
      "Epoch 11/250\n",
      "152/152 - 2s - loss: 2.9998 - accuracy: 0.7359 - val_loss: 1.1411 - val_accuracy: 0.8065\n",
      "Epoch 12/250\n",
      "152/152 - 2s - loss: 2.7093 - accuracy: 0.7317 - val_loss: 1.6923 - val_accuracy: 0.7731\n",
      "Epoch 13/250\n",
      "152/152 - 2s - loss: 2.0989 - accuracy: 0.7354 - val_loss: 0.7062 - val_accuracy: 0.8056\n",
      "Epoch 14/250\n",
      "152/152 - 2s - loss: 1.4653 - accuracy: 0.7381 - val_loss: 0.9236 - val_accuracy: 0.7868\n",
      "Epoch 15/250\n",
      "152/152 - 2s - loss: 1.4847 - accuracy: 0.7476 - val_loss: 0.5863 - val_accuracy: 0.7900\n",
      "Epoch 16/250\n",
      "152/152 - 2s - loss: 0.9147 - accuracy: 0.7622 - val_loss: 0.4727 - val_accuracy: 0.8055\n",
      "Epoch 17/250\n",
      "152/152 - 2s - loss: 0.4609 - accuracy: 0.8035 - val_loss: 0.4369 - val_accuracy: 0.8041\n",
      "Epoch 18/250\n",
      "152/152 - 2s - loss: 0.5501 - accuracy: 0.7834 - val_loss: 0.9084 - val_accuracy: 0.6188\n",
      "Epoch 19/250\n",
      "152/152 - 2s - loss: 0.4561 - accuracy: 0.8003 - val_loss: 0.4184 - val_accuracy: 0.8131\n",
      "Epoch 20/250\n",
      "152/152 - 2s - loss: 0.4252 - accuracy: 0.8107 - val_loss: 0.4152 - val_accuracy: 0.8149\n",
      "Epoch 21/250\n",
      "152/152 - 2s - loss: 0.4162 - accuracy: 0.8152 - val_loss: 0.4114 - val_accuracy: 0.8154\n",
      "Epoch 22/250\n",
      "152/152 - 2s - loss: 0.4209 - accuracy: 0.8124 - val_loss: 0.4235 - val_accuracy: 0.8094\n",
      "Epoch 23/250\n",
      "152/152 - 2s - loss: 0.5099 - accuracy: 0.7855 - val_loss: 0.4126 - val_accuracy: 0.8165\n",
      "Epoch 24/250\n",
      "152/152 - 2s - loss: 0.4176 - accuracy: 0.8135 - val_loss: 0.4129 - val_accuracy: 0.8166\n",
      "Epoch 25/250\n",
      "152/152 - 2s - loss: 0.4095 - accuracy: 0.8185 - val_loss: 0.4185 - val_accuracy: 0.8132\n",
      "Epoch 26/250\n",
      "152/152 - 2s - loss: 0.4112 - accuracy: 0.8178 - val_loss: 0.4643 - val_accuracy: 0.7866\n",
      "Epoch 27/250\n",
      "152/152 - 2s - loss: 0.4350 - accuracy: 0.8072 - val_loss: 0.4052 - val_accuracy: 0.8187\n",
      "Epoch 28/250\n",
      "152/152 - 2s - loss: 0.4071 - accuracy: 0.8193 - val_loss: 0.3990 - val_accuracy: 0.8227\n",
      "Epoch 29/250\n",
      "152/152 - 2s - loss: 0.4023 - accuracy: 0.8226 - val_loss: 0.4050 - val_accuracy: 0.8198\n",
      "Epoch 30/250\n",
      "152/152 - 2s - loss: 0.4154 - accuracy: 0.8174 - val_loss: 0.4007 - val_accuracy: 0.8239\n",
      "Epoch 31/250\n",
      "152/152 - 2s - loss: 0.4039 - accuracy: 0.8216 - val_loss: 0.4428 - val_accuracy: 0.8063\n",
      "Epoch 32/250\n",
      "152/152 - 2s - loss: 0.4065 - accuracy: 0.8206 - val_loss: 0.4027 - val_accuracy: 0.8214\n",
      "Epoch 33/250\n",
      "152/152 - 2s - loss: 0.4085 - accuracy: 0.8203 - val_loss: 0.3961 - val_accuracy: 0.8260\n",
      "Epoch 34/250\n",
      "152/152 - 2s - loss: 0.4017 - accuracy: 0.8232 - val_loss: 0.3974 - val_accuracy: 0.8256\n",
      "Epoch 35/250\n",
      "152/152 - 2s - loss: 0.4065 - accuracy: 0.8216 - val_loss: 0.4297 - val_accuracy: 0.8132\n",
      "Epoch 36/250\n",
      "152/152 - 2s - loss: 0.4067 - accuracy: 0.8213 - val_loss: 0.4245 - val_accuracy: 0.8135\n",
      "Epoch 37/250\n",
      "152/152 - 2s - loss: 0.4022 - accuracy: 0.8230 - val_loss: 0.4020 - val_accuracy: 0.8235\n",
      "Epoch 38/250\n",
      "152/152 - 2s - loss: 0.4023 - accuracy: 0.8235 - val_loss: 0.4021 - val_accuracy: 0.8235\n",
      "Epoch 39/250\n",
      "152/152 - 2s - loss: 0.4009 - accuracy: 0.8240 - val_loss: 0.4080 - val_accuracy: 0.8231\n",
      "Epoch 40/250\n",
      "152/152 - 2s - loss: 0.4035 - accuracy: 0.8224 - val_loss: 0.4032 - val_accuracy: 0.8235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/250\n",
      "152/152 - 2s - loss: 0.4040 - accuracy: 0.8234 - val_loss: 0.4022 - val_accuracy: 0.8233\n",
      "Epoch 42/250\n",
      "152/152 - 2s - loss: 0.3998 - accuracy: 0.8247 - val_loss: 0.3986 - val_accuracy: 0.8266\n",
      "Epoch 43/250\n",
      "152/152 - 2s - loss: 0.4083 - accuracy: 0.8212 - val_loss: 0.4633 - val_accuracy: 0.7944\n",
      "Epoch 44/250\n",
      "152/152 - 2s - loss: 0.4049 - accuracy: 0.8231 - val_loss: 0.4110 - val_accuracy: 0.8215\n",
      "Epoch 45/250\n",
      "152/152 - 2s - loss: 0.4046 - accuracy: 0.8221 - val_loss: 0.3980 - val_accuracy: 0.8279\n",
      "Epoch 46/250\n",
      "152/152 - 2s - loss: 0.4028 - accuracy: 0.8235 - val_loss: 0.3927 - val_accuracy: 0.8280\n",
      "Epoch 47/250\n",
      "152/152 - 2s - loss: 0.4066 - accuracy: 0.8218 - val_loss: 0.4033 - val_accuracy: 0.8224\n",
      "Epoch 48/250\n",
      "152/152 - 2s - loss: 0.4079 - accuracy: 0.8221 - val_loss: 0.3964 - val_accuracy: 0.8270\n",
      "Epoch 49/250\n",
      "152/152 - 2s - loss: 0.4117 - accuracy: 0.8202 - val_loss: 0.4414 - val_accuracy: 0.8111\n",
      "Epoch 50/250\n",
      "152/152 - 2s - loss: 0.4066 - accuracy: 0.8223 - val_loss: 0.3936 - val_accuracy: 0.8271\n",
      "Epoch 51/250\n",
      "152/152 - 2s - loss: 0.4051 - accuracy: 0.8229 - val_loss: 0.3929 - val_accuracy: 0.8274\n",
      "Epoch 52/250\n",
      "152/152 - 2s - loss: 0.4081 - accuracy: 0.8211 - val_loss: 0.4075 - val_accuracy: 0.8217\n",
      "Epoch 53/250\n",
      "152/152 - 2s - loss: 0.4141 - accuracy: 0.8201 - val_loss: 0.4048 - val_accuracy: 0.8219\n",
      "Epoch 54/250\n",
      "152/152 - 2s - loss: 0.4064 - accuracy: 0.8223 - val_loss: 0.4216 - val_accuracy: 0.8157\n",
      "Epoch 55/250\n",
      "152/152 - 2s - loss: 0.4082 - accuracy: 0.8215 - val_loss: 0.3955 - val_accuracy: 0.8255\n",
      "Epoch 56/250\n",
      "152/152 - 2s - loss: 0.4134 - accuracy: 0.8205 - val_loss: 0.4110 - val_accuracy: 0.8166\n",
      "Epoch 57/250\n",
      "152/152 - 2s - loss: 0.4062 - accuracy: 0.8226 - val_loss: 0.4136 - val_accuracy: 0.8234\n",
      "Epoch 58/250\n",
      "152/152 - 2s - loss: 0.4419 - accuracy: 0.8067 - val_loss: 0.4064 - val_accuracy: 0.8209\n",
      "Epoch 59/250\n",
      "152/152 - 2s - loss: 0.4397 - accuracy: 0.8068 - val_loss: 0.4239 - val_accuracy: 0.8160\n",
      "Epoch 60/250\n",
      "152/152 - 2s - loss: 0.4266 - accuracy: 0.8159 - val_loss: 0.4126 - val_accuracy: 0.8212\n",
      "Epoch 61/250\n",
      "152/152 - 2s - loss: 0.4163 - accuracy: 0.8189 - val_loss: 0.4087 - val_accuracy: 0.8208\n",
      "Epoch 62/250\n",
      "152/152 - 2s - loss: 0.4189 - accuracy: 0.8175 - val_loss: 0.4268 - val_accuracy: 0.8167\n",
      "Epoch 63/250\n",
      "152/152 - 2s - loss: 0.4198 - accuracy: 0.8169 - val_loss: 0.4173 - val_accuracy: 0.8085\n",
      "Epoch 64/250\n",
      "152/152 - 2s - loss: 0.4183 - accuracy: 0.8171 - val_loss: 0.4218 - val_accuracy: 0.8123\n",
      "Epoch 65/250\n",
      "152/152 - 2s - loss: 0.4113 - accuracy: 0.8201 - val_loss: 0.4054 - val_accuracy: 0.8196\n",
      "Epoch 66/250\n",
      "152/152 - 2s - loss: 0.4158 - accuracy: 0.8179 - val_loss: 0.4069 - val_accuracy: 0.8213\n",
      "Epoch 67/250\n",
      "152/152 - 2s - loss: 0.4158 - accuracy: 0.8173 - val_loss: 0.4308 - val_accuracy: 0.8139\n",
      "Epoch 68/250\n",
      "152/152 - 2s - loss: 0.4086 - accuracy: 0.8213 - val_loss: 0.3984 - val_accuracy: 0.8258\n",
      "Epoch 69/250\n",
      "152/152 - 2s - loss: 0.4071 - accuracy: 0.8226 - val_loss: 0.3997 - val_accuracy: 0.8243\n",
      "Epoch 70/250\n",
      "152/152 - 2s - loss: 0.4095 - accuracy: 0.8199 - val_loss: 0.4377 - val_accuracy: 0.8073\n",
      "Epoch 71/250\n",
      "152/152 - 2s - loss: 0.4087 - accuracy: 0.8208 - val_loss: 0.4037 - val_accuracy: 0.8221\n",
      "Epoch 72/250\n",
      "152/152 - 2s - loss: 0.4099 - accuracy: 0.8213 - val_loss: 0.4271 - val_accuracy: 0.8180\n",
      "Epoch 73/250\n",
      "152/152 - 2s - loss: 0.4117 - accuracy: 0.8202 - val_loss: 0.3992 - val_accuracy: 0.8243\n",
      "Epoch 74/250\n",
      "152/152 - 2s - loss: 0.4045 - accuracy: 0.8221 - val_loss: 0.3984 - val_accuracy: 0.8244\n",
      "Epoch 75/250\n",
      "152/152 - 2s - loss: 0.4045 - accuracy: 0.8226 - val_loss: 0.4069 - val_accuracy: 0.8186\n",
      "Epoch 76/250\n",
      "152/152 - 2s - loss: 0.4050 - accuracy: 0.8221 - val_loss: 0.4039 - val_accuracy: 0.8218\n",
      "Epoch 77/250\n",
      "152/152 - 2s - loss: 0.4006 - accuracy: 0.8236 - val_loss: 0.4115 - val_accuracy: 0.8134\n",
      "Epoch 78/250\n",
      "152/152 - 2s - loss: 0.4074 - accuracy: 0.8220 - val_loss: 0.3985 - val_accuracy: 0.8233\n",
      "Epoch 79/250\n",
      "152/152 - 2s - loss: 0.4054 - accuracy: 0.8225 - val_loss: 0.4080 - val_accuracy: 0.8210\n",
      "Epoch 80/250\n",
      "152/152 - 2s - loss: 0.4046 - accuracy: 0.8228 - val_loss: 0.3982 - val_accuracy: 0.8229\n",
      "Epoch 81/250\n",
      "152/152 - 2s - loss: 0.4033 - accuracy: 0.8226 - val_loss: 0.4421 - val_accuracy: 0.8136\n",
      "Epoch 82/250\n",
      "152/152 - 2s - loss: 0.4069 - accuracy: 0.8225 - val_loss: 0.3994 - val_accuracy: 0.8249\n",
      "Epoch 83/250\n",
      "152/152 - 2s - loss: 0.4051 - accuracy: 0.8227 - val_loss: 0.4148 - val_accuracy: 0.8204\n",
      "Epoch 84/250\n",
      "152/152 - 2s - loss: 0.4044 - accuracy: 0.8234 - val_loss: 0.4035 - val_accuracy: 0.8196\n",
      "Epoch 85/250\n",
      "152/152 - 2s - loss: 0.4034 - accuracy: 0.8239 - val_loss: 0.3986 - val_accuracy: 0.8249\n",
      "Epoch 86/250\n",
      "152/152 - 2s - loss: 0.4008 - accuracy: 0.8243 - val_loss: 0.4138 - val_accuracy: 0.8172\n",
      "Epoch 87/250\n",
      "152/152 - 2s - loss: 0.4051 - accuracy: 0.8227 - val_loss: 0.3965 - val_accuracy: 0.8239\n",
      "Epoch 88/250\n",
      "152/152 - 2s - loss: 0.4144 - accuracy: 0.8194 - val_loss: 0.4117 - val_accuracy: 0.8215\n",
      "Epoch 89/250\n",
      "152/152 - 2s - loss: 0.4021 - accuracy: 0.8247 - val_loss: 0.3982 - val_accuracy: 0.8250\n",
      "Epoch 90/250\n",
      "152/152 - 2s - loss: 0.3991 - accuracy: 0.8249 - val_loss: 0.4192 - val_accuracy: 0.8200\n",
      "Epoch 91/250\n",
      "152/152 - 2s - loss: 0.4060 - accuracy: 0.8239 - val_loss: 0.3978 - val_accuracy: 0.8257\n",
      "Epoch 92/250\n",
      "152/152 - 2s - loss: 0.4027 - accuracy: 0.8243 - val_loss: 0.3990 - val_accuracy: 0.8242\n",
      "Epoch 93/250\n",
      "152/152 - 2s - loss: 0.4003 - accuracy: 0.8248 - val_loss: 0.3977 - val_accuracy: 0.8253\n",
      "Epoch 94/250\n",
      "152/152 - 2s - loss: 0.4163 - accuracy: 0.8197 - val_loss: 0.4176 - val_accuracy: 0.8189\n",
      "Epoch 95/250\n",
      "152/152 - 2s - loss: 0.4037 - accuracy: 0.8238 - val_loss: 0.4166 - val_accuracy: 0.8229\n",
      "Epoch 96/250\n",
      "152/152 - 2s - loss: 0.4033 - accuracy: 0.8240 - val_loss: 0.4044 - val_accuracy: 0.8188\n",
      "Epoch 97/250\n",
      "152/152 - 2s - loss: 0.4029 - accuracy: 0.8229 - val_loss: 0.4053 - val_accuracy: 0.8234\n",
      "Epoch 98/250\n",
      "152/152 - 2s - loss: 0.4056 - accuracy: 0.8220 - val_loss: 0.4104 - val_accuracy: 0.8199\n",
      "Epoch 99/250\n",
      "152/152 - 2s - loss: 0.4022 - accuracy: 0.8233 - val_loss: 0.4066 - val_accuracy: 0.8221\n",
      "Epoch 100/250\n",
      "152/152 - 2s - loss: 0.3994 - accuracy: 0.8250 - val_loss: 0.3966 - val_accuracy: 0.8244\n",
      "Epoch 101/250\n",
      "152/152 - 2s - loss: 0.4033 - accuracy: 0.8233 - val_loss: 0.4083 - val_accuracy: 0.8217\n",
      "Epoch 102/250\n",
      "152/152 - 2s - loss: 0.4006 - accuracy: 0.8241 - val_loss: 0.4017 - val_accuracy: 0.8261\n",
      "Epoch 103/250\n",
      "152/152 - 2s - loss: 0.4038 - accuracy: 0.8238 - val_loss: 0.4046 - val_accuracy: 0.8249\n",
      "Epoch 104/250\n",
      "152/152 - 2s - loss: 0.4048 - accuracy: 0.8233 - val_loss: 0.3963 - val_accuracy: 0.8259\n",
      "Epoch 105/250\n",
      "152/152 - 2s - loss: 0.4739 - accuracy: 0.8157 - val_loss: 0.4109 - val_accuracy: 0.8198\n",
      "Epoch 106/250\n",
      "152/152 - 2s - loss: 0.4036 - accuracy: 0.8235 - val_loss: 0.3959 - val_accuracy: 0.8248\n",
      "Epoch 107/250\n",
      "152/152 - 2s - loss: 0.3991 - accuracy: 0.8252 - val_loss: 0.4127 - val_accuracy: 0.8179\n",
      "Epoch 108/250\n",
      "152/152 - 2s - loss: 0.3978 - accuracy: 0.8247 - val_loss: 0.3967 - val_accuracy: 0.8249\n",
      "Epoch 109/250\n",
      "152/152 - 2s - loss: 0.3970 - accuracy: 0.8260 - val_loss: 0.3971 - val_accuracy: 0.8262\n",
      "Epoch 110/250\n",
      "152/152 - 2s - loss: 0.3979 - accuracy: 0.8254 - val_loss: 0.4009 - val_accuracy: 0.8220\n",
      "Epoch 111/250\n",
      "152/152 - 2s - loss: 0.3994 - accuracy: 0.8251 - val_loss: 0.4012 - val_accuracy: 0.8258\n",
      "Epoch 112/250\n",
      "152/152 - 2s - loss: 0.4007 - accuracy: 0.8246 - val_loss: 0.4028 - val_accuracy: 0.8242\n",
      "Epoch 113/250\n",
      "152/152 - 2s - loss: 0.3974 - accuracy: 0.8261 - val_loss: 0.4011 - val_accuracy: 0.8233\n",
      "Epoch 114/250\n",
      "152/152 - 2s - loss: 0.3996 - accuracy: 0.8259 - val_loss: 0.4040 - val_accuracy: 0.8244\n",
      "Epoch 115/250\n",
      "152/152 - 2s - loss: 0.4028 - accuracy: 0.8233 - val_loss: 0.4018 - val_accuracy: 0.8227\n",
      "Epoch 116/250\n",
      "152/152 - 2s - loss: 0.4026 - accuracy: 0.8220 - val_loss: 0.4048 - val_accuracy: 0.8235\n",
      "Epoch 117/250\n",
      "152/152 - 2s - loss: 0.4083 - accuracy: 0.8222 - val_loss: 0.3959 - val_accuracy: 0.8274\n",
      "Epoch 118/250\n",
      "152/152 - 2s - loss: 0.4015 - accuracy: 0.8243 - val_loss: 0.4004 - val_accuracy: 0.8224\n",
      "Epoch 119/250\n",
      "152/152 - 2s - loss: 0.4003 - accuracy: 0.8228 - val_loss: 0.4064 - val_accuracy: 0.8216\n",
      "Epoch 120/250\n",
      "152/152 - 2s - loss: 0.4044 - accuracy: 0.8219 - val_loss: 0.4009 - val_accuracy: 0.8242\n",
      "Epoch 121/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 - 2s - loss: 0.3997 - accuracy: 0.8237 - val_loss: 0.4012 - val_accuracy: 0.8226\n",
      "Epoch 122/250\n",
      "152/152 - 2s - loss: 0.4230 - accuracy: 0.8199 - val_loss: 0.4010 - val_accuracy: 0.8229\n",
      "Epoch 123/250\n",
      "152/152 - 2s - loss: 0.3988 - accuracy: 0.8240 - val_loss: 0.4191 - val_accuracy: 0.8167\n",
      "Epoch 124/250\n",
      "152/152 - 2s - loss: 0.3996 - accuracy: 0.8236 - val_loss: 0.4041 - val_accuracy: 0.8241\n",
      "Epoch 125/250\n",
      "152/152 - 2s - loss: 0.4007 - accuracy: 0.8231 - val_loss: 0.3980 - val_accuracy: 0.8247\n",
      "Epoch 126/250\n",
      "152/152 - 2s - loss: 0.4090 - accuracy: 0.8204 - val_loss: 0.4084 - val_accuracy: 0.8223\n",
      "Epoch 127/250\n",
      "152/152 - 2s - loss: 0.4028 - accuracy: 0.8225 - val_loss: 0.4052 - val_accuracy: 0.8181\n",
      "Epoch 128/250\n",
      "152/152 - 2s - loss: 0.3993 - accuracy: 0.8242 - val_loss: 0.4123 - val_accuracy: 0.8193\n",
      "Epoch 129/250\n",
      "152/152 - 2s - loss: 0.4179 - accuracy: 0.8162 - val_loss: 0.4008 - val_accuracy: 0.8226\n",
      "Epoch 130/250\n",
      "152/152 - 2s - loss: 0.3996 - accuracy: 0.8244 - val_loss: 0.4003 - val_accuracy: 0.8230\n",
      "Epoch 131/250\n",
      "152/152 - 2s - loss: 0.3971 - accuracy: 0.8250 - val_loss: 0.3997 - val_accuracy: 0.8195\n",
      "Epoch 132/250\n",
      "152/152 - 2s - loss: 0.4348 - accuracy: 0.8207 - val_loss: 0.3993 - val_accuracy: 0.8212\n",
      "Epoch 133/250\n",
      "152/152 - 2s - loss: 0.3972 - accuracy: 0.8248 - val_loss: 0.4041 - val_accuracy: 0.8209\n",
      "Epoch 134/250\n",
      "152/152 - 2s - loss: 0.3974 - accuracy: 0.8248 - val_loss: 0.4008 - val_accuracy: 0.8201\n",
      "Epoch 135/250\n",
      "152/152 - 2s - loss: 0.3999 - accuracy: 0.8239 - val_loss: 0.3976 - val_accuracy: 0.8229\n",
      "Epoch 136/250\n",
      "152/152 - 2s - loss: 0.3996 - accuracy: 0.8238 - val_loss: 0.4088 - val_accuracy: 0.8215\n",
      "Epoch 137/250\n",
      "152/152 - 2s - loss: 0.3995 - accuracy: 0.8235 - val_loss: 0.4041 - val_accuracy: 0.8177\n",
      "Epoch 138/250\n",
      "152/152 - 2s - loss: 0.3991 - accuracy: 0.8239 - val_loss: 0.3991 - val_accuracy: 0.8246\n",
      "Epoch 139/250\n",
      "152/152 - 2s - loss: 0.3982 - accuracy: 0.8242 - val_loss: 0.4086 - val_accuracy: 0.8194\n",
      "Epoch 140/250\n",
      "152/152 - 2s - loss: 0.4008 - accuracy: 0.8234 - val_loss: 0.4011 - val_accuracy: 0.8240\n",
      "Epoch 141/250\n",
      "152/152 - 2s - loss: 0.4016 - accuracy: 0.8240 - val_loss: 0.4003 - val_accuracy: 0.8231\n",
      "Epoch 142/250\n",
      "152/152 - 2s - loss: 0.3989 - accuracy: 0.8241 - val_loss: 0.4051 - val_accuracy: 0.8220\n",
      "Epoch 143/250\n",
      "152/152 - 2s - loss: 0.3976 - accuracy: 0.8248 - val_loss: 0.3985 - val_accuracy: 0.8234\n",
      "Epoch 144/250\n",
      "152/152 - 2s - loss: 0.4019 - accuracy: 0.8232 - val_loss: 0.3982 - val_accuracy: 0.8242\n",
      "Epoch 145/250\n",
      "152/152 - 2s - loss: 0.3979 - accuracy: 0.8242 - val_loss: 0.4254 - val_accuracy: 0.8116\n",
      "Epoch 146/250\n",
      "152/152 - 2s - loss: 0.4007 - accuracy: 0.8241 - val_loss: 0.4300 - val_accuracy: 0.8118\n",
      "Epoch 147/250\n",
      "152/152 - 2s - loss: 0.4011 - accuracy: 0.8238 - val_loss: 0.3985 - val_accuracy: 0.8249\n",
      "Epoch 148/250\n",
      "152/152 - 2s - loss: 0.3993 - accuracy: 0.8245 - val_loss: 0.4036 - val_accuracy: 0.8221\n",
      "Epoch 149/250\n",
      "152/152 - 2s - loss: 0.4073 - accuracy: 0.8222 - val_loss: 0.3993 - val_accuracy: 0.8236\n",
      "Epoch 150/250\n",
      "152/152 - 2s - loss: 0.3963 - accuracy: 0.8258 - val_loss: 0.4044 - val_accuracy: 0.8207\n",
      "Epoch 151/250\n",
      "152/152 - 2s - loss: 0.4041 - accuracy: 0.8221 - val_loss: 0.3989 - val_accuracy: 0.8259\n",
      "Epoch 152/250\n",
      "152/152 - 2s - loss: 0.3953 - accuracy: 0.8262 - val_loss: 0.3980 - val_accuracy: 0.8245\n",
      "Epoch 153/250\n",
      "152/152 - 2s - loss: 0.3980 - accuracy: 0.8252 - val_loss: 0.4020 - val_accuracy: 0.8239\n",
      "Epoch 154/250\n",
      "152/152 - 2s - loss: 0.4226 - accuracy: 0.8202 - val_loss: 0.4030 - val_accuracy: 0.8221\n",
      "Epoch 155/250\n",
      "152/152 - 2s - loss: 0.3980 - accuracy: 0.8244 - val_loss: 0.4031 - val_accuracy: 0.8248\n",
      "Epoch 156/250\n",
      "152/152 - 2s - loss: 0.3988 - accuracy: 0.8247 - val_loss: 0.4039 - val_accuracy: 0.8223\n",
      "Epoch 157/250\n",
      "152/152 - 2s - loss: 0.4023 - accuracy: 0.8229 - val_loss: 0.3987 - val_accuracy: 0.8222\n",
      "Epoch 158/250\n",
      "152/152 - 2s - loss: 0.3949 - accuracy: 0.8264 - val_loss: 0.4004 - val_accuracy: 0.8245\n",
      "Epoch 159/250\n",
      "152/152 - 2s - loss: 0.3947 - accuracy: 0.8260 - val_loss: 0.4058 - val_accuracy: 0.8233\n",
      "Epoch 160/250\n",
      "152/152 - 2s - loss: 0.3991 - accuracy: 0.8246 - val_loss: 0.4011 - val_accuracy: 0.8219\n",
      "Epoch 161/250\n",
      "152/152 - 2s - loss: 0.3974 - accuracy: 0.8245 - val_loss: 0.4043 - val_accuracy: 0.8195\n",
      "Epoch 162/250\n",
      "152/152 - 2s - loss: 0.3954 - accuracy: 0.8262 - val_loss: 0.4140 - val_accuracy: 0.8184\n",
      "Epoch 163/250\n",
      "152/152 - 2s - loss: 0.3949 - accuracy: 0.8258 - val_loss: 0.4039 - val_accuracy: 0.8208\n",
      "Epoch 164/250\n",
      "152/152 - 2s - loss: 0.3960 - accuracy: 0.8258 - val_loss: 0.4028 - val_accuracy: 0.8240\n",
      "Epoch 165/250\n",
      "152/152 - 2s - loss: 0.3960 - accuracy: 0.8256 - val_loss: 0.4022 - val_accuracy: 0.8235\n",
      "Epoch 166/250\n",
      "152/152 - 2s - loss: 0.4004 - accuracy: 0.8245 - val_loss: 0.3991 - val_accuracy: 0.8233\n",
      "Epoch 167/250\n",
      "152/152 - 2s - loss: 0.3966 - accuracy: 0.8254 - val_loss: 0.4021 - val_accuracy: 0.8235\n",
      "Epoch 168/250\n",
      "152/152 - 2s - loss: 0.3961 - accuracy: 0.8259 - val_loss: 0.4162 - val_accuracy: 0.8148\n",
      "Epoch 169/250\n",
      "152/152 - 2s - loss: 0.3978 - accuracy: 0.8249 - val_loss: 0.3986 - val_accuracy: 0.8238\n",
      "Epoch 170/250\n",
      "152/152 - 2s - loss: 0.3987 - accuracy: 0.8252 - val_loss: 0.3994 - val_accuracy: 0.8205\n",
      "Epoch 171/250\n",
      "152/152 - 2s - loss: 0.3959 - accuracy: 0.8256 - val_loss: 0.4076 - val_accuracy: 0.8236\n",
      "Epoch 172/250\n",
      "152/152 - 2s - loss: 0.3943 - accuracy: 0.8265 - val_loss: 0.4116 - val_accuracy: 0.8234\n",
      "Epoch 173/250\n",
      "152/152 - 2s - loss: 0.3965 - accuracy: 0.8253 - val_loss: 0.4062 - val_accuracy: 0.8166\n",
      "Epoch 174/250\n",
      "152/152 - 2s - loss: 0.3950 - accuracy: 0.8262 - val_loss: 0.4020 - val_accuracy: 0.8216\n",
      "Epoch 175/250\n",
      "152/152 - 2s - loss: 0.4012 - accuracy: 0.8236 - val_loss: 0.4003 - val_accuracy: 0.8228\n",
      "Epoch 176/250\n",
      "152/152 - 2s - loss: 0.3969 - accuracy: 0.8260 - val_loss: 0.4079 - val_accuracy: 0.8195\n",
      "Epoch 177/250\n",
      "152/152 - 2s - loss: 0.3995 - accuracy: 0.8247 - val_loss: 0.4158 - val_accuracy: 0.8234\n",
      "Epoch 178/250\n",
      "152/152 - 2s - loss: 0.3953 - accuracy: 0.8262 - val_loss: 0.4114 - val_accuracy: 0.8133\n",
      "Epoch 179/250\n",
      "152/152 - 2s - loss: 0.3951 - accuracy: 0.8259 - val_loss: 0.3994 - val_accuracy: 0.8213\n",
      "Epoch 180/250\n",
      "152/152 - 2s - loss: 0.3954 - accuracy: 0.8266 - val_loss: 0.4030 - val_accuracy: 0.8236\n",
      "Epoch 181/250\n",
      "152/152 - 2s - loss: 0.3933 - accuracy: 0.8268 - val_loss: 0.4113 - val_accuracy: 0.8200\n",
      "Epoch 182/250\n",
      "152/152 - 2s - loss: 0.3942 - accuracy: 0.8274 - val_loss: 0.4036 - val_accuracy: 0.8210\n",
      "Epoch 183/250\n",
      "152/152 - 2s - loss: 0.3970 - accuracy: 0.8255 - val_loss: 0.4117 - val_accuracy: 0.8179\n",
      "Epoch 184/250\n",
      "152/152 - 2s - loss: 0.3974 - accuracy: 0.8253 - val_loss: 0.4274 - val_accuracy: 0.8111\n",
      "Epoch 185/250\n",
      "152/152 - 2s - loss: 0.3964 - accuracy: 0.8248 - val_loss: 0.4065 - val_accuracy: 0.8184\n",
      "Epoch 186/250\n",
      "152/152 - 2s - loss: 0.3936 - accuracy: 0.8267 - val_loss: 0.4220 - val_accuracy: 0.8144\n",
      "Epoch 187/250\n",
      "152/152 - 2s - loss: 0.3947 - accuracy: 0.8261 - val_loss: 0.4008 - val_accuracy: 0.8194\n",
      "Epoch 188/250\n",
      "152/152 - 2s - loss: 0.3959 - accuracy: 0.8258 - val_loss: 0.4030 - val_accuracy: 0.8219\n",
      "Epoch 189/250\n",
      "152/152 - 2s - loss: 0.3937 - accuracy: 0.8265 - val_loss: 0.3990 - val_accuracy: 0.8254\n",
      "Epoch 190/250\n",
      "152/152 - 2s - loss: 0.3930 - accuracy: 0.8277 - val_loss: 0.4235 - val_accuracy: 0.8154\n",
      "Epoch 191/250\n",
      "152/152 - 2s - loss: 0.3937 - accuracy: 0.8272 - val_loss: 0.4141 - val_accuracy: 0.8191\n",
      "Epoch 192/250\n",
      "152/152 - 2s - loss: 0.3937 - accuracy: 0.8271 - val_loss: 0.3994 - val_accuracy: 0.8251\n",
      "Epoch 193/250\n",
      "152/152 - 2s - loss: 0.3933 - accuracy: 0.8267 - val_loss: 0.4073 - val_accuracy: 0.8219\n",
      "Epoch 194/250\n",
      "152/152 - 2s - loss: 0.4018 - accuracy: 0.8244 - val_loss: 0.4579 - val_accuracy: 0.7958\n",
      "Epoch 195/250\n",
      "152/152 - 2s - loss: 0.3940 - accuracy: 0.8269 - val_loss: 0.4061 - val_accuracy: 0.8228\n",
      "Epoch 196/250\n",
      "152/152 - 2s - loss: 0.3901 - accuracy: 0.8283 - val_loss: 0.4060 - val_accuracy: 0.8198\n",
      "Epoch 197/250\n",
      "152/152 - 2s - loss: 0.3932 - accuracy: 0.8275 - val_loss: 0.4024 - val_accuracy: 0.8231\n",
      "Epoch 198/250\n",
      "152/152 - 2s - loss: 0.3971 - accuracy: 0.8268 - val_loss: 0.4052 - val_accuracy: 0.8202\n",
      "Epoch 199/250\n",
      "152/152 - 2s - loss: 0.3987 - accuracy: 0.8261 - val_loss: 0.4171 - val_accuracy: 0.8197\n",
      "Epoch 200/250\n",
      "152/152 - 2s - loss: 0.3939 - accuracy: 0.8270 - val_loss: 0.4004 - val_accuracy: 0.8235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 201/250\n",
      "152/152 - 2s - loss: 0.3913 - accuracy: 0.8272 - val_loss: 0.4103 - val_accuracy: 0.8135\n",
      "Epoch 202/250\n",
      "152/152 - 2s - loss: 0.3919 - accuracy: 0.8278 - val_loss: 0.4103 - val_accuracy: 0.8178\n",
      "Epoch 203/250\n",
      "152/152 - 2s - loss: 0.3913 - accuracy: 0.8280 - val_loss: 0.4033 - val_accuracy: 0.8231\n",
      "Epoch 204/250\n",
      "152/152 - 2s - loss: 0.3927 - accuracy: 0.8279 - val_loss: 0.3999 - val_accuracy: 0.8243\n",
      "Epoch 205/250\n",
      "152/152 - 2s - loss: 0.3950 - accuracy: 0.8268 - val_loss: 0.4011 - val_accuracy: 0.8239\n",
      "Epoch 206/250\n",
      "152/152 - 2s - loss: 0.3928 - accuracy: 0.8274 - val_loss: 0.3994 - val_accuracy: 0.8243\n",
      "Epoch 207/250\n",
      "152/152 - 2s - loss: 0.3929 - accuracy: 0.8279 - val_loss: 0.4006 - val_accuracy: 0.8239\n",
      "Epoch 208/250\n",
      "152/152 - 2s - loss: 0.3900 - accuracy: 0.8290 - val_loss: 0.3986 - val_accuracy: 0.8242\n",
      "Epoch 209/250\n",
      "152/152 - 2s - loss: 0.3923 - accuracy: 0.8279 - val_loss: 0.4053 - val_accuracy: 0.8180\n",
      "Epoch 210/250\n",
      "152/152 - 2s - loss: 0.3947 - accuracy: 0.8269 - val_loss: 0.3991 - val_accuracy: 0.8239\n",
      "Epoch 211/250\n",
      "152/152 - 2s - loss: 0.3900 - accuracy: 0.8285 - val_loss: 0.3995 - val_accuracy: 0.8233\n",
      "Epoch 212/250\n",
      "152/152 - 2s - loss: 0.3914 - accuracy: 0.8279 - val_loss: 0.4000 - val_accuracy: 0.8227\n",
      "Epoch 213/250\n",
      "152/152 - 2s - loss: 0.3915 - accuracy: 0.8284 - val_loss: 0.4059 - val_accuracy: 0.8191\n",
      "Epoch 214/250\n",
      "152/152 - 2s - loss: 0.3938 - accuracy: 0.8272 - val_loss: 0.4078 - val_accuracy: 0.8227\n",
      "Epoch 215/250\n",
      "152/152 - 2s - loss: 0.3951 - accuracy: 0.8275 - val_loss: 0.4034 - val_accuracy: 0.8207\n",
      "Epoch 216/250\n",
      "152/152 - 2s - loss: 0.3948 - accuracy: 0.8270 - val_loss: 0.4272 - val_accuracy: 0.8110\n",
      "Epoch 217/250\n",
      "152/152 - 2s - loss: 0.3962 - accuracy: 0.8271 - val_loss: 0.4003 - val_accuracy: 0.8238\n",
      "Epoch 218/250\n",
      "152/152 - 2s - loss: 0.3914 - accuracy: 0.8281 - val_loss: 0.4161 - val_accuracy: 0.8223\n",
      "Epoch 219/250\n",
      "152/152 - 2s - loss: 0.3941 - accuracy: 0.8266 - val_loss: 0.4014 - val_accuracy: 0.8227\n",
      "Epoch 220/250\n",
      "152/152 - 2s - loss: 0.3918 - accuracy: 0.8283 - val_loss: 0.4073 - val_accuracy: 0.8209\n",
      "Epoch 221/250\n",
      "152/152 - 2s - loss: 0.3939 - accuracy: 0.8272 - val_loss: 0.4213 - val_accuracy: 0.8190\n",
      "Epoch 222/250\n",
      "152/152 - 2s - loss: 0.3912 - accuracy: 0.8284 - val_loss: 0.4108 - val_accuracy: 0.8197\n",
      "Epoch 223/250\n",
      "152/152 - 2s - loss: 0.3912 - accuracy: 0.8281 - val_loss: 0.4308 - val_accuracy: 0.8082\n",
      "Epoch 224/250\n",
      "152/152 - 2s - loss: 0.3931 - accuracy: 0.8272 - val_loss: 0.4102 - val_accuracy: 0.8153\n",
      "Epoch 225/250\n",
      "152/152 - 2s - loss: 0.3928 - accuracy: 0.8272 - val_loss: 0.4036 - val_accuracy: 0.8225\n",
      "Epoch 226/250\n",
      "152/152 - 2s - loss: 0.3897 - accuracy: 0.8291 - val_loss: 0.4086 - val_accuracy: 0.8207\n",
      "Epoch 227/250\n",
      "152/152 - 2s - loss: 0.3930 - accuracy: 0.8279 - val_loss: 0.4350 - val_accuracy: 0.8150\n",
      "Epoch 228/250\n",
      "152/152 - 2s - loss: 0.3915 - accuracy: 0.8290 - val_loss: 0.4123 - val_accuracy: 0.8190\n",
      "Epoch 229/250\n",
      "152/152 - 2s - loss: 0.3958 - accuracy: 0.8271 - val_loss: 0.3997 - val_accuracy: 0.8248\n",
      "Epoch 230/250\n",
      "152/152 - 2s - loss: 0.3967 - accuracy: 0.8269 - val_loss: 0.3981 - val_accuracy: 0.8240\n",
      "Epoch 231/250\n",
      "152/152 - 2s - loss: 0.3914 - accuracy: 0.8283 - val_loss: 0.4108 - val_accuracy: 0.8218\n",
      "Epoch 232/250\n",
      "152/152 - 2s - loss: 0.3883 - accuracy: 0.8304 - val_loss: 0.4082 - val_accuracy: 0.8201\n",
      "Epoch 233/250\n",
      "152/152 - 2s - loss: 0.3932 - accuracy: 0.8280 - val_loss: 0.4006 - val_accuracy: 0.8229\n",
      "Epoch 234/250\n",
      "152/152 - 2s - loss: 0.3894 - accuracy: 0.8295 - val_loss: 0.4041 - val_accuracy: 0.8206\n",
      "Epoch 235/250\n",
      "152/152 - 2s - loss: 0.3890 - accuracy: 0.8299 - val_loss: 0.4031 - val_accuracy: 0.8242\n",
      "Epoch 236/250\n",
      "152/152 - 2s - loss: 0.3892 - accuracy: 0.8294 - val_loss: 0.4045 - val_accuracy: 0.8243\n",
      "Epoch 237/250\n",
      "152/152 - 2s - loss: 0.3918 - accuracy: 0.8284 - val_loss: 0.3998 - val_accuracy: 0.8242\n",
      "Epoch 238/250\n",
      "152/152 - 2s - loss: 0.3872 - accuracy: 0.8302 - val_loss: 0.4145 - val_accuracy: 0.8190\n",
      "Epoch 239/250\n",
      "152/152 - 2s - loss: 0.3901 - accuracy: 0.8292 - val_loss: 0.4041 - val_accuracy: 0.8216\n",
      "Epoch 240/250\n",
      "152/152 - 2s - loss: 0.3930 - accuracy: 0.8279 - val_loss: 0.4087 - val_accuracy: 0.8233\n",
      "Epoch 241/250\n",
      "152/152 - 2s - loss: 0.4104 - accuracy: 0.8230 - val_loss: 0.4048 - val_accuracy: 0.8214\n",
      "Epoch 242/250\n",
      "152/152 - 2s - loss: 0.3900 - accuracy: 0.8296 - val_loss: 0.4018 - val_accuracy: 0.8210\n",
      "Epoch 243/250\n",
      "152/152 - 2s - loss: 0.3930 - accuracy: 0.8286 - val_loss: 0.4086 - val_accuracy: 0.8206\n",
      "Epoch 244/250\n",
      "152/152 - 2s - loss: 0.3886 - accuracy: 0.8301 - val_loss: 0.4179 - val_accuracy: 0.8214\n",
      "Epoch 245/250\n",
      "152/152 - 2s - loss: 0.3906 - accuracy: 0.8298 - val_loss: 0.4023 - val_accuracy: 0.8240\n",
      "Epoch 246/250\n",
      "152/152 - 2s - loss: 0.3934 - accuracy: 0.8276 - val_loss: 0.4099 - val_accuracy: 0.8197\n",
      "Epoch 247/250\n",
      "152/152 - 2s - loss: 0.3858 - accuracy: 0.8308 - val_loss: 0.4089 - val_accuracy: 0.8205\n",
      "Epoch 248/250\n",
      "152/152 - 2s - loss: 0.3910 - accuracy: 0.8286 - val_loss: 0.4143 - val_accuracy: 0.8178\n",
      "Epoch 249/250\n",
      "152/152 - 2s - loss: 0.3905 - accuracy: 0.8288 - val_loss: 0.4046 - val_accuracy: 0.8215\n",
      "Epoch 250/250\n",
      "152/152 - 2s - loss: 0.3893 - accuracy: 0.8297 - val_loss: 0.4132 - val_accuracy: 0.8170\n",
      "1-layer-4096\n",
      "Epoch 1/250\n",
      "152/152 - 3s - loss: 643.2208 - accuracy: 0.6526 - val_loss: 18.5541 - val_accuracy: 0.8030\n",
      "Epoch 2/250\n",
      "152/152 - 3s - loss: 78.2639 - accuracy: 0.6955 - val_loss: 36.3933 - val_accuracy: 0.7620\n",
      "Epoch 3/250\n",
      "152/152 - 3s - loss: 30.5179 - accuracy: 0.7335 - val_loss: 50.1218 - val_accuracy: 0.7288\n",
      "Epoch 4/250\n",
      "152/152 - 3s - loss: 23.3504 - accuracy: 0.7372 - val_loss: 43.0643 - val_accuracy: 0.7194\n",
      "Epoch 5/250\n",
      "152/152 - 3s - loss: 19.6101 - accuracy: 0.7228 - val_loss: 5.8066 - val_accuracy: 0.8096\n",
      "Epoch 6/250\n",
      "152/152 - 3s - loss: 14.7834 - accuracy: 0.7330 - val_loss: 4.0818 - val_accuracy: 0.8108\n",
      "Epoch 7/250\n",
      "152/152 - 3s - loss: 11.0963 - accuracy: 0.7268 - val_loss: 18.8541 - val_accuracy: 0.7178\n",
      "Epoch 8/250\n",
      "152/152 - 4s - loss: 13.1387 - accuracy: 0.7179 - val_loss: 1.9598 - val_accuracy: 0.8063\n",
      "Epoch 9/250\n",
      "152/152 - 4s - loss: 5.8641 - accuracy: 0.7134 - val_loss: 2.7526 - val_accuracy: 0.7808\n",
      "Epoch 10/250\n",
      "152/152 - 4s - loss: 6.6436 - accuracy: 0.6837 - val_loss: 2.1699 - val_accuracy: 0.8009\n",
      "Epoch 11/250\n",
      "152/152 - 4s - loss: 2.8647 - accuracy: 0.7441 - val_loss: 1.7619 - val_accuracy: 0.7955\n",
      "Epoch 12/250\n",
      "152/152 - 4s - loss: 2.2121 - accuracy: 0.7418 - val_loss: 1.1516 - val_accuracy: 0.7967\n",
      "Epoch 13/250\n",
      "152/152 - 4s - loss: 2.8197 - accuracy: 0.7396 - val_loss: 15.8028 - val_accuracy: 0.7165\n",
      "Epoch 14/250\n",
      "152/152 - 3s - loss: 1.4921 - accuracy: 0.7685 - val_loss: 0.5801 - val_accuracy: 0.7986\n",
      "Epoch 15/250\n",
      "152/152 - 3s - loss: 2.1808 - accuracy: 0.7328 - val_loss: 0.5277 - val_accuracy: 0.8052\n",
      "Epoch 16/250\n",
      "152/152 - 4s - loss: 1.0142 - accuracy: 0.7395 - val_loss: 0.6234 - val_accuracy: 0.7880\n",
      "Epoch 17/250\n",
      "152/152 - 3s - loss: 0.7718 - accuracy: 0.7651 - val_loss: 1.0638 - val_accuracy: 0.7461\n",
      "Epoch 18/250\n",
      "152/152 - 3s - loss: 0.4772 - accuracy: 0.8005 - val_loss: 0.4885 - val_accuracy: 0.7855\n",
      "Epoch 19/250\n",
      "152/152 - 3s - loss: 1.2580 - accuracy: 0.7458 - val_loss: 0.4272 - val_accuracy: 0.8119\n",
      "Epoch 20/250\n",
      "152/152 - 3s - loss: 0.4333 - accuracy: 0.8089 - val_loss: 0.4225 - val_accuracy: 0.8112\n",
      "Epoch 21/250\n",
      "152/152 - 3s - loss: 0.6725 - accuracy: 0.7927 - val_loss: 0.4211 - val_accuracy: 0.8140\n",
      "Epoch 22/250\n",
      "152/152 - 3s - loss: 0.4259 - accuracy: 0.8102 - val_loss: 0.4096 - val_accuracy: 0.8163\n",
      "Epoch 23/250\n",
      "152/152 - 3s - loss: 0.4158 - accuracy: 0.8149 - val_loss: 0.4105 - val_accuracy: 0.8157\n",
      "Epoch 24/250\n",
      "152/152 - 3s - loss: 0.4181 - accuracy: 0.8137 - val_loss: 0.4045 - val_accuracy: 0.8191\n",
      "Epoch 25/250\n",
      "152/152 - 3s - loss: 0.4147 - accuracy: 0.8150 - val_loss: 0.4099 - val_accuracy: 0.8135\n",
      "Epoch 26/250\n",
      "152/152 - 3s - loss: 0.4217 - accuracy: 0.8124 - val_loss: 0.4464 - val_accuracy: 0.7973\n",
      "Epoch 27/250\n",
      "152/152 - 3s - loss: 0.4262 - accuracy: 0.8106 - val_loss: 0.4011 - val_accuracy: 0.8210\n",
      "Epoch 28/250\n",
      "152/152 - 3s - loss: 0.4202 - accuracy: 0.8138 - val_loss: 0.4250 - val_accuracy: 0.8116\n",
      "Epoch 29/250\n",
      "152/152 - 3s - loss: 0.4268 - accuracy: 0.8103 - val_loss: 0.4153 - val_accuracy: 0.8145\n",
      "Epoch 30/250\n",
      "152/152 - 3s - loss: 0.4406 - accuracy: 0.8041 - val_loss: 0.4024 - val_accuracy: 0.8214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/250\n",
      "152/152 - 3s - loss: 0.4134 - accuracy: 0.8170 - val_loss: 0.3990 - val_accuracy: 0.8233\n",
      "Epoch 32/250\n",
      "152/152 - 3s - loss: 0.4157 - accuracy: 0.8162 - val_loss: 0.4153 - val_accuracy: 0.8154\n",
      "Epoch 33/250\n",
      "152/152 - 3s - loss: 0.4262 - accuracy: 0.8118 - val_loss: 0.3963 - val_accuracy: 0.8253\n",
      "Epoch 34/250\n",
      "152/152 - 3s - loss: 0.4158 - accuracy: 0.8172 - val_loss: 0.4014 - val_accuracy: 0.8232\n",
      "Epoch 35/250\n",
      "152/152 - 3s - loss: 0.4046 - accuracy: 0.8212 - val_loss: 0.4384 - val_accuracy: 0.8031\n",
      "Epoch 36/250\n",
      "152/152 - 3s - loss: 0.4218 - accuracy: 0.8132 - val_loss: 0.3961 - val_accuracy: 0.8252\n",
      "Epoch 37/250\n",
      "152/152 - 3s - loss: 0.4043 - accuracy: 0.8224 - val_loss: 0.4125 - val_accuracy: 0.8170\n",
      "Epoch 38/250\n",
      "152/152 - 3s - loss: 0.4024 - accuracy: 0.8233 - val_loss: 0.3978 - val_accuracy: 0.8258\n",
      "Epoch 39/250\n",
      "152/152 - 3s - loss: 0.4085 - accuracy: 0.8206 - val_loss: 0.3990 - val_accuracy: 0.8254\n",
      "Epoch 40/250\n",
      "152/152 - 3s - loss: 0.4046 - accuracy: 0.8232 - val_loss: 0.4032 - val_accuracy: 0.8238\n",
      "Epoch 41/250\n",
      "152/152 - 3s - loss: 0.4045 - accuracy: 0.8228 - val_loss: 0.3941 - val_accuracy: 0.8277\n",
      "Epoch 42/250\n",
      "152/152 - 3s - loss: 0.4025 - accuracy: 0.8228 - val_loss: 0.3988 - val_accuracy: 0.8265\n",
      "Epoch 43/250\n",
      "152/152 - 3s - loss: 0.4016 - accuracy: 0.8241 - val_loss: 0.3985 - val_accuracy: 0.8260\n",
      "Epoch 44/250\n",
      "152/152 - 3s - loss: 0.4040 - accuracy: 0.8232 - val_loss: 0.4607 - val_accuracy: 0.8059\n",
      "Epoch 45/250\n",
      "152/152 - 4s - loss: 0.4026 - accuracy: 0.8246 - val_loss: 0.3969 - val_accuracy: 0.8260\n",
      "Epoch 46/250\n",
      "152/152 - 4s - loss: 0.4052 - accuracy: 0.8226 - val_loss: 0.3977 - val_accuracy: 0.8249\n",
      "Epoch 47/250\n",
      "152/152 - 3s - loss: 0.4047 - accuracy: 0.8234 - val_loss: 0.4212 - val_accuracy: 0.8246\n",
      "Epoch 48/250\n",
      "152/152 - 3s - loss: 0.4052 - accuracy: 0.8218 - val_loss: 0.4053 - val_accuracy: 0.8250\n",
      "Epoch 49/250\n",
      "152/152 - 3s - loss: 0.4061 - accuracy: 0.8229 - val_loss: 0.4356 - val_accuracy: 0.8169\n",
      "Epoch 50/250\n",
      "152/152 - 3s - loss: 0.4069 - accuracy: 0.8221 - val_loss: 0.4045 - val_accuracy: 0.8233\n",
      "Epoch 51/250\n",
      "152/152 - 3s - loss: 0.4020 - accuracy: 0.8237 - val_loss: 0.4064 - val_accuracy: 0.8235\n",
      "Epoch 52/250\n",
      "152/152 - 3s - loss: 0.4084 - accuracy: 0.8216 - val_loss: 0.4290 - val_accuracy: 0.8134\n",
      "Epoch 53/250\n",
      "152/152 - 3s - loss: 0.4101 - accuracy: 0.8203 - val_loss: 0.4327 - val_accuracy: 0.8048\n",
      "Epoch 54/250\n",
      "152/152 - 4s - loss: 0.4074 - accuracy: 0.8225 - val_loss: 0.3977 - val_accuracy: 0.8250\n",
      "Epoch 55/250\n",
      "152/152 - 3s - loss: 0.4051 - accuracy: 0.8231 - val_loss: 0.4404 - val_accuracy: 0.8085\n",
      "Epoch 56/250\n",
      "152/152 - 3s - loss: 0.4106 - accuracy: 0.8197 - val_loss: 0.4058 - val_accuracy: 0.8235\n",
      "Epoch 57/250\n",
      "152/152 - 3s - loss: 0.4096 - accuracy: 0.8209 - val_loss: 0.4151 - val_accuracy: 0.8189\n",
      "Epoch 58/250\n",
      "152/152 - 3s - loss: 0.4102 - accuracy: 0.8209 - val_loss: 0.4386 - val_accuracy: 0.8080\n",
      "Epoch 59/250\n",
      "152/152 - 3s - loss: 0.4124 - accuracy: 0.8205 - val_loss: 0.4357 - val_accuracy: 0.8193\n",
      "Epoch 60/250\n",
      "152/152 - 3s - loss: 0.4081 - accuracy: 0.8213 - val_loss: 0.4077 - val_accuracy: 0.8240\n",
      "Epoch 61/250\n",
      "152/152 - 3s - loss: 0.4103 - accuracy: 0.8203 - val_loss: 0.4160 - val_accuracy: 0.8252\n",
      "Epoch 62/250\n",
      "152/152 - 3s - loss: 0.4126 - accuracy: 0.8206 - val_loss: 0.3998 - val_accuracy: 0.8244\n",
      "Epoch 63/250\n",
      "152/152 - 3s - loss: 0.4104 - accuracy: 0.8212 - val_loss: 0.3938 - val_accuracy: 0.8260\n",
      "Epoch 64/250\n",
      "152/152 - 3s - loss: 0.4248 - accuracy: 0.8139 - val_loss: 0.4703 - val_accuracy: 0.7944\n",
      "Epoch 65/250\n",
      "152/152 - 3s - loss: 0.4288 - accuracy: 0.8127 - val_loss: 0.3986 - val_accuracy: 0.8252\n",
      "Epoch 66/250\n",
      "152/152 - 4s - loss: 0.4138 - accuracy: 0.8185 - val_loss: 0.3976 - val_accuracy: 0.8228\n",
      "Epoch 67/250\n",
      "152/152 - 3s - loss: 0.4063 - accuracy: 0.8211 - val_loss: 0.4255 - val_accuracy: 0.8151\n",
      "Epoch 68/250\n",
      "152/152 - 3s - loss: 0.4087 - accuracy: 0.8207 - val_loss: 0.3938 - val_accuracy: 0.8275\n",
      "Epoch 69/250\n",
      "152/152 - 3s - loss: 0.4091 - accuracy: 0.8208 - val_loss: 0.4087 - val_accuracy: 0.8203\n",
      "Epoch 70/250\n",
      "152/152 - 4s - loss: 0.4086 - accuracy: 0.8208 - val_loss: 0.3929 - val_accuracy: 0.8268\n",
      "Epoch 71/250\n",
      "152/152 - 3s - loss: 0.4158 - accuracy: 0.8183 - val_loss: 0.3958 - val_accuracy: 0.8249\n",
      "Epoch 72/250\n",
      "152/152 - 3s - loss: 0.4094 - accuracy: 0.8205 - val_loss: 0.4575 - val_accuracy: 0.8040\n",
      "Epoch 73/250\n",
      "152/152 - 3s - loss: 0.4071 - accuracy: 0.8216 - val_loss: 0.4057 - val_accuracy: 0.8215\n",
      "Epoch 74/250\n",
      "152/152 - 3s - loss: 0.4128 - accuracy: 0.8197 - val_loss: 0.4540 - val_accuracy: 0.8134\n",
      "Epoch 75/250\n",
      "152/152 - 3s - loss: 0.4066 - accuracy: 0.8209 - val_loss: 0.3964 - val_accuracy: 0.8251\n",
      "Epoch 76/250\n",
      "152/152 - 3s - loss: 0.4152 - accuracy: 0.8173 - val_loss: 0.4039 - val_accuracy: 0.8223\n",
      "Epoch 77/250\n",
      "152/152 - 4s - loss: 0.4285 - accuracy: 0.8145 - val_loss: 0.4694 - val_accuracy: 0.8116\n",
      "Epoch 78/250\n",
      "152/152 - 3s - loss: 0.4191 - accuracy: 0.8175 - val_loss: 0.4216 - val_accuracy: 0.8148\n",
      "Epoch 79/250\n",
      "152/152 - 4s - loss: 0.4164 - accuracy: 0.8187 - val_loss: 0.4238 - val_accuracy: 0.8199\n",
      "Epoch 80/250\n",
      "152/152 - 3s - loss: 0.4124 - accuracy: 0.8203 - val_loss: 0.4041 - val_accuracy: 0.8206\n",
      "Epoch 81/250\n",
      "152/152 - 3s - loss: 0.4197 - accuracy: 0.8168 - val_loss: 0.6776 - val_accuracy: 0.5159\n",
      "Epoch 82/250\n",
      "152/152 - 3s - loss: 0.4510 - accuracy: 0.8082 - val_loss: 0.4070 - val_accuracy: 0.8183\n",
      "Epoch 83/250\n",
      "152/152 - 3s - loss: 0.4131 - accuracy: 0.8175 - val_loss: 0.4107 - val_accuracy: 0.8206\n",
      "Epoch 84/250\n",
      "152/152 - 3s - loss: 0.4124 - accuracy: 0.8174 - val_loss: 0.4270 - val_accuracy: 0.8135\n",
      "Epoch 85/250\n",
      "152/152 - 4s - loss: 0.4172 - accuracy: 0.8162 - val_loss: 0.4030 - val_accuracy: 0.8198\n",
      "Epoch 86/250\n",
      "152/152 - 3s - loss: 0.4124 - accuracy: 0.8180 - val_loss: 0.4262 - val_accuracy: 0.8114\n",
      "Epoch 87/250\n",
      "152/152 - 4s - loss: 0.4102 - accuracy: 0.8187 - val_loss: 0.4032 - val_accuracy: 0.8211\n",
      "Epoch 88/250\n",
      "152/152 - 3s - loss: 0.4123 - accuracy: 0.8183 - val_loss: 0.4041 - val_accuracy: 0.8211\n",
      "Epoch 89/250\n",
      "152/152 - 3s - loss: 0.4071 - accuracy: 0.8200 - val_loss: 0.4091 - val_accuracy: 0.8200\n",
      "Epoch 90/250\n",
      "152/152 - 3s - loss: 0.4152 - accuracy: 0.8179 - val_loss: 0.4081 - val_accuracy: 0.8200\n",
      "Epoch 91/250\n",
      "152/152 - 3s - loss: 0.4073 - accuracy: 0.8199 - val_loss: 0.4013 - val_accuracy: 0.8223\n",
      "Epoch 92/250\n",
      "152/152 - 3s - loss: 0.4044 - accuracy: 0.8203 - val_loss: 0.4015 - val_accuracy: 0.8214\n",
      "Epoch 93/250\n",
      "152/152 - 3s - loss: 0.4060 - accuracy: 0.8205 - val_loss: 0.4013 - val_accuracy: 0.8228\n",
      "Epoch 94/250\n",
      "152/152 - 3s - loss: 0.4071 - accuracy: 0.8201 - val_loss: 0.4024 - val_accuracy: 0.8193\n",
      "Epoch 95/250\n",
      "152/152 - 3s - loss: 0.4028 - accuracy: 0.8214 - val_loss: 0.4059 - val_accuracy: 0.8182\n",
      "Epoch 96/250\n",
      "152/152 - 3s - loss: 0.4135 - accuracy: 0.8176 - val_loss: 0.4557 - val_accuracy: 0.7966\n",
      "Epoch 97/250\n",
      "152/152 - 3s - loss: 0.4126 - accuracy: 0.8185 - val_loss: 0.4068 - val_accuracy: 0.8233\n",
      "Epoch 98/250\n",
      "152/152 - 3s - loss: 0.4028 - accuracy: 0.8214 - val_loss: 0.4037 - val_accuracy: 0.8209\n",
      "Epoch 99/250\n",
      "152/152 - 4s - loss: 0.4033 - accuracy: 0.8214 - val_loss: 0.3982 - val_accuracy: 0.8226\n",
      "Epoch 100/250\n",
      "152/152 - 3s - loss: 0.4043 - accuracy: 0.8205 - val_loss: 0.3998 - val_accuracy: 0.8221\n",
      "Epoch 101/250\n",
      "152/152 - 3s - loss: 0.4048 - accuracy: 0.8213 - val_loss: 0.4012 - val_accuracy: 0.8236\n",
      "Epoch 102/250\n",
      "152/152 - 3s - loss: 0.4029 - accuracy: 0.8211 - val_loss: 0.3989 - val_accuracy: 0.8197\n",
      "Epoch 103/250\n",
      "152/152 - 3s - loss: 0.4062 - accuracy: 0.8205 - val_loss: 0.4026 - val_accuracy: 0.8218\n",
      "Epoch 104/250\n",
      "152/152 - 3s - loss: 0.4063 - accuracy: 0.8214 - val_loss: 0.3981 - val_accuracy: 0.8236\n",
      "Epoch 105/250\n",
      "152/152 - 4s - loss: 0.4136 - accuracy: 0.8173 - val_loss: 0.4007 - val_accuracy: 0.8226\n",
      "Epoch 106/250\n",
      "152/152 - 4s - loss: 0.4083 - accuracy: 0.8198 - val_loss: 0.3987 - val_accuracy: 0.8233\n",
      "Epoch 107/250\n",
      "152/152 - 3s - loss: 0.4054 - accuracy: 0.8211 - val_loss: 0.4017 - val_accuracy: 0.8209\n",
      "Epoch 108/250\n",
      "152/152 - 3s - loss: 0.4024 - accuracy: 0.8227 - val_loss: 0.4053 - val_accuracy: 0.8191\n",
      "Epoch 109/250\n",
      "152/152 - 4s - loss: 0.4073 - accuracy: 0.8209 - val_loss: 0.4130 - val_accuracy: 0.8204\n",
      "Epoch 110/250\n",
      "152/152 - 4s - loss: 0.4014 - accuracy: 0.8227 - val_loss: 0.4001 - val_accuracy: 0.8241\n",
      "Epoch 111/250\n",
      "152/152 - 3s - loss: 0.4053 - accuracy: 0.8217 - val_loss: 0.4019 - val_accuracy: 0.8234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/250\n",
      "152/152 - 3s - loss: 0.4220 - accuracy: 0.8171 - val_loss: 0.3978 - val_accuracy: 0.8242\n",
      "Epoch 113/250\n",
      "152/152 - 3s - loss: 0.4008 - accuracy: 0.8220 - val_loss: 0.4001 - val_accuracy: 0.8236\n",
      "Epoch 114/250\n",
      "152/152 - 3s - loss: 0.4028 - accuracy: 0.8228 - val_loss: 0.4023 - val_accuracy: 0.8227\n",
      "Epoch 115/250\n",
      "152/152 - 3s - loss: 0.4036 - accuracy: 0.8220 - val_loss: 0.3988 - val_accuracy: 0.8226\n",
      "Epoch 116/250\n",
      "152/152 - 3s - loss: 0.4128 - accuracy: 0.8182 - val_loss: 0.4088 - val_accuracy: 0.8199\n",
      "Epoch 117/250\n",
      "152/152 - 3s - loss: 0.4017 - accuracy: 0.8231 - val_loss: 0.3977 - val_accuracy: 0.8242\n",
      "Epoch 118/250\n",
      "152/152 - 3s - loss: 0.4004 - accuracy: 0.8228 - val_loss: 0.4122 - val_accuracy: 0.8190\n",
      "Epoch 119/250\n",
      "152/152 - 3s - loss: 0.4153 - accuracy: 0.8186 - val_loss: 0.3988 - val_accuracy: 0.8239\n",
      "Epoch 120/250\n",
      "152/152 - 3s - loss: 0.3980 - accuracy: 0.8242 - val_loss: 0.3978 - val_accuracy: 0.8227\n",
      "Epoch 121/250\n",
      "152/152 - 3s - loss: 0.4011 - accuracy: 0.8221 - val_loss: 0.4078 - val_accuracy: 0.8212\n",
      "Epoch 122/250\n",
      "152/152 - 3s - loss: 0.4002 - accuracy: 0.8233 - val_loss: 0.3999 - val_accuracy: 0.8232\n",
      "Epoch 123/250\n",
      "152/152 - 3s - loss: 0.4027 - accuracy: 0.8235 - val_loss: 0.4055 - val_accuracy: 0.8221\n",
      "Epoch 124/250\n",
      "152/152 - 3s - loss: 0.4180 - accuracy: 0.8198 - val_loss: 0.4487 - val_accuracy: 0.8141\n",
      "Epoch 125/250\n",
      "152/152 - 3s - loss: 0.4012 - accuracy: 0.8229 - val_loss: 0.4139 - val_accuracy: 0.8203\n",
      "Epoch 126/250\n",
      "152/152 - 3s - loss: 0.4029 - accuracy: 0.8226 - val_loss: 0.3996 - val_accuracy: 0.8231\n",
      "Epoch 127/250\n",
      "152/152 - 3s - loss: 0.3989 - accuracy: 0.8243 - val_loss: 0.3981 - val_accuracy: 0.8233\n",
      "Epoch 128/250\n",
      "152/152 - 3s - loss: 0.4096 - accuracy: 0.8197 - val_loss: 0.3987 - val_accuracy: 0.8205\n",
      "Epoch 129/250\n",
      "152/152 - 3s - loss: 0.4006 - accuracy: 0.8238 - val_loss: 0.4000 - val_accuracy: 0.8234\n",
      "Epoch 130/250\n",
      "152/152 - 3s - loss: 0.3992 - accuracy: 0.8242 - val_loss: 0.4067 - val_accuracy: 0.8192\n",
      "Epoch 131/250\n",
      "152/152 - 3s - loss: 0.4000 - accuracy: 0.8240 - val_loss: 0.4545 - val_accuracy: 0.7988\n",
      "Epoch 132/250\n",
      "152/152 - 3s - loss: 0.3991 - accuracy: 0.8242 - val_loss: 0.4043 - val_accuracy: 0.8228\n",
      "Epoch 133/250\n",
      "152/152 - 3s - loss: 0.3998 - accuracy: 0.8240 - val_loss: 0.4110 - val_accuracy: 0.8114\n",
      "Epoch 134/250\n",
      "152/152 - 3s - loss: 0.3995 - accuracy: 0.8236 - val_loss: 0.3990 - val_accuracy: 0.8232\n",
      "Epoch 135/250\n",
      "152/152 - 3s - loss: 0.3974 - accuracy: 0.8245 - val_loss: 0.4092 - val_accuracy: 0.8199\n",
      "Epoch 136/250\n",
      "152/152 - 3s - loss: 0.4024 - accuracy: 0.8228 - val_loss: 0.4287 - val_accuracy: 0.8139\n",
      "Epoch 137/250\n",
      "152/152 - 4s - loss: 0.4031 - accuracy: 0.8233 - val_loss: 0.4129 - val_accuracy: 0.8176\n",
      "Epoch 138/250\n",
      "152/152 - 4s - loss: 0.4001 - accuracy: 0.8239 - val_loss: 0.3980 - val_accuracy: 0.8237\n",
      "Epoch 139/250\n",
      "152/152 - 3s - loss: 0.4046 - accuracy: 0.8224 - val_loss: 0.3979 - val_accuracy: 0.8237\n",
      "Epoch 140/250\n",
      "152/152 - 3s - loss: 0.4009 - accuracy: 0.8241 - val_loss: 0.4132 - val_accuracy: 0.8137\n",
      "Epoch 141/250\n",
      "152/152 - 3s - loss: 0.4002 - accuracy: 0.8239 - val_loss: 0.4170 - val_accuracy: 0.8150\n",
      "Epoch 142/250\n",
      "152/152 - 4s - loss: 1.0523 - accuracy: 0.5180 - val_loss: 1.0291 - val_accuracy: 0.2835\n",
      "Epoch 143/250\n",
      "152/152 - 3s - loss: 0.9880 - accuracy: 0.2925 - val_loss: 0.8853 - val_accuracy: 0.2835\n",
      "Epoch 144/250\n",
      "152/152 - 3s - loss: 0.8397 - accuracy: 0.2844 - val_loss: 0.8009 - val_accuracy: 0.2835\n",
      "Epoch 145/250\n",
      "152/152 - 3s - loss: 0.7711 - accuracy: 0.2844 - val_loss: 0.7448 - val_accuracy: 0.2836\n",
      "Epoch 146/250\n",
      "152/152 - 3s - loss: 0.7237 - accuracy: 0.2844 - val_loss: 0.7049 - val_accuracy: 0.2836\n",
      "Epoch 147/250\n",
      "152/152 - 3s - loss: 0.6897 - accuracy: 0.5559 - val_loss: 0.6759 - val_accuracy: 0.7163\n",
      "Epoch 148/250\n",
      "152/152 - 3s - loss: 0.6648 - accuracy: 0.7156 - val_loss: 0.6544 - val_accuracy: 0.7164\n",
      "Epoch 149/250\n",
      "152/152 - 3s - loss: 0.6463 - accuracy: 0.7156 - val_loss: 0.6384 - val_accuracy: 0.7164\n",
      "Epoch 150/250\n",
      "152/152 - 3s - loss: 0.6325 - accuracy: 0.7156 - val_loss: 0.6266 - val_accuracy: 0.7164\n",
      "Epoch 151/250\n",
      "152/152 - 3s - loss: 0.6223 - accuracy: 0.7156 - val_loss: 0.6178 - val_accuracy: 0.7164\n",
      "Epoch 152/250\n",
      "152/152 - 3s - loss: 0.6148 - accuracy: 0.7156 - val_loss: 0.6113 - val_accuracy: 0.7164\n",
      "Epoch 153/250\n",
      "152/152 - 3s - loss: 0.6093 - accuracy: 0.7156 - val_loss: 0.6067 - val_accuracy: 0.7164\n",
      "Epoch 154/250\n",
      "152/152 - 3s - loss: 0.6054 - accuracy: 0.7156 - val_loss: 0.6033 - val_accuracy: 0.7164\n",
      "Epoch 155/250\n",
      "152/152 - 3s - loss: 0.6026 - accuracy: 0.7156 - val_loss: 0.6009 - val_accuracy: 0.7165\n",
      "Epoch 156/250\n",
      "152/152 - 3s - loss: 0.6006 - accuracy: 0.7156 - val_loss: 0.5993 - val_accuracy: 0.7165\n",
      "Epoch 157/250\n",
      "152/152 - 3s - loss: 0.5993 - accuracy: 0.7156 - val_loss: 0.5982 - val_accuracy: 0.7165\n",
      "Epoch 158/250\n",
      "152/152 - 3s - loss: 0.5984 - accuracy: 0.7156 - val_loss: 0.5974 - val_accuracy: 0.7165\n",
      "Epoch 159/250\n",
      "152/152 - 3s - loss: 0.5979 - accuracy: 0.7156 - val_loss: 0.5970 - val_accuracy: 0.7165\n",
      "Epoch 160/250\n",
      "152/152 - 3s - loss: 0.5975 - accuracy: 0.7156 - val_loss: 0.5967 - val_accuracy: 0.7165\n",
      "Epoch 161/250\n",
      "152/152 - 3s - loss: 0.5973 - accuracy: 0.7156 - val_loss: 0.5965 - val_accuracy: 0.7165\n",
      "Epoch 162/250\n",
      "152/152 - 3s - loss: 0.5972 - accuracy: 0.7156 - val_loss: 0.5964 - val_accuracy: 0.7165\n",
      "Epoch 163/250\n",
      "152/152 - 3s - loss: 0.5971 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 164/250\n",
      "152/152 - 3s - loss: 0.5971 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 165/250\n",
      "152/152 - 3s - loss: 0.5971 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 166/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 167/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 168/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 169/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 170/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 171/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 172/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 173/250\n",
      "152/152 - 4s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 174/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 175/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 176/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 177/250\n",
      "152/152 - 4s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 178/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 179/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 180/250\n",
      "152/152 - 4s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 181/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 182/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 183/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 184/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 185/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 186/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 187/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 188/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 189/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 190/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 191/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 192/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 193/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 194/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 195/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 196/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 197/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 198/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 199/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 200/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 201/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 202/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 203/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 204/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 205/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 206/250\n",
      "152/152 - 3s - loss: 0.5971 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 207/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 208/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 209/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 210/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 211/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 212/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 213/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 214/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 215/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 216/250\n",
      "152/152 - 3s - loss: 0.5971 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 217/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 218/250\n",
      "152/152 - 3s - loss: 0.5971 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 219/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 220/250\n",
      "152/152 - 4s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 221/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 222/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 223/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 224/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 225/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 226/250\n",
      "152/152 - 4s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 227/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 228/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 229/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 230/250\n",
      "152/152 - 4s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 231/250\n",
      "152/152 - 4s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 232/250\n",
      "152/152 - 4s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 233/250\n",
      "152/152 - 4s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 234/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 235/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 236/250\n",
      "152/152 - 3s - loss: 0.5971 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 237/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 238/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 239/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 240/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 241/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 242/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 243/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 244/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 245/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 246/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 247/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 248/250\n",
      "152/152 - 3s - loss: 0.5971 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 249/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 250/250\n",
      "152/152 - 3s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n"
     ]
    }
   ],
   "source": [
    "# lower the number of epochs\n",
    "epochs = 250\n",
    "\n",
    "batch_size = 1024\n",
    "simplehistories = []\n",
    "\n",
    "name=\"1-layer-64\"\n",
    "print(name)\n",
    "model01 = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        keras.layers.Flatten(),        \n",
    "        keras.layers.Dense(128, activation='relu'),\n",
    "        keras.layers.Dense(1, activation='sigmoid')\n",
    "    ],name=name\n",
    ")\n",
    "\n",
    "model01.compile(loss=\"binary_crossentropy\", optimizer=Adam(learning_rate=0.001), metrics=[\"accuracy\"])\n",
    "\n",
    "simplehistories.append(model01.fit(x_train, y_train, batch_size=batch_size,\n",
    "                                   epochs=epochs, validation_data=(x_val,y_val),\n",
    "                                   verbose=2))\n",
    "\n",
    "\n",
    "name=\"1-layer-128\"\n",
    "print(name)\n",
    "model02 = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        keras.layers.Flatten(),        \n",
    "        keras.layers.Dense(256, activation='relu'),\n",
    "        keras.layers.Dense(1, activation='sigmoid')\n",
    "    ],name=name\n",
    ")\n",
    "\n",
    "model02.compile(loss=\"binary_crossentropy\", optimizer=Adam(learning_rate=0.001), metrics=[\"accuracy\"])\n",
    "\n",
    "simplehistories.append(model02.fit(x_train, y_train, batch_size=batch_size, \n",
    "                                   epochs=epochs, validation_data=(x_val,y_val),\n",
    "                                   verbose=2))\n",
    "\n",
    "name=\"1-layer-256\"\n",
    "print(name)\n",
    "model03 = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        keras.layers.Flatten(),        \n",
    "        keras.layers.Dense(512, activation='relu'),\n",
    "        keras.layers.Dense(1, activation='sigmoid')\n",
    "    ],name=name\n",
    ")\n",
    "\n",
    "model03.compile(loss=\"binary_crossentropy\", optimizer=Adam(learning_rate=0.001), metrics=[\"accuracy\"])\n",
    "\n",
    "simplehistories.append(model03.fit(x_train, y_train, batch_size=batch_size, \n",
    "                                   epochs=epochs, validation_data=(x_val,y_val),\n",
    "                                   verbose=2))\n",
    "\n",
    "name=\"1-layer-512\"\n",
    "print(name)\n",
    "model04 = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        keras.layers.Flatten(),        \n",
    "        keras.layers.Dense(1024, activation='relu'),\n",
    "        keras.layers.Dense(1, activation='sigmoid')\n",
    "    ],name=name\n",
    ")\n",
    "\n",
    "model04.compile(loss=\"binary_crossentropy\", optimizer=Adam(learning_rate=0.001), metrics=[\"accuracy\"])\n",
    "\n",
    "simplehistories.append(model04.fit(x_train, y_train, batch_size=batch_size, \n",
    "                                   epochs=epochs, validation_data=(x_val,y_val),\n",
    "                                   verbose=2))\n",
    "\n",
    "name=\"1-layer-2048\"\n",
    "print(name)\n",
    "model05 = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        keras.layers.Flatten(),        \n",
    "        keras.layers.Dense(2048, activation='relu'),\n",
    "        keras.layers.Dense(1, activation='sigmoid')\n",
    "    ],name=name\n",
    ")\n",
    "\n",
    "model05.compile(loss=\"binary_crossentropy\", optimizer=Adam(learning_rate=0.001), metrics=[\"accuracy\"])\n",
    "\n",
    "simplehistories.append(model05.fit(x_train, y_train, batch_size=batch_size, \n",
    "                                   epochs=epochs, validation_data=(x_val,y_val),\n",
    "                                   verbose=2))\n",
    "\n",
    "name=\"1-layer-4096\"\n",
    "print(name)\n",
    "model06 = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        keras.layers.Flatten(),        \n",
    "        keras.layers.Dense(4096, activation='relu'),\n",
    "        keras.layers.Dense(1, activation='sigmoid')\n",
    "    ],name=name\n",
    ")\n",
    "\n",
    "model06.compile(loss=\"binary_crossentropy\", optimizer=Adam(learning_rate=0.001), metrics=[\"accuracy\"])\n",
    "\n",
    "simplehistories.append(model06.fit(x_train, y_train, batch_size=batch_size, \n",
    "                                   epochs=epochs, validation_data=(x_val,y_val),\n",
    "                                   verbose=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_50ea15c6_cee4_11eb_9345_40e230e37f37\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >loss</th>        <th class=\"col_heading level0 col1\" >accuracy</th>        <th class=\"col_heading level0 col2\" >val_loss</th>        <th class=\"col_heading level0 col3\" >val_accuracy</th>    </tr>    <tr>        <th class=\"index_name level0\" >model size</th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_50ea15c6_cee4_11eb_9345_40e230e37f37level0_row0\" class=\"row_heading level0 row0\" >1-layer-64</th>\n",
       "                        <td id=\"T_50ea15c6_cee4_11eb_9345_40e230e37f37row0_col0\" class=\"data row0 col0\" >0.39</td>\n",
       "                        <td id=\"T_50ea15c6_cee4_11eb_9345_40e230e37f37row0_col1\" class=\"data row0 col1\" >82.94%</td>\n",
       "                        <td id=\"T_50ea15c6_cee4_11eb_9345_40e230e37f37row0_col2\" class=\"data row0 col2\" >0.40</td>\n",
       "                        <td id=\"T_50ea15c6_cee4_11eb_9345_40e230e37f37row0_col3\" class=\"data row0 col3\" >82.36%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_50ea15c6_cee4_11eb_9345_40e230e37f37level0_row1\" class=\"row_heading level0 row1\" >1-layer-128</th>\n",
       "                        <td id=\"T_50ea15c6_cee4_11eb_9345_40e230e37f37row1_col0\" class=\"data row1 col0\" >0.38</td>\n",
       "                        <td id=\"T_50ea15c6_cee4_11eb_9345_40e230e37f37row1_col1\" class=\"data row1 col1\" >83.41%</td>\n",
       "                        <td id=\"T_50ea15c6_cee4_11eb_9345_40e230e37f37row1_col2\" class=\"data row1 col2\" >0.40</td>\n",
       "                        <td id=\"T_50ea15c6_cee4_11eb_9345_40e230e37f37row1_col3\" class=\"data row1 col3\" >82.65%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_50ea15c6_cee4_11eb_9345_40e230e37f37level0_row2\" class=\"row_heading level0 row2\" >1-layer-256</th>\n",
       "                        <td id=\"T_50ea15c6_cee4_11eb_9345_40e230e37f37row2_col0\" class=\"data row2 col0\" >0.40</td>\n",
       "                        <td id=\"T_50ea15c6_cee4_11eb_9345_40e230e37f37row2_col1\" class=\"data row2 col1\" >82.25%</td>\n",
       "                        <td id=\"T_50ea15c6_cee4_11eb_9345_40e230e37f37row2_col2\" class=\"data row2 col2\" >0.41</td>\n",
       "                        <td id=\"T_50ea15c6_cee4_11eb_9345_40e230e37f37row2_col3\" class=\"data row2 col3\" >81.69%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_50ea15c6_cee4_11eb_9345_40e230e37f37level0_row3\" class=\"row_heading level0 row3\" >1-layer-512</th>\n",
       "                        <td id=\"T_50ea15c6_cee4_11eb_9345_40e230e37f37row3_col0\" class=\"data row3 col0\" >0.41</td>\n",
       "                        <td id=\"T_50ea15c6_cee4_11eb_9345_40e230e37f37row3_col1\" class=\"data row3 col1\" >81.40%</td>\n",
       "                        <td id=\"T_50ea15c6_cee4_11eb_9345_40e230e37f37row3_col2\" class=\"data row3 col2\" >0.42</td>\n",
       "                        <td id=\"T_50ea15c6_cee4_11eb_9345_40e230e37f37row3_col3\" class=\"data row3 col3\" >80.80%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_50ea15c6_cee4_11eb_9345_40e230e37f37level0_row4\" class=\"row_heading level0 row4\" >1-layer-2048</th>\n",
       "                        <td id=\"T_50ea15c6_cee4_11eb_9345_40e230e37f37row4_col0\" class=\"data row4 col0\" >0.39</td>\n",
       "                        <td id=\"T_50ea15c6_cee4_11eb_9345_40e230e37f37row4_col1\" class=\"data row4 col1\" >82.97%</td>\n",
       "                        <td id=\"T_50ea15c6_cee4_11eb_9345_40e230e37f37row4_col2\" class=\"data row4 col2\" >0.41</td>\n",
       "                        <td id=\"T_50ea15c6_cee4_11eb_9345_40e230e37f37row4_col3\" class=\"data row4 col3\" >81.70%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_50ea15c6_cee4_11eb_9345_40e230e37f37level0_row5\" class=\"row_heading level0 row5\" >1-layer-4096</th>\n",
       "                        <td id=\"T_50ea15c6_cee4_11eb_9345_40e230e37f37row5_col0\" class=\"data row5 col0\" >0.60</td>\n",
       "                        <td id=\"T_50ea15c6_cee4_11eb_9345_40e230e37f37row5_col1\" class=\"data row5 col1\" >71.56%</td>\n",
       "                        <td id=\"T_50ea15c6_cee4_11eb_9345_40e230e37f37row5_col2\" class=\"data row5 col2\" >0.60</td>\n",
       "                        <td id=\"T_50ea15c6_cee4_11eb_9345_40e230e37f37row5_col3\" class=\"data row5 col3\" >71.65%</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1dfbea0de08>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['model size' ,'loss', 'accuracy', 'val_loss', 'val_accuracy']\n",
    "df_simple_nets = pd.DataFrame(columns = columns)\n",
    "\n",
    "for history in simplehistories:\n",
    "    df_temp = pd.DataFrame([[history.model.name,\n",
    "                              history.history['loss'][-1],\n",
    "                              history.history['accuracy'][-1],\n",
    "                              history.history['val_loss'][-1],\n",
    "                              history.history['val_accuracy'][-1]]], \n",
    "                    columns = columns)\n",
    "    df_simple_nets = df_simple_nets.append(df_temp)\n",
    "\n",
    "df_simple_nets = df_simple_nets.set_index('model size')\n",
    "\n",
    "df_simple_nets = df_simple_nets.style.format({\n",
    "    'loss': '{:,.2f}'.format,\n",
    "    'accuracy': '{:,.2%}'.format,\n",
    "    'val_loss': '{:,.2f}'.format,\n",
    "    'val_accuracy': '{:,.2%}'.format,\n",
    "})\n",
    "\n",
    "df_simple_nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for history in simplehistories[:]:\n",
    "    plt.plot(history.history['accuracy'], alpha=.6)\n",
    "    \n",
    "plt.xlabel('epoch')\n",
    "plt.ylim([0.75,0.9])\n",
    "plt.legend([model01.name, model02.name, model03.name, model04.name, model05.name, model06.name], loc='lower right')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "for history in histories[:]:\n",
    "    plt.plot(history.history['val_accuracy'], alpha=.6)\n",
    "    \n",
    "plt.xlabel('epoch')\n",
    "plt.ylim([0.6,0.9])\n",
    "plt.legend([model01.name, model02.name, model03.name, model04.name, model05.name, model06.name], loc='lower right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results from simple dense net\n",
    "\n",
    "The simple dense net reaches a accuracy on out test dataset of nearly 72 percent. This sounds respectable for such a simple network. A closer look on our confusion matrix reveals that our network suffers from our imbalanced data and is not able to counter the imbalance and thus classifies nearly all patches as non-cancer.\n",
    "\n",
    "\n",
    "At this point it is difficult to assess what exactly has to be improved, but we suspect the following issues persist:\n",
    "\n",
    "1. The Neural Network does not learn enough from the features, most likely the size of the network is insufficient to learn the features. When increasing the number of layers and the size of the layers we will encounter additional challenges:\n",
    "    - We could be overfitting our data, which we can mitigate by using dropbout layer\n",
    "    - We could have a vanishing gradient, which can be mitigated by using normalisazion betweek the hidden layers \n",
    "2. The network minimizes the loss, since the data is imbalanced it will inherently favor negative classifications. To counter this multiple options are available\n",
    "    - We could downsample the negative patches or upsample the positive patches , where the latter is preferred since no data is ignored this way.\n",
    "    - We could apply balanced weights to increase the impact to the loss function for the positive patches. This should result in an equivalent result than the upsampling.\n",
    "\n",
    "We will takle the two above mentioned issues after each other. Fist we try to increase the model size and tune the hyperparameters to fit the data better and learn the complexity of the input. Second we will apply class weights to tackle specifically the imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-layer-128-norm\n",
      "Epoch 1/500\n",
      "152/152 - 1s - loss: 0.7923 - accuracy: 0.7936 - val_loss: 1.2630 - val_accuracy: 0.7803\n",
      "Epoch 2/500\n",
      "152/152 - 1s - loss: 0.4534 - accuracy: 0.8270 - val_loss: 0.4527 - val_accuracy: 0.8188\n",
      "Epoch 3/500\n",
      "152/152 - 1s - loss: 0.4406 - accuracy: 0.8364 - val_loss: 0.3942 - val_accuracy: 0.8320\n",
      "Epoch 4/500\n",
      "152/152 - 1s - loss: 0.3855 - accuracy: 0.8473 - val_loss: 0.4356 - val_accuracy: 0.8415\n",
      "Epoch 5/500\n",
      "152/152 - 1s - loss: 0.4277 - accuracy: 0.8445 - val_loss: 0.3802 - val_accuracy: 0.8460\n",
      "Epoch 6/500\n",
      "152/152 - 1s - loss: 0.3801 - accuracy: 0.8540 - val_loss: 0.3915 - val_accuracy: 0.8470\n",
      "Epoch 7/500\n",
      "152/152 - 1s - loss: 0.3305 - accuracy: 0.8640 - val_loss: 0.3687 - val_accuracy: 0.8452\n",
      "Epoch 8/500\n",
      "152/152 - 1s - loss: 0.3295 - accuracy: 0.8666 - val_loss: 0.3768 - val_accuracy: 0.8424\n",
      "Epoch 9/500\n",
      "152/152 - 1s - loss: 0.4136 - accuracy: 0.8586 - val_loss: 0.3684 - val_accuracy: 0.8459\n",
      "Epoch 10/500\n",
      "152/152 - 1s - loss: 0.3114 - accuracy: 0.8730 - val_loss: 0.3735 - val_accuracy: 0.8438\n",
      "Epoch 11/500\n",
      "152/152 - 1s - loss: 0.3033 - accuracy: 0.8771 - val_loss: 0.3734 - val_accuracy: 0.8454\n",
      "Epoch 12/500\n",
      "152/152 - 1s - loss: 0.2904 - accuracy: 0.8829 - val_loss: 0.3949 - val_accuracy: 0.8450\n",
      "Epoch 13/500\n",
      "152/152 - 1s - loss: 0.2944 - accuracy: 0.8818 - val_loss: 0.3826 - val_accuracy: 0.8419\n",
      "Epoch 14/500\n",
      "152/152 - 1s - loss: 0.2737 - accuracy: 0.8904 - val_loss: 0.4315 - val_accuracy: 0.8398\n",
      "Epoch 15/500\n",
      "152/152 - 1s - loss: 0.2758 - accuracy: 0.8900 - val_loss: 0.3839 - val_accuracy: 0.8417\n",
      "Epoch 16/500\n",
      "152/152 - 1s - loss: 0.2596 - accuracy: 0.8978 - val_loss: 0.3900 - val_accuracy: 0.8402\n",
      "Epoch 17/500\n",
      "152/152 - 1s - loss: 0.2541 - accuracy: 0.8998 - val_loss: 0.3929 - val_accuracy: 0.8419\n",
      "Epoch 18/500\n",
      "152/152 - 1s - loss: 0.2399 - accuracy: 0.9070 - val_loss: 0.4279 - val_accuracy: 0.8268\n",
      "Epoch 19/500\n",
      "152/152 - 1s - loss: 0.2426 - accuracy: 0.9068 - val_loss: 0.4030 - val_accuracy: 0.8413\n",
      "Epoch 20/500\n",
      "152/152 - 1s - loss: 0.2355 - accuracy: 0.9096 - val_loss: 0.4296 - val_accuracy: 0.8333\n",
      "Epoch 21/500\n",
      "152/152 - 1s - loss: 0.2210 - accuracy: 0.9157 - val_loss: 0.4282 - val_accuracy: 0.8371\n",
      "Epoch 22/500\n",
      "152/152 - 1s - loss: 0.2114 - accuracy: 0.9201 - val_loss: 0.4488 - val_accuracy: 0.8304\n",
      "Epoch 23/500\n",
      "152/152 - 1s - loss: 0.2029 - accuracy: 0.9241 - val_loss: 0.4449 - val_accuracy: 0.8354\n",
      "Epoch 24/500\n",
      "152/152 - 1s - loss: 0.1986 - accuracy: 0.9262 - val_loss: 0.4582 - val_accuracy: 0.8324\n",
      "Epoch 25/500\n",
      "152/152 - 1s - loss: 0.1869 - accuracy: 0.9305 - val_loss: 0.5041 - val_accuracy: 0.8363\n",
      "Epoch 26/500\n",
      "152/152 - 1s - loss: 0.1835 - accuracy: 0.9329 - val_loss: 0.5090 - val_accuracy: 0.8397\n",
      "Epoch 27/500\n",
      "152/152 - 1s - loss: 0.1657 - accuracy: 0.9403 - val_loss: 0.4884 - val_accuracy: 0.8323\n",
      "Epoch 28/500\n",
      "152/152 - 1s - loss: 0.1527 - accuracy: 0.9458 - val_loss: 0.5154 - val_accuracy: 0.8232\n",
      "Epoch 29/500\n",
      "152/152 - 1s - loss: 0.1559 - accuracy: 0.9453 - val_loss: 0.5238 - val_accuracy: 0.8264\n",
      "Epoch 30/500\n",
      "152/152 - 1s - loss: 0.1557 - accuracy: 0.9469 - val_loss: 0.5738 - val_accuracy: 0.8080\n",
      "Epoch 31/500\n",
      "Restoring model weights from the end of the best epoch.\n",
      "152/152 - 1s - loss: 0.1368 - accuracy: 0.9525 - val_loss: 0.5564 - val_accuracy: 0.8203\n",
      "Epoch 00031: early stopping\n",
      "1-layer-128-norm-dropout\n",
      "Epoch 1/500\n",
      "152/152 - 1s - loss: 0.7144 - accuracy: 0.7842 - val_loss: 1.8851 - val_accuracy: 0.7352\n",
      "Epoch 2/500\n",
      "152/152 - 1s - loss: 0.4052 - accuracy: 0.8286 - val_loss: 0.4841 - val_accuracy: 0.8215\n",
      "Epoch 3/500\n",
      "152/152 - 1s - loss: 0.3798 - accuracy: 0.8412 - val_loss: 0.3692 - val_accuracy: 0.8467\n",
      "Epoch 4/500\n",
      "152/152 - 1s - loss: 0.3643 - accuracy: 0.8482 - val_loss: 0.3628 - val_accuracy: 0.8507\n",
      "Epoch 5/500\n",
      "152/152 - 1s - loss: 0.3537 - accuracy: 0.8538 - val_loss: 0.3595 - val_accuracy: 0.8518\n",
      "Epoch 6/500\n",
      "152/152 - 1s - loss: 0.3456 - accuracy: 0.8570 - val_loss: 0.3607 - val_accuracy: 0.8510\n",
      "Epoch 7/500\n",
      "152/152 - 1s - loss: 0.3398 - accuracy: 0.8601 - val_loss: 0.3543 - val_accuracy: 0.8524\n",
      "Epoch 8/500\n",
      "152/152 - 1s - loss: 0.3346 - accuracy: 0.8615 - val_loss: 0.3534 - val_accuracy: 0.8514\n",
      "Epoch 9/500\n",
      "152/152 - 1s - loss: 0.3282 - accuracy: 0.8646 - val_loss: 0.3608 - val_accuracy: 0.8510\n",
      "Epoch 10/500\n",
      "152/152 - 1s - loss: 0.3248 - accuracy: 0.8664 - val_loss: 0.3555 - val_accuracy: 0.8523\n",
      "Epoch 11/500\n",
      "152/152 - 1s - loss: 0.3196 - accuracy: 0.8694 - val_loss: 0.3623 - val_accuracy: 0.8490\n",
      "Epoch 12/500\n",
      "152/152 - 1s - loss: 0.3159 - accuracy: 0.8711 - val_loss: 0.3572 - val_accuracy: 0.8513\n",
      "Epoch 13/500\n",
      "152/152 - 1s - loss: 0.3099 - accuracy: 0.8732 - val_loss: 0.3616 - val_accuracy: 0.8498\n",
      "Epoch 14/500\n",
      "152/152 - 1s - loss: 0.3051 - accuracy: 0.8760 - val_loss: 0.3589 - val_accuracy: 0.8534\n",
      "Epoch 15/500\n",
      "152/152 - 1s - loss: 0.3021 - accuracy: 0.8769 - val_loss: 0.3623 - val_accuracy: 0.8510\n",
      "Epoch 16/500\n",
      "152/152 - 1s - loss: 0.2961 - accuracy: 0.8794 - val_loss: 0.3645 - val_accuracy: 0.8500\n",
      "Epoch 17/500\n",
      "152/152 - 1s - loss: 0.2921 - accuracy: 0.8822 - val_loss: 0.3681 - val_accuracy: 0.8522\n",
      "Epoch 18/500\n",
      "152/152 - 1s - loss: 0.2883 - accuracy: 0.8833 - val_loss: 0.3732 - val_accuracy: 0.8464\n",
      "Epoch 19/500\n",
      "152/152 - 1s - loss: 0.2832 - accuracy: 0.8855 - val_loss: 0.3923 - val_accuracy: 0.8485\n",
      "Epoch 20/500\n",
      "152/152 - 1s - loss: 0.2796 - accuracy: 0.8878 - val_loss: 0.3737 - val_accuracy: 0.8503\n",
      "Epoch 21/500\n",
      "152/152 - 1s - loss: 0.2751 - accuracy: 0.8903 - val_loss: 0.3811 - val_accuracy: 0.8501\n",
      "Epoch 22/500\n",
      "152/152 - 1s - loss: 0.2696 - accuracy: 0.8927 - val_loss: 0.3872 - val_accuracy: 0.8450\n",
      "Epoch 23/500\n",
      "152/152 - 1s - loss: 0.2650 - accuracy: 0.8950 - val_loss: 0.3862 - val_accuracy: 0.8473\n",
      "Epoch 24/500\n",
      "152/152 - 1s - loss: 0.2625 - accuracy: 0.8957 - val_loss: 0.3926 - val_accuracy: 0.8499\n",
      "Epoch 25/500\n",
      "152/152 - 1s - loss: 0.2555 - accuracy: 0.8982 - val_loss: 0.3982 - val_accuracy: 0.8505\n",
      "Epoch 26/500\n",
      "152/152 - 1s - loss: 0.2506 - accuracy: 0.9014 - val_loss: 0.3976 - val_accuracy: 0.8481\n",
      "Epoch 27/500\n",
      "152/152 - 1s - loss: 0.2514 - accuracy: 0.9012 - val_loss: 0.4081 - val_accuracy: 0.8464\n",
      "Epoch 28/500\n",
      "152/152 - 1s - loss: 0.2445 - accuracy: 0.9046 - val_loss: 0.4058 - val_accuracy: 0.8416\n",
      "Epoch 29/500\n",
      "152/152 - 1s - loss: 0.2397 - accuracy: 0.9067 - val_loss: 0.4126 - val_accuracy: 0.8442\n",
      "Epoch 30/500\n",
      "152/152 - 1s - loss: 0.2341 - accuracy: 0.9090 - val_loss: 0.4145 - val_accuracy: 0.8445\n",
      "Epoch 31/500\n",
      "152/152 - 1s - loss: 0.2327 - accuracy: 0.9094 - val_loss: 0.4200 - val_accuracy: 0.8458\n",
      "Epoch 32/500\n",
      "152/152 - 1s - loss: 0.2303 - accuracy: 0.9100 - val_loss: 0.4292 - val_accuracy: 0.8451\n",
      "Epoch 33/500\n",
      "152/152 - 1s - loss: 0.2255 - accuracy: 0.9129 - val_loss: 0.4242 - val_accuracy: 0.8446\n",
      "Epoch 34/500\n",
      "152/152 - 1s - loss: 0.2220 - accuracy: 0.9142 - val_loss: 0.4383 - val_accuracy: 0.8414\n",
      "Epoch 35/500\n",
      "152/152 - 1s - loss: 0.2149 - accuracy: 0.9173 - val_loss: 0.4408 - val_accuracy: 0.8457\n",
      "Epoch 36/500\n",
      "152/152 - 1s - loss: 0.2163 - accuracy: 0.9174 - val_loss: 0.4594 - val_accuracy: 0.8452\n",
      "Epoch 37/500\n",
      "152/152 - 1s - loss: 0.2150 - accuracy: 0.9174 - val_loss: 0.4544 - val_accuracy: 0.8445\n",
      "Epoch 38/500\n",
      "152/152 - 1s - loss: 0.2048 - accuracy: 0.9226 - val_loss: 0.4806 - val_accuracy: 0.8397\n",
      "Epoch 39/500\n",
      "Restoring model weights from the end of the best epoch.\n",
      "152/152 - 1s - loss: 0.2008 - accuracy: 0.9237 - val_loss: 0.4828 - val_accuracy: 0.8454\n",
      "Epoch 00039: early stopping\n",
      "2-layer-128-256\n",
      "Epoch 1/500\n",
      "152/152 - 1s - loss: 47.2690 - accuracy: 0.6270 - val_loss: 16.3310 - val_accuracy: 0.2942\n",
      "Epoch 2/500\n",
      "152/152 - 1s - loss: 10.3213 - accuracy: 0.6385 - val_loss: 1.6409 - val_accuracy: 0.7677\n",
      "Epoch 3/500\n",
      "152/152 - 1s - loss: 1.0090 - accuracy: 0.7355 - val_loss: 0.4505 - val_accuracy: 0.8021\n",
      "Epoch 4/500\n",
      "152/152 - 1s - loss: 0.4646 - accuracy: 0.7924 - val_loss: 0.4358 - val_accuracy: 0.8017\n",
      "Epoch 5/500\n",
      "152/152 - 1s - loss: 0.4526 - accuracy: 0.7971 - val_loss: 0.4399 - val_accuracy: 0.7989\n",
      "Epoch 6/500\n",
      "152/152 - 1s - loss: 0.5189 - accuracy: 0.7838 - val_loss: 0.4372 - val_accuracy: 0.8038\n",
      "Epoch 7/500\n",
      "152/152 - 1s - loss: 0.4371 - accuracy: 0.8041 - val_loss: 0.4276 - val_accuracy: 0.8091\n",
      "Epoch 8/500\n",
      "152/152 - 1s - loss: 0.4813 - accuracy: 0.7913 - val_loss: 0.5536 - val_accuracy: 0.7837\n",
      "Epoch 9/500\n",
      "152/152 - 1s - loss: 7.5466 - accuracy: 0.6279 - val_loss: 0.5962 - val_accuracy: 0.7165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/500\n",
      "152/152 - 1s - loss: 0.5968 - accuracy: 0.7156 - val_loss: 0.5960 - val_accuracy: 0.7165\n",
      "Epoch 11/500\n",
      "152/152 - 1s - loss: 0.5968 - accuracy: 0.7156 - val_loss: 0.5960 - val_accuracy: 0.7165\n",
      "Epoch 12/500\n",
      "152/152 - 1s - loss: 0.5967 - accuracy: 0.7156 - val_loss: 0.5962 - val_accuracy: 0.7165\n",
      "Epoch 13/500\n",
      "152/152 - 1s - loss: 0.5969 - accuracy: 0.7156 - val_loss: 0.5961 - val_accuracy: 0.7165\n",
      "Epoch 14/500\n",
      "152/152 - 1s - loss: 0.5466 - accuracy: 0.7156 - val_loss: 0.4919 - val_accuracy: 0.7165\n",
      "Epoch 15/500\n",
      "152/152 - 1s - loss: 0.4738 - accuracy: 0.7324 - val_loss: 0.4648 - val_accuracy: 0.7863\n",
      "Epoch 16/500\n",
      "152/152 - 1s - loss: 0.4580 - accuracy: 0.7925 - val_loss: 0.4542 - val_accuracy: 0.7956\n",
      "Epoch 17/500\n",
      "152/152 - 1s - loss: 0.4475 - accuracy: 0.7969 - val_loss: 0.4380 - val_accuracy: 0.7993\n",
      "Epoch 18/500\n",
      "152/152 - 1s - loss: 0.4411 - accuracy: 0.7993 - val_loss: 0.4354 - val_accuracy: 0.7991\n",
      "Epoch 19/500\n",
      "152/152 - 1s - loss: 0.4373 - accuracy: 0.8003 - val_loss: 0.4292 - val_accuracy: 0.8017\n",
      "Epoch 20/500\n",
      "152/152 - 1s - loss: 0.4347 - accuracy: 0.8016 - val_loss: 0.4266 - val_accuracy: 0.8045\n",
      "Epoch 21/500\n",
      "152/152 - 1s - loss: 0.4311 - accuracy: 0.8034 - val_loss: 0.4319 - val_accuracy: 0.7997\n",
      "Epoch 22/500\n",
      "152/152 - 1s - loss: 0.4312 - accuracy: 0.8042 - val_loss: 0.4229 - val_accuracy: 0.8058\n",
      "Epoch 23/500\n",
      "152/152 - 1s - loss: 0.4291 - accuracy: 0.8046 - val_loss: 0.4225 - val_accuracy: 0.8053\n",
      "Epoch 24/500\n",
      "152/152 - 1s - loss: 0.4302 - accuracy: 0.8047 - val_loss: 0.4655 - val_accuracy: 0.7976\n",
      "Epoch 25/500\n",
      "152/152 - 1s - loss: 0.4287 - accuracy: 0.8052 - val_loss: 0.4206 - val_accuracy: 0.8072\n",
      "Epoch 26/500\n",
      "152/152 - 1s - loss: 0.4259 - accuracy: 0.8058 - val_loss: 0.4210 - val_accuracy: 0.8076\n",
      "Epoch 27/500\n",
      "152/152 - 1s - loss: 0.4267 - accuracy: 0.8059 - val_loss: 0.4239 - val_accuracy: 0.8033\n",
      "Epoch 28/500\n",
      "152/152 - 1s - loss: 0.4305 - accuracy: 0.8045 - val_loss: 0.4493 - val_accuracy: 0.8034\n",
      "Epoch 29/500\n",
      "152/152 - 1s - loss: 0.4277 - accuracy: 0.8062 - val_loss: 0.4636 - val_accuracy: 0.8017\n",
      "Epoch 30/500\n",
      "152/152 - 1s - loss: 0.4281 - accuracy: 0.8061 - val_loss: 0.4220 - val_accuracy: 0.8080\n",
      "Epoch 31/500\n",
      "152/152 - 1s - loss: 0.4274 - accuracy: 0.8063 - val_loss: 0.4529 - val_accuracy: 0.7975\n",
      "Epoch 32/500\n",
      "Restoring model weights from the end of the best epoch.\n",
      "152/152 - 1s - loss: 0.4261 - accuracy: 0.8070 - val_loss: 0.4259 - val_accuracy: 0.8067\n",
      "Epoch 00032: early stopping\n",
      "3-layer-256-512-256\n",
      "Epoch 1/500\n",
      "152/152 - 1s - loss: 111.0006 - accuracy: 0.6314 - val_loss: 4.9608 - val_accuracy: 0.7716\n",
      "Epoch 2/500\n",
      "152/152 - 1s - loss: 15.5253 - accuracy: 0.6660 - val_loss: 4.2978 - val_accuracy: 0.7800\n",
      "Epoch 3/500\n",
      "152/152 - 1s - loss: 7.2124 - accuracy: 0.7037 - val_loss: 2.0857 - val_accuracy: 0.7924\n",
      "Epoch 4/500\n",
      "152/152 - 1s - loss: 18.9377 - accuracy: 0.6648 - val_loss: 14.6706 - val_accuracy: 0.7165\n",
      "Epoch 5/500\n",
      "152/152 - 1s - loss: 5.7005 - accuracy: 0.6620 - val_loss: 0.8265 - val_accuracy: 0.7832\n",
      "Epoch 6/500\n",
      "152/152 - 1s - loss: 0.6708 - accuracy: 0.7551 - val_loss: 0.4802 - val_accuracy: 0.7754\n",
      "Epoch 7/500\n",
      "152/152 - 1s - loss: 0.4719 - accuracy: 0.7877 - val_loss: 0.4966 - val_accuracy: 0.7681\n",
      "Epoch 8/500\n",
      "152/152 - 1s - loss: 0.4517 - accuracy: 0.7972 - val_loss: 0.4172 - val_accuracy: 0.8143\n",
      "Epoch 9/500\n",
      "152/152 - 1s - loss: 0.4344 - accuracy: 0.8042 - val_loss: 0.4083 - val_accuracy: 0.8169\n",
      "Epoch 10/500\n",
      "152/152 - 1s - loss: 0.4577 - accuracy: 0.7969 - val_loss: 0.4340 - val_accuracy: 0.8044\n",
      "Epoch 11/500\n",
      "152/152 - 1s - loss: 0.6120 - accuracy: 0.7733 - val_loss: 0.9099 - val_accuracy: 0.7608\n",
      "Epoch 12/500\n",
      "152/152 - 1s - loss: 0.4910 - accuracy: 0.7886 - val_loss: 0.4737 - val_accuracy: 0.7817\n",
      "Epoch 13/500\n",
      "152/152 - 1s - loss: 0.4313 - accuracy: 0.8067 - val_loss: 0.4169 - val_accuracy: 0.8147\n",
      "Epoch 14/500\n",
      "152/152 - 1s - loss: 0.4250 - accuracy: 0.8095 - val_loss: 0.4153 - val_accuracy: 0.8131\n",
      "Epoch 15/500\n",
      "152/152 - 1s - loss: 0.4331 - accuracy: 0.8070 - val_loss: 0.4474 - val_accuracy: 0.8002\n",
      "Epoch 16/500\n",
      "152/152 - 1s - loss: 0.4194 - accuracy: 0.8125 - val_loss: 0.4097 - val_accuracy: 0.8158\n",
      "Epoch 17/500\n",
      "152/152 - 1s - loss: 0.4279 - accuracy: 0.8092 - val_loss: 0.4333 - val_accuracy: 0.8089\n",
      "Epoch 18/500\n",
      "152/152 - 1s - loss: 0.4211 - accuracy: 0.8119 - val_loss: 0.4261 - val_accuracy: 0.8100\n",
      "Epoch 19/500\n",
      "152/152 - 1s - loss: 0.4174 - accuracy: 0.8151 - val_loss: 0.4051 - val_accuracy: 0.8222\n",
      "Epoch 20/500\n",
      "152/152 - 1s - loss: 0.4160 - accuracy: 0.8162 - val_loss: 0.4023 - val_accuracy: 0.8212\n",
      "Epoch 21/500\n",
      "152/152 - 1s - loss: 0.4169 - accuracy: 0.8144 - val_loss: 0.4273 - val_accuracy: 0.8078\n",
      "Epoch 22/500\n",
      "152/152 - 1s - loss: 0.4146 - accuracy: 0.8163 - val_loss: 0.4258 - val_accuracy: 0.8052\n",
      "Epoch 23/500\n",
      "152/152 - 1s - loss: 0.4109 - accuracy: 0.8181 - val_loss: 0.3985 - val_accuracy: 0.8253\n",
      "Epoch 24/500\n",
      "152/152 - 1s - loss: 0.4088 - accuracy: 0.8189 - val_loss: 0.4032 - val_accuracy: 0.8222\n",
      "Epoch 25/500\n",
      "152/152 - 1s - loss: 0.4079 - accuracy: 0.8206 - val_loss: 0.4044 - val_accuracy: 0.8211\n",
      "Epoch 26/500\n",
      "152/152 - 1s - loss: 0.4107 - accuracy: 0.8191 - val_loss: 0.4257 - val_accuracy: 0.8120\n",
      "Epoch 27/500\n",
      "152/152 - 1s - loss: 0.4111 - accuracy: 0.8196 - val_loss: 0.4088 - val_accuracy: 0.8211\n",
      "Epoch 28/500\n",
      "152/152 - 1s - loss: 13.7635 - accuracy: 0.7655 - val_loss: 0.7465 - val_accuracy: 0.2855\n",
      "Epoch 29/500\n",
      "152/152 - 1s - loss: 0.9171 - accuracy: 0.6503 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 30/500\n",
      "152/152 - 1s - loss: 0.6299 - accuracy: 0.7156 - val_loss: 0.5962 - val_accuracy: 0.7165\n",
      "Epoch 31/500\n",
      "152/152 - 1s - loss: 0.5973 - accuracy: 0.7156 - val_loss: 0.5962 - val_accuracy: 0.7165\n",
      "Epoch 32/500\n",
      "152/152 - 1s - loss: 0.5969 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 33/500\n",
      "152/152 - 1s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 34/500\n",
      "152/152 - 1s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5962 - val_accuracy: 0.7165\n",
      "Epoch 35/500\n",
      "152/152 - 1s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 36/500\n",
      "152/152 - 1s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 37/500\n",
      "152/152 - 1s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 38/500\n",
      "152/152 - 1s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 39/500\n",
      "152/152 - 1s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 40/500\n",
      "152/152 - 1s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 41/500\n",
      "152/152 - 1s - loss: 0.5969 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 42/500\n",
      "152/152 - 1s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 43/500\n",
      "152/152 - 1s - loss: 0.5969 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 44/500\n",
      "152/152 - 1s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 45/500\n",
      "152/152 - 1s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 46/500\n",
      "152/152 - 1s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5965 - val_accuracy: 0.7165\n",
      "Epoch 47/500\n",
      "152/152 - 1s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5963 - val_accuracy: 0.7165\n",
      "Epoch 48/500\n",
      "Restoring model weights from the end of the best epoch.\n",
      "152/152 - 1s - loss: 0.5970 - accuracy: 0.7156 - val_loss: 0.5964 - val_accuracy: 0.7165\n",
      "Epoch 00048: early stopping\n",
      "3-layer-512-256-128-norm\n",
      "Epoch 1/500\n",
      "152/152 - 1s - loss: 0.3785 - accuracy: 0.8337 - val_loss: 1.2057 - val_accuracy: 0.7177\n",
      "Epoch 2/500\n",
      "152/152 - 1s - loss: 0.3443 - accuracy: 0.8520 - val_loss: 0.8481 - val_accuracy: 0.7289\n",
      "Epoch 3/500\n",
      "152/152 - 1s - loss: 0.3334 - accuracy: 0.8571 - val_loss: 2.3673 - val_accuracy: 0.7165\n",
      "Epoch 4/500\n",
      "152/152 - 1s - loss: 0.3227 - accuracy: 0.8630 - val_loss: 1.3137 - val_accuracy: 0.7165\n",
      "Epoch 5/500\n",
      "152/152 - 1s - loss: 0.3146 - accuracy: 0.8677 - val_loss: 2.3450 - val_accuracy: 0.7165\n",
      "Epoch 6/500\n",
      "152/152 - 1s - loss: 0.3015 - accuracy: 0.8740 - val_loss: 1.9009 - val_accuracy: 0.7166\n",
      "Epoch 7/500\n",
      "152/152 - 1s - loss: 0.2919 - accuracy: 0.8780 - val_loss: 1.9438 - val_accuracy: 0.7165\n",
      "Epoch 8/500\n",
      "152/152 - 1s - loss: 0.2822 - accuracy: 0.8832 - val_loss: 0.7697 - val_accuracy: 0.7237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/500\n",
      "152/152 - 1s - loss: 0.2715 - accuracy: 0.8879 - val_loss: 1.4003 - val_accuracy: 0.7165\n",
      "Epoch 10/500\n",
      "152/152 - 1s - loss: 0.2601 - accuracy: 0.8935 - val_loss: 1.6288 - val_accuracy: 0.7165\n",
      "Epoch 11/500\n",
      "152/152 - 1s - loss: 0.2490 - accuracy: 0.8985 - val_loss: 1.0179 - val_accuracy: 0.7312\n",
      "Epoch 12/500\n",
      "152/152 - 1s - loss: 0.2374 - accuracy: 0.9038 - val_loss: 2.8520 - val_accuracy: 0.7165\n",
      "Epoch 13/500\n",
      "152/152 - 1s - loss: 0.2227 - accuracy: 0.9098 - val_loss: 1.6045 - val_accuracy: 0.7136\n",
      "Epoch 14/500\n",
      "152/152 - 1s - loss: 0.2094 - accuracy: 0.9157 - val_loss: 2.0124 - val_accuracy: 0.7173\n",
      "Epoch 15/500\n",
      "152/152 - 1s - loss: 0.1962 - accuracy: 0.9216 - val_loss: 2.0446 - val_accuracy: 0.7166\n",
      "Epoch 16/500\n",
      "152/152 - 1s - loss: 0.1766 - accuracy: 0.9311 - val_loss: 1.0263 - val_accuracy: 0.7655\n",
      "Epoch 17/500\n",
      "152/152 - 1s - loss: 0.1649 - accuracy: 0.9354 - val_loss: 0.8847 - val_accuracy: 0.7632\n",
      "Epoch 18/500\n",
      "152/152 - 1s - loss: 0.1526 - accuracy: 0.9398 - val_loss: 1.3282 - val_accuracy: 0.7141\n",
      "Epoch 19/500\n",
      "152/152 - 1s - loss: 0.1356 - accuracy: 0.9473 - val_loss: 1.6988 - val_accuracy: 0.6960\n",
      "Epoch 20/500\n",
      "152/152 - 1s - loss: 0.1281 - accuracy: 0.9500 - val_loss: 3.8501 - val_accuracy: 0.7165\n",
      "Epoch 21/500\n",
      "152/152 - 1s - loss: 0.1134 - accuracy: 0.9567 - val_loss: 1.7845 - val_accuracy: 0.7211\n",
      "Epoch 22/500\n",
      "152/152 - 1s - loss: 0.1041 - accuracy: 0.9598 - val_loss: 4.5144 - val_accuracy: 0.7189\n",
      "Epoch 23/500\n",
      "152/152 - 1s - loss: 0.0917 - accuracy: 0.9656 - val_loss: 1.3465 - val_accuracy: 0.7578\n",
      "Epoch 24/500\n",
      "152/152 - 1s - loss: 0.0858 - accuracy: 0.9675 - val_loss: 4.1020 - val_accuracy: 0.7186\n",
      "Epoch 25/500\n",
      "152/152 - 1s - loss: 0.0714 - accuracy: 0.9739 - val_loss: 2.5963 - val_accuracy: 0.7445\n",
      "Epoch 26/500\n",
      "152/152 - 1s - loss: 0.0666 - accuracy: 0.9756 - val_loss: 1.7809 - val_accuracy: 0.7662\n",
      "Epoch 27/500\n",
      "152/152 - 1s - loss: 0.0628 - accuracy: 0.9770 - val_loss: 1.4093 - val_accuracy: 0.7420\n",
      "Epoch 28/500\n",
      "152/152 - 1s - loss: 0.0582 - accuracy: 0.9788 - val_loss: 3.0797 - val_accuracy: 0.7430\n",
      "Epoch 29/500\n",
      "152/152 - 1s - loss: 0.0564 - accuracy: 0.9793 - val_loss: 3.4452 - val_accuracy: 0.7622\n",
      "Epoch 30/500\n",
      "152/152 - 1s - loss: 0.0457 - accuracy: 0.9836 - val_loss: 3.5080 - val_accuracy: 0.7840\n",
      "Epoch 31/500\n",
      "152/152 - 1s - loss: 0.0484 - accuracy: 0.9822 - val_loss: 5.2264 - val_accuracy: 0.7201\n",
      "Epoch 32/500\n",
      "152/152 - 1s - loss: 0.0446 - accuracy: 0.9838 - val_loss: 4.5502 - val_accuracy: 0.7234\n",
      "Epoch 33/500\n",
      "152/152 - 1s - loss: 0.0411 - accuracy: 0.9851 - val_loss: 2.1768 - val_accuracy: 0.7602\n",
      "Epoch 34/500\n",
      "152/152 - 1s - loss: 0.0386 - accuracy: 0.9858 - val_loss: 3.2567 - val_accuracy: 0.7569\n",
      "Epoch 35/500\n",
      "152/152 - 1s - loss: 0.0347 - accuracy: 0.9875 - val_loss: 2.8711 - val_accuracy: 0.7578\n",
      "Epoch 36/500\n",
      "152/152 - 1s - loss: 0.0417 - accuracy: 0.9846 - val_loss: 1.7172 - val_accuracy: 0.7485\n",
      "Epoch 37/500\n",
      "152/152 - 1s - loss: 0.0357 - accuracy: 0.9870 - val_loss: 2.0977 - val_accuracy: 0.7668\n",
      "Epoch 38/500\n",
      "152/152 - 1s - loss: 0.0253 - accuracy: 0.9914 - val_loss: 1.6086 - val_accuracy: 0.8164\n",
      "Epoch 39/500\n",
      "152/152 - 1s - loss: 0.0220 - accuracy: 0.9929 - val_loss: 1.6583 - val_accuracy: 0.7795\n",
      "Epoch 40/500\n",
      "152/152 - 1s - loss: 0.0318 - accuracy: 0.9887 - val_loss: 2.6042 - val_accuracy: 0.7547\n",
      "Epoch 41/500\n",
      "152/152 - 1s - loss: 0.0302 - accuracy: 0.9889 - val_loss: 3.2264 - val_accuracy: 0.7404\n",
      "Epoch 42/500\n",
      "152/152 - 1s - loss: 0.0296 - accuracy: 0.9892 - val_loss: 4.1985 - val_accuracy: 0.7340\n",
      "Epoch 43/500\n",
      "152/152 - 1s - loss: 0.0309 - accuracy: 0.9887 - val_loss: 5.0889 - val_accuracy: 0.7299\n",
      "Epoch 44/500\n",
      "152/152 - 1s - loss: 0.0234 - accuracy: 0.9918 - val_loss: 3.9229 - val_accuracy: 0.7580\n",
      "Epoch 45/500\n",
      "152/152 - 1s - loss: 0.0145 - accuracy: 0.9952 - val_loss: 1.7542 - val_accuracy: 0.8223\n",
      "Epoch 46/500\n",
      "152/152 - 1s - loss: 0.0249 - accuracy: 0.9909 - val_loss: 2.9483 - val_accuracy: 0.7555\n",
      "Epoch 47/500\n",
      "152/152 - 1s - loss: 0.0324 - accuracy: 0.9882 - val_loss: 1.4792 - val_accuracy: 0.7814\n",
      "Epoch 48/500\n",
      "152/152 - 1s - loss: 0.0240 - accuracy: 0.9913 - val_loss: 2.8021 - val_accuracy: 0.7446\n",
      "Epoch 49/500\n",
      "152/152 - 1s - loss: 0.0281 - accuracy: 0.9899 - val_loss: 4.6364 - val_accuracy: 0.7387\n",
      "Epoch 50/500\n",
      "152/152 - 1s - loss: 0.0192 - accuracy: 0.9931 - val_loss: 3.3258 - val_accuracy: 0.7676\n",
      "Epoch 51/500\n",
      "152/152 - 1s - loss: 0.0176 - accuracy: 0.9938 - val_loss: 2.7955 - val_accuracy: 0.7443\n",
      "Epoch 52/500\n",
      "152/152 - 1s - loss: 0.0245 - accuracy: 0.9914 - val_loss: 3.6059 - val_accuracy: 0.7442\n",
      "Epoch 53/500\n",
      "152/152 - 1s - loss: 0.0196 - accuracy: 0.9930 - val_loss: 2.2167 - val_accuracy: 0.7933\n",
      "Epoch 54/500\n",
      "152/152 - 1s - loss: 0.0146 - accuracy: 0.9951 - val_loss: 4.7546 - val_accuracy: 0.7223\n",
      "Epoch 55/500\n",
      "152/152 - 1s - loss: 0.0192 - accuracy: 0.9930 - val_loss: 2.4553 - val_accuracy: 0.8103\n",
      "Epoch 56/500\n",
      "152/152 - 1s - loss: 0.0240 - accuracy: 0.9911 - val_loss: 1.4776 - val_accuracy: 0.8161\n",
      "Epoch 57/500\n",
      "152/152 - 1s - loss: 0.0189 - accuracy: 0.9933 - val_loss: 2.1285 - val_accuracy: 0.8062\n",
      "Epoch 58/500\n",
      "152/152 - 1s - loss: 0.0144 - accuracy: 0.9952 - val_loss: 2.2257 - val_accuracy: 0.7609\n",
      "Epoch 59/500\n",
      "152/152 - 1s - loss: 0.0145 - accuracy: 0.9949 - val_loss: 2.5327 - val_accuracy: 0.8079\n",
      "Epoch 60/500\n",
      "152/152 - 1s - loss: 0.0231 - accuracy: 0.9917 - val_loss: 6.4490 - val_accuracy: 0.7230\n",
      "Epoch 61/500\n",
      "152/152 - 1s - loss: 0.0284 - accuracy: 0.9898 - val_loss: 3.4663 - val_accuracy: 0.7580\n",
      "Epoch 62/500\n",
      "152/152 - 1s - loss: 0.0189 - accuracy: 0.9934 - val_loss: 2.6526 - val_accuracy: 0.8192\n",
      "Epoch 63/500\n",
      "152/152 - 1s - loss: 0.0120 - accuracy: 0.9960 - val_loss: 1.6839 - val_accuracy: 0.8093\n",
      "Epoch 64/500\n",
      "152/152 - 1s - loss: 0.0128 - accuracy: 0.9956 - val_loss: 3.8316 - val_accuracy: 0.7335\n",
      "Epoch 65/500\n",
      "152/152 - 1s - loss: 0.0174 - accuracy: 0.9941 - val_loss: 2.1334 - val_accuracy: 0.8211\n",
      "Epoch 66/500\n",
      "152/152 - 1s - loss: 0.0164 - accuracy: 0.9944 - val_loss: 3.1258 - val_accuracy: 0.8107\n",
      "Epoch 67/500\n",
      "152/152 - 1s - loss: 0.0155 - accuracy: 0.9946 - val_loss: 3.7772 - val_accuracy: 0.7529\n",
      "Epoch 68/500\n",
      "152/152 - 1s - loss: 0.0186 - accuracy: 0.9932 - val_loss: 6.7297 - val_accuracy: 0.7217\n",
      "Epoch 69/500\n",
      "152/152 - 1s - loss: 0.0203 - accuracy: 0.9927 - val_loss: 3.0765 - val_accuracy: 0.7997\n",
      "Epoch 70/500\n",
      "Restoring model weights from the end of the best epoch.\n",
      "152/152 - 1s - loss: 0.0137 - accuracy: 0.9953 - val_loss: 5.6114 - val_accuracy: 0.7560\n",
      "Epoch 00070: early stopping\n",
      "3-layer-512-256-128-dropout\n",
      "Epoch 1/500\n",
      "152/152 - 1s - loss: 0.4563 - accuracy: 0.7996 - val_loss: 0.5794 - val_accuracy: 0.7498\n",
      "Epoch 2/500\n",
      "152/152 - 1s - loss: 0.4057 - accuracy: 0.8240 - val_loss: 0.7082 - val_accuracy: 0.4926\n",
      "Epoch 3/500\n",
      "152/152 - 1s - loss: 0.3852 - accuracy: 0.8341 - val_loss: 0.6106 - val_accuracy: 0.6965\n",
      "Epoch 4/500\n",
      "152/152 - 1s - loss: 0.3747 - accuracy: 0.8388 - val_loss: 0.5749 - val_accuracy: 0.7456\n",
      "Epoch 5/500\n",
      "152/152 - 1s - loss: 0.3684 - accuracy: 0.8417 - val_loss: 0.4358 - val_accuracy: 0.8135\n",
      "Epoch 6/500\n",
      "152/152 - 1s - loss: 0.3620 - accuracy: 0.8457 - val_loss: 0.4555 - val_accuracy: 0.8215\n",
      "Epoch 7/500\n",
      "152/152 - 1s - loss: 0.3569 - accuracy: 0.8485 - val_loss: 0.4392 - val_accuracy: 0.7919\n",
      "Epoch 8/500\n",
      "152/152 - 1s - loss: 0.3525 - accuracy: 0.8509 - val_loss: 0.4718 - val_accuracy: 0.8250\n",
      "Epoch 9/500\n",
      "152/152 - 1s - loss: 0.3505 - accuracy: 0.8513 - val_loss: 0.4302 - val_accuracy: 0.7775\n",
      "Epoch 10/500\n",
      "152/152 - 1s - loss: 0.3456 - accuracy: 0.8539 - val_loss: 0.5289 - val_accuracy: 0.7359\n",
      "Epoch 11/500\n",
      "152/152 - 1s - loss: 0.3433 - accuracy: 0.8549 - val_loss: 0.6121 - val_accuracy: 0.7525\n",
      "Epoch 12/500\n",
      "152/152 - 1s - loss: 0.3413 - accuracy: 0.8574 - val_loss: 0.4258 - val_accuracy: 0.7969\n",
      "Epoch 13/500\n",
      "152/152 - 1s - loss: 0.3376 - accuracy: 0.8583 - val_loss: 0.4494 - val_accuracy: 0.7715\n",
      "Epoch 14/500\n",
      "152/152 - 1s - loss: 0.3336 - accuracy: 0.8607 - val_loss: 0.7014 - val_accuracy: 0.7522\n",
      "Epoch 15/500\n",
      "152/152 - 1s - loss: 0.3305 - accuracy: 0.8612 - val_loss: 0.6643 - val_accuracy: 0.7388\n",
      "Epoch 16/500\n",
      "152/152 - 1s - loss: 0.3301 - accuracy: 0.8616 - val_loss: 0.4802 - val_accuracy: 0.7643\n",
      "Epoch 17/500\n",
      "152/152 - 1s - loss: 0.3274 - accuracy: 0.8633 - val_loss: 0.4501 - val_accuracy: 0.7848\n",
      "Epoch 18/500\n",
      "152/152 - 1s - loss: 0.3232 - accuracy: 0.8651 - val_loss: 0.4454 - val_accuracy: 0.8138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/500\n",
      "152/152 - 1s - loss: 0.3202 - accuracy: 0.8669 - val_loss: 0.9876 - val_accuracy: 0.7331\n",
      "Epoch 20/500\n",
      "152/152 - 1s - loss: 0.3196 - accuracy: 0.8674 - val_loss: 0.5114 - val_accuracy: 0.7821\n",
      "Epoch 21/500\n",
      "152/152 - 1s - loss: 0.3167 - accuracy: 0.8690 - val_loss: 0.6830 - val_accuracy: 0.7663\n",
      "Epoch 22/500\n",
      "152/152 - 1s - loss: 0.3122 - accuracy: 0.8712 - val_loss: 0.7225 - val_accuracy: 0.7573\n",
      "Epoch 23/500\n",
      "152/152 - 1s - loss: 0.3114 - accuracy: 0.8713 - val_loss: 0.5918 - val_accuracy: 0.7962\n",
      "Epoch 24/500\n",
      "152/152 - 1s - loss: 0.3089 - accuracy: 0.8725 - val_loss: 0.7699 - val_accuracy: 0.7529\n",
      "Epoch 25/500\n",
      "152/152 - 1s - loss: 0.3070 - accuracy: 0.8739 - val_loss: 0.9777 - val_accuracy: 0.7329\n",
      "Epoch 26/500\n",
      "152/152 - 1s - loss: 0.3056 - accuracy: 0.8735 - val_loss: 0.5064 - val_accuracy: 0.7817\n",
      "Epoch 27/500\n",
      "152/152 - 1s - loss: 0.3037 - accuracy: 0.8754 - val_loss: 0.9904 - val_accuracy: 0.7528\n",
      "Epoch 28/500\n",
      "152/152 - 1s - loss: 0.3020 - accuracy: 0.8769 - val_loss: 0.8708 - val_accuracy: 0.7489\n",
      "Epoch 29/500\n",
      "152/152 - 1s - loss: 0.2996 - accuracy: 0.8775 - val_loss: 1.0346 - val_accuracy: 0.7175\n",
      "Epoch 30/500\n",
      "152/152 - 1s - loss: 0.2973 - accuracy: 0.8779 - val_loss: 0.5413 - val_accuracy: 0.7772\n",
      "Epoch 31/500\n",
      "152/152 - 1s - loss: 0.2949 - accuracy: 0.8790 - val_loss: 0.6145 - val_accuracy: 0.7756\n",
      "Epoch 32/500\n",
      "152/152 - 1s - loss: 0.2934 - accuracy: 0.8798 - val_loss: 0.8104 - val_accuracy: 0.7713\n",
      "Epoch 33/500\n",
      "Restoring model weights from the end of the best epoch.\n",
      "152/152 - 1s - loss: 0.2909 - accuracy: 0.8814 - val_loss: 0.8214 - val_accuracy: 0.7561\n",
      "Epoch 00033: early stopping\n",
      "3-layer-512-256-128-norm-dropout\n",
      "Epoch 1/500\n",
      "152/152 - 1s - loss: 0.4659 - accuracy: 0.7959 - val_loss: 0.8847 - val_accuracy: 0.7489\n",
      "Epoch 2/500\n",
      "152/152 - 1s - loss: 0.4044 - accuracy: 0.8249 - val_loss: 0.4860 - val_accuracy: 0.7848\n",
      "Epoch 3/500\n",
      "152/152 - 1s - loss: 0.3819 - accuracy: 0.8352 - val_loss: 0.4200 - val_accuracy: 0.8190\n",
      "Epoch 4/500\n",
      "152/152 - 1s - loss: 0.3712 - accuracy: 0.8404 - val_loss: 0.4325 - val_accuracy: 0.8234\n",
      "Epoch 5/500\n",
      "152/152 - 1s - loss: 0.3639 - accuracy: 0.8449 - val_loss: 0.4287 - val_accuracy: 0.8066\n",
      "Epoch 6/500\n",
      "152/152 - 1s - loss: 0.3568 - accuracy: 0.8482 - val_loss: 0.4299 - val_accuracy: 0.7760\n",
      "Epoch 7/500\n",
      "152/152 - 1s - loss: 0.3535 - accuracy: 0.8503 - val_loss: 0.4210 - val_accuracy: 0.7913\n",
      "Epoch 8/500\n",
      "152/152 - 1s - loss: 0.3496 - accuracy: 0.8520 - val_loss: 0.4173 - val_accuracy: 0.8147\n",
      "Epoch 9/500\n",
      "152/152 - 1s - loss: 0.3460 - accuracy: 0.8537 - val_loss: 0.4244 - val_accuracy: 0.7889\n",
      "Epoch 10/500\n",
      "152/152 - 1s - loss: 0.3440 - accuracy: 0.8550 - val_loss: 0.4194 - val_accuracy: 0.8257\n",
      "Epoch 11/500\n",
      "152/152 - 1s - loss: 0.3409 - accuracy: 0.8571 - val_loss: 0.3910 - val_accuracy: 0.8218\n",
      "Epoch 12/500\n",
      "152/152 - 1s - loss: 0.3395 - accuracy: 0.8569 - val_loss: 0.4243 - val_accuracy: 0.8109\n",
      "Epoch 13/500\n",
      "152/152 - 1s - loss: 0.3361 - accuracy: 0.8595 - val_loss: 0.5869 - val_accuracy: 0.7457\n",
      "Epoch 14/500\n",
      "152/152 - 1s - loss: 0.3326 - accuracy: 0.8612 - val_loss: 0.7492 - val_accuracy: 0.7357\n",
      "Epoch 15/500\n",
      "152/152 - 1s - loss: 0.3282 - accuracy: 0.8625 - val_loss: 0.4254 - val_accuracy: 0.7924\n",
      "Epoch 16/500\n",
      "152/152 - 1s - loss: 0.3278 - accuracy: 0.8639 - val_loss: 0.7625 - val_accuracy: 0.7352\n",
      "Epoch 17/500\n",
      "152/152 - 1s - loss: 0.3257 - accuracy: 0.8644 - val_loss: 0.7229 - val_accuracy: 0.7613\n",
      "Epoch 18/500\n",
      "152/152 - 1s - loss: 0.3215 - accuracy: 0.8678 - val_loss: 0.7056 - val_accuracy: 0.7539\n",
      "Epoch 19/500\n",
      "152/152 - 1s - loss: 0.3215 - accuracy: 0.8668 - val_loss: 0.8107 - val_accuracy: 0.7450\n",
      "Epoch 20/500\n",
      "152/152 - 1s - loss: 0.3189 - accuracy: 0.8683 - val_loss: 1.0848 - val_accuracy: 0.7275\n",
      "Epoch 21/500\n",
      "152/152 - 1s - loss: 0.3154 - accuracy: 0.8710 - val_loss: 0.6763 - val_accuracy: 0.7488\n",
      "Epoch 22/500\n",
      "152/152 - 1s - loss: 0.3129 - accuracy: 0.8717 - val_loss: 0.6151 - val_accuracy: 0.7673\n",
      "Epoch 23/500\n",
      "152/152 - 1s - loss: 0.3111 - accuracy: 0.8728 - val_loss: 0.6944 - val_accuracy: 0.7742\n",
      "Epoch 24/500\n",
      "152/152 - 1s - loss: 0.3071 - accuracy: 0.8745 - val_loss: 0.7690 - val_accuracy: 0.7747\n",
      "Epoch 25/500\n",
      "152/152 - 1s - loss: 0.3077 - accuracy: 0.8734 - val_loss: 0.7477 - val_accuracy: 0.7569\n",
      "Epoch 26/500\n",
      "152/152 - 1s - loss: 0.3078 - accuracy: 0.8734 - val_loss: 0.5285 - val_accuracy: 0.7763\n",
      "Epoch 27/500\n",
      "152/152 - 1s - loss: 0.3037 - accuracy: 0.8755 - val_loss: 1.0625 - val_accuracy: 0.7482\n",
      "Epoch 28/500\n",
      "152/152 - 1s - loss: 0.3034 - accuracy: 0.8765 - val_loss: 0.4915 - val_accuracy: 0.7908\n",
      "Epoch 29/500\n",
      "152/152 - 1s - loss: 0.3019 - accuracy: 0.8767 - val_loss: 0.4460 - val_accuracy: 0.7944\n",
      "Epoch 30/500\n",
      "152/152 - 1s - loss: 0.2987 - accuracy: 0.8779 - val_loss: 0.7327 - val_accuracy: 0.7474\n",
      "Epoch 31/500\n",
      "152/152 - 1s - loss: 0.2954 - accuracy: 0.8788 - val_loss: 1.6069 - val_accuracy: 0.7426\n",
      "Epoch 32/500\n",
      "152/152 - 1s - loss: 0.2942 - accuracy: 0.8802 - val_loss: 0.4635 - val_accuracy: 0.8148\n",
      "Epoch 33/500\n",
      "152/152 - 1s - loss: 0.2914 - accuracy: 0.8814 - val_loss: 0.8784 - val_accuracy: 0.7674\n",
      "Epoch 34/500\n",
      "152/152 - 1s - loss: 0.2891 - accuracy: 0.8831 - val_loss: 1.2653 - val_accuracy: 0.7429\n",
      "Epoch 35/500\n",
      "Restoring model weights from the end of the best epoch.\n",
      "152/152 - 1s - loss: 0.2872 - accuracy: 0.8838 - val_loss: 0.9111 - val_accuracy: 0.7504\n",
      "Epoch 00035: early stopping\n"
     ]
    }
   ],
   "source": [
    "# lower the number of epochs\n",
    "epochs = 500\n",
    "\n",
    "batch_size = 1024\n",
    "histories = []\n",
    "\n",
    "name=\"1-layer-128-norm\"\n",
    "print(name)\n",
    "model07 = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dense(128, activation='relu'),\n",
    "        keras.layers.Dense(1, activation='sigmoid')\n",
    "    ],name=name\n",
    ")\n",
    "\n",
    "model07.compile(loss=\"binary_crossentropy\", optimizer=Adam(learning_rate=0.001), metrics=[\"accuracy\"])\n",
    "\n",
    "histories.append(model07.fit(x_train, y_train, batch_size=batch_size, epochs=epochs,\n",
    "                            validation_data=(x_val,y_val), verbose=2, callbacks=[es]))\n",
    "\n",
    "name=\"1-layer-128-norm-dropout\"\n",
    "print(name)\n",
    "model08 = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dense(128, activation='relu'),\n",
    "        keras.layers.Dropout(0.4),\n",
    "        keras.layers.Dense(1, activation='sigmoid')\n",
    "    ],name=name\n",
    ")\n",
    "\n",
    "model08.compile(loss=\"binary_crossentropy\", optimizer=Adam(learning_rate=0.001), metrics=[\"accuracy\"])\n",
    "\n",
    "histories.append(model08.fit(x_train, y_train, batch_size=batch_size, epochs=epochs,\n",
    "                            validation_data=(x_val,y_val), verbose=2, callbacks=[es]))\n",
    "\n",
    "\n",
    "name=\"2-layer-128-256\"\n",
    "print(name)\n",
    "model09 = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        keras.layers.Flatten(),        \n",
    "        keras.layers.Dense(128, activation='relu'),\n",
    "        keras.layers.Dense(256, activation='relu'),\n",
    "        keras.layers.Dense(1, activation='sigmoid')\n",
    "    ],name=name\n",
    ")\n",
    "\n",
    "model09.compile(loss=\"binary_crossentropy\", optimizer=Adam(learning_rate=0.001), metrics=[\"accuracy\"])\n",
    "\n",
    "histories.append(model09.fit(x_train, y_train, batch_size=batch_size, epochs=epochs,\n",
    "                            validation_data=(x_val,y_val), verbose=2, callbacks=[es]))\n",
    "\n",
    "name=\"3-layer-256-512-256\"\n",
    "print(name)\n",
    "model10 = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        keras.layers.Flatten(),        \n",
    "        keras.layers.Dense(512, activation='relu'),\n",
    "        keras.layers.Dense(256, activation='relu'),\n",
    "        keras.layers.Dense(128, activation='relu'),\n",
    "        keras.layers.Dense(1, activation='sigmoid')\n",
    "    ],name=name\n",
    ")\n",
    "\n",
    "model10.compile(loss=\"binary_crossentropy\", optimizer=Adam(learning_rate=0.001), metrics=[\"accuracy\"])\n",
    "\n",
    "histories.append(model10.fit(x_train, y_train, batch_size=batch_size, epochs=epochs,\n",
    "                            validation_data=(x_val,y_val), verbose=2, callbacks=[es]))\n",
    "\n",
    "name=\"3-layer-512-256-128-norm\"\n",
    "print(name)\n",
    "model11 = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        keras.layers.Flatten(),        \n",
    "        keras.layers.Dense(512, activation='relu'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dense(256, activation='relu'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dense(128, activation='relu'),\n",
    "        keras.layers.Dense(1, activation='sigmoid')\n",
    "    ],name=name\n",
    ")\n",
    "\n",
    "model11.compile(loss=\"binary_crossentropy\", optimizer=Adam(learning_rate=0.001), metrics=[\"accuracy\"])\n",
    "\n",
    "histories.append(model11.fit(x_train, y_train, batch_size=batch_size, epochs=epochs,\n",
    "                            validation_data=(x_val,y_val), verbose=2, callbacks=[es]))\n",
    "\n",
    "name=\"3-layer-512-256-128-dropout\"\n",
    "print(name)\n",
    "model12 = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        keras.layers.Flatten(),        \n",
    "        keras.layers.Dense(512, activation='relu'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dropout(0.4),\n",
    "        keras.layers.Dense(256, activation='relu'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dropout(0.4),\n",
    "        keras.layers.Dense(128, activation='relu'),\n",
    "        keras.layers.Dropout(0.4),\n",
    "        keras.layers.Dense(1, activation='sigmoid')\n",
    "    ],name=name\n",
    ")\n",
    "\n",
    "model12.compile(loss=\"binary_crossentropy\", optimizer=Adam(learning_rate=0.001), metrics=[\"accuracy\"])\n",
    "\n",
    "histories.append(model12.fit(x_train, y_train, batch_size=batch_size, epochs=epochs,\n",
    "                            validation_data=(x_val,y_val), verbose=2, callbacks=[es]))\n",
    "\n",
    "name=\"3-layer-512-256-128-norm-dropout\"\n",
    "print(name)\n",
    "model13 = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        keras.layers.Flatten(),        \n",
    "        keras.layers.Dense(512, activation='relu'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dropout(0.4),\n",
    "        keras.layers.Dense(256, activation='relu'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dropout(0.4),\n",
    "        keras.layers.Dense(128, activation='relu'),\n",
    "        keras.layers.Dropout(0.4),\n",
    "        keras.layers.Dense(1, activation='sigmoid')\n",
    "    ],name=name\n",
    ")\n",
    "\n",
    "model13.compile(loss=\"binary_crossentropy\", optimizer=Adam(learning_rate=0.001), metrics=[\"accuracy\"])\n",
    "\n",
    "histories.append(model13.fit(x_train, y_train, batch_size=batch_size, epochs=epochs,\n",
    "                            validation_data=(x_val,y_val), verbose=2, callbacks=[es]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_89eee96e_ceec_11eb_b807_40e230e37f37\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >loss</th>        <th class=\"col_heading level0 col1\" >accuracy</th>        <th class=\"col_heading level0 col2\" >val_loss</th>        <th class=\"col_heading level0 col3\" >val_accuracy</th>    </tr>    <tr>        <th class=\"index_name level0\" >model size</th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_89eee96e_ceec_11eb_b807_40e230e37f37level0_row0\" class=\"row_heading level0 row0\" >1-layer-128-norm</th>\n",
       "                        <td id=\"T_89eee96e_ceec_11eb_b807_40e230e37f37row0_col0\" class=\"data row0 col0\" >0.38</td>\n",
       "                        <td id=\"T_89eee96e_ceec_11eb_b807_40e230e37f37row0_col1\" class=\"data row0 col1\" >85.40%</td>\n",
       "                        <td id=\"T_89eee96e_ceec_11eb_b807_40e230e37f37row0_col2\" class=\"data row0 col2\" >0.39</td>\n",
       "                        <td id=\"T_89eee96e_ceec_11eb_b807_40e230e37f37row0_col3\" class=\"data row0 col3\" >84.70%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_89eee96e_ceec_11eb_b807_40e230e37f37level0_row1\" class=\"row_heading level0 row1\" >1-layer-128-norm-dropout</th>\n",
       "                        <td id=\"T_89eee96e_ceec_11eb_b807_40e230e37f37row1_col0\" class=\"data row1 col0\" >0.31</td>\n",
       "                        <td id=\"T_89eee96e_ceec_11eb_b807_40e230e37f37row1_col1\" class=\"data row1 col1\" >87.60%</td>\n",
       "                        <td id=\"T_89eee96e_ceec_11eb_b807_40e230e37f37row1_col2\" class=\"data row1 col2\" >0.36</td>\n",
       "                        <td id=\"T_89eee96e_ceec_11eb_b807_40e230e37f37row1_col3\" class=\"data row1 col3\" >85.34%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_89eee96e_ceec_11eb_b807_40e230e37f37level0_row2\" class=\"row_heading level0 row2\" >2-layer-128-256</th>\n",
       "                        <td id=\"T_89eee96e_ceec_11eb_b807_40e230e37f37row2_col0\" class=\"data row2 col0\" >0.44</td>\n",
       "                        <td id=\"T_89eee96e_ceec_11eb_b807_40e230e37f37row2_col1\" class=\"data row2 col1\" >80.41%</td>\n",
       "                        <td id=\"T_89eee96e_ceec_11eb_b807_40e230e37f37row2_col2\" class=\"data row2 col2\" >0.43</td>\n",
       "                        <td id=\"T_89eee96e_ceec_11eb_b807_40e230e37f37row2_col3\" class=\"data row2 col3\" >80.91%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_89eee96e_ceec_11eb_b807_40e230e37f37level0_row3\" class=\"row_heading level0 row3\" >3-layer-256-512-256</th>\n",
       "                        <td id=\"T_89eee96e_ceec_11eb_b807_40e230e37f37row3_col0\" class=\"data row3 col0\" >0.41</td>\n",
       "                        <td id=\"T_89eee96e_ceec_11eb_b807_40e230e37f37row3_col1\" class=\"data row3 col1\" >81.81%</td>\n",
       "                        <td id=\"T_89eee96e_ceec_11eb_b807_40e230e37f37row3_col2\" class=\"data row3 col2\" >0.40</td>\n",
       "                        <td id=\"T_89eee96e_ceec_11eb_b807_40e230e37f37row3_col3\" class=\"data row3 col3\" >82.53%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_89eee96e_ceec_11eb_b807_40e230e37f37level0_row4\" class=\"row_heading level0 row4\" >3-layer-512-256-128-norm</th>\n",
       "                        <td id=\"T_89eee96e_ceec_11eb_b807_40e230e37f37row4_col0\" class=\"data row4 col0\" >0.01</td>\n",
       "                        <td id=\"T_89eee96e_ceec_11eb_b807_40e230e37f37row4_col1\" class=\"data row4 col1\" >99.52%</td>\n",
       "                        <td id=\"T_89eee96e_ceec_11eb_b807_40e230e37f37row4_col2\" class=\"data row4 col2\" >1.75</td>\n",
       "                        <td id=\"T_89eee96e_ceec_11eb_b807_40e230e37f37row4_col3\" class=\"data row4 col3\" >82.23%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_89eee96e_ceec_11eb_b807_40e230e37f37level0_row5\" class=\"row_heading level0 row5\" >3-layer-512-256-128-dropout</th>\n",
       "                        <td id=\"T_89eee96e_ceec_11eb_b807_40e230e37f37row5_col0\" class=\"data row5 col0\" >0.35</td>\n",
       "                        <td id=\"T_89eee96e_ceec_11eb_b807_40e230e37f37row5_col1\" class=\"data row5 col1\" >85.09%</td>\n",
       "                        <td id=\"T_89eee96e_ceec_11eb_b807_40e230e37f37row5_col2\" class=\"data row5 col2\" >0.47</td>\n",
       "                        <td id=\"T_89eee96e_ceec_11eb_b807_40e230e37f37row5_col3\" class=\"data row5 col3\" >82.50%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_89eee96e_ceec_11eb_b807_40e230e37f37level0_row6\" class=\"row_heading level0 row6\" >3-layer-512-256-128-norm-dropout</th>\n",
       "                        <td id=\"T_89eee96e_ceec_11eb_b807_40e230e37f37row6_col0\" class=\"data row6 col0\" >0.34</td>\n",
       "                        <td id=\"T_89eee96e_ceec_11eb_b807_40e230e37f37row6_col1\" class=\"data row6 col1\" >85.50%</td>\n",
       "                        <td id=\"T_89eee96e_ceec_11eb_b807_40e230e37f37row6_col2\" class=\"data row6 col2\" >0.42</td>\n",
       "                        <td id=\"T_89eee96e_ceec_11eb_b807_40e230e37f37row6_col3\" class=\"data row6 col3\" >82.57%</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1dfc1b6a5c8>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist1 = acc_df(histories)\n",
    "hist1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for history in histories[:]:\n",
    "    plt.plot(history.history['accuracy'], alpha=.6)\n",
    "    \n",
    "plt.xlabel('epoch')\n",
    "plt.legend([model07.name,model08.name,model09.name,\n",
    "            model10.name,model11.name,model12.name,model13.name], loc='lower right')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "for history in histories[:]:\n",
    "    plt.plot(history.history['val_accuracy'], alpha=.6)\n",
    "    \n",
    "plt.xlabel('epoch')\n",
    "plt.ylim([0.6,0.9])\n",
    "plt.legend([model07.name,model08.name,model09.name,\n",
    "            model10.name,model11.name,model12.name,model13.name], loc='lower right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot accuracy\n",
    "#plt = acc_plot(histories[1])\n",
    "#plt.show()\n",
    "\n",
    "# plot loss\n",
    "#plt = loss_plot(histories[1])\n",
    "#plt.show()\n",
    "\n",
    "# plot confuction matrix\n",
    "plt=conf_matrix(model08, x_test, y_test)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learnings\n",
    "- In the above chart we first of all see that just increasing the number of layers and the number of hidden nodes per layer did not improve the performance. On the contrary we can recognize that in the 3rd network the loss is increasing significantly and and the fourth and fifth layer the loss cannot be displayed. This evidence suggests an exploding/vanishing gradient.\n",
    "- None of the models are able to reach higher performance for our imbalanced dataset and account for the cancer positive cells\n",
    "With the different model sizes, learning rates, normalization and dropout layers most issues should have be tackled, so lets run tha above models again with balanced weights, that account for the relative number of positive/negative patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight for class 0: 1.40\n",
      "Weight for class 1: 3.52\n"
     ]
    }
   ],
   "source": [
    "# lower the number of epochs\n",
    "epochs = 150\n",
    "\n",
    "total = np.asarray(y_data).shape[0]\n",
    "pos = sum(np.asarray(y_data))\n",
    "neg = total - pos\n",
    "\n",
    "# Scaling by total/2 helps keep the loss to a similar magnitude.\n",
    "# The sum of the weights of all examples stays the same.\n",
    "# weight_for_0 = (1 / neg) * (total / 2.0)\n",
    "# weight_for_1 = (1 / pos) * (total / 2.0)\n",
    "\n",
    "weight_for_0 = (1 / neg) * total\n",
    "weight_for_1 = (1 / pos) * total\n",
    "\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
    "print('Weight for class 1: {:.2f}'.format(weight_for_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-layer-128-norm-dropout\n",
      "Epoch 1/500\n",
      "152/152 - 1s - loss: 6.7010 - accuracy: 0.7492 - val_loss: 1.0601 - val_accuracy: 0.7758\n",
      "Epoch 2/500\n",
      "152/152 - 1s - loss: 0.9146 - accuracy: 0.7881 - val_loss: 0.4027 - val_accuracy: 0.8296\n",
      "Epoch 3/500\n",
      "152/152 - 1s - loss: 0.8769 - accuracy: 0.7972 - val_loss: 0.3958 - val_accuracy: 0.8178\n",
      "Epoch 4/500\n",
      "152/152 - 1s - loss: 0.8570 - accuracy: 0.8004 - val_loss: 0.4225 - val_accuracy: 0.8021\n",
      "Epoch 5/500\n",
      "152/152 - 1s - loss: 0.8366 - accuracy: 0.8051 - val_loss: 0.4024 - val_accuracy: 0.8197\n",
      "Epoch 6/500\n",
      "152/152 - 1s - loss: 0.8255 - accuracy: 0.8081 - val_loss: 0.3779 - val_accuracy: 0.8279\n",
      "Epoch 7/500\n",
      "152/152 - 1s - loss: 0.8151 - accuracy: 0.8106 - val_loss: 0.4314 - val_accuracy: 0.7927\n",
      "Epoch 8/500\n",
      "152/152 - 1s - loss: 0.8030 - accuracy: 0.8135 - val_loss: 0.4041 - val_accuracy: 0.8168\n",
      "Epoch 9/500\n",
      "152/152 - 1s - loss: 0.8063 - accuracy: 0.8114 - val_loss: 0.4144 - val_accuracy: 0.8134\n",
      "Epoch 10/500\n",
      "152/152 - 1s - loss: 0.7931 - accuracy: 0.8146 - val_loss: 0.4051 - val_accuracy: 0.8191\n",
      "Epoch 11/500\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "152/152 - 1s - loss: 0.7836 - accuracy: 0.8185 - val_loss: 0.4352 - val_accuracy: 0.7933\n",
      "Epoch 12/500\n",
      "152/152 - 1s - loss: 0.7327 - accuracy: 0.8322 - val_loss: 0.3858 - val_accuracy: 0.8274\n",
      "Epoch 13/500\n",
      "152/152 - 1s - loss: 0.7135 - accuracy: 0.8377 - val_loss: 0.3862 - val_accuracy: 0.8256\n",
      "Epoch 14/500\n",
      "152/152 - 1s - loss: 0.7062 - accuracy: 0.8395 - val_loss: 0.3736 - val_accuracy: 0.8357\n",
      "Epoch 15/500\n",
      "152/152 - 1s - loss: 0.6998 - accuracy: 0.8406 - val_loss: 0.3882 - val_accuracy: 0.8257\n",
      "Epoch 16/500\n",
      "152/152 - 1s - loss: 0.6899 - accuracy: 0.8432 - val_loss: 0.3837 - val_accuracy: 0.8283\n",
      "Epoch 17/500\n",
      "152/152 - 1s - loss: 0.6856 - accuracy: 0.8444 - val_loss: 0.3893 - val_accuracy: 0.8239\n",
      "Epoch 18/500\n",
      "152/152 - 1s - loss: 0.6772 - accuracy: 0.8464 - val_loss: 0.3904 - val_accuracy: 0.8235\n",
      "Epoch 19/500\n",
      "152/152 - 1s - loss: 0.6679 - accuracy: 0.8477 - val_loss: 0.3881 - val_accuracy: 0.8285\n",
      "Epoch 20/500\n",
      "152/152 - 1s - loss: 0.6587 - accuracy: 0.8507 - val_loss: 0.3913 - val_accuracy: 0.8274\n",
      "Epoch 21/500\n",
      "152/152 - 1s - loss: 0.6531 - accuracy: 0.8526 - val_loss: 0.3941 - val_accuracy: 0.8240\n",
      "Epoch 22/500\n",
      "152/152 - 1s - loss: 0.6434 - accuracy: 0.8548 - val_loss: 0.4002 - val_accuracy: 0.8204\n",
      "Epoch 23/500\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "152/152 - 1s - loss: 0.6373 - accuracy: 0.8560 - val_loss: 0.3971 - val_accuracy: 0.8213\n",
      "Epoch 24/500\n",
      "152/152 - 1s - loss: 0.6085 - accuracy: 0.8629 - val_loss: 0.3953 - val_accuracy: 0.8266\n",
      "Epoch 25/500\n",
      "152/152 - 1s - loss: 0.6041 - accuracy: 0.8645 - val_loss: 0.3950 - val_accuracy: 0.8270\n",
      "Epoch 26/500\n",
      "152/152 - 1s - loss: 0.5986 - accuracy: 0.8653 - val_loss: 0.3919 - val_accuracy: 0.8290\n",
      "Epoch 27/500\n",
      "152/152 - 1s - loss: 0.5966 - accuracy: 0.8659 - val_loss: 0.3921 - val_accuracy: 0.8292\n",
      "Epoch 28/500\n",
      "152/152 - 1s - loss: 0.5925 - accuracy: 0.8675 - val_loss: 0.3949 - val_accuracy: 0.8280\n",
      "Epoch 29/500\n",
      "152/152 - 1s - loss: 0.5915 - accuracy: 0.8676 - val_loss: 0.3992 - val_accuracy: 0.8258\n",
      "Epoch 30/500\n",
      "152/152 - 1s - loss: 0.5891 - accuracy: 0.8681 - val_loss: 0.3979 - val_accuracy: 0.8266\n",
      "Epoch 31/500\n",
      "152/152 - 1s - loss: 0.5845 - accuracy: 0.8703 - val_loss: 0.3980 - val_accuracy: 0.8273\n",
      "Epoch 32/500\n",
      "152/152 - 1s - loss: 0.5872 - accuracy: 0.8690 - val_loss: 0.3999 - val_accuracy: 0.8269\n",
      "Epoch 33/500\n",
      "152/152 - 1s - loss: 0.5807 - accuracy: 0.8706 - val_loss: 0.3996 - val_accuracy: 0.8274\n",
      "Epoch 34/500\n",
      "152/152 - 1s - loss: 0.5815 - accuracy: 0.8700 - val_loss: 0.4027 - val_accuracy: 0.8261\n",
      "Epoch 35/500\n",
      "152/152 - 1s - loss: 0.5810 - accuracy: 0.8697 - val_loss: 0.4006 - val_accuracy: 0.8273\n",
      "Epoch 36/500\n",
      "152/152 - 1s - loss: 0.5746 - accuracy: 0.8715 - val_loss: 0.4019 - val_accuracy: 0.8287\n",
      "Epoch 37/500\n",
      "152/152 - 1s - loss: 0.5708 - accuracy: 0.8725 - val_loss: 0.3983 - val_accuracy: 0.8317\n",
      "Epoch 38/500\n",
      "152/152 - 1s - loss: 0.5762 - accuracy: 0.8717 - val_loss: 0.3969 - val_accuracy: 0.8312\n",
      "Epoch 39/500\n",
      "Restoring model weights from the end of the best epoch.\n",
      "152/152 - 1s - loss: 0.5712 - accuracy: 0.8732 - val_loss: 0.4021 - val_accuracy: 0.8297\n",
      "Epoch 00039: early stopping\n",
      "2-layer-128-256-norm-dropout\n",
      "Epoch 1/500\n",
      "152/152 - 1s - loss: 1.0279 - accuracy: 0.7732 - val_loss: 1.2139 - val_accuracy: 0.7630\n",
      "Epoch 2/500\n",
      "152/152 - 1s - loss: 0.8947 - accuracy: 0.8024 - val_loss: 0.3844 - val_accuracy: 0.8344\n",
      "Epoch 3/500\n",
      "152/152 - 1s - loss: 0.8604 - accuracy: 0.8123 - val_loss: 0.4031 - val_accuracy: 0.8264\n",
      "Epoch 4/500\n",
      "152/152 - 1s - loss: 0.8291 - accuracy: 0.8198 - val_loss: 0.4072 - val_accuracy: 0.8134\n",
      "Epoch 5/500\n",
      "152/152 - 1s - loss: 0.8150 - accuracy: 0.8222 - val_loss: 0.3996 - val_accuracy: 0.8246\n",
      "Epoch 6/500\n",
      "152/152 - 1s - loss: 0.7987 - accuracy: 0.8280 - val_loss: 0.4622 - val_accuracy: 0.7900\n",
      "Epoch 7/500\n",
      "152/152 - 1s - loss: 0.7913 - accuracy: 0.8279 - val_loss: 0.4104 - val_accuracy: 0.8250\n",
      "Epoch 8/500\n",
      "152/152 - 1s - loss: 0.7803 - accuracy: 0.8305 - val_loss: 0.4584 - val_accuracy: 0.8124\n",
      "Epoch 9/500\n",
      "152/152 - 1s - loss: 0.7707 - accuracy: 0.8325 - val_loss: 0.4256 - val_accuracy: 0.8062\n",
      "Epoch 10/500\n",
      "152/152 - 1s - loss: 0.7610 - accuracy: 0.8347 - val_loss: 0.4525 - val_accuracy: 0.8057\n",
      "Epoch 11/500\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "152/152 - 1s - loss: 0.7484 - accuracy: 0.8358 - val_loss: 0.3973 - val_accuracy: 0.8251\n",
      "Epoch 12/500\n",
      "152/152 - 1s - loss: 0.7094 - accuracy: 0.8461 - val_loss: 0.4241 - val_accuracy: 0.8154\n",
      "Epoch 13/500\n",
      "152/152 - 1s - loss: 0.6875 - accuracy: 0.8493 - val_loss: 0.4167 - val_accuracy: 0.8200\n",
      "Epoch 14/500\n",
      "152/152 - 1s - loss: 0.6816 - accuracy: 0.8515 - val_loss: 0.4007 - val_accuracy: 0.8251\n",
      "Epoch 15/500\n",
      "152/152 - 1s - loss: 0.6775 - accuracy: 0.8499 - val_loss: 0.4057 - val_accuracy: 0.8230\n",
      "Epoch 16/500\n",
      "152/152 - 1s - loss: 0.6684 - accuracy: 0.8517 - val_loss: 0.3882 - val_accuracy: 0.8305\n",
      "Epoch 17/500\n",
      "152/152 - 1s - loss: 0.6656 - accuracy: 0.8525 - val_loss: 0.4034 - val_accuracy: 0.8254\n",
      "Epoch 18/500\n",
      "152/152 - 1s - loss: 0.6596 - accuracy: 0.8536 - val_loss: 0.4065 - val_accuracy: 0.8194\n",
      "Epoch 19/500\n",
      "152/152 - 1s - loss: 0.6536 - accuracy: 0.8545 - val_loss: 0.4081 - val_accuracy: 0.8224\n",
      "Epoch 20/500\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "152/152 - 1s - loss: 0.6479 - accuracy: 0.8571 - val_loss: 0.3934 - val_accuracy: 0.8267\n",
      "Epoch 21/500\n",
      "152/152 - 1s - loss: 0.6392 - accuracy: 0.8582 - val_loss: 0.4030 - val_accuracy: 0.8239\n",
      "Epoch 22/500\n",
      "152/152 - 1s - loss: 0.6360 - accuracy: 0.8589 - val_loss: 0.4072 - val_accuracy: 0.8209\n",
      "Epoch 23/500\n",
      "152/152 - 1s - loss: 0.6351 - accuracy: 0.8585 - val_loss: 0.4023 - val_accuracy: 0.8240\n",
      "Epoch 24/500\n",
      "152/152 - 1s - loss: 0.6344 - accuracy: 0.8586 - val_loss: 0.4024 - val_accuracy: 0.8235\n",
      "Epoch 25/500\n",
      "152/152 - 1s - loss: 0.6327 - accuracy: 0.8600 - val_loss: 0.4033 - val_accuracy: 0.8228\n",
      "Epoch 26/500\n",
      "152/152 - 1s - loss: 0.6336 - accuracy: 0.8593 - val_loss: 0.4032 - val_accuracy: 0.8224\n",
      "Epoch 27/500\n",
      "Restoring model weights from the end of the best epoch.\n",
      "152/152 - 1s - loss: 0.6303 - accuracy: 0.8598 - val_loss: 0.4051 - val_accuracy: 0.8223\n",
      "Epoch 00027: early stopping\n",
      "3-layer-512-256-128-norm-dropout\n",
      "Epoch 1/500\n",
      "152/152 - 1s - loss: 1.0050 - accuracy: 0.7774 - val_loss: 1.6796 - val_accuracy: 0.7186\n",
      "Epoch 2/500\n",
      "152/152 - 1s - loss: 0.8786 - accuracy: 0.8074 - val_loss: 0.7048 - val_accuracy: 0.4918\n",
      "Epoch 3/500\n",
      "152/152 - 1s - loss: 0.8580 - accuracy: 0.8120 - val_loss: 0.6494 - val_accuracy: 0.6209\n",
      "Epoch 4/500\n",
      "152/152 - 1s - loss: 0.8431 - accuracy: 0.8170 - val_loss: 0.4503 - val_accuracy: 0.8142\n",
      "Epoch 5/500\n",
      "152/152 - 1s - loss: 0.8366 - accuracy: 0.8182 - val_loss: 0.6019 - val_accuracy: 0.7707\n",
      "Epoch 6/500\n",
      "152/152 - 1s - loss: 0.8264 - accuracy: 0.8202 - val_loss: 0.4153 - val_accuracy: 0.8167\n",
      "Epoch 7/500\n",
      "152/152 - 1s - loss: 0.8197 - accuracy: 0.8229 - val_loss: 0.4001 - val_accuracy: 0.8287\n",
      "Epoch 8/500\n",
      "152/152 - 1s - loss: 0.8105 - accuracy: 0.8254 - val_loss: 0.4983 - val_accuracy: 0.7827\n",
      "Epoch 9/500\n",
      "152/152 - 1s - loss: 0.8075 - accuracy: 0.8256 - val_loss: 0.7577 - val_accuracy: 0.7664\n",
      "Epoch 10/500\n",
      "152/152 - 1s - loss: 0.7994 - accuracy: 0.8290 - val_loss: 0.4922 - val_accuracy: 0.7979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/500\n",
      "152/152 - 1s - loss: 0.7906 - accuracy: 0.8309 - val_loss: 0.3981 - val_accuracy: 0.8324\n",
      "Epoch 12/500\n",
      "152/152 - 1s - loss: 0.7898 - accuracy: 0.8314 - val_loss: 0.4758 - val_accuracy: 0.7973\n",
      "Epoch 13/500\n",
      "152/152 - 1s - loss: 0.7799 - accuracy: 0.8331 - val_loss: 0.4245 - val_accuracy: 0.8082\n",
      "Epoch 14/500\n",
      "152/152 - 1s - loss: 0.7771 - accuracy: 0.8340 - val_loss: 0.4526 - val_accuracy: 0.8003\n",
      "Epoch 15/500\n",
      "152/152 - 1s - loss: 0.7693 - accuracy: 0.8378 - val_loss: 0.4183 - val_accuracy: 0.8282\n",
      "Epoch 16/500\n",
      "152/152 - 1s - loss: 0.7634 - accuracy: 0.8385 - val_loss: 0.4215 - val_accuracy: 0.8250\n",
      "Epoch 17/500\n",
      "152/152 - 1s - loss: 0.7602 - accuracy: 0.8393 - val_loss: 0.7969 - val_accuracy: 0.7738\n",
      "Epoch 18/500\n",
      "152/152 - 1s - loss: 0.7553 - accuracy: 0.8389 - val_loss: 0.4742 - val_accuracy: 0.7936\n",
      "Epoch 19/500\n",
      "152/152 - 1s - loss: 0.7513 - accuracy: 0.8404 - val_loss: 0.4221 - val_accuracy: 0.8014\n",
      "Epoch 20/500\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "152/152 - 1s - loss: 0.7456 - accuracy: 0.8398 - val_loss: 2.1687 - val_accuracy: 0.7277\n",
      "Epoch 21/500\n",
      "152/152 - 1s - loss: 0.7172 - accuracy: 0.8472 - val_loss: 0.5033 - val_accuracy: 0.7796\n",
      "Epoch 22/500\n",
      "152/152 - 1s - loss: 0.6995 - accuracy: 0.8491 - val_loss: 0.5304 - val_accuracy: 0.7702\n",
      "Epoch 23/500\n",
      "152/152 - 1s - loss: 0.6952 - accuracy: 0.8506 - val_loss: 0.5020 - val_accuracy: 0.7840\n",
      "Epoch 24/500\n",
      "152/152 - 1s - loss: 0.6919 - accuracy: 0.8512 - val_loss: 0.5152 - val_accuracy: 0.7725\n",
      "Epoch 25/500\n",
      "152/152 - 1s - loss: 0.6841 - accuracy: 0.8535 - val_loss: 0.5096 - val_accuracy: 0.7768\n",
      "Epoch 26/500\n",
      "152/152 - 1s - loss: 0.6875 - accuracy: 0.8512 - val_loss: 0.4749 - val_accuracy: 0.8006\n",
      "Epoch 27/500\n",
      "152/152 - 1s - loss: 0.6831 - accuracy: 0.8523 - val_loss: 0.5842 - val_accuracy: 0.7469\n",
      "Epoch 28/500\n",
      "152/152 - 1s - loss: 0.6840 - accuracy: 0.8529 - val_loss: 0.5118 - val_accuracy: 0.7776\n",
      "Epoch 29/500\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "152/152 - 1s - loss: 0.6763 - accuracy: 0.8539 - val_loss: 0.4851 - val_accuracy: 0.7864\n",
      "Epoch 30/500\n",
      "152/152 - 1s - loss: 0.6751 - accuracy: 0.8538 - val_loss: 0.5119 - val_accuracy: 0.7760\n",
      "Epoch 31/500\n",
      "152/152 - 1s - loss: 0.6718 - accuracy: 0.8548 - val_loss: 0.4987 - val_accuracy: 0.7815\n",
      "Epoch 32/500\n",
      "152/152 - 1s - loss: 0.6692 - accuracy: 0.8552 - val_loss: 0.5046 - val_accuracy: 0.7801\n",
      "Epoch 33/500\n",
      "152/152 - 1s - loss: 0.6714 - accuracy: 0.8547 - val_loss: 0.5322 - val_accuracy: 0.7621\n",
      "Epoch 34/500\n",
      "152/152 - 1s - loss: 0.6679 - accuracy: 0.8562 - val_loss: 0.5254 - val_accuracy: 0.7706\n",
      "Epoch 35/500\n",
      "152/152 - 1s - loss: 0.6714 - accuracy: 0.8551 - val_loss: 0.5018 - val_accuracy: 0.7816\n",
      "Epoch 36/500\n",
      "Restoring model weights from the end of the best epoch.\n",
      "152/152 - 1s - loss: 0.6700 - accuracy: 0.8556 - val_loss: 0.5189 - val_accuracy: 0.7718\n",
      "Epoch 00036: early stopping\n"
     ]
    }
   ],
   "source": [
    "# lower the number of epochs\n",
    "epochs = 500\n",
    "\n",
    "batch_size = 1024\n",
    "histories = []\n",
    "\n",
    "name=\"1-layer-128-norm-dropout\"\n",
    "print(name)\n",
    "model14 = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dense(128, activation='relu'),\n",
    "        keras.layers.Dropout(0.4),\n",
    "        keras.layers.Dense(1, activation='sigmoid')\n",
    "    ],name=name\n",
    ")\n",
    "\n",
    "model14.compile(loss=\"binary_crossentropy\", optimizer=Adam(learning_rate=0.01), metrics=[\"accuracy\"])\n",
    "\n",
    "histories.append(model14.fit(x_train, y_train, batch_size=batch_size, epochs=epochs,\n",
    "                            validation_data=(x_val,y_val), verbose=2, callbacks=[lrr, es],\n",
    "                            class_weight=class_weight))\n",
    "\n",
    "\n",
    "name=\"2-layer-128-256-norm-dropout\"\n",
    "print(name)\n",
    "model15 = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dense(128, activation='relu'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dropout(0.4),\n",
    "        keras.layers.Dense(256, activation='relu'),\n",
    "        keras.layers.Dropout(0.4),\n",
    "        keras.layers.Dense(1, activation='sigmoid')\n",
    "    ],name=name\n",
    ")\n",
    "\n",
    "model15.compile(loss=\"binary_crossentropy\", optimizer=Adam(learning_rate=0.01), metrics=[\"accuracy\"])\n",
    "\n",
    "histories.append(model15.fit(x_train, y_train, batch_size=batch_size, epochs=epochs,\n",
    "                            validation_data=(x_val,y_val), verbose=2, callbacks=[lrr, es],\n",
    "                            class_weight=class_weight))\n",
    "\n",
    "name=\"3-layer-512-256-128-norm-dropout\"\n",
    "print(name)\n",
    "model16 = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        keras.layers.Flatten(),        \n",
    "        keras.layers.Dense(512, activation='relu'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dropout(0.4),\n",
    "        keras.layers.Dense(256, activation='relu'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dropout(0.4),\n",
    "        keras.layers.Dense(128, activation='relu'),\n",
    "        keras.layers.Dropout(0.4),\n",
    "        keras.layers.Dense(1, activation='sigmoid')\n",
    "    ],name=name\n",
    ")\n",
    "\n",
    "model16.compile(loss=\"binary_crossentropy\", optimizer=Adam(learning_rate=0.01), metrics=[\"accuracy\"])\n",
    "\n",
    "histories.append(model16.fit(x_train, y_train, batch_size=batch_size, epochs=epochs,\n",
    "                            validation_data=(x_val,y_val), verbose=2, callbacks=[lrr, es],\n",
    "                            class_weight=class_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_b93ece76_ceee_11eb_8648_40e230e37f37\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >loss</th>        <th class=\"col_heading level0 col1\" >accuracy</th>        <th class=\"col_heading level0 col2\" >val_loss</th>        <th class=\"col_heading level0 col3\" >val_accuracy</th>    </tr>    <tr>        <th class=\"index_name level0\" >model size</th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_b93ece76_ceee_11eb_8648_40e230e37f37level0_row0\" class=\"row_heading level0 row0\" >1-layer-128-norm-dropout</th>\n",
       "                        <td id=\"T_b93ece76_ceee_11eb_8648_40e230e37f37row0_col0\" class=\"data row0 col0\" >0.71</td>\n",
       "                        <td id=\"T_b93ece76_ceee_11eb_8648_40e230e37f37row0_col1\" class=\"data row0 col1\" >83.95%</td>\n",
       "                        <td id=\"T_b93ece76_ceee_11eb_8648_40e230e37f37row0_col2\" class=\"data row0 col2\" >0.37</td>\n",
       "                        <td id=\"T_b93ece76_ceee_11eb_8648_40e230e37f37row0_col3\" class=\"data row0 col3\" >83.57%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b93ece76_ceee_11eb_8648_40e230e37f37level0_row1\" class=\"row_heading level0 row1\" >2-layer-128-256-norm-dropout</th>\n",
       "                        <td id=\"T_b93ece76_ceee_11eb_8648_40e230e37f37row1_col0\" class=\"data row1 col0\" >0.89</td>\n",
       "                        <td id=\"T_b93ece76_ceee_11eb_8648_40e230e37f37row1_col1\" class=\"data row1 col1\" >80.24%</td>\n",
       "                        <td id=\"T_b93ece76_ceee_11eb_8648_40e230e37f37row1_col2\" class=\"data row1 col2\" >0.38</td>\n",
       "                        <td id=\"T_b93ece76_ceee_11eb_8648_40e230e37f37row1_col3\" class=\"data row1 col3\" >83.44%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b93ece76_ceee_11eb_8648_40e230e37f37level0_row2\" class=\"row_heading level0 row2\" >3-layer-512-256-128-norm-dropout</th>\n",
       "                        <td id=\"T_b93ece76_ceee_11eb_8648_40e230e37f37row2_col0\" class=\"data row2 col0\" >0.79</td>\n",
       "                        <td id=\"T_b93ece76_ceee_11eb_8648_40e230e37f37row2_col1\" class=\"data row2 col1\" >83.09%</td>\n",
       "                        <td id=\"T_b93ece76_ceee_11eb_8648_40e230e37f37row2_col2\" class=\"data row2 col2\" >0.40</td>\n",
       "                        <td id=\"T_b93ece76_ceee_11eb_8648_40e230e37f37row2_col3\" class=\"data row2 col3\" >83.24%</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1dfc8884688>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist2 = acc_df(histories)\n",
    "hist2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for history in histories[:]:\n",
    "    plt.plot(history.history['accuracy'], alpha=.6)\n",
    "    \n",
    "plt.xlabel('epoch')\n",
    "plt.legend([model14.name, model15.name, model16.name], loc='lower right')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "for history in histories[:]:\n",
    "    plt.plot(history.history['val_accuracy'], alpha=.6)\n",
    "    \n",
    "plt.xlabel('epoch')\n",
    "plt.ylim([0.6,0.9])\n",
    "plt.legend([model14.name, model15.name, model16.name], loc='lower right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learnings\n",
    "- The confusion matrix starts to look better, malicious cells are now classified much less as non-malicious than before\n",
    "- In the graph above we see that the validation accuracy and loss is decreasing/increasing towards the end\n",
    "- Train accuracy is now much closer to the validation accuracy (at least for the best epoch) over time they still diverge\n",
    "\n",
    "Since the training and validatio accuracy are close we can reduce the dropout rate, but at the same time we will add an imageDataGenerator to hopefully increase generalizability of our model.On top we define a learning rate schedule that reduces when a plateau is reached and change all optimizations to from stochastig gradient descent to the adam optimizer.\n",
    "\n",
    "Since the smaller networks needed more epochs to show improvements we remove the early stopping criterion for those and increase the patience for the rest, to make sure not to stop too early"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image Data Augmentation\n",
    "\n",
    "train_generator = ImageDataGenerator(rotation_range=90, horizontal_flip=True, vertical_flip=True)\n",
    "\n",
    "test_generator = ImageDataGenerator(rotation_range=90, horizontal_flip=True, vertical_flip=True)\n",
    "\n",
    "val_generator = ImageDataGenerator(rotation_range=90, horizontal_flip=True, vertical_flip=True)\n",
    "\n",
    "train_generator.fit(x_train)\n",
    "test_generator.fit(x_test)\n",
    "val_generator.fit(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-layer-128-norm-dropout\n",
      "Epoch 1/500\n",
      "4857/4857 [==============================] - 95s 19ms/step - loss: 1.6144 - accuracy: 0.6678 - val_loss: 0.4506 - val_accuracy: 0.7793\n",
      "Epoch 2/500\n",
      "4857/4857 [==============================] - 95s 19ms/step - loss: 1.2168 - accuracy: 0.5925 - val_loss: 0.5447 - val_accuracy: 0.7210\n",
      "Epoch 3/500\n",
      "4857/4857 [==============================] - 96s 20ms/step - loss: 1.3798 - accuracy: 0.4868 - val_loss: 0.7305 - val_accuracy: 0.2835\n",
      "Epoch 4/500\n",
      "4857/4857 [==============================] - 96s 20ms/step - loss: 1.3876 - accuracy: 0.4769 - val_loss: 0.6901 - val_accuracy: 0.7165\n",
      "Epoch 5/500\n",
      "4857/4857 [==============================] - 96s 20ms/step - loss: 1.3876 - accuracy: 0.4894 - val_loss: 0.6946 - val_accuracy: 0.2835\n",
      "Epoch 6/500\n",
      "4857/4857 [==============================] - 96s 20ms/step - loss: 1.3875 - accuracy: 0.5027 - val_loss: 0.7012 - val_accuracy: 0.2835\n",
      "Epoch 7/500\n",
      "4857/4857 [==============================] - ETA: 0s - loss: 1.3875 - accuracy: 0.4735"
     ]
    }
   ],
   "source": [
    "# lower the number of epochs\n",
    "epochs = 500\n",
    "\n",
    "batch_size = 512\n",
    "histories = []\n",
    "\n",
    "name=\"1-layer-128-norm-dropout\"\n",
    "print(name)\n",
    "model14 = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dense(128, activation='relu'),\n",
    "        keras.layers.Dropout(0.4),\n",
    "        keras.layers.Dense(1, activation='sigmoid')\n",
    "    ],name=name\n",
    ")\n",
    "\n",
    "model14.compile(loss=\"binary_crossentropy\", optimizer=Adam(learning_rate=0.01), metrics=[\"accuracy\"])\n",
    "\n",
    "histories.append(model14.fit(train_generator.flow(x_train, y_train, batch_size=32),\n",
    "                             batch_size=batch_size, epochs=epochs,\n",
    "                             validation_data=val_generator.flow(x_val,y_val, batch_size=32),\n",
    "                             verbose=1, callbacks=[lrr, es],\n",
    "                             class_weight=class_weight))\n",
    "\n",
    "\n",
    "name=\"2-layer-128-256-norm-dropout\"\n",
    "print(name)\n",
    "model15 = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dense(128, activation='relu'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dropout(0.4),\n",
    "        keras.layers.Dense(256, activation='relu'),\n",
    "        keras.layers.Dropout(0.4),\n",
    "        keras.layers.Dense(1, activation='sigmoid')\n",
    "    ],name=name\n",
    ")\n",
    "\n",
    "model15.compile(loss=\"binary_crossentropy\", optimizer=Adam(learning_rate=0.01), metrics=[\"accuracy\"])\n",
    "\n",
    "histories.append(model15.fit(train_generator.flow(x_train, y_train, batch_size=32),\n",
    "                             batch_size=batch_size, epochs=epochs,\n",
    "                             validation_data=val_generator.flow(x_val,y_val, batch_size=32),\n",
    "                             verbose=1, callbacks=[lrr, es],\n",
    "                             class_weight=class_weight))\n",
    "\n",
    "name=\"3-layer-512-256-128-norm-dropout\"\n",
    "print(name)\n",
    "model16 = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        keras.layers.Flatten(),        \n",
    "        keras.layers.Dense(512, activation='relu'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dropout(0.4),\n",
    "        keras.layers.Dense(256, activation='relu'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dropout(0.4),\n",
    "        keras.layers.Dense(128, activation='relu'),\n",
    "        keras.layers.Dropout(0.4),\n",
    "        keras.layers.Dense(1, activation='sigmoid')\n",
    "    ],name=name\n",
    ")\n",
    "\n",
    "model16.compile(loss=\"binary_crossentropy\", optimizer=Adam(learning_rate=0.01), metrics=[\"accuracy\"])\n",
    "\n",
    "histories.append(model16.fit(train_generator.flow(x_train, y_train, batch_size=32),\n",
    "                             batch_size=batch_size, epochs=epochs,\n",
    "                             validation_data=val_generator.flow(x_val,y_val, batch_size=32),\n",
    "                             verbose=1, callbacks=[lrr, es],\n",
    "                             class_weight=class_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist3 = acc_df(histories)\n",
    "hist3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot accuracy\n",
    "plt1 = acc_plot(callback_balanced_histories[-1])\n",
    "plt.show()\n",
    "\n",
    "# plot loss\n",
    "plt2 = loss_plot(callback_balanced_histories[-1])\n",
    "plt.show()\n",
    "\n",
    "loaded_model = keras.models.load_model('callback-balanced-3-layer-4096-2048-1024-norm-dropout.hdf5')\n",
    "\n",
    "# plot confuction matrix\n",
    "plt=conf_matrix(loaded_model, x_test, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "The final model does not seem to be far superior to previous ones if we observe the accuracy and the loss. It has one of the best performances if we measure validation loss and accuracy, but the first model with the learning rate 0.01 reached a similar performance according to those measures.\n",
    "Since we are building a model for medical diagnosis, accuracy and loss are not neccessarily the most important measures (even though it makes sense to optimize them). including the confusion matrix in our model evaluation shows that we are constantly improving on predicting malicious cells and also minimize the classification of malicious cells as harmless, a missclassification, which could have severe implications for the patient.\n",
    "\n",
    "Increasing the size of the model to a certain size, adding dropout and normalization layers, countering the imbalance of the data with balanced weights as well as applying a learning rate schedule improved the result significantly.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
