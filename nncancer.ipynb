{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation\n",
    "Currently AI is advancing in the field of healthcare to improve detection of malignant tumors, give treatment recommendations, engage patients and support in administrative activities (Davenport and Kalakota 2019). Our goal is to contribute to this field by applying a neural network with transfer learning on a dataset with the aim to detect malignant cells of breast cancer. \n",
    "\n",
    "According to Krebsliga Schweiz (2021), there are 6’250 new cases and 1’410 deaths associated with breast cancer in Switzerland every year. Early diagnosis and treatment are a key to increasing the 5-year survival rate of patients.  \n",
    "\n",
    "From a technical standpoint we want to investigate the performance differences between neural networks with and without transfer learning in the field of tumor detection.\n",
    "\n",
    "## Data\n",
    "\n",
    "We use the Kaggle dataset: Breast Histopathology Images, which contains 277’524 images that are classified whether the sample is positive or negative for Invasive Ductal Carcinoma (IDC). Therefore, we face a binary classification problem with this dataset. The sample dataset contains images scanned at 40x zoom that are prepared in 50 x 50-pixel patches.\n",
    "\n",
    "[Kaggle Dataset](https://www.kaggle.com/paultimothymooney/breast-histopathology-images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "# used to access folder structures\n",
    "import os\n",
    "\n",
    "# used to open images\n",
    "import PIL\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# For Image Data Augmentation\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "from tensorflow.keras.layers import Flatten, Dense, BatchNormalization, Activation, Dropout\n",
    "\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Check for gpu support\n",
    "# Troubleshooting: \n",
    "# Python Version = 3.7.9\n",
    "# tensorflow Version = 2.3.0\n",
    "# tf.keras Version = 2.4.0\n",
    "'''\n",
    "from platform import python_version\n",
    "print(python_version())\n",
    "print(tf.__version__)\n",
    "print(tf.keras.__version__)\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "* Initialize the path to all the images\n",
    "* Create a dataframe with 3 collumns, which store the patient Id, the path to the picture and the picture itself\n",
    "* Crete the new file strucure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Patients total: 279\n",
      "Total Images in dataset:  277524\n"
     ]
    }
   ],
   "source": [
    "base_path = \"images/IDC_regular_ps50_idx5/\"\n",
    "folder = os.listdir(base_path)\n",
    "print(\"No. of Patients total:\",len(folder))\n",
    "\n",
    "total_images = 0\n",
    "for n in range(len(folder)):\n",
    "    patient_id = folder[n]\n",
    "    for c in [0, 1]:\n",
    "        patient_path = base_path + patient_id\n",
    "        class_path = patient_path + '/' + str(c) + '/'\n",
    "        subfiles = os.listdir(class_path)\n",
    "        total_images += len(subfiles)\n",
    "        \n",
    "print(\"Total Images in dataset: \", total_images )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In total there are 279 patients in our dataset, from images of those patients in total 277'524 patches were created which each consist of a 50x50 pixel patch. While the number of patches to be analysed consists of a good number of samples to train a neural network, the relatively low number of patients indicates that further verification of our results would be needed to confirm generalizablility.  \n",
    "\n",
    "Next we iterate over the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-be1e54117069>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m# Fill the patient Data dataframe with the patient and the number of pos and neg patches\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mpatientData\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"patient_id\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpatient_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mpatientData\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"nrPos\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnrPos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mpatientData\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"nrNeg\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnrNeg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    877\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 879\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    880\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    881\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1494\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1495\u001b[0m             \u001b[1;31m# validate the location\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1496\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1497\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1498\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_integer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1435\u001b[0m         \u001b[0mlen_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1436\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mlen_axis\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mlen_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1437\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"single positional indexer is out-of-bounds\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[1;31m# -------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "# create an empty dataframe with a column for each the patient id,\n",
    "# the path to the image and the target label for each patch\n",
    "data = pd.DataFrame(index=np.arange(0, total_images), columns=[\"patient_id\", \"path\", \"target\"])\n",
    "\n",
    "patientData = pd.DataFrame(index=np.arange(0, len(folder)), columns=[\"patient_id\", \"nrPos\", \"nrNeg\"])\n",
    "\n",
    "k = 0\n",
    "n = 0\n",
    "# Iterate over all patients (1 folder = 1 patient)\n",
    "for n in range(len(folder)):\n",
    "    \n",
    "    # Fill the patient Data dataframe with the patient and the number of pos and neg patches\n",
    "    if n > 0:\n",
    "        patientData.iloc[n-1][\"patient_id\"] = patient_id\n",
    "        patientData.iloc[n-1][\"nrPos\"] = nrPos\n",
    "        patientData.iloc[n-1][\"nrNeg\"] = nrNeg\n",
    "    \n",
    "    nrPos = 0\n",
    "    nrNeg = 0\n",
    "    \n",
    "    patient_id = folder[n]\n",
    "    patient_path = base_path + patient_id \n",
    "    \n",
    "    # Iterate over the two subfolders with the negative and positive patches \n",
    "    for c in [0,1]:\n",
    "        \n",
    "        # Count the number of positive and negative patches per patient\n",
    "        if c == 0: nrNeg += 1\n",
    "        else: nrPos += 1\n",
    "        \n",
    "        class_path = patient_path + \"/\" + str(c) + \"/\"\n",
    "        subfiles = os.listdir(class_path)\n",
    "        \n",
    "        # Iterate over the images in the subfolder and fill the dataframe\n",
    "        for m in range(len(subfiles)):\n",
    "            image_path = subfiles[m]\n",
    "            data.iloc[k][\"path\"] = class_path + image_path\n",
    "            data.iloc[k][\"target\"] = c\n",
    "            data.iloc[k][\"patient_id\"] = patient_id\n",
    "            k += 1  \n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data=[]\n",
    "y_data=[]\n",
    "resized = 0\n",
    "\n",
    "for index, row in data[:].iterrows():\n",
    "    image = PIL.Image.open(row['path'])\n",
    "    npImage = np.asarray(image)\n",
    "    \n",
    "    # Resize images with format different than our 50x50 patches\n",
    "    if npImage.shape != (50, 50, 3):\n",
    "        resized += 1\n",
    "        image = image.resize((50, 50))\n",
    "        npImage = np.asarray(image)\n",
    "    X_data.append(npImage)\n",
    "    y_data.append(row['target'])\n",
    "    \n",
    "    \n",
    "print('X_data shape: ', np.array(X_data).shape)\n",
    "print('y_data shape: ', np.array(y_data).shape)\n",
    "\n",
    "print('In total %d patches had to be resized, since the format differed from 50x50'%resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train-validation-test split\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(np.asarray(X_data),np.asarray(y_data),test_size=1/6)\n",
    "\n",
    "x_train,x_val,y_train,y_val=train_test_split(x_train,y_train,test_size=.3)\n",
    "\n",
    "#Dimension of the kaggle dataset\n",
    "print((x_train.shape,y_train.shape))\n",
    "print((x_val.shape,y_val.shape))\n",
    "print((x_test.shape,y_test.shape))\n",
    "\n",
    "input_shape=x_train.shape[1:]\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image Data Augmentation\n",
    "\n",
    "train_generator = ImageDataGenerator(rotation_range=20, horizontal_flip=True, vertical_flip=True)\n",
    "\n",
    "val_generator = ImageDataGenerator(rotation_range=20, horizontal_flip=True, vertical_flip=True)\n",
    "\n",
    "train_generator.fit(x_train)\n",
    "val_generator.fit(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Learning Rate Annealer\n",
    "lrr = ReduceLROnPlateau(monitor='val_accuracy',\n",
    "                       factor=.1,\n",
    "                       patience=3,\n",
    "                       min_lr=1e-8,\n",
    "                       verbose=2)\n",
    "\n",
    "\n",
    "#Early stopping callback\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5, verbose=2,\n",
    "                                      mode='auto', baseline=None, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=\"5x5ConvX2-3x3ConvX2_512DenseWith0.2DropoutX2\"\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        \n",
    "        layers.Conv2D(64,kernel_size=(5,5),activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(64,kernel_size=(5,5),activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(pool_size=(2,2)),\n",
    "        \n",
    "        layers.Conv2D(64,kernel_size=(3,3),activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(64,kernel_size=(3,3),activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(pool_size=(2,2)),\n",
    "\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(1024,activation='relu'),\n",
    "        layers.Dropout(0.4),\n",
    "        layers.Dense(1024,activation='relu'),\n",
    "        layers.Dropout(0.4),\n",
    "\n",
    "        layers.Dense(1, activation='sigmoid')    \n",
    "    \n",
    "    ],name=name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 50\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=Adam(epsilon=1e-07, learning_rate=0.001), metrics=[\"accuracy\"])\n",
    "\n",
    "history=model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1,callbacks=[es, lrr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "input = tf.keras.Input(shape=input_shape)\n",
    "beforeModel = tf.keras.layers.UpSampling2D()(input)\n",
    "beforeModel = tf.keras.layers.UpSampling2D()(beforeModel)\n",
    "#beforeModel = tf.keras.layers.UpSampling2D()(beforeModel)\n",
    "print(beforeModel)\n",
    "resnet = tf.keras.applications.ResNet50(include_top=False,weights='imagenet',input_shape=(200,200,3))\n",
    "resnet.trainable=False\n",
    "\n",
    "x = resnet(beforeModel,training=False)\n",
    "x = keras.layers.Flatten()(x)\n",
    "\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(1024,\n",
    "                       kernel_regularizer=l2(0.001),\n",
    "                       bias_regularizer=l2(0.001),\n",
    "                       activation='relu')(x) # dense layer 1 \n",
    "'''\n",
    "x = keras.layers.Dropout(0.3)(x)\n",
    "\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(1024,\n",
    "                       activation='relu',\n",
    "                       kernel_regularizer=l2(0.001),\n",
    "                       bias_regularizer=l2(0.001))(x) # dense layer 2\n",
    "x = keras.layers.Dropout(0.2)(x) \n",
    "'''\n",
    "\n",
    "output = keras.layers.Dense(units=1, activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = keras.Model(inputs = input, outputs = output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=Adam(epsilon=0.1, learning_rate=0.001), metrics=[\"accuracy\"])\n",
    "log_dir= os.path.join('logs','ResNet50',datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"),'')\n",
    "\n",
    "# tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "history=model.fit(train_generator.flow(x_train, y_train),\n",
    "                  batch_size=batch_size, epochs=epochs,\n",
    "                  validation_data=val_generator.flow(x_val, y_val),\n",
    "                  callbacks=[es, lrr]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_gpu]",
   "language": "python",
   "name": "conda-env-tensorflow_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
