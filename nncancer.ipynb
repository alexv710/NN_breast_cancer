{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation\n",
    "Currently AI is advancing in the field of healthcare to improve detection of malignant tumors, give treatment recommendations, engage patients and support in administrative activities (Davenport and Kalakota 2019). Our goal is to contribute to this field by applying a neural network with transfer learning on a dataset with the aim to detect malignant cells of breast cancer. \n",
    "\n",
    "According to Krebsliga Schweiz (2021), there are 6’250 new cases and 1’410 deaths associated with breast cancer in Switzerland every year. Early diagnosis and treatment are a key to increasing the 5-year survival rate of patients.  \n",
    "\n",
    "From a technical standpoint we want to investigate the performance differences between neural networks with and without transfer learning in the field of tumor detection.\n",
    "\n",
    "## Data\n",
    "\n",
    "We use the Kaggle dataset: Breast Histopathology Images, which contains 277’524 images that are classified whether the sample is positive or negative for Invasive Ductal Carcinoma (IDC). Therefore, we face a binary classification problem with this dataset. The sample dataset contains images scanned at 40x zoom that are prepared in 50 x 50-pixel patches.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# For Image Data Augmentation\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "from tensorflow.keras.layers import Flatten,Dense,BatchNormalization,Activation,Dropout\n",
    "\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.9\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 3066200698734201097\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 11325525889116922010\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 9988323456\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 7027747020207288649\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 14191895077087359917\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "* Initialize the path to all the images\n",
    "* Create a dataframe with 3 collumns, which store the patient Id, the path to the picture and the picture itself\n",
    "* Crete the new file strucure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Patients total: 279\n",
      "Total Images in dataset:  277524\n"
     ]
    }
   ],
   "source": [
    "base_path = \"images/IDC_regular_ps50_idx5/\"\n",
    "folder = listdir(base_path)\n",
    "print(\"No. of Patients total:\",len(folder))\n",
    "\n",
    "total_images = 0\n",
    "for n in range(len(folder)):\n",
    "    patient_id = folder[n]\n",
    "    for c in [0, 1]:\n",
    "        patient_path = base_path + patient_id\n",
    "        class_path = patient_path + '/' + str(c) + '/'\n",
    "        subfiles = listdir(class_path)\n",
    "        total_images += len(subfiles)\n",
    "        \n",
    "print(\"Total Images in dataset: \", total_images )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a pandas data frame to store the patient Id, the path to every patch and the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>path</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10253</td>\n",
       "      <td>images/IDC_regular_ps50_idx5/10253/0/10253_idx...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10253</td>\n",
       "      <td>images/IDC_regular_ps50_idx5/10253/0/10253_idx...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10253</td>\n",
       "      <td>images/IDC_regular_ps50_idx5/10253/0/10253_idx...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10253</td>\n",
       "      <td>images/IDC_regular_ps50_idx5/10253/0/10253_idx...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10253</td>\n",
       "      <td>images/IDC_regular_ps50_idx5/10253/0/10253_idx...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  patient_id                                               path target\n",
       "0      10253  images/IDC_regular_ps50_idx5/10253/0/10253_idx...      0\n",
       "1      10253  images/IDC_regular_ps50_idx5/10253/0/10253_idx...      0\n",
       "2      10253  images/IDC_regular_ps50_idx5/10253/0/10253_idx...      0\n",
       "3      10253  images/IDC_regular_ps50_idx5/10253/0/10253_idx...      0\n",
       "4      10253  images/IDC_regular_ps50_idx5/10253/0/10253_idx...      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(index=np.arange(0, total_images), columns=[\"patient_id\", \"path\", \"target\"])\n",
    "\n",
    "k = 0\n",
    "for n in range(len(folder)):\n",
    "    patient_id = folder[n]\n",
    "    patient_path = base_path + patient_id \n",
    "    for c in [0,1]:\n",
    "        class_path = patient_path + \"/\" + str(c) + \"/\"\n",
    "        subfiles = listdir(class_path)\n",
    "        for m in range(len(subfiles)):\n",
    "            image_path = subfiles[m]\n",
    "            data.iloc[k][\"path\"] = class_path + image_path\n",
    "            data.iloc[k][\"target\"] = c\n",
    "            data.iloc[k][\"patient_id\"] = patient_id\n",
    "            k += 1  \n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_data shape:  (277524, 50, 50, 3)\n",
      "y_data shape:  (277524,)\n"
     ]
    }
   ],
   "source": [
    "X_data=[]\n",
    "y_data=[]\n",
    "for index, row in data[:].iterrows():\n",
    "    image = Image.open(row['path'])\n",
    "    npImage = np.asarray(image)\n",
    "    \n",
    "    # Resize images with format different than our 50x50 patches\n",
    "    if npImage.shape != (50, 50, 3):\n",
    "        image = image.resize((50, 50))\n",
    "        npImage = np.asarray(image)\n",
    "    X_data.append(npImage)\n",
    "    y_data.append(row['target'])\n",
    "    \n",
    "    \n",
    "print('X_data shape: ', np.array(X_data).shape)\n",
    "print('y_data shape: ', np.array(y_data).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((161889, 50, 50, 3), (161889,))\n",
      "((69381, 50, 50, 3), (69381,))\n",
      "((46254, 50, 50, 3), (46254,))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(50, 50, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train-validation-test split\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(np.asarray(X_data),np.asarray(y_data),test_size=1/6)\n",
    "\n",
    "x_train,x_val,y_train,y_val=train_test_split(x_train,y_train,test_size=.3)\n",
    "\n",
    "#Dimension of the kaggle dataset\n",
    "print((x_train.shape,y_train.shape))\n",
    "print((x_val.shape,y_val.shape))\n",
    "print((x_test.shape,y_test.shape))\n",
    "\n",
    "input_shape=x_train.shape[1:]\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image Data Augmentation\n",
    "\n",
    "train_generator = ImageDataGenerator(rotation_range=20, horizontal_flip=True, vertical_flip=True)\n",
    "\n",
    "val_generator = ImageDataGenerator(rotation_range=20, horizontal_flip=True, vertical_flip=True)\n",
    "\n",
    "train_generator.fit(x_train)\n",
    "val_generator.fit(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Learning Rate Annealer\n",
    "lrr = ReduceLROnPlateau(monitor='val_accuracy',\n",
    "                       factor=.1,\n",
    "                       patience=3,\n",
    "                       min_lr=1e-8,\n",
    "                       verbose=2)\n",
    "\n",
    "\n",
    "#Early stopping callback\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5, verbose=2,\n",
    "                                      mode='auto', baseline=None, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=\"5x5ConvX2-3x3ConvX2_512DenseWith0.2DropoutX2\"\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        \n",
    "        layers.Conv2D(64,kernel_size=(5,5),activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(64,kernel_size=(5,5),activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(pool_size=(2,2)),\n",
    "        \n",
    "        layers.Conv2D(64,kernel_size=(3,3),activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(64,kernel_size=(3,3),activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(pool_size=(2,2)),\n",
    "\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(1024,activation='relu'),\n",
    "        layers.Dropout(0.4),\n",
    "        layers.Dense(1024,activation='relu'),\n",
    "        layers.Dropout(0.4),\n",
    "\n",
    "        layers.Dense(1, activation='sigmoid')    \n",
    "    \n",
    "    ],name=name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"5x5ConvX2-3x3ConvX2_512DenseWith0.2DropoutX2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 46, 46, 64)        4864      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 46, 46, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 42, 42, 64)        102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 42, 42, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 21, 21, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 19, 19, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 19, 19, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 17, 17, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 17, 17, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              4195328   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 5,428,161\n",
      "Trainable params: 5,427,649\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "   1/1139 [..............................] - ETA: 0s - loss: 1.7037 - accuracy: 0.3672WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0099s vs `on_train_batch_end` time: 0.0160s). Check your callbacks.\n",
      "1139/1139 [==============================] - 29s 25ms/step - loss: 0.3921 - accuracy: 0.8414 - val_loss: 0.4829 - val_accuracy: 0.7831\n",
      "Epoch 2/50\n",
      "1139/1139 [==============================] - 28s 25ms/step - loss: 0.3430 - accuracy: 0.8573 - val_loss: 1.2053 - val_accuracy: 0.7414\n",
      "Epoch 3/50\n",
      "1139/1139 [==============================] - 28s 25ms/step - loss: 0.3282 - accuracy: 0.8634 - val_loss: 0.3942 - val_accuracy: 0.8388\n",
      "Epoch 4/50\n",
      "1139/1139 [==============================] - 28s 25ms/step - loss: 0.3172 - accuracy: 0.8684 - val_loss: 2.5420 - val_accuracy: 0.7314\n",
      "Epoch 5/50\n",
      "1139/1139 [==============================] - 28s 25ms/step - loss: 0.3115 - accuracy: 0.8711 - val_loss: 0.5026 - val_accuracy: 0.8143\n",
      "Epoch 6/50\n",
      "1139/1139 [==============================] - 28s 25ms/step - loss: 0.3042 - accuracy: 0.8738 - val_loss: 0.3133 - val_accuracy: 0.8727\n",
      "Epoch 7/50\n",
      "1139/1139 [==============================] - 28s 25ms/step - loss: 0.2958 - accuracy: 0.8772 - val_loss: 1.2316 - val_accuracy: 0.7676\n",
      "Epoch 8/50\n",
      "1139/1139 [==============================] - 28s 25ms/step - loss: 0.2877 - accuracy: 0.8799 - val_loss: 0.5397 - val_accuracy: 0.7687\n",
      "Epoch 9/50\n",
      "1137/1139 [============================>.] - ETA: 0s - loss: 0.2806 - accuracy: 0.8836 ETA: 0s - loss: 0.2808 - \n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "1139/1139 [==============================] - 28s 25ms/step - loss: 0.2807 - accuracy: 0.8835 - val_loss: 0.4500 - val_accuracy: 0.8049\n",
      "Epoch 10/50\n",
      "1139/1139 [==============================] - 28s 25ms/step - loss: 0.2432 - accuracy: 0.8971 - val_loss: 0.2828 - val_accuracy: 0.8849\n",
      "Epoch 11/50\n",
      "1139/1139 [==============================] - 28s 24ms/step - loss: 0.2281 - accuracy: 0.9021 - val_loss: 0.3008 - val_accuracy: 0.8771\n",
      "Epoch 12/50\n",
      "1139/1139 [==============================] - 28s 25ms/step - loss: 0.2179 - accuracy: 0.9078 - val_loss: 0.3109 - val_accuracy: 0.8771\n",
      "Epoch 13/50\n",
      "1139/1139 [==============================] - ETA: 0s - loss: 0.2073 - accuracy: 0.9119\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "1139/1139 [==============================] - 28s 25ms/step - loss: 0.2073 - accuracy: 0.9119 - val_loss: 0.3160 - val_accuracy: 0.8784\n",
      "Epoch 14/50\n",
      "1139/1139 [==============================] - 28s 25ms/step - loss: 0.1955 - accuracy: 0.9168 - val_loss: 0.3011 - val_accuracy: 0.8815\n",
      "Epoch 15/50\n",
      "1139/1139 [==============================] - ETA: 0s - loss: 0.1932 - accuracy: 0.9178Restoring model weights from the end of the best epoch.\n",
      "1139/1139 [==============================] - 30s 26ms/step - loss: 0.1932 - accuracy: 0.9178 - val_loss: 0.3031 - val_accuracy: 0.8820\n",
      "Epoch 00015: early stopping\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 50\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=Adam(epsilon=1e-07, learning_rate=0.001), metrics=[\"accuracy\"])\n",
    "\n",
    "history=model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1,callbacks=[es, lrr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"up_sampling2d_5/resize/ResizeNearestNeighbor:0\", shape=(None, 200, 200, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "input = tf.keras.Input(shape=input_shape)\n",
    "beforeModel = tf.keras.layers.UpSampling2D()(input)\n",
    "beforeModel = tf.keras.layers.UpSampling2D()(beforeModel)\n",
    "#beforeModel = tf.keras.layers.UpSampling2D()(beforeModel)\n",
    "print(beforeModel)\n",
    "resnet = tf.keras.applications.ResNet50(include_top=False,weights='imagenet',input_shape=(200,200,3))\n",
    "resnet.trainable=False\n",
    "\n",
    "x = resnet(beforeModel,training=False)\n",
    "x = keras.layers.Flatten()(x)\n",
    "\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(1024,\n",
    "                       kernel_regularizer=l2(0.001),\n",
    "                       bias_regularizer=l2(0.001),\n",
    "                       activation='relu')(x) # dense layer 1 \n",
    "'''\n",
    "x = keras.layers.Dropout(0.3)(x)\n",
    "\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(1024,\n",
    "                       activation='relu',\n",
    "                       kernel_regularizer=l2(0.001),\n",
    "                       bias_regularizer=l2(0.001))(x) # dense layer 2\n",
    "x = keras.layers.Dropout(0.2)(x) \n",
    "'''\n",
    "\n",
    "output = keras.layers.Dense(units=1, activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 50, 50, 3)]       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2 (None, 100, 100, 3)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2 (None, 200, 200, 3)       0         \n",
      "_________________________________________________________________\n",
      "resnet50 (Functional)        (None, 7, 7, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 100352)            401408    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              102761472 \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 126,751,617\n",
      "Trainable params: 102,963,201\n",
      "Non-trainable params: 23,788,416\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Model(inputs = input, outputs = output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5060/5060 [==============================] - 537s 106ms/step - loss: 2.2228 - accuracy: 0.8577 - val_loss: 2.0273 - val_accuracy: 0.8688\n",
      "Epoch 2/50\n",
      "5060/5060 [==============================] - 543s 107ms/step - loss: 1.8582 - accuracy: 0.8720 - val_loss: 1.7214 - val_accuracy: 0.8651\n",
      "Epoch 3/50\n",
      "5060/5060 [==============================] - 529s 105ms/step - loss: 1.5719 - accuracy: 0.8753 - val_loss: 1.4555 - val_accuracy: 0.8752\n",
      "Epoch 4/50\n",
      "5060/5060 [==============================] - 534s 106ms/step - loss: 1.3404 - accuracy: 0.8777 - val_loss: 1.2451 - val_accuracy: 0.8752\n",
      "Epoch 5/50\n",
      "5060/5060 [==============================] - 541s 107ms/step - loss: 1.1508 - accuracy: 0.8794 - val_loss: 1.0796 - val_accuracy: 0.8767\n",
      "Epoch 6/50\n",
      "5060/5060 [==============================] - 531s 105ms/step - loss: 0.9960 - accuracy: 0.8805 - val_loss: 0.9508 - val_accuracy: 0.8740\n",
      "Epoch 7/50\n",
      "5060/5060 [==============================] - 533s 105ms/step - loss: 0.8713 - accuracy: 0.8812 - val_loss: 0.8302 - val_accuracy: 0.8761\n",
      "Epoch 8/50\n",
      "5060/5060 [==============================] - 530s 105ms/step - loss: 0.7687 - accuracy: 0.8821 - val_loss: 0.7381 - val_accuracy: 0.8778\n",
      "Epoch 9/50\n",
      "5060/5060 [==============================] - 525s 104ms/step - loss: 0.6841 - accuracy: 0.8826 - val_loss: 0.6627 - val_accuracy: 0.8782\n",
      "Epoch 10/50\n",
      "5060/5060 [==============================] - 524s 104ms/step - loss: 0.6142 - accuracy: 0.8842 - val_loss: 0.6050 - val_accuracy: 0.8765\n",
      "Epoch 11/50\n",
      "5060/5060 [==============================] - 525s 104ms/step - loss: 0.5591 - accuracy: 0.8845 - val_loss: 0.5535 - val_accuracy: 0.8790\n",
      "Epoch 12/50\n",
      "5060/5060 [==============================] - 524s 104ms/step - loss: 0.5149 - accuracy: 0.8856 - val_loss: 0.5166 - val_accuracy: 0.8774\n",
      "Epoch 13/50\n",
      "5060/5060 [==============================] - 524s 104ms/step - loss: 0.4758 - accuracy: 0.8859 - val_loss: 0.4840 - val_accuracy: 0.8758\n",
      "Epoch 14/50\n",
      "5060/5060 [==============================] - ETA: 0s - loss: 0.4466 - accuracy: 0.8855\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "5060/5060 [==============================] - 524s 104ms/step - loss: 0.4466 - accuracy: 0.8855 - val_loss: 0.4513 - val_accuracy: 0.8778\n",
      "Epoch 15/50\n",
      "5060/5060 [==============================] - 525s 104ms/step - loss: 0.4196 - accuracy: 0.8915 - val_loss: 0.4416 - val_accuracy: 0.8804\n",
      "Epoch 16/50\n",
      "5060/5060 [==============================] - 525s 104ms/step - loss: 0.4121 - accuracy: 0.8934 - val_loss: 0.4385 - val_accuracy: 0.8815\n",
      "Epoch 17/50\n",
      "5060/5060 [==============================] - 524s 104ms/step - loss: 0.4066 - accuracy: 0.8941 - val_loss: 0.4379 - val_accuracy: 0.8814\n",
      "Epoch 18/50\n",
      "5060/5060 [==============================] - 525s 104ms/step - loss: 0.4022 - accuracy: 0.8952 - val_loss: 0.4363 - val_accuracy: 0.8826\n",
      "Epoch 19/50\n",
      "5060/5060 [==============================] - 525s 104ms/step - loss: 0.3981 - accuracy: 0.8951 - val_loss: 0.4303 - val_accuracy: 0.8828\n",
      "Epoch 20/50\n",
      "5060/5060 [==============================] - 524s 104ms/step - loss: 0.3934 - accuracy: 0.8965 - val_loss: 0.4295 - val_accuracy: 0.8826\n",
      "Epoch 21/50\n",
      "5060/5060 [==============================] - 524s 104ms/step - loss: 0.3898 - accuracy: 0.8969 - val_loss: 0.4252 - val_accuracy: 0.8822\n",
      "Epoch 22/50\n",
      "5060/5060 [==============================] - ETA: 0s - loss: 0.3862 - accuracy: 0.8967\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "5060/5060 [==============================] - 524s 104ms/step - loss: 0.3862 - accuracy: 0.8967 - val_loss: 0.4239 - val_accuracy: 0.8823\n",
      "Epoch 23/50\n",
      "5060/5060 [==============================] - 524s 104ms/step - loss: 0.3838 - accuracy: 0.8972 - val_loss: 0.4241 - val_accuracy: 0.8813\n",
      "Epoch 24/50\n",
      "5060/5060 [==============================] - 525s 104ms/step - loss: 0.3814 - accuracy: 0.8986 - val_loss: 0.4219 - val_accuracy: 0.8833\n",
      "Epoch 25/50\n",
      "5060/5060 [==============================] - 524s 104ms/step - loss: 0.3801 - accuracy: 0.8991 - val_loss: 0.4243 - val_accuracy: 0.8802\n",
      "Epoch 26/50\n",
      "5060/5060 [==============================] - 524s 104ms/step - loss: 0.3804 - accuracy: 0.8991 - val_loss: 0.4218 - val_accuracy: 0.8830\n",
      "Epoch 27/50\n",
      "5060/5060 [==============================] - ETA: 0s - loss: 0.3793 - accuracy: 0.9002\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "5060/5060 [==============================] - 524s 104ms/step - loss: 0.3793 - accuracy: 0.9002 - val_loss: 0.4215 - val_accuracy: 0.8825\n",
      "Epoch 28/50\n",
      "5060/5060 [==============================] - 524s 104ms/step - loss: 0.3788 - accuracy: 0.8996 - val_loss: 0.4219 - val_accuracy: 0.8830\n",
      "Epoch 29/50\n",
      "5060/5060 [==============================] - ETA: 0s - loss: 0.3786 - accuracy: 0.8996Restoring model weights from the end of the best epoch.\n",
      "5060/5060 [==============================] - 524s 104ms/step - loss: 0.3786 - accuracy: 0.8996 - val_loss: 0.4221 - val_accuracy: 0.8821\n",
      "Epoch 00029: early stopping\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=Adam(epsilon=0.1, learning_rate=0.001), metrics=[\"accuracy\"])\n",
    "log_dir= os.path.join('logs','ResNet50',datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"),'')\n",
    "\n",
    "# tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "history=model.fit(train_generator.flow(x_train, y_train),\n",
    "                  batch_size=batch_size, epochs=epochs,\n",
    "                  validation_data=val_generator.flow(x_val, y_val),\n",
    "                  callbacks=[es, lrr]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_gpu] *",
   "language": "python",
   "name": "conda-env-tensorflow_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
