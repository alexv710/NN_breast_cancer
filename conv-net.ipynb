{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pickle\n",
    "\n",
    "# used to access folder structures\n",
    "import os\n",
    "\n",
    "# used to open images\n",
    "import PIL\n",
    "\n",
    "# Graphs, visualizations\n",
    "import matplotlib.pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "import scipy\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.regularizers import l2\n",
    "# For Image Data Augmentation\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Flatten, Dense, BatchNormalization, Activation, Dropout\n",
    "from tensorflow.keras import layers\n",
    "from keras.optimizers import Adam, SGD\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data From Pickle file\n",
    "\n",
    "with open('y.pickle', 'rb') as f:\n",
    "    y_data = pickle.load(f)\n",
    "f.close()\n",
    "with open('X.pickle', 'rb') as f:\n",
    "    X_data = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train-validation-test split\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(\n",
    "    np.asarray(X_data),np.asarray(y_data),test_size=.3, random_state=42\n",
    ")\n",
    "\n",
    "input_shape=x_train.shape[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Learning Rate Annealer\n",
    "lrr = ReduceLROnPlateau(monitor='val_accuracy',\n",
    "                       factor=.1,\n",
    "                       patience=3,\n",
    "                       min_lr=1e-8,\n",
    "                       verbose=2)\n",
    "\n",
    "\n",
    "#Early stopping callback\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5, verbose=2,\n",
    "                                      mode='auto', baseline=None, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "131/342 [==========>...................] - ETA: 1:50 - loss: 0.8094 - accuracy: 0.6100"
     ]
    }
   ],
   "source": [
    "batch_size = 512\n",
    "epochs = 100\n",
    "\n",
    "\n",
    "name=\"5x5ConvX2-3x3ConvX2_512DenseWith0.2DropoutX2\"\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        \n",
    "        layers.Conv2D(64,kernel_size=(5,5),activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(64,kernel_size=(5,5),activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(pool_size=(2,2)),\n",
    "        \n",
    "        layers.Conv2D(64,kernel_size=(3,3),activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(64,kernel_size=(3,3),activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(pool_size=(2,2)),\n",
    "\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(1024,activation='relu'),\n",
    "        layers.Dropout(0.4),\n",
    "        layers.Dense(1024,activation='relu'),\n",
    "        layers.Dropout(0.4),\n",
    "\n",
    "        layers.Dense(1, activation='sigmoid')    \n",
    "    \n",
    "    ],name=name\n",
    ")\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=SGD(learning_rate=0.0001), metrics=[\"accuracy\"])\n",
    "\n",
    "history=model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.plot(history.history['loss'][1:])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_acc', 'test_acc', 'train_loss', 'test_loss'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnseminar",
   "language": "python",
   "name": "nnseminar"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
