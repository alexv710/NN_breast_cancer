{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation\n",
    "Currently AI is advancing in the field of healthcare to improve detection of malignant tumors, give treatment recommendations, engage patients and support in administrative activities (Davenport and Kalakota 2019). Our goal is to contribute to this field by applying a neural network with transfer learning on a dataset with the aim to detect malignant cells of breast cancer. \n",
    "\n",
    "According to Krebsliga Schweiz (2021), there are 6’250 new cases and 1’410 deaths associated with breast cancer in Switzerland every year. Early diagnosis and treatment are a key to increasing the 5-year survival rate of patients.  \n",
    "\n",
    "From a technical standpoint we want to investigate the performance differences between neural networks with and without transfer learning in the field of tumor detection.\n",
    "\n",
    "## Data\n",
    "\n",
    "We use the Kaggle dataset: Breast Histopathology Images, which contains 277’524 images that are classified whether the sample is positive or negative for Invasive Ductal Carcinoma (IDC). Therefore, we face a binary classification problem with this dataset. The sample dataset contains images scanned at 40x zoom that are prepared in 50 x 50-pixel patches.\n",
    "\n",
    "[Kaggle Dataset](https://www.kaggle.com/paultimothymooney/breast-histopathology-images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pickle\n",
    "\n",
    "# used to access folder structures\n",
    "import os\n",
    "\n",
    "# used to open images\n",
    "import PIL\n",
    "\n",
    "# Graphs, visualizations\n",
    "import matplotlib.pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "import scipy\n",
    "\n",
    "# import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.regularizers import l2\n",
    "# For Image Data Augmentation\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "# from tensorflow.keras.layers import Flatten, Dense, BatchNormalization, Activation, Dropout\n",
    "# from tensorflow.keras import layers\n",
    "from keras.optimizers import Adam, SGD\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for gpu support\n",
    "# Troubleshooting: \n",
    "# Python Version = 3.7.9\n",
    "# tensorflow Version = 2.3.0\n",
    "# tf.keras Version = 2.4.0\n",
    "\n",
    "# from platform import python_version\n",
    "# print(python_version())\n",
    "# print(tf.__version__)\n",
    "# print(tf.keras.__version__)\n",
    "\n",
    "# from tensorflow.python.client import device_lib\n",
    "# print(device_lib.list_local_devices())\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Data From Pickle file\n",
    "\n",
    "with open('y.pickle', 'rb') as f:\n",
    "    y_data = pickle.load(f)\n",
    "f.close()\n",
    "y_data\n",
    "\n",
    "with open('X.pickle', 'rb') as f:\n",
    "    X_data = pickle.load(f)\n",
    "f.close()\n",
    "type(X_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learnings\n",
    "* The data of positive and negative samples is unbalanced, where patients have more negative patches than positive ones\n",
    "* This could lead to an imbalanced result where we classify more patches as negative, which would be a severe mistake in cancer detection. A confusion matrix should be sufficient so verify this concern, when the model is trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((194266, 50, 50, 3), (194266,))\n",
      "((83258, 50, 50, 3), (83258,))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(50, 50, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train-validation-test split\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(np.asarray(X_data),np.asarray(y_data),test_size=.3, random_state=42)\n",
    "\n",
    "#x_train,x_val,y_train,y_val=train_test_split(x_train,y_train,test_size=.3)\n",
    "\n",
    "#Dimension of the kaggle dataset\n",
    "print((x_train.shape,y_train.shape))\n",
    "#print((x_val.shape,y_val.shape))\n",
    "print((x_test.shape,y_test.shape))\n",
    "\n",
    "input_shape=x_train.shape[1:]\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 200, 200, 3), dtype=tf.float32, name=None), name='up_sampling2d_1/resize/ResizeNearestNeighbor:0', description=\"created by layer 'up_sampling2d_1'\")\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94773248/94765736 [==============================] - 22s 0us/step\n"
     ]
    }
   ],
   "source": [
    "input_shape = (50, 50, 3)\n",
    "model_input = keras.Input(shape=input_shape)\n",
    "beforeModel = keras.layers.UpSampling2D()(model_input)\n",
    "\n",
    "# load pretrained resnet, don't train resnet\n",
    "print(beforeModel)\n",
    "resnet = keras.applications.ResNet50(include_top=False,weights='imagenet',input_shape=(200,200,3))\n",
    "resnet.trainable=False\n",
    "x = resnet(beforeModel,training=False)\n",
    "\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dense(1024,\n",
    "                       kernel_regularizer=l2(0.001),\n",
    "                       bias_regularizer=l2(0.001),\n",
    "                       activation='relu')(x) # dense layer 1 \n",
    "output = keras.layers.Dense(units=1, activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 50, 50, 3)]       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 100, 100, 3)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 200, 200, 3)       0         \n",
      "_________________________________________________________________\n",
      "resnet50 (Functional)        (None, 7, 7, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 100352)            401408    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              102761472 \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 126,751,617\n",
      "Trainable params: 102,963,201\n",
      "Non-trainable params: 23,788,416\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Model(inputs = model_input, outputs = output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=Adam(epsilon=0.1, learning_rate=0.001), metrics=[\"accuracy\"])\n",
    "log_dir= os.path.join('logs','ResNet50',datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"),'')\n",
    "\n",
    "# tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "history=model.fit(train_generator.flow(x_train, y_train),\n",
    "                  batch_size=batch_size, epochs=epochs,\n",
    "                  validation_data=val_generator.flow(x_val, y_val),\n",
    "                  callbacks=[es, lrr]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hope to improve the performance of the transfer learning model by adding more layers before and after the pretrained resnet.\n",
    "The intuition is that by adding layers we increase the capacity of the model to fit more complex functions. Besides that we add regularization layers like Dropout and BatchNormalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input = tf.keras.Input(shape=input_shape)\n",
    "beforeModel = tf.keras.layers.UpSampling2D()(model_input)\n",
    "beforeModel = tf.keras.layers.UpSampling2D()(beforeModel)\n",
    "beforeModel = tf.keras.layers.UpSampling2D()(beforeModel)\n",
    "print(beforeModel)\n",
    "resnet = tf.keras.applications.ResNet50(include_top=False,weights='imagenet',input_shape=(200,200,3))\n",
    "resnet.trainable=False\n",
    "x = resnet(beforeModel,training=False)\n",
    "\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(1024,\n",
    "                       kernel_regularizer=l2(0.001),\n",
    "                       bias_regularizer=l2(0.001),\n",
    "                       activation='relu')(x) # dense layer 1 \n",
    "\n",
    "x = keras.layers.Dropout(0.3)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(1024,\n",
    "                       activation='relu',\n",
    "                       kernel_regularizer=l2(0.001),\n",
    "                       bias_regularizer=l2(0.001))(x) # dense layer 2\n",
    "x = keras.layers.Dropout(0.2)(x) \n",
    "\n",
    "output = keras.layers.Dense(units=1, activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(inputs = model_input, outputs = output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=Adam(epsilon=0.1, learning_rate=0.001), metrics=[\"accuracy\"])\n",
    "log_dir= os.path.join('logs','ResNet50',datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"),'')\n",
    "\n",
    "# tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "history=model.fit(train_generator.flow(x_train, y_train),\n",
    "                  batch_size=batch_size, epochs=epochs,\n",
    "                  validation_data=val_generator.flow(x_val, y_val),\n",
    "                  callbacks=[es, lrr]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning: Experimenting with Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [0.1, 0.01, 0.0001]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
