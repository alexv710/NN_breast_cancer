{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation\n",
    "Currently AI is advancing in the field of healthcare to improve detection of malignant tumors, give treatment recommendations, engage patients and support in administrative activities (Davenport and Kalakota 2019). Our goal is to contribute to this field by applying a neural network with transfer learning on a dataset with the aim to detect malignant cells of breast cancer. \n",
    "\n",
    "According to Krebsliga Schweiz (2021), there are 6’250 new cases and 1’410 deaths associated with breast cancer in Switzerland every year. Early diagnosis and treatment are a key to increasing the 5-year survival rate of patients.  \n",
    "\n",
    "From a technical standpoint we want to investigate the performance differences between neural networks with and without transfer learning in the field of tumor detection.\n",
    "\n",
    "## Data\n",
    "\n",
    "We use the Kaggle dataset: Breast Histopathology Images, which contains 277’524 images that are classified whether the sample is positive or negative for Invasive Ductal Carcinoma (IDC). Therefore, we face a binary classification problem with this dataset. The sample dataset contains images scanned at 40x zoom that are prepared in 50 x 50-pixel patches.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# For Image Data Augmentation\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "from tensorflow.keras.layers import Flatten,Dense,BatchNormalization,Activation,Dropout\n",
    "\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.9\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 3066200698734201097\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 11325525889116922010\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 9988323456\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 7027747020207288649\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 14191895077087359917\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "* Initialize the path to all the images\n",
    "* Create a dataframe with 3 collumns, which store the patient Id, the path to the picture and the picture itself\n",
    "* Crete the new file strucure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Patients total: 279\n",
      "Total Images in dataset:  277524\n"
     ]
    }
   ],
   "source": [
    "base_path = \"images/IDC_regular_ps50_idx5/\"\n",
    "folder = listdir(base_path)\n",
    "print(\"No. of Patients total:\",len(folder))\n",
    "\n",
    "total_images = 0\n",
    "for n in range(len(folder)):\n",
    "    patient_id = folder[n]\n",
    "    for c in [0, 1]:\n",
    "        patient_path = base_path + patient_id\n",
    "        class_path = patient_path + '/' + str(c) + '/'\n",
    "        subfiles = listdir(class_path)\n",
    "        total_images += len(subfiles)\n",
    "        \n",
    "print(\"Total Images in dataset: \", total_images )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a pandas data frame to store the patient Id, the path to every patch and the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>path</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10253</td>\n",
       "      <td>images/IDC_regular_ps50_idx5/10253/0/10253_idx...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10253</td>\n",
       "      <td>images/IDC_regular_ps50_idx5/10253/0/10253_idx...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10253</td>\n",
       "      <td>images/IDC_regular_ps50_idx5/10253/0/10253_idx...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10253</td>\n",
       "      <td>images/IDC_regular_ps50_idx5/10253/0/10253_idx...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10253</td>\n",
       "      <td>images/IDC_regular_ps50_idx5/10253/0/10253_idx...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  patient_id                                               path target\n",
       "0      10253  images/IDC_regular_ps50_idx5/10253/0/10253_idx...      0\n",
       "1      10253  images/IDC_regular_ps50_idx5/10253/0/10253_idx...      0\n",
       "2      10253  images/IDC_regular_ps50_idx5/10253/0/10253_idx...      0\n",
       "3      10253  images/IDC_regular_ps50_idx5/10253/0/10253_idx...      0\n",
       "4      10253  images/IDC_regular_ps50_idx5/10253/0/10253_idx...      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(index=np.arange(0, total_images), columns=[\"patient_id\", \"path\", \"target\"])\n",
    "\n",
    "k = 0\n",
    "for n in range(len(folder)):\n",
    "    patient_id = folder[n]\n",
    "    patient_path = base_path + patient_id \n",
    "    for c in [0,1]:\n",
    "        class_path = patient_path + \"/\" + str(c) + \"/\"\n",
    "        subfiles = listdir(class_path)\n",
    "        for m in range(len(subfiles)):\n",
    "            image_path = subfiles[m]\n",
    "            data.iloc[k][\"path\"] = class_path + image_path\n",
    "            data.iloc[k][\"target\"] = c\n",
    "            data.iloc[k][\"patient_id\"] = patient_id\n",
    "            k += 1  \n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_data shape:  (277524, 50, 50, 3)\n",
      "y_data shape:  (277524,)\n"
     ]
    }
   ],
   "source": [
    "X_data=[]\n",
    "y_data=[]\n",
    "for index, row in data[:].iterrows():\n",
    "    image = Image.open(row['path'])\n",
    "    npImage = np.asarray(image)\n",
    "    \n",
    "    # Resize images with format different than our 50x50 patches\n",
    "    if npImage.shape != (50, 50, 3):\n",
    "        image = image.resize((50, 50))\n",
    "        npImage = np.asarray(image)\n",
    "    X_data.append(npImage)\n",
    "    y_data.append(row['target'])\n",
    "    \n",
    "    \n",
    "print('X_data shape: ', np.array(X_data).shape)\n",
    "print('y_data shape: ', np.array(y_data).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((161889, 50, 50, 3), (161889,))\n",
      "((69381, 50, 50, 3), (69381,))\n",
      "((46254, 50, 50, 3), (46254,))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(50, 50, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train-validation-test split\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(np.asarray(X_data),np.asarray(y_data),test_size=1/6)\n",
    "\n",
    "x_train,x_val,y_train,y_val=train_test_split(x_train,y_train,test_size=.3)\n",
    "\n",
    "#Dimension of the kaggle dataset\n",
    "print((x_train.shape,y_train.shape))\n",
    "print((x_val.shape,y_val.shape))\n",
    "print((x_test.shape,y_test.shape))\n",
    "\n",
    "input_shape=x_train.shape[1:]\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image Data Augmentation\n",
    "\n",
    "train_generator = ImageDataGenerator(rotation_range=20, horizontal_flip=True, vertical_flip=True)\n",
    "\n",
    "val_generator = ImageDataGenerator(rotation_range=20, horizontal_flip=True, vertical_flip=True)\n",
    "\n",
    "train_generator.fit(x_train)\n",
    "val_generator.fit(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Learning Rate Annealer\n",
    "lrr = ReduceLROnPlateau(monitor='val_accuracy',\n",
    "                       factor=.1,\n",
    "                       patience=3,\n",
    "                       min_lr=1e-8,\n",
    "                       verbose=1)\n",
    "\n",
    "\n",
    "#Early stopping callback\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5, verbose=1,\n",
    "                                      mode='auto', baseline=None, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=\"5x5ConvX2-3x3ConvX2_512DenseWith0.2DropoutX2\"\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        \n",
    "        layers.Conv2D(64,kernel_size=(5,5),activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(64,kernel_size=(5,5),activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(pool_size=(2,2)),\n",
    "        \n",
    "        layers.Conv2D(64,kernel_size=(3,3),activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(64,kernel_size=(3,3),activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(pool_size=(2,2)),\n",
    "\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(1024,activation='relu'),\n",
    "        layers.Dropout(0.4),\n",
    "        layers.Dense(1024,activation='relu'),\n",
    "        layers.Dropout(0.4),\n",
    "\n",
    "        layers.Dense(1, activation='sigmoid')    \n",
    "    \n",
    "    ],name=name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"5x5ConvX2-3x3ConvX2_512DenseWith0.2DropoutX2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 46, 46, 64)        4864      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 46, 46, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 42, 42, 64)        102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 42, 42, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 21, 21, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 19, 19, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 19, 19, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 17, 17, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 17, 17, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              4195328   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 5,428,161\n",
      "Trainable params: 5,427,649\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "   1/1139 [..............................] - ETA: 0s - loss: 1.7037 - accuracy: 0.3672WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0099s vs `on_train_batch_end` time: 0.0160s). Check your callbacks.\n",
      "1139/1139 [==============================] - 29s 25ms/step - loss: 0.3921 - accuracy: 0.8414 - val_loss: 0.4829 - val_accuracy: 0.7831\n",
      "Epoch 2/50\n",
      " 560/1139 [=============>................] - ETA: 13s - loss: 0.3524 - accuracy: 0.8540"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 50\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=Adam(epsilon=1e-07, learning_rate=0.001), metrics=[\"accuracy\"])\n",
    "\n",
    "history=model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1,callbacks=[es, lrr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "input = tf.keras.Input(shape=input_shape)\n",
    "beforeModel = tf.keras.layers.UpSampling2D()(input)\n",
    "beforeModel = tf.keras.layers.UpSampling2D()(beforeModel)\n",
    "beforeModel = tf.keras.layers.Reshape((224,224), input_shape(200, 200))\n",
    "#beforeModel = tf.keras.layers.UpSampling2D()(beforeModel)\n",
    "print(beforeModel)\n",
    "resnet = tf.keras.applications.ResNet50(include_top=False,weights='imagenet',input_shape=(224,224,3))\n",
    "resnet.trainable=False\n",
    "\n",
    "x = resnet(beforeModel,training=False)\n",
    "x = keras.layers.Flatten()(x)\n",
    "\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(1024,\n",
    "                       kernel_regularizer=l2(0.001),\n",
    "                       bias_regularizer=l2(0.001),\n",
    "                       activation='relu')(x) # dense layer 1 \n",
    "'''\n",
    "x = keras.layers.Dropout(0.3)(x)\n",
    "\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(1024,\n",
    "                       activation='relu',\n",
    "                       kernel_regularizer=l2(0.001),\n",
    "                       bias_regularizer=l2(0.001))(x) # dense layer 2\n",
    "x = keras.layers.Dropout(0.2)(x) \n",
    "'''\n",
    "\n",
    "output = keras.layers.Dense(units=1, activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(inputs = input, outputs = output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=Adam(epsilon=0.1, learning_rate=0.001), metrics=[\"accuracy\"])\n",
    "log_dir= os.path.join('logs','ResNet50',datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"),'')\n",
    "\n",
    "# tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "history=model.fit(train_generator.flow(x_train, y_train),\n",
    "                  batch_size=batch_size, epochs=epochs,\n",
    "                  validation_data=val_generator.flow(x_val, y_val),\n",
    "                  callbacks=[es, lrr]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_gpu] *",
   "language": "python",
   "name": "conda-env-tensorflow_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
